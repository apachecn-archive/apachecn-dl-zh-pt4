# 零、前言

PyTorch 因其灵活性和易用性吸引了数据科学专业人士和深度学习从业者的注意。这本书介绍了深度学习和 PyTorch 的基本构建模块。它展示了如何使用实用的方法解决现实世界的问题。您还将学习一些现代架构和技术，用于解决一些前沿研究问题。

这本书提供了各种先进的深度学习架构背后的直觉，如 ResNet、DenseNet、Inception 和 Seq2Seq，而没有深入数学。它还展示了如何进行迁移学习，如何使用预先计算的特征加速迁移学习，以及如何使用嵌入、预训练嵌入、LSTM 和一维卷积进行文本分类。

到本书结束时，你将成为一名熟练的深度学习实践者，能够使用这里学到的不同技术解决一些业务问题。

# 这本书是给谁的

这本书面向对深度学习感兴趣的工程师、数据分析师和数据科学家，以及那些希望用 PyTorch 探索和实现高级算法的人。机器学习的知识是有帮助的，但不是强制性的。Python 编程知识是预期的。

# 这本书涵盖的内容

[第 1 章](1.html)，*使用 PyTorch* 开始深度学习，回顾了**人工智能** ( **AI** )和机器学习的历史，并展望了深度学习的最新发展。我们还将讨论硬件和算法的各种改进如何在不同应用程序中实现深度学习的巨大成功。最后，我们将介绍漂亮的 PyTorch Python 库，它是由脸书在 Torch 之上构建的。

[第二章](2.html)、*神经网络的构建模块*，讨论 PyTorch 的各种构建模块的知识，如变量、张量、`nn.module`，以及如何使用它们开发神经网络。

[第 3 章](2.html)，*深入研究神经网络*，涵盖训练神经网络所涉及的不同过程，例如数据准备、批量张量的数据加载器、用于创建网络架构的`torch.nn`包以及 PyTorch 损失函数和优化器的使用。

[第 4 章](3.html)，*机器学习的基础*，涵盖了不同类型的机器学习问题，以及过拟合和欠拟合等挑战。我们还介绍了不同的技术，如数据扩充、添加漏失以及使用批量标准化来防止过度拟合。

[第五章](4.html)，*计算机视觉的深度学习*，讲解了**卷积神经网络**(**CNN**)的构建模块，比如一维和二维卷积，最大池化，平均池化，基本 CNN 架构，迁移学习，使用预卷积特征训练更快。

[第 6 章](5.html)、*使用序列数据和文本的深度学习*，涵盖了词嵌入、如何使用预训练嵌入、RNN、LSTM 和一维卷积在`IMDB`数据集上进行文本分类。

[第七章](6.html)，*生成网络*，讲解如何使用深度学习生成艺术图像，使用 DCGAN 生成新图像，使用语言建模生成文本。

[第 8 章](7.html)，*现代网络架构*，探讨了为现代计算机视觉应用提供动力的 ResNet、Inception 和 DenseNet 等架构。我们将快速介绍支持语言翻译和图像字幕等现代系统的编码器-解码器架构。

[第九章](8.html)，*接下来呢？*，查看总结我们所学的内容，并查看让自己在深度学习领域保持更新。

# 从这本书中获得最大收益

所有章节(除了[第 1 章](1.html)、*使用 PyTorch 进行深度学习入门*和[第 9 章](8.html)、*下一步做什么*)都在本书的 GitHub 资源库中有关联的 Jupyter 笔记本。为了节省空间，文本中可能不包含代码运行所需的导入。你应该能够运行笔记本上的所有代码。

这本书侧重于实用的插图，所以当你阅读章节时，请运行 Jupyter 笔记本。

访问带有 GPU 的计算机将有助于快速运行代码。有一些公司，如[paperspace.com](https://www.paperspace.com/)和[www.crestle.com](https://www.crestle.com/)抽象了运行深度学习算法所需的大量复杂性。

# 下载示例代码文件

你可以从你在 www.packtpub.com[的账户](http://www.packtpub.com)下载本书的示例代码文件。如果你在别处购买了这本书，你可以访问 www.packtpub.com/support 并注册，让文件直接通过电子邮件发送给你。

您可以按照以下步骤下载代码文件:

1.  在[www.packtpub.com](http://www.packtpub.com/support)登录或注册。
2.  选择支持选项卡。
3.  点击代码下载和勘误表。
4.  在搜索框中输入图书名称，然后按照屏幕指示进行操作。

下载文件后，请确保使用最新版本的解压缩或解压文件夹:

*   WinRAR/7-Zip for Windows
*   适用于 Mac 的 Zipeg/iZip/UnRarX
*   用于 Linux 的 7-Zip/PeaZip

这本书的代码包也托管在 GitHub 的 https://GitHub . com/packt publishing/Deep-Learning-with-py torch 上。如果代码有更新，它将在现有的 GitHub 库中更新。

我们在 https://github.com/PacktPublishing/也有丰富的书籍和视频目录中的其他代码包。看看他们！

# 下载彩色图像

我们还提供了一个 PDF 文件，其中有本书中使用的截图/图表的彩色图像。可以在这里下载:[https://www . packtpub . com/sites/default/files/downloads/deeplearningwithpythorch _ color images . pdf](https://www.packtpub.com/sites/default/files/downloads/DeepLearningwithPyTorch_ColorImages.pdf)

# 使用的惯例

本书通篇使用了许多文本约定。

`CodeInText`:表示文本中的码字、数据库表名、文件夹名、文件名、文件扩展名、路径名、伪 URL、用户输入和 Twitter 句柄。这里有一个例子:“自定义类要实现两个主要函数，即`__len__(self)`和`__getitem__(self, idx)`”

代码块设置如下:

```
x,y = get_data() # x - represents training data,y -                 represents target variables

w,b = get_weights() # w,b - Learnable parameters

for i in range(500):
    y_pred = simple_network(x) # function which computes wx + b
    loss = loss_fn(y,y_pred) # calculates sum of the squared differences of y and y_pred

if i % 50 == 0: 
        print(loss)
    optimize(learning_rate) # Adjust w,b to minimize the loss
```

任何命令行输入或输出都按如下方式编写:

```
conda install pytorch torchvision cuda80 -c soumith
```

**粗体**:表示一个新术语、一个重要单词或您在屏幕上看到的单词。

警告或重要提示如下所示。

提示和技巧是这样出现的。

# 取得联系

我们随时欢迎读者的反馈。

**总体反馈**:发送电子邮件`feedback@packtpub.com`，在邮件主题中提及书名。如果您对本书的任何方面有疑问，请发邮件至`questions@packtpub.com`联系我们。

**勘误表**:虽然我们已经尽力确保内容的准确性，但错误还是会发生。如果你在这本书里发现了一个错误，请告诉我们，我们将不胜感激。请访问[www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata)，选择您的图书，点击勘误表提交表格链接，并输入详细信息。

盗版:如果您在互联网上遇到任何形式的我们作品的非法拷贝，如果您能提供我们的地址或网站名称，我们将不胜感激。请通过`copyright@packtpub.com`联系我们，并提供材料链接。

**如果你有兴趣成为一名作家**:如果有一个你擅长的主题，并且你有兴趣写书或投稿，请访问[authors.packtpub.com](http://authors.packtpub.com/)。

# 复习

请留下评论。一旦你阅读并使用了这本书，为什么不在你购买它的网站上留下评论呢？潜在的读者可以看到并使用您不带偏见的意见来做出购买决定，我们 Packt 可以了解您对我们产品的看法，我们的作者可以看到您对他们的书的反馈。谢谢大家！

更多关于 Packt 的信息，请访问[packtpub.com](https://www.packtpub.com/)。