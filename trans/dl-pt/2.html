<html xmlns:epub="http://www.idpf.org/2007/ops" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pls="http://www.w3.org/2005/01/pronunciation-lexicon" xmlns:ssml="http://www.w3.org/2001/10/synthesis">
<head>
  <meta charset="UTF-8"/>
  <title>Building Blocks of Neural Networks</title>
  
  
</head>
<body>
  <div><h1 class="header-title">神经网络的构建模块</h1>
                
            
            
                
<p class="mce-root">理解神经网络的基本构建块，如张量、张量运算和梯度下降，对于构建复杂的神经网络非常重要。在本章中，我们将通过涵盖以下主题来构建我们在神经网络中的第一个<kbd>Hello world</kbd>程序:</p>
<ul>
<li class="mce-root">安装PyTorch</li>
<li class="mce-root">实现我们的第一个神经网络</li>
<li class="mce-root">将神经网络分割成功能块</li>
<li class="mce-root">浏览每个基本块，包括张量、变量、自动签名、梯度和优化器</li>
<li class="mce-root">使用PyTorch加载数据</li>
</ul>


            

            
        
    </div>


  <div><h1 class="header-title">安装PyTorch</h1>
                
            
            
                
<p>PyTorch以Python包的形式提供，你可以使用<kbd>pip</kbd>或<kbd>conda</kbd>来构建它，也可以从源代码构建它。本书推荐的方法是使用Anaconda Python 3发行版。要安装Anaconda，请参考位于<a href="https://conda.io/docs/user-guide/install/index.html" target="_blank">https://conda.io/docs/user-guide/install/index.html</a>的Anaconda官方文档。所有的例子都可以在本书的GitHub库中以Jupyter笔记本的形式获得。我强烈建议你使用Jupyter Notebook，因为它允许你进行交互式实验。如果您已经安装了Anaconda Python，那么您可以继续执行下面的PyTorch安装步骤。</p>
<p>对于基于GPU的Cuda 8安装:</p>
<pre><strong>conda install pytorch torchvision cuda80 -c soumith</strong></pre>
<p>对于基于GPU的Cuda 7.5安装:</p>
<pre><strong>conda install pytorch torchvision -c soumith</strong></pre>
<p>对于非基于GPU的安装:</p>
<pre><strong>conda install pytorch torchvision -c soumith</strong></pre>
<p>在撰写本文时，PyTorch无法在Windows机器上运行，因此您可以尝试一个<strong>虚拟机</strong> ( <strong> VM </strong>)或Docker映像。</p>


            

            
        
    </div>


  <div><h1 class="header-title">我们的第一个神经网络</h1>
                
            
            
                
<p>我们提出了我们的第一个神经网络，它学习如何将训练样本(输入数组)映射到目标(输出数组)。让我们假设我们为最大的在线公司之一，<strong> Wondermovies，</strong>提供视频点播服务。我们的训练数据集包含一个表示用户在该平台上观看电影的平均时间的功能，我们希望预测每个用户在未来一周内在该平台上花费的时间。只是一个假想的用例，不要想太多。构建这种解决方案的一些高级活动如下:</p>
<ul>
<li><strong>数据准备</strong>:函数<kbd>get_data</kbd>准备包含输入和输出数据的张量(数组)</li>
<li><strong>创建可学习的</strong> <strong>参数</strong>:<kbd>get_weights</kbd>函数为我们提供了包含随机值的张量，我们将优化这些张量来解决我们的问题</li>
<li><strong>网络模型</strong>:<kbd>simple_network</kbd>函数产生输入数据的输出，应用线性规则，将权重与输入数据相乘，并添加偏差项(<em> y = Wx+b </em>)</li>
<li><strong>损失</strong>:<kbd>loss_fn</kbd>函数提供了关于模型有多好的信息</li>
<li><strong>优化器</strong>:<kbd>optimize</kbd>函数帮助我们调整最初创建的随机权重，以帮助模型更精确地计算目标值</li>
</ul>
<p>如果你是机器学习的新手，不要担心，因为我们会在本章结束时准确理解每个函数的作用。下面的函数抽象出PyTorch代码，使我们更容易理解。我们将深入探讨每一项功能的细节。前述高级活动对于大多数机器学习和深度学习问题来说是常见的。本书后面的章节讨论了可以用来改进每个功能以构建有用的应用程序的技术。</p>
<p>让我们考虑以下神经网络的线性回归方程:</p>
<p style="padding-left: 180px"><img height="19" width="80" class="fm-editor-equation" src="img/c152c855-4352-491c-8602-80be5cd3c4d3.png"/></p>
<p>让我们用PyTorch编写第一个神经网络:</p>
<pre>x,y = get_data() # x - represents training data,y -                 represents target variables<br/><br/>w,b = get_weights() # w,b - Learnable parameters<br/><br/>for i in range(500):<br/>    y_pred = simple_network(x) # function which computes wx + b<br/>    loss = loss_fn(y,y_pred) # calculates sum of the squared differences of y and y_pred<br/>    <br/>if i % 50 == 0: <br/>        print(loss)<br/>    optimize(learning_rate) # Adjust w,b to minimize the loss</pre>
<p>在本章结束时，你将对每个函数内部发生的事情有一个概念。</p>


            

            
        
    </div>


  <div><h1 class="header-title">数据准备</h1>
                
            
            
                
<p>PyTorch提供了两种数据抽象，称为<kbd>tensors</kbd>和<kbd>variables</kbd>。张量类似于<kbd>numpy</kbd>阵列，它们也可以用在GPU上，从而提高性能。它们提供了在GPU和CPU之间切换的简单方法。对于某些操作，我们可以注意到性能的提升，机器学习算法可以理解不同形式的数据，只有当数据表示为数字的张量时。张量就像Python数组，大小可以改变。例如，图像可以表示为三维数组(高度、重量、通道(RGB))。深度学习中使用大小高达五维的张量是很常见的。一些常用的张量如下:</p>
<ul>
<li>标量(零维张量)</li>
<li>向量(一维张量)</li>
<li>矩阵(二维张量)</li>
<li>三维张量</li>
<li>切片张量</li>
<li>四维张量</li>
<li>五维张量</li>
<li>GPU上的张量</li>
</ul>


            

            
        
    </div>


  <div><h1 class="header-title">标量(零维张量)</h1>
                
            
            
                
<p>只包含一个元素的张量叫做标量。它通常属于<kbd>FloatTensor</kbd>或<kbd>LongTensor</kbd>类型。在写这篇文章的时候，PyTorch还没有一个特殊的零维张量。因此，我们使用一个元素的一维张量，如下所示:</p>
<pre>x = torch.rand(10)<br/>x.size()<br/><br/>Output - torch.Size([10])</pre>


            

            
        
    </div>


  <div><h1 class="header-title">向量(一维张量)</h1>
                
            
            
                
<p>一个<kbd>vector</kbd>只是一个元素数组。例如，我们可以使用一个向量来存储上周的平均温度:</p>
<pre>temp = torch.FloatTensor([23,24,24.5,26,27.2,23.0])<br/>temp.size()<br/><br/>Output - torch.Size([6])</pre>


            

            
        
    </div>


  <div><h1 class="header-title">矩阵(二维张量)</h1>
                
            
            
                
<p>大多数结构化数据以表格或矩阵的形式表示。我们将使用一个名为<kbd>Boston House Prices</kbd>的数据集，它在Python scikit-learn机器学习库中很容易获得。数据集是一个由<kbd>506</kbd>样本或行和代表每个样本的<kbd>13</kbd>特征组成的<kbd>numpy</kbd>数组。Torch提供了一个名为<kbd>from_numpy()</kbd>的实用函数，它将一个<kbd>numpy</kbd>数组转换成一个<kbd>torch</kbd>张量。得到的张量的形状是<kbd>506</kbd>行x <kbd>13</kbd>列:</p>
<pre>boston_tensor = torch.from_numpy(boston.data)<br/>boston_tensor.size()<br/><br/>Output: torch.Size([506, 13])<br/><br/>boston_tensor[:2]<br/><br/>Output:<br/>Columns 0 to 7 <br/>   0.0063 18.0000 2.3100 0.0000 0.5380 6.5750 65.2000 4.0900<br/>   0.0273 0.0000 7.0700 0.0000 0.4690 6.4210 78.9000 4.9671<br/><br/>Columns 8 to 12 <br/>   1.0000 296.0000 15.3000 396.9000 4.9800<br/>   2.0000 242.0000 17.8000 396.9000 9.1400<br/>[torch.DoubleTensor of size 2x13]</pre>


            

            
        
    </div>


  <div><h1 class="header-title">三维张量</h1>
                
            
            
                
<p>当我们把多个矩阵加在一起，我们得到一个三维张量。三维张量用于表示类似数据的图像。图像可以表示为矩阵中的数字，这些数字堆叠在一起。图像形状的一个例子是<kbd>224</kbd>、<kbd>224</kbd>、<kbd>3</kbd>，其中第一个索引代表高度，第二个代表宽度，第三个代表通道(RGB)。使用下面的代码片段，让我们看看计算机是如何看到熊猫的:</p>
<pre>from PIL import Image<br/># Read a panda image from disk using a library called PIL and convert it to numpy array<br/>panda = np.array(Image.open('panda.jpg').resize((224,224)))<br/>panda_tensor = torch.from_numpy(panda)<br/>panda_tensor.size()<br/><br/>Output - torch.Size([224, 224, 3])<br/>#Display panda<br/>plt.imshow(panda)<br/><br/></pre>
<p>由于显示大小为<kbd>224</kbd>、<kbd>224</kbd>、<kbd>3</kbd>的张量将占据书中的几页，我们将显示图像，并学习将图像分割成更小的张量以使其可视化:</p>
<div><img src="img/b5de7e6a-4c8a-4aed-91da-5d4180b3f9f3.png"/></div>
<p>显示图像</p>


            

            
        
    </div>


  <div><h1 class="header-title">切片张量</h1>
                
            
            
                
<p>处理张量的一个常见方法是切掉它的一部分。一个简单的例子是选择一维张量的前五个元素；姑且称之为张量<kbd>sales</kbd>。我们使用一个简单的符号，<kbd>sales[:slice_index]</kbd>,其中<kbd>slice_index</kbd>代表你想要切片张量的索引:</p>
<pre>sales = torch.FloatTensor([1000.0,323.2,333.4,444.5,1000.0,323.2,333.4,444.5])<br/><br/>sales[:5]<br/> 1000.0000<br/>  323.2000<br/>  333.4000<br/>  444.5000<br/> 1000.0000<br/>[torch.FloatTensor of size 5]<br/><br/>sales[:-5]<br/> 1000.0000<br/>  323.2000<br/>  333.4000<br/>[torch.FloatTensor of size 3]<br/><br/></pre>
<p>让我们用我们的熊猫图像做更多有趣的事情，比如看看当只选择一个通道时熊猫图像是什么样子，看看如何选择熊猫的脸。</p>
<p>这里，我们仅从熊猫图像中选择一个通道:</p>
<pre>plt.imshow(panda_tensor[:,:,0].numpy())<br/>#0 represents the first channel of RGB</pre>
<p>输出如下所示:</p>
<div><img height="233" width="249" src="img/21adcb3c-80af-424f-9cc0-16258a64e071.png"/></div>
<p>现在，让我们裁剪图像。假设我们想为熊猫制作一个人脸检测器，我们只需要一张熊猫的脸。我们裁剪张量图像，使其仅包含熊猫的面部:</p>
<pre class="mce-root">plt.imshow(panda_tensor[25:175,60:130,0].numpy())</pre>
<p class="mce-root">输出如下所示:</p>
<div><img height="256" width="146" class="alignnone size-full wp-image-690 image-border" src="img/47dea173-616d-4538-89fd-c376e409ff73.png"/></div>
<p>另一个常见的例子是，你需要选择一个张量的特定元素:</p>
<pre>#torch.eye(shape) produces an diagonal matrix with 1 as it diagonal #elements.<br/>sales = torch.eye(3,3)<br/>sales[0,1]<br/><br/>Output- 0.00.0</pre>
<p>当我们讨论使用CNN构建图像分类器时，我们将在<a href="4.html" target="_blank">第5章</a>、<em>用于计算机视觉的深度学习、</em>中重温图像数据。</p>
<p>大多数PyTorch张量运算与<kbd>NumPy</kbd>运算非常相似。</p>


            

            
        
    </div>


  <div><h1 class="header-title">四维张量</h1>
                
            
            
                
<p>四维张量类型的一个常见示例是一批图像。现代的CPU和GPU经过优化，可以更快地对多个实例执行相同的操作。因此，它们处理一幅图像或一批图像需要相似的时间。因此，通常使用一批例子，而不是一次使用一个图像。选择批量大小并不简单；这取决于几个因素。使用更大批量或完整数据集的一个主要限制是GPU内存限制— <em> 16 </em>、<em> 32 </em>和<em> 64 </em>是常用的批量大小。</p>
<p>让我们看一个例子，其中我们加载一批大小为<kbd>64</kbd> x <kbd>224</kbd> x <kbd>224</kbd> x <kbd>3</kbd>的cat图像，其中<em> 64 </em>表示图像的批大小或数量，<em> 244 </em>表示高度和宽度，<em> 3 </em>表示通道:</p>
<pre>#Read cat images from disk<br/>cats = glob(data_path+'*.jpg')<br/>#Convert images into numpy arrays<br/>cat_imgs = np.array([np.array(Image.open(cat).resize((224,224))) for cat in cats[:64]]) <br/>cat_imgs = cat_imgs.reshape(-1,224,224,3)<br/>cat_tensors = torch.from_numpy(cat_imgs)<br/>cat_tensors.size()<br/><br/>Output - torch.Size([64, 224, 224, 3])</pre>


            

            
        
    </div>


  <div><h1 class="header-title">五维张量</h1>
                
            
            
                
<p>一个可能必须使用五维张量的常见例子是视频数据。视频可以分割成帧，例如，包含熊猫玩球的30秒视频可能包含30帧，这可以表示为形状张量(1 x 30 x 224 x 224 x 3)。一批这样的视频可以表示为形状张量(32×30×224×224×3)——<em>30</em>在示例中表示单个视频片段中的帧数，其中<em> 32 </em>表示这样的视频片段的数量。</p>


            

            
        
    </div>


  <div><h1 class="header-title">GPU上的张量</h1>
                
            
            
                
<p>我们已经学会了如何用张量表示来表示不同形式的数据。一旦我们有了张量形式的数据，我们执行的一些常见操作是加法、减法、乘法、点积和矩阵乘法。所有这些操作都可以在CPU或GPU上执行。PyTorch提供了一个名为<kbd>cuda()</kbd>的简单函数，将CPU上的一个张量复制到GPU上。我们将了解一些运算，并比较CPU和GPU上矩阵乘法运算的性能。</p>
<p>张量加法可以通过使用以下代码获得:</p>
<pre>#Various ways you can perform tensor addition<br/>a = torch.rand(2,2) <br/>b = torch.rand(2,2)<br/>c = a + b<br/>d = torch.add(a,b)<br/>#For in-place addition<br/>a.add_(5)<br/><br/>#Multiplication of different tensors<br/><br/>a*b<br/>a.mul(b)<br/>#For in-place multiplication<br/>a.mul_(b)</pre>
<p>对于张量矩阵乘法，让我们比较代码在CPU和GPU上的性能。任何张量都可以通过调用<kbd>.cuda()</kbd>函数移动到GPU。</p>
<p>GPU上的乘法运行如下:</p>
<pre>a = torch.rand(10000,10000)<br/>b = torch.rand(10000,10000)<br/><br/>a.matmul(b)<br/><br/>Time taken: 3.23 s<br/><br/>#Move the tensors to GPU<br/>a = a.cuda()<br/>b = b.cuda()<br/><br/>a.matmul(b)<br/><br/>Time taken: 11.2 µs</pre>
<p>这些加法、减法和矩阵乘法的基本运算可以用来构建复杂的运算，比如一个<strong>卷积神经网络</strong> ( <strong> CNN </strong>)和一个<strong>递归神经网络</strong> ( <strong> RNN </strong>)，我们将在本书后面的章节中了解到。</p>


            

            
        
    </div>


  <div><h1 class="header-title">变量</h1>
                
            
            
                
<p class="mce-root CDPAlignLeft CDPAlign">深度学习算法通常被表示为计算图。下面是我们在示例中构建的变量计算图的一个简单示例:</p>
<div><img height="242" width="170" class="alignnone size-full wp-image-332 image-border" src="img/4bffe8e5-599a-424e-8217-abbdee0cc8b2.png"/></div>
<p>可变计算图</p>
<p>前面计算图中的每个圆圈代表一个变量。变量在张量对象、其渐变和对创建它的函数的引用周围形成一层薄薄的包装。下图显示了<kbd>Variable</kbd>类组件:</p>
<div><img height="98" width="141" class="alignnone size-full wp-image-333 image-border" src="img/c3cefc1f-2e5c-4d58-a488-f970ea340fa4.png"/></div>
<p>可变类别</p>
<p>梯度是指<kbd>loss</kbd>函数相对于各种参数(<strong> W </strong>、<strong> b </strong>)的变化率。例如，如果<strong> a </strong>的梯度为2，那么<strong> a </strong>的值的任何变化都会将<strong> Y </strong>的值修改两倍。如果这不清楚，不要担心——大多数深度学习框架会为我们计算梯度。在这一章中，我们将学习如何使用这些渐变来提高模型的性能。</p>
<p>除了渐变之外，一个变量还有一个对创建它的函数的引用，而这个函数又引用了每个变量是如何创建的。例如，变量<kbd>a</kbd>有信息表明它是作为<kbd>X</kbd>和<kbd>W</kbd>的乘积的结果而生成的。</p>
<p>让我们看一个例子，在这个例子中，我们创建变量并检查梯度和函数引用:</p>
<pre>x = Variable(torch.ones(2,2),requires_grad=True)<br/>y = x.mean()<br/><br/>y.backward()<br/><br/>x.grad<br/>Variable containing:
 0.2500  0.2500
 0.2500  0.2500
[torch.FloatTensor of size 2x2]<br/><br/>x.grad_fn<br/>Output - None<br/><br/>x.data<br/> 1 1<br/> 1 1<br/>[torch.FloatTensor of size 2x2]<br/><br/>y.grad_fn<br/>&lt;torch.autograd.function.MeanBackward at 0x7f6ee5cfc4f8&gt;</pre>
<p>在前面的例子中，我们对变量调用了一个<kbd>backward</kbd>操作来计算梯度。默认情况下，变量的梯度是零。</p>
<p>变量的<kbd>grad_fn</kbd>指向它创建的函数。如果变量是由用户创建的，比如我们例子中的变量<kbd>x</kbd>，那么函数引用就是<kbd>None</kbd>。在变量<kbd>y,</kbd>的情况下，指的是它的函数引用<kbd>MeanBackward</kbd>。</p>
<p>数据属性访问与变量相关联的张量。</p>


            

            
        
    </div>


  <div><h1 class="header-title">为我们的神经网络创造数据</h1>
                
            
            
                
<p>我们第一个神经网络代码中的<kbd>get_data</kbd>函数创建了两个变量<kbd>x</kbd>和<kbd>y</kbd>，大小分别为(<kbd>17</kbd>、<kbd>1</kbd>)和(<kbd>17</kbd>)。我们将看看函数内部发生了什么:</p>
<pre>def get_data():<br/>    train_X = np.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,<br/>                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])<br/>    train_Y = np.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,<br/>                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])<br/>    dtype = torch.FloatTensor<br/>    X = Variable(torch.from_numpy(train_X).type(dtype),requires_grad=False).view(17,1)<br/>    y = Variable(torch.from_numpy(train_Y).type(dtype),requires_grad=False)<br/>    return X,y<br/><br/></pre>


            

            
        
    </div>


  <div><h1 class="header-title">创建可学习的参数</h1>
                
            
            
                
<p>在我们的神经网络示例中，我们有两个可学习参数<kbd>w</kbd>和<kbd>b</kbd>，以及两个固定参数<kbd>x</kbd>和<kbd>y</kbd>。我们已经在我们的<kbd>get_data</kbd>函数中创建了变量<kbd>x</kbd>和<kbd>y</kbd>。可学习参数使用随机初始化创建，并将<kbd>require_grad</kbd>参数设置为<kbd>True</kbd>，不像<kbd>x</kbd>和<kbd>y</kbd>设置为<kbd>False</kbd>。初始化可学习参数有不同的方法，我们将在接下来的章节中探讨。让我们来看看我们的<kbd>get_weights</kbd>函数:</p>
<pre>def get_weights():<br/>    w = Variable(torch.randn(1),requires_grad = True)<br/>    b = Variable(torch.randn(1),requires_grad=True)<br/>    return w,b</pre>
<p>前面的大部分代码都是不言自明的；<kbd>torch.randn</kbd>创建任意给定形状的随机值。</p>


            

            
        
    </div>


  <div><h1 class="header-title">神经网络模型</h1>
                
            
            
                
<p>一旦我们使用PyTorch变量定义了模型的输入和输出，我们就必须构建一个模型，学习如何从输入映射输出。在传统编程中，我们通过手工编码不同的逻辑来构建函数，以将输入映射到输出。然而，在深度学习和机器学习中，我们通过向它显示输入和相关输出来学习函数。在我们的例子中，我们实现了一个简单的神经网络，它试图将输入映射到输出，假设是线性关系。线性关系可以表示为<em> y = wx + b </em>，其中<em> w </em>和<em> b </em>为可学习参数。我们的网络要学习<em> w </em>和<em> b </em>的值，这样<em> wx + b </em>才会更接近实际的<em> y </em>。让我们可视化我们的训练数据集和我们的神经网络必须学习的模型:</p>
<div><img height="283" width="426" class="alignnone size-full wp-image-334 image-border" src="img/4780c540-f052-46b7-94eb-6580d4ae5814.png"/></div>
<p>输入数据点</p>
<p>下图显示了拟合输入数据点的线性模型:</p>
<div><img height="248" width="360" class="alignnone size-full wp-image-335 image-border" src="img/81c03405-d31a-45b7-9fbd-4de358111092.png"/></div>
<p>根据输入数据点拟合的线性模型</p>
<p>图像中的深灰色(蓝色)线代表我们的网络学习的模型。</p>


            

            
        
    </div>


  <div><h1 class="header-title">网络实施</h1>
                
            
            
                
<p>因为我们有实现网络所需的所有参数(<kbd>x</kbd>、<kbd>w</kbd>、<kbd>b</kbd>和<kbd>y</kbd>，所以我们在<kbd>w</kbd>和<kbd>x</kbd>之间执行矩阵乘法。然后，用<kbd>b</kbd>对结果求和。这将给出我们预测的<kbd>y</kbd>。该功能的实现如下:</p>
<pre>def simple_network(x):<br/>    y_pred = torch.matmul(x,w)+b<br/>    return y_pred</pre>
<p>PyTorch还在<kbd>torch.nn</kbd>中提供了一个更高层次的抽象，称为<strong>层</strong>，它将负责与神经网络中可用的大多数常见技术相关的大多数底层初始化和操作。我们使用底层操作来理解这些函数内部发生了什么。在后面的章节中，即<a href="4.html" target="_blank">第5章</a>，计算机视觉的深度学习和<a href="5.html" target="_blank">第6章</a>，使用序列数据和文本的深度学习，我们将依靠PyTorch抽象来构建复杂的神经网络或函数。先前的模型可以表示为一个<kbd>torch.nn</kbd>层，如下所示:</p>
<pre>f = nn.Linear(17,1) # Much simpler.</pre>
<p>现在我们已经计算了<kbd>y</kbd>值，我们需要知道我们的模型有多好，这在<kbd>loss</kbd>函数中完成。</p>


            

            
        
    </div>


  <div><h1 class="header-title">损失函数</h1>
                
            
            
                
<p>当我们从随机值开始时，我们的可学习参数<kbd>w</kbd>和<kbd>b</kbd>将导致<kbd>y_pred</kbd>，它将不会接近实际的<kbd>y</kbd>。因此，我们需要定义一个函数来告诉模型它的预测值与实际值有多接近。由于这是一个回归问题，我们使用一个称为<strong>误差平方和</strong> ( <strong> SSE </strong>)的损失函数。我们取预测的<kbd>y</kbd>和实际的<kbd>y</kbd>之差，并求平方。SSE有助于模型了解预测值与实际值的接近程度。<kbd>torch.nn</kbd>库有不同的损失函数，比如MSELoss和交叉熵损失。然而，对于这一章，让我们自己实现<kbd>loss</kbd>函数:</p>
<pre>def loss_fn(y,y_pred):<br/>    loss = (y_pred-y).pow(2).sum()<br/>    for param in [w,b]:<br/>        if not param.grad is None: param.grad.data.zero_()<br/>    loss.backward()<br/>    return loss.data[0]</pre>
<p>除了计算损失，我们还调用了<kbd>backward</kbd>操作，它计算我们的可学习参数<kbd>w</kbd>和<kbd>b</kbd>的梯度。由于我们将不止一次地使用<kbd>loss</kbd>函数，我们通过调用<kbd>grad.data.zero_()</kbd>操作来移除任何先前计算的梯度。我们第一次调用<kbd>backward</kbd>函数时，渐变是空的，所以我们只在渐变不是<kbd>None</kbd>时将渐变归零。</p>


            

            
        
    </div>


  <div><h1 class="header-title">优化神经网络</h1>
                
            
            
                
<p>我们从随机权重开始预测我们的目标，并为我们的算法计算损失。我们通过在最后一个<kbd>loss</kbd>变量上调用<kbd>backward</kbd>函数来计算梯度。整个过程重复一个时期，也就是说，重复整个例子集。在大多数真实世界的例子中，我们将在每次迭代中执行优化步骤，这是整个集合的一个小的子集。一旦计算出损耗，我们就用计算出的梯度优化这些值，从而降低损耗，这在以下函数中实现:</p>
<pre>def optimize(learning_rate):<br/>    w.data -= learning_rate * w.grad.data<br/>    b.data -= learning_rate * b.grad.data</pre>
<p>学习率是一个超参数，它允许我们通过少量的梯度来调整变量中的值，其中梯度表示每个变量(<kbd>w</kbd>和<kbd>b</kbd>)需要调整的方向。</p>
<p>不同的优化器，比如Adam、RmsProp和SGD已经在<kbd>torch.optim</kbd>包中使用。我们将在后面的章节中利用这些优化器来减少损失或提高精度。</p>


            

            
        
    </div>


  <div><h1 class="header-title">加载数据</h1>
                
            
            
                
<p>为深度学习算法准备数据本身可能是一个复杂的管道。PyTorch提供了许多实用程序类，这些类抽象了许多复杂性，例如通过多线程、数据扩充和批处理实现的数据并行化。在本章中，我们将看看两个重要的实用程序类，即<kbd>Dataset</kbd>类和<kbd>DataLoader</kbd>类。为了理解如何使用这些类，让我们从ka ggle(<a href="https://www.kaggle.com/c/dogs-vs-cats/data" target="_blank">https://www.kaggle.com/c/dogs-vs-cats/data</a>)获取<kbd>Dogs vs. Cats</kbd>数据集，并创建一个数据管道，以PyTorch张量的形式生成一批图像。</p>


            

            
        
    </div>


  <div><h1 class="header-title">数据集类</h1>
                
            
            
                
<p>任何自定义数据集类，比如说我们的<kbd>Dogs</kbd>数据集类，都必须从PyTorch数据集类继承。自定义类必须实现两个主要功能，即<kbd>__len__(self)</kbd>和<kbd>__getitem__(self, idx)</kbd>。任何充当<kbd>Dataset</kbd>类的自定义类应该类似于下面的代码片段:</p>
<pre>from torch.utils.data import Dataset<br/>class DogsAndCatsDataset(Dataset):<br/>    def __init__(self,):<br/>        pass<br/>    def __len__(self):<br/>        pass<br/>    def __getitem__(self,idx):<br/>        pass</pre>
<p>如果需要的话，我们在<kbd>init</kbd>方法中进行初始化——例如，在我们的例子中，读取表的索引和图像的文件名。<kbd>__len__(self)</kbd>操作负责返回数据集中最大数量的元素。每次调用<kbd>__getitem__(self, idx)</kbd>操作时，它都会返回一个基于<kbd>idx</kbd>的元素。下面的代码实现了我们的<kbd>DogsAndCatsDataset</kbd>类:</p>
<pre>class DogsAndCatsDataset(Dataset):<br/>    <br/>    def __init__(self,root_dir,size=(224,224)):<br/>        self.files = glob(root_dir)<br/>        self.size = size <br/>        <br/>    def __len__(self):<br/>        return len(self.files)<br/>    <br/>    def __getitem__(self,idx):<br/>        img = np.asarray(Image.open(self.files[idx]).resize(self.size))<br/>        label = self.files[idx].split('/')[-2]<br/>        return img,label</pre>
<p>一旦创建了<kbd>DogsAndCatsDataset</kbd>类，我们就可以创建一个对象并迭代它，如下面的代码所示:</p>
<pre>for image,label in dogsdset:<br/>#Apply your DL on the dataset.</pre>
<p>对单个数据实例应用深度学习算法不是最佳的。我们需要一批数据，因为现代GPU在对一批数据执行时会优化性能。<kbd>DataLoader</kbd>类通过抽象大量的复杂性来帮助创建批处理。</p>


            

            
        
    </div>


  <div><h1 class="header-title">数据加载器类</h1>
                
            
            
                
<p>PyTorch的<kbd>utils</kbd>类中的<kbd>DataLoader</kbd>类组合了一个数据集对象和不同的采样器，如<kbd>SequentialSampler</kbd>和<kbd>RandomSampler</kbd>，并使用单进程或多进程迭代器为我们提供了一批图像。采样器是为算法提供数据的不同策略。以下是我们的<kbd>Dogs vs. Cats</kbd>数据集的<kbd>DataLoader</kbd>示例:</p>
<pre>dataloader = DataLoader(dogsdset,batch_size=32,num_workers=2)<br/>for imgs , labels in dataloader:<br/>     #Apply your DL on the dataset.<br/>     pass</pre>
<p class="mce-root"><kbd>imgs</kbd>将包含一个形状张量(32，224，224，3)，其中<em> 32 </em>表示批量大小。</p>
<p>PyTorch团队还维护了两个有用的库，称为<kbd>torchvision</kbd>和<kbd>torchtext</kbd>，它们构建在<kbd>Dataset</kbd>和<kbd>DataLoader</kbd>类之上。我们将在相关章节中使用它们。</p>


            

            
        
    </div>


  <div><h1 class="header-title">摘要</h1>
                
            
            
                
<p>在这一章中，我们探索了PyTorch提供的各种数据结构和操作。我们使用PyTorch的基本块实现了几个组件。为了准备数据，我们创建了算法使用的张量。我们的网络架构是一个模型，用于学习预测用户在我们的Wondermovies平台上花费的平均时间。我们使用损失函数来检查我们的模型的标准，并使用<kbd>optimize</kbd>函数来调整我们的模型的可学习参数，使其性能更好。</p>
<p>我们还研究了PyTorch如何通过抽象出一些需要我们并行化和增加数据的复杂性来简化数据管道的创建。</p>
<p>在下一章，我们将深入研究神经网络和深度学习算法是如何工作的。我们将探索用于构建网络架构、损失函数和优化的各种PyTorch内置模块。我们还将展示如何在真实数据集上使用它们。</p>


            

            
        
    </div>


  <div><h1 class="header-title">深入研究神经网络</h1>
                
            
            
                
<p class="mce-root">在本章中，我们将探索用于解决现实世界问题的深度学习架构的不同模块。在前一章中，我们使用PyTorch的低级操作来构建网络架构、损失函数和优化器等模块。在本章中，我们将探索解决现实世界问题所需的神经网络的一些重要组件，以及PyTorch如何通过提供大量高级函数来抽象出大量复杂性。在本章的最后，我们将构建算法来解决现实世界中的问题，如回归、二元分类和多类分类。</p>
<p>在本章中，我们将讨论以下主题:</p>
<ul>
<li>深入探究神经网络的各种构建模块</li>
<li>探索PyTorch中的高级功能以构建深度学习架构</li>
<li>将深度学习应用于真实世界的图像分类问题</li>
</ul>


            

            
        
    </div>


  <div><h1 class="header-title">深入探究神经网络的构建模块</h1>
                
            
            
                
<p>正如我们在前一章中了解到的，训练深度学习算法需要以下步骤:</p>
<ol>
<li>构建数据管道</li>
</ol>
<p> </p>
<ol start="2">
<li>构建网络架构</li>
<li>使用损失函数评估架构</li>
<li>使用优化算法优化网络架构权重</li>
</ol>
<p>在前一章中，网络由使用PyTorch数值运算构建的简单线性模型组成。虽然使用数值运算为玩具问题构建神经架构更容易，但当我们试图构建解决不同领域复杂问题所需的架构时，这很快变得复杂，例如计算机视觉和自然语言处理。大多数深度学习框架，如PyTorch、TensorFlow和Apache MXNet，都提供了更高级别的功能，抽象了很多这种复杂性。这些更高级别的功能在深度学习框架中被称为<strong>层</strong>。它们接受输入数据，应用我们在前一章看到的转换，然后输出数据。为了解决现实世界的问题，深度学习架构由1到150个层次组成，有时甚至更多。抽象底层操作和训练深度学习算法将看起来像下面的图表:</p>
<p><img height="372" width="509" class="alignnone size-full wp-image-336 image-border" src="img/14187b0e-8fa2-415e-a890-6695d3bcae31.png"/></p>
<p>总结前面的图表，任何深度学习训练都涉及到获取数据，建立一个架构，通常是将一堆层放在一起，使用损失函数评估模型的准确性，然后通过优化我们网络的权重来优化算法。在解决一些现实世界的问题之前，我们将开始理解PyTorch为构建层、损失函数和优化器提供的高级抽象。</p>


            

            
        
    </div>


  <div><h1 class="header-title">层——神经网络的基本模块</h1>
                
            
            
                
<p>在本章的其余部分，我们将遇到不同类型的层。首先，让我们试着了解最重要的一层，线性层，它的功能与我们之前的网络架构完全相同。线性图层应用线性变换:</p>
<p style="padding-left: 180px"><img height="17" width="100" class="fm-editor-equation" src="img/e6333f93-736c-4658-957a-180b30f69600.png"/></p>
<p>它的强大之处在于，我们在上一章中编写的整个函数可以用一行代码编写，如下所示:</p>
<pre>from torch.nn import Linear<br/>myLayer = Linear(in_features=10,out_features=5,bias=True)</pre>
<p>前面代码中的<kbd>myLayer</kbd>将接受大小为<kbd>10</kbd>的张量，并在应用线性变换后输出大小为<kbd>5</kbd>的张量。让我们看一个简单的例子来说明如何做到这一点:</p>
<pre>inp = Variable(torch.randn(1,10))<br/>myLayer = Linear(in_features=10,out_features=5,bias=True)<br/>myLayer(inp)</pre>
<p>我们可以使用<kbd>weights</kbd>和<kbd>bias</kbd>属性访问该层的可训练参数:</p>
<pre class="mce-root">myLayer.weight<br/><br/><strong>Output</strong> :<br/>Parameter containing:<br/>-0.2386 0.0828 0.2904 0.3133 0.2037 0.1858 -0.2642 0.2862 0.2874 0.1141<br/> 0.0512 -0.2286 -0.1717 0.0554 0.1766 -0.0517 0.3112 0.0980 -0.2364 -0.0442<br/> 0.0776 -0.2169 0.0183 -0.0384 0.0606 0.2890 -0.0068 0.2344 0.2711 -0.3039<br/> 0.1055 0.0224 0.2044 0.0782 0.0790 0.2744 -0.1785 -0.1681 -0.0681 0.3141<br/> 0.2715 0.2606 -0.0362 0.0113 0.1299 -0.1112 -0.1652 0.2276 0.3082 -0.2745<br/>[torch.FloatTensor of size 5x10]<br/><br/>myLayer.bias<br/><strong><br/>Output :<br/></strong>Parameter containing:<strong><br/></strong>-0.2646<strong><br/></strong>-0.2232<strong><br/></strong> 0.2444<strong><br/></strong> 0.2177<strong><br/></strong> 0.0897<strong><br/></strong>[torch.FloatTensor of size 5</pre>
<p>线性层有不同的称呼，比如跨越不同框架的<strong>密集</strong>或<strong>全连通层</strong>。用于解决真实世界用例的深度学习架构通常包含不止一层。在PyTorch中，我们可以通过多种方式实现，如下所示。</p>
<p>一种简单的方法是将一层的输出传递给另一层:</p>
<pre>myLayer1 = Linear(10,5)<br/>myLayer2 = Linear(5,2)<br/>myLayer2(myLayer1(inp))</pre>
<p>每一层都有自己的可学习参数。使用多层背后的想法是，每一层将学习某种模式，后面的层将在此基础上构建。仅仅将线性层加在一起是有问题的，因为除了线性层的简单表示之外，他们学不到任何新的东西。让我们通过一个简单的例子来说明为什么将多个线性层堆叠在一起没有意义。</p>
<p>假设我们有两个线性图层，权重如下:</p>
<table>
<tbody>
<tr>
<td><strong>层层</strong></td>
<td>
<p><strong>权重1 </strong></p>
</td>
</tr>
<tr>
<td>
<p>第1层</p>
</td>
<td>
<p>3.0</p>
</td>
</tr>
<tr>
<td>
<p>第2层</p>
</td>
<td>
<p>2.0</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p class="mce-root">具有两个不同层的前述体系结构可以简单地表示为具有不同层的单个层。因此，仅仅堆叠多个线性层不会帮助我们的算法学习任何新的东西。有时，这可能不清楚，所以我们可以用下面的数学公式来形象化这个架构:</p>
<div><img height="21" width="233" class="fm-editor-equation" src="img/4556ddc4-d0e1-4e0e-a153-c2ec2c779701.png"/></div>
<div><img height="21" width="223" class="fm-editor-equation" src="img/7a28a3ad-2d64-4937-9309-5c062885025f.png"/></div>
<p>为了解决这个问题，我们有不同的非线性函数来帮助学习不同的关系，而不是只关注线性关系。</p>
<p>深度学习中有许多不同的非线性函数可用。PyTorch以层的形式提供了这些非线性功能，我们将能够像使用线性层一样使用它们。</p>
<p>一些流行的非线性函数如下:</p>
<ul>
<li>乙状结肠的</li>
<li>双曲正切</li>
<li>热卢</li>
<li>泄漏ReLU</li>
</ul>


            

            
        
    </div>


  <div><h1 class="header-title">非线性激活</h1>
                
            
            
                
<p>非线性激活是接受输入，然后应用数学变换并产生输出的功能。我们在实践中会遇到几种非线性运算。我们将讨论一些流行的非线性激活函数。</p>


            

            
        
    </div>


  <div><h1 class="header-title">乙状结肠的</h1>
                
            
            
                
<p>sigmoid激活函数具有简单的数学形式，如下所示:</p>
<p style="padding-left: 150px"><img height="28" width="186" class="fm-editor-equation" src="img/aabbaeb0-9f60-44df-940e-9b3874c3ece2.png"/></p>
<p>sigmoid函数直观地接受一个实数值，并输出一个介于0和1之间的数字。对于大的负数，它返回接近零的值，对于大的正数，它返回接近1的值。下图代表不同的sigmoid函数输出:</p>
<div><img height="260" width="386" class="alignnone size-full wp-image-337 image-border" src="img/beb8c9f1-c75f-4e24-b654-5536c74ca248.png"/></div>
<p>sigmoid函数在历史上曾被用于不同的架构，但最近它不再流行，因为它有一个主要缺点。当sigmoid函数的输出接近于0或1时，sigmoid函数之前的层的梯度接近于0，因此，前一层的可学习参数的梯度接近于0，并且权重不经常调整，导致死神经元。</p>


            

            
        
    </div>


  <div><h1 class="header-title">双曲正切</h1>
                
            
            
                
<p>双曲正切非线性函数压缩-1和1范围内的实数值。当tanh输出接近-1和1的极值时，tanh也面临相同的饱和梯度问题。然而，它优于sigmoid，因为tanh的输出以零为中心:</p>
<div><img height="253" width="382" src="img/eec87fd4-fe4f-408b-b831-4157206a684f.png"/></div>
<p>图片来源:http://data review . info/article/eto-nuzhno-znat-klyuchevyie-rekomendatsii-po-glubokomu-obucheniyu-chast-2/</p>


            

            
        
    </div>


  <div><h1 class="header-title">热卢</h1>
                
            
            
                
<p>ReLU在最近几年变得更受欢迎；我们可以在几乎任何现代建筑中找到它的用法或它的变体之一。它有一个简单的数学公式:</p>
<p style="padding-left: 210px"><em> f(x)=max(0，x) </em></p>
<p>简而言之，ReLU将任何负到零的输入压缩，并保留正数不变。我们可以将ReLU函数形象化如下:</p>
<div><img height="262" width="385" class="alignnone size-full wp-image-339 image-border" src="img/dd8dabd2-67a6-41f6-85bd-99575eadf301.png"/></div>
<p>图片来源:http://data review . info/article/eto-nuzhno-znat-klyuchevyie-rekomendatsii-po-glubokomu-obucheniyu-chast-2/</p>
<p>使用ReLU的一些优点和缺点如下:</p>
<ul>
<li>它有助于优化器更快地找到正确的权重集。从技术上讲，它使随机梯度下降的收敛速度更快。</li>
<li>它的计算成本很低，因为我们只是设定阈值，而不是像对sigmoid和tangent函数那样计算任何东西。</li>
<li>ReLU有一个缺点；当大梯度在反向传播期间穿过它时，它们通常变得无响应；这些被称为<strong>死中子</strong>，可以通过仔细选择学习率来控制。在<a href="3.html" target="_blank">第四章</a>、<em>机器学习基础</em>讨论调整学习率的不同方式时，我们会讨论如何选择学习率。</li>
</ul>


            

            
        
    </div>


  <div><h1 class="header-title">泄漏ReLU</h1>
                
            
            
                
<p>Leaky ReLU试图解决一个垂死的问题，它不是饱和到零，而是饱和到一个非常小的数，比如0.001。对于某些用例，这个激活函数提供了优于其他函数的性能，但是它并不一致。</p>


            

            
        
    </div>


  <div><h1 class="header-title">PyTorch非线性激活</h1>
                
            
            
                
<p>PyTorch已经为我们实现了大多数常见的非线性激活功能，它可以像任何其他层一样使用。让我们看一个如何在PyTorch中使用<kbd>ReLU</kbd>函数的简单例子:</p>
<pre>sample_data = Variable(torch.Tensor([[1,2,-1,-1]]))<br/>myRelu = ReLU()<br/>myRelu(sample_data)<br/><br/>Output:<br/><br/>Variable containing:<br/> 1 2 0 0<br/>[torch.FloatTensor of size 1x4]</pre>
<p>在前面的例子中，我们取了一个有两个正值和两个负值的张量，并对其应用了一个<kbd>ReLU</kbd>，它将负数阈值化为<kbd>0</kbd>，并保留正数。</p>
<p class="mce-root">现在我们已经涵盖了构建网络架构所需的大部分细节，让我们构建一个可用于解决现实世界问题的深度学习架构。在前一章中，我们使用了一种简单的方法，以便我们可以只关注深度学习算法如何工作。我们将不再使用这种风格来构建我们的架构；相反，我们将按照PyTorch中的设计方式来构建架构。</p>


            

            
        
    </div>


  <div><h1 class="header-title">构建深度学习算法的PyTorch方式</h1>
                
            
            
                
<p>PyTorch中的所有网络都实现为类，子类化一个名为<kbd>nn.Module</kbd>的PyTorch类，并且应该实现<kbd>__init__</kbd>和<kbd>forward</kbd>方法。在<kbd>init</kbd>函数中，我们初始化任何层，比如我们在上一节中提到的<kbd>linear</kbd>层。在<kbd>forward</kbd>方法中，我们将输入数据传递给在<kbd>init</kbd>方法中初始化的层，并返回最终输出。非线性函数通常直接用在<kbd>forward</kbd>函数中，有些也用在<kbd>init</kbd>方法中。以下代码片段显示了深度学习架构是如何在PyTorch中实现的:</p>
<pre>class MyFirstNetwork(nn.Module):<br/>    <br/>    def __init__(self,input_size,hidden_size,output_size):<br/>        super(MyFirstNetwork,self).__init__()<br/>        self.layer1 = nn.Linear(input_size,hidden_size)<br/>        self.layer2 = nn.Linear(hidden_size,output_size)<br/>        <br/>    def __forward__(self,input): <br/>        out = self.layer1(input)<br/>        out = nn.ReLU(out)<br/>        out = self.layer2(out)<br/>        return out<br/><br/></pre>
<p>如果您是Python的新手，前面的一些代码可能很难理解，但它所做的只是继承一个父类并在其中实现两个方法。在Python中，我们通过将父类作为参数传递给类名来子类化。在Python中，<kbd>init</kbd>方法充当构造函数，<kbd>super</kbd>用于将子类的参数传递给父类，在我们的例子中是<kbd>nn.Module</kbd>。</p>


            

            
        
    </div>


  <div><h1 class="header-title">不同机器学习问题的模型架构</h1>
                
            
            
                
<p>我们正在解决的这种问题将决定我们将使用什么样的层，从线性层开始到用于顺序数据的<strong>长期短期记忆</strong> ( <strong> LSTM </strong>)。基于你试图解决的问题的类型，你的最后一层是确定的。我们通常使用任何机器学习或深度学习算法来解决三个问题。让我们看看最后一层是什么样子的:</p>
<ul>
<li>对于回归问题，例如预测要出售的t恤的价格，我们将使用最后一个图层作为输出为1的线性图层，它输出连续值。</li>
<li>为了将给定图像分类为t恤或衬衫，您将使用sigmoid激活函数，因为它输出接近1或0的值，这通常被称为<strong>二元分类问题</strong>。</li>
<li>对于多类分类，我们必须对给定图像是t恤、牛仔裤、衬衫还是连衣裙进行分类，我们将在网络末端使用softmax层。让我们试着直观地理解softmax是做什么的，而不去研究它的数学。例如，它从前一个线性图层获取输入，并输出给定数量的示例的概率。在我们的例子中，它将被训练来预测每种类型图像的四种概率。记住，所有这些概率加起来总是1。</li>
</ul>


            

            
        
    </div>


  <div><h1 class="header-title">损失函数</h1>
                
            
            
                
<p>一旦我们定义了我们的网络架构，我们剩下两个重要的步骤。一个是计算我们的网络在执行回归、分类的特定任务方面有多好，下一个是优化权重。</p>
<p>优化器(梯度下降)通常接受一个标量值，所以我们的<kbd>loss</kbd>函数应该生成一个标量值，在我们的训练过程中必须将其最小化。某些用例需要两个或更多损失函数，例如预测道路上的障碍物并将其归类为行人。即使在这种情况下，我们也需要将损失合并到单个标量中，以便优化器最小化。我们将在最后一章用一个真实的例子详细讨论将多个损失合并到单个标量的例子。</p>
<p>在前一章中，我们定义了自己的<kbd>loss</kbd>函数。PyTorch提供了常用的<kbd>loss</kbd>函数的几种实现。我们来看看用于回归和分类的<kbd>loss</kbd>函数。</p>
<p>回归问题常用的<kbd>loss</kbd>函数是<strong>均方误差</strong> ( <strong> MSE </strong>)。它与我们在上一章中实现的<kbd>loss</kbd>函数相同。我们可以使用PyTorch中实现的<kbd>loss</kbd>函数，如下所示:</p>
<pre>loss = nn.MSELoss()<br/>input = Variable(torch.randn(3, 5), requires_grad=True)<br/>target = Variable(torch.randn(3, 5))<br/>output = loss(input, target)<br/>output.backward()</pre>
<p class="mce-root">对于分类，我们使用交叉熵损失。在研究交叉熵的数学之前，让我们先了解一下交叉熵损失是怎么回事。它计算预测概率的分类网络的损失，其总和应该为1，就像我们的softmax层一样。当预测概率偏离正确概率时，交叉熵损失增加。例如，如果我们的分类算法预测下面的图像有0.1的概率是一只猫，但它实际上是一只熊猫，那么交叉熵损失会更高。如果它预测与实际标签相似，那么交叉熵损失将会更低:</p>
<div><img height="231" width="292" class="alignnone size-full wp-image-689 image-border" src="img/7f8abb0b-31dc-4e78-a06a-1a29631d7706.png"/></div>
<p>让我们看一个在Python代码中如何实现的示例:</p>
<pre>def cross_entropy(true_label, prediction):
    if true_label == 1:
        return -log(prediction)
    else:
        return -log(1 - prediction)</pre>
<p>要在分类问题中使用交叉熵损失，我们真的不需要担心内部会发生什么——我们需要记住的是，当我们的预测不好时，损失会很高，当预测好时，损失会很低。PyTorch为我们提供了一个<kbd>loss</kbd>的实现，我们可以使用它，如下所示:</p>
<pre>loss = nn.CrossEntropyLoss()<br/>input = Variable(torch.randn(3, 5), requires_grad=True)<br/>target = Variable(torch.LongTensor(3).random_(5))<br/>output = loss(input, target)<br/>output.backward()</pre>
<p>PyTorch的其他一些<kbd>loss</kbd>功能如下:</p>
<table>
<tbody>
<tr>
<td>
<p>L1损失</p>
</td>
<td>
<p class="mce-root">大多用作正则项。我们将在<a href="3.html" target="_blank">第四章</a>、<em>机器学习基础</em>中进一步讨论。</p>
</td>
</tr>
<tr>
<td>
<p>MSE损失</p>
</td>
<td>
<p>用作回归问题的损失函数。</p>
</td>
</tr>
<tr>
<td>
<p>交叉熵损失</p>
</td>
<td>
<p class="mce-root">用于二元和多类分类问题。</p>
</td>
</tr>
<tr>
<td>
<p>NLL损失</p>
</td>
<td>
<p class="mce-root">用于分类问题，并允许我们使用特定的权重来处理不平衡的数据集。</p>
</td>
</tr>
<tr>
<td>
<p>NLL损耗2d</p>
</td>
<td>
<p class="mce-root">用于按像素分类，主要用于与图像分割相关的问题。</p>
</td>
</tr>
</tbody>
</table>


            

            
        
    </div>


  <div><h1 class="header-title">优化网络架构</h1>
                
            
            
                
<p>一旦我们计算出网络的损耗，我们将优化权重以减少损耗，从而提高算法的准确性。为了简单起见，让我们把这些优化器看作是黑盒，它接受损失函数和所有可学习的参数，并稍微移动它们以提高我们的性能。PyTorch提供了深度学习所需的大部分常用优化器。如果你想探索这些优化器内部发生了什么，并且有数学背景，我强烈推荐下面的一些博客:</p>
<ul>
<li>【http://colah.github.io/posts/2015-08-Backprop/ T4】</li>
<li><a href="http://ruder.io/deep-learning-optimization-2017/" target="_blank">http://ruder.io/deep-learning-optimization-2017/</a></li>
</ul>
<p>PyTorch提供的一些优化器如下:</p>
<ul>
<li>阿达德尔塔</li>
<li>阿达格拉德</li>
<li>圣经》和《古兰经》传统中）亚当（人类第一人的名字</li>
<li>SparseAdam</li>
<li>阿达马克斯</li>
<li>ASGD</li>
<li>LBFGS</li>
<li>RMSProp</li>
<li>Rprop</li>
<li>签名于</li>
</ul>
<p>我们将在<a href="3.html" target="_blank">第四章</a>、<em>机器学习基础</em>中深入一些算法的细节，以及一些优点和权衡。让我们来看看创建任何<kbd>optimizer</kbd>的一些重要步骤:</p>
<pre>optimizer = optim.SGD(model.parameters(), lr = 0.01)</pre>
<p>在前面的例子中，我们创建了一个<kbd>SGD</kbd>优化器，它将网络的所有可学习参数作为第一个参数，并将一个学习速率作为可学习参数的变化率。在<a href="3.html" target="_blank">第4章</a>、<em>机器学习的基础</em>中，我们将深入学习速率和动量的更多细节，这是优化器的一个重要参数。一旦你创建了一个优化器对象，我们需要在我们的循环中调用<kbd>zero_grad()</kbd>,因为参数将累积在前面的<kbd>optimizer</kbd>调用中创建的梯度:</p>
<pre>for input, target in dataset:
    optimizer.zero_grad()
    output = model(input)
    loss = loss_fn(output, target)
    loss.backward()
    optimizer.step()</pre>
<p>一旦我们在<kbd>loss</kbd>函数上调用<kbd>backward</kbd>，它计算梯度(可学习参数需要改变的量)，我们调用<kbd>optimizer.step()</kbd>，它对我们的可学习参数进行实际的改变。</p>
<p>现在，我们已经介绍了帮助计算机看到/识别图像所需的大部分组件。让我们建立一个复杂的深度学习模型，可以区分狗和猫，以将所有理论付诸实践。</p>


            

            
        
    </div>


  <div><h1 class="header-title">使用深度学习的图像分类</h1>
                
            
            
                
<p>解决任何现实问题最重要的一步是获取数据。Kaggle提供了大量关于不同数据科学问题的竞赛。我们将挑选2014年出现的一个问题，我们将在本章中用来测试我们的深度学习算法，并在<a xmlns:epub="http://www.idpf.org/2007/ops" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pls="http://www.w3.org/2005/01/pronunciation-lexicon" xmlns:ssml="http://www.w3.org/2001/10/synthesis" href="4.html" target="_blank">第五章</a>、<em xmlns:epub="http://www.idpf.org/2007/ops" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pls="http://www.w3.org/2005/01/pronunciation-lexicon" xmlns:ssml="http://www.w3.org/2001/10/synthesis">计算机视觉的深度学习</em>中对其进行改进，这些问题将在<strong xmlns:epub="http://www.idpf.org/2007/ops" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pls="http://www.w3.org/2005/01/pronunciation-lexicon" xmlns:ssml="http://www.w3.org/2001/10/synthesis">卷积神经网络</strong>(<strong xmlns:epub="http://www.idpf.org/2007/ops" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pls="http://www.w3.org/2005/01/pronunciation-lexicon" xmlns:ssml="http://www.w3.org/2001/10/synthesis">CNN</strong>)和一些我们可以用来提高图像识别模型性能的高级技术中出现。你可以从https://www.kaggle.com/c/dogs-vs-cats/data下载数据。该数据集包含25，000张狗和猫的图像。数据的预处理以及训练、验证和测试分割的创建是我们在实现算法之前需要执行的一些重要步骤。数据下载后，查看一下，它显示文件夹包含以下格式的图像:</p>
<div><img height="164" width="186" class="alignnone size-full wp-image-341 image-border" src="img/c746e70e-bf9a-40be-8f68-7493de1eb7ac.png"/></div>
<p>大多数框架在以下面的格式提供时，使阅读图像和给它们贴标签变得更容易。这意味着每个类都应该有一个单独的图像文件夹。这里，所有的猫图像应该在<kbd>cat</kbd>文件夹中，狗图像应该在<kbd>dog</kbd>文件夹中:</p>
<div><img height="339" width="202" class="alignnone size-full wp-image-342 image-border" src="img/bf800adb-ed3e-4f0e-b644-de91d3789ce5.png"/></div>
<p>Python使得将数据转换成正确的格式变得很容易。让我们快速地看一下代码，然后，我们将浏览它的重要部分:</p>
<pre>path = '../chapter3/dogsandcats/'<br/><br/>#Read all the files inside our folder.<br/>files = glob(os.path.join(path,'*/*.jpg'))<br/><br/>print(f'Total no of images {len(files)}')<br/><br/>no_of_images = len(files)<br/><br/>#Create a shuffled index which can be used to create a validation data set<br/>shuffle = np.random.permutation(no_of_images)<br/><br/>#Create a validation directory for holding validation images.<br/>os.mkdir(os.path.join(path,'valid'))<br/><br/>#Create directories with label names <br/>for t in ['train','valid']:<br/>     for folder in ['dog/','cat/']:<br/>          os.mkdir(os.path.join(path,t,folder)) <br/><br/>#Copy a small subset of images into the validation folder.<br/>for i in shuffle[:2000]:<br/>     folder = files[i].split('/')[-1].split('.')[0]<br/>     image = files[i].split('/')[-1]<br/>     os.rename(files[i],os.path.join(path,'valid',folder,image))<br/><br/>#Copy a small subset of images into the training folder.<br/>for i in shuffle[2000:]:<br/>     folder = files[i].split('/')[-1].split('.')[0]<br/>     image = files[i].split('/')[-1]<br/>     os.rename(files[i],os.path.join(path,'train',folder,image))</pre>
<p>前面的代码所做的就是检索所有的文件并挑选2，000张图片来创建一个验证集。它将所有的图片分为猫和狗两类。创建单独的验证集是一种常见且重要的做法，因为在相同的数据上测试我们的算法是不公平的。为了创建一个<kbd>validation</kbd>数据集，我们创建了一个数字列表，这些数字在图像的长度范围内，并以随机的顺序排列。混排的数字作为索引，让我们挑选一组图像来创建我们的<kbd>validation</kbd>数据集。让我们详细检查代码的每一部分。</p>
<p>我们使用以下代码创建一个文件:</p>
<pre>files = glob(os.path.join(path,'*/*.jpg'))</pre>
<p><kbd>glob</kbd>方法返回特定路径中的所有文件。当有大量图像时，我们也可以使用<kbd>iglob</kbd>，它返回一个迭代器，而不是将名称加载到内存中。在我们的例子中，我们只有25，000个文件名，可以很容易地放入内存。</p>
<p>我们可以使用下面的代码来打乱我们的文件:</p>
<pre>shuffle = np.random.permutation(no_of_images)</pre>
<p>前面的代码返回25，000个数字，范围从0到25，000，顺序是随机的，我们将使用这些数字作为选择图像子集的索引，以创建一个<kbd>validation</kbd>数据集。</p>
<p>我们可以创建一个验证码，如下所示:</p>
<pre>os.mkdir(os.path.join(path,'valid'))<br/>for t in ['train','valid']:<br/>     for folder in ['dog/','cat/']:<br/>          os.mkdir(os.path.join(path,t,folder)) </pre>
<p>前面的代码创建了一个<kbd>validation</kbd>文件夹，并基于<kbd>train</kbd>和<kbd>valid</kbd>目录中的类别(猫和狗)创建了文件夹。</p>
<p>我们可以用下面的代码打乱一个索引:</p>
<pre>for i in shuffle[:2000]:<br/>     folder = files[i].split('/')[-1].split('.')[0]<br/>     image = files[i].split('/')[-1]<br/>     os.rename(files[i],os.path.join(path,'valid',folder,image))</pre>
<p>在前面的代码中，我们使用我们的混洗索引为我们的验证集随机选取<kbd>2000</kbd>个不同的图像。我们对训练数据做一些类似的事情来分离<kbd>train</kbd>目录中的图像。</p>
<p>既然我们有了所需格式的数据，让我们快速地看看如何将图像加载为PyTorch张量。</p>


            

            
        
    </div>


  <div><h1 class="header-title">将数据加载到PyTorch张量中</h1>
                
            
            
                
<p>PyTorch <kbd>torchvision.datasets</kbd>包提供了一个名为<kbd>ImageFolder</kbd>的实用程序类，当数据以上述格式呈现时，该类可用于加载图像及其相关标签。通常的做法是执行以下预处理步骤:</p>
<ol>
<li>将所有图像调整到相同的大小。大多数深度学习架构都希望图像大小相同。</li>
<li>用数据集的平均值和标准差归一化数据集。</li>
<li>将图像数据集转换为PyTorch张量。</li>
</ol>
<p>PyTorch通过在<kbd>transforms</kbd>模块中提供许多实用函数，简化了这些预处理步骤。对于我们的示例，让我们应用三个转换:</p>
<ul>
<li>缩放至256 x 256的图像尺寸</li>
<li>转换为PyTorch张量</li>
<li>标准化数据(我们将在第五章<a href="4.html" target="_blank">的</a>、<em>计算机视觉的深度学习</em>中讨论我们如何得出均值和标准差)</li>
</ul>
<p>以下代码演示了如何使用<kbd>ImageFolder</kbd>类应用转换和加载图像:</p>
<pre>simple_transform=transforms.Compose([transforms.Scale((224,224)),<br/>                             transforms.ToTensor(),<br/>                             transforms.Normalize([0.485, 0.456,                     0.406], [0.229, 0.224, 0.225])])<br/>train = ImageFolder('dogsandcats/train/',simple_transform)<br/>valid = ImageFolder('dogsandcats/valid/',simple_transform)</pre>
<p><kbd>train</kbd>对象保存数据集的所有图像和相关标签。它包含两个重要的属性:一个给出类和数据集中使用的相关索引之间的映射，另一个给出类的列表:</p>
<ul>
<li><kbd>train.class_to_idx - {'cat': 0, 'dog': 1}</kbd></li>
<li><kbd>train.classes - ['cat', 'dog']</kbd></li>
</ul>
<p class="mce-root">将加载到张量中的数据可视化通常是最佳实践。为了可视化张量，我们必须重塑张量的形状，并对其值进行反规格化。下面的函数为我们完成了这项工作:</p>
<pre>def imshow(inp):<br/>    """Imshow for Tensor."""<br/>    inp = inp.numpy().transpose((1, 2, 0))<br/>    mean = np.array([0.485, 0.456, 0.406])<br/>    std = np.array([0.229, 0.224, 0.225])<br/>    inp = std * inp + mean<br/>    inp = np.clip(inp, 0, 1)<br/>    plt.imshow(inp)<br/>   </pre>
<p>现在，我们可以将我们的张量传递给前面的<kbd>imshow</kbd>函数，它将张量转换成图像:</p>
<pre>imshow(train[50][0])</pre>
<p class="mce-root CDPAlignLeft CDPAlign">上述代码生成以下输出:</p>
<div><img height="189" width="197" class="alignnone size-full wp-image-343 image-border" src="img/6fc5e3ac-369e-4a9f-bcbc-70395c8ed587.png"/></div>


            

            
        
    </div>


  <div><h1 class="header-title">批量加载PyTorch张量</h1>
                
            
            
                
<p>在深度学习或机器学习中，批量处理图像样本是一种常见的做法，因为现代的<strong>图形处理单元</strong>(<strong>GPU</strong>)和CPU经过优化，可以在一批图像上更快地运行操作。批量大小通常取决于我们使用的GPU的种类。每个GPU都有自己的内存，内存从2 GB到12 GB不等，商用GPU有时会更多。PyTorch提供了<kbd>DataLoader</kbd>类，它接收一个数据集并返回给我们一批图像。它抽象了批处理中的许多复杂性，例如使用多个工人来应用转换。以下代码将之前的<kbd>train</kbd>和<kbd>valid</kbd>数据集转换为数据加载器:</p>
<pre>train_data_gen =  <br/>  torch.utils.data.DataLoader(train,batch_size=64,num_workers=3)<br/>valid_data_gen = <br/>  torch.utils.data.DataLoader(valid,batch_size=64,num_workers=3)</pre>
<p><kbd>DataLoader</kbd>类为我们提供了许多选项，其中一些最常用的选项如下:</p>
<ul>
<li><kbd>shuffle</kbd>:为真时，每次调用数据加载器时都会打乱图像。</li>
<li><kbd>num_workers</kbd>:负责并行化。通常使用的工作线程数量少于机器中可用的内核数量。</li>
</ul>


            

            
        
    </div>


  <div><h1 class="header-title">构建网络架构</h1>
                
            
            
                
<p class="mce-root">对于大多数真实世界的用例，特别是在计算机视觉中，我们很少构建自己的架构。有不同的架构可以快速用于解决我们现实世界的问题。对于我们的例子，我们使用了一种流行的深度学习算法，叫做<strong xmlns:epub="http://www.idpf.org/2007/ops" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pls="http://www.w3.org/2005/01/pronunciation-lexicon" xmlns:ssml="http://www.w3.org/2001/10/synthesis"> ResNet </strong>，它在2015年的不同比赛中获得了一等奖，比如与计算机视觉相关的ImageNet。为了更简单的理解，让我们假设这个算法是一堆不同的PyTorch层仔细地绑在一起，而不是集中在这个算法内部发生了什么。当我们了解CNN时，我们将在第五章、<em xmlns:epub="http://www.idpf.org/2007/ops" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pls="http://www.w3.org/2005/01/pronunciation-lexicon" xmlns:ssml="http://www.w3.org/2001/10/synthesis">计算机视觉的深度学习</em>中看到ResNet算法的一些关键构建模块。PyTorch通过在<kbd xmlns:epub="http://www.idpf.org/2007/ops" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pls="http://www.w3.org/2005/01/pronunciation-lexicon" xmlns:ssml="http://www.w3.org/2001/10/synthesis">torchvision.models</kbd>模块中提供现成的算法，使得使用这些流行算法变得更加容易。因此，对于这个例子，让我们快速地看一下如何使用这个算法，然后遍历每一行代码:</p>
<pre>model_ft = models.resnet18(pretrained=True)<br/>num_ftrs = model_ft.fc.in_features<br/>model_ft.fc = nn.Linear(num_ftrs, 2)<br/><br/>if is_cuda:<br/>    model_ft = model_ft.cuda()</pre>
<p class="mce-root"><kbd>models.resnet18(pertrained = True)</kbd>对象创建算法的一个实例，它是PyTorch层的集合。我们可以通过打印<kbd>model_ft</kbd>来快速看一下ResNet算法的构成。算法的一小部分看起来像下面的截图。我没有包括完整的算法，因为它可以运行几页:</p>
<div><img height="327" width="612" class="alignnone size-full wp-image-344 image-border" src="img/09088b50-3dab-4b63-996f-498a5c52bfe2.png"/></div>
<p>正如我们所看到的，ResNet架构是层的集合，即<kbd>Conv2d</kbd>、<kbd>BatchNorm2d</kbd>和<kbd>MaxPool2d</kbd>，它们以一种特定的方式连接在一起。所有这些算法都会接受一个名为<strong> pretrained </strong>的参数。当<kbd>pretrained</kbd>是<kbd>True</kbd>时，算法的权重已经针对预测1000个不同类别的特定ImageNet分类问题进行了调整，这些类别包括汽车、船只、鱼、猫和狗。该算法被训练来预测1，000个ImageNet类别，并且权重被调整到该算法达到最先进精度的某个点。这些权重被存储并与我们用于用例的模型共享。当以微调的权重开始时，算法往往比以随机权重开始时工作得更好。因此，对于我们的用例，我们从预训练重量开始。</p>
<p>ResNet算法不能直接使用，因为它被训练为预测1，000个类别中的一个。对于我们的用例，我们只需要预测狗和猫这两个类别中的一个。为此，我们采用ResNet模型的最后一层，即<kbd>linear</kbd>层，并将输出特性更改为两个，如以下代码所示:</p>
<pre>model_ft.fc = nn.Linear(num_ftrs, 2)</pre>
<p>如果你在基于GPU的机器上运行这个算法，那么为了让算法在GPU上运行，我们在模型上调用<kbd>cuda</kbd>方法。强烈建议您在GPU驱动的机器上运行这些程序；用一个不到一美元的GPU来旋转一个云实例是很容易的。以下代码片段中的最后一行告诉PyTorch在GPU上运行代码:</p>
<pre>if is_cuda:<br/>    model_ft = model_ft.cuda()</pre>


            

            
        
    </div>


  <div><h1 class="header-title">训练模型</h1>
                
            
            
                
<p>在前面的章节中，我们已经创建了<kbd>DataLoader</kbd>实例和算法。现在，让我们训练模型。为此，我们需要一个<kbd>loss</kbd>函数和一个<kbd>optimizer</kbd>:</p>
<pre># Loss and Optimizer<br/>learning_rate = 0.001<br/>criterion = nn.CrossEntropyLoss()<br/>optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)<br/>exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7,  <br/>  gamma=0.1)</pre>
<p>在前面的代码中，我们创建了基于<kbd>CrossEntropyLoss</kbd>的<kbd>loss</kbd>函数和基于<kbd>SGD</kbd>的优化器。<kbd>StepLR</kbd>功能有助于动态改变学习率。我们将在<a href="3.html" target="_blank">第4章</a>、<em>机器学习基础</em>中讨论可用于调整学习速率的不同策略。</p>
<p>下面的<kbd>train_model</kbd>函数接受一个模型，并通过运行多个时期和减少损失来调整我们算法的权重:</p>
<pre>def train_model(model, criterion, optimizer, scheduler, num_epochs=25):<br/>    since = time.time()<br/><br/>    best_model_wts = model.state_dict()<br/>    best_acc = 0.0<br/><br/>    for epoch in range(num_epochs):<br/>        print('Epoch {}/{}'.format(epoch, num_epochs - 1))<br/>        print('-' * 10)<br/><br/>        # Each epoch has a training and validation phase<br/>        for phase in ['train', 'valid']:<br/>            if phase == 'train':<br/>                scheduler.step()<br/>                model.train(True) # Set model to training mode<br/>            else:<br/>                model.train(False) # Set model to evaluate mode<br/><br/>            running_loss = 0.0<br/>            running_corrects = 0<br/><br/>            # Iterate over data.<br/>            for data in dataloaders[phase]:<br/>                # get the inputs<br/>                inputs, labels = data<br/><br/>                # wrap them in Variable<br/>                if is_cuda:<br/>                    inputs = Variable(inputs.cuda())<br/>                    labels = Variable(labels.cuda())<br/>                else:<br/>                    inputs, labels = Variable(inputs),                 Variable(labels)<br/><br/>                # zero the parameter gradients<br/>                optimizer.zero_grad()<br/><br/>                # forward<br/>                outputs = model(inputs)<br/>                _, preds = torch.max(outputs.data, 1)<br/>                loss = criterion(outputs, labels)<br/><br/>                # backward + optimize only if in training phase<br/>                if phase == 'train':<br/>                    loss.backward()<br/>                    optimizer.step()<br/><br/>                # statistics<br/>                running_loss += loss.data[0]<br/>                running_corrects += torch.sum(preds == labels.data)<br/><br/>            epoch_loss = running_loss / dataset_sizes[phase]<br/>            epoch_acc = running_corrects / dataset_sizes[phase]<br/><br/>            print('{} Loss: {:.4f} Acc: {:.4f}'.format(<br/>                phase, epoch_loss, epoch_acc))<br/><br/>            # deep copy the model<br/>            if phase == 'valid' and epoch_acc &gt; best_acc:<br/>                best_acc = epoch_acc<br/>                best_model_wts = model.state_dict()<br/><br/>        print()<br/><br/>    time_elapsed = time.time() - since<br/>    print('Training complete in {:.0f}m {:.0f}s'.format(<br/>        time_elapsed // 60, time_elapsed % 60))<br/>    print('Best val Acc: {:4f}'.format(best_acc))<br/><br/>    # load best model weights<br/>    model.load_state_dict(best_model_wts)<br/>    return model</pre>
<p>上述函数执行以下操作:</p>
<ol>
<li>通过模型传递图像并计算损失。</li>
<li>在训练阶段反向传播。对于验证/测试阶段，它不调整权重。</li>
<li>对于每个时期，损失在批次间累积。</li>
<li>存储最佳模型并打印验证精度。</li>
</ol>
<p>前面的模型在运行了<kbd>25</kbd>个时期后，得到了87%的验证准确度。下面是前面的<kbd>train_model</kbd>函数在我们的<kbd>Dogs vs. Cats</kbd>数据集上运行时生成的日志；为了节省篇幅，我只是将过去几个时代的结果包括在本书中:</p>
<pre>Epoch 18/24
----------
train Loss: 0.0044 Acc: 0.9877
valid Loss: 0.0059 Acc: 0.8740

Epoch 19/24
----------
train Loss: 0.0043 Acc: 0.9914
valid Loss: 0.0059 Acc: 0.8725

Epoch 20/24
----------
train Loss: 0.0041 Acc: 0.9932
valid Loss: 0.0060 Acc: 0.8725

Epoch 21/24
----------
train Loss: 0.0041 Acc: 0.9937
valid Loss: 0.0060 Acc: 0.8725

Epoch 22/24
----------
train Loss: 0.0041 Acc: 0.9938
valid Loss: 0.0060 Acc: 0.8725

Epoch 23/24
----------
train Loss: 0.0041 Acc: 0.9938
valid Loss: 0.0060 Acc: 0.8725

Epoch 24/24
----------
train Loss: 0.0040 Acc: 0.9939
valid Loss: 0.0060 Acc: 0.8725

Training complete in 27m 8s
Best val Acc: 0.874000</pre>
<p>在接下来的章节中，我们将学习更先进的技术，帮助我们以更快的方式训练更精确的模型。之前的模型在Titan X GPU上运行大约需要30分钟。我们将介绍有助于更快训练模型的不同技术。</p>


            

            
        
    </div>


  <div><h1 class="header-title">摘要</h1>
                
            
            
                
<p>在本章中，我们探索了Pytorch中神经网络的完整生命周期，从构建不同类型的层开始，添加激活，计算交叉熵损失，最后通过使用SGD优化器调整层的权重来优化网络性能(即最小化损失)。</p>
<p>我们已经研究了如何将流行的ResNET体系结构应用于二元或多类分类问题。</p>
<p>在这样做的同时，我们试图解决现实世界中的图像分类问题，将猫图像分类为猫，将狗图像分类为狗。该知识可用于对不同种类/类别的实体进行分类，例如对鱼的种类进行分类、识别不同种类的狗、对植物幼苗进行分类、将宫颈癌归为1型、2型和3型等等。</p>
<p>在下一章，我们将学习机器学习的基础知识。</p>


            

            
        
    </div>
</body>
</html>