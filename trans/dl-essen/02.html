<html><head/><body>
<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Getting Yourself Ready for Deep Learning</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">让自己为深度学习做好准备</h1>
                
            
            
                
<p class="calibre2">由于最近<strong class="calibre13">人工神经网络</strong>(<strong class="calibre13">ann</strong>)在<strong class="calibre13">人工智能</strong> ( <strong class="calibre13"> AI </strong>)的不同应用中取得的成就，例如计算机视觉、<strong class="calibre13">自然语言处理</strong> ( <strong class="calibre13"> NLP </strong>)和语音识别，深度学习已经成为大多数现实世界实施的突出技术基础。本章旨在成为如何在现实世界中试验和应用深度学习技术的起点。</p>
<p class="calibre2">我们将回答一个关键问题，即开始深度学习需要哪些技能和概念。我们将具体回答以下问题:</p>
<ul class="calibre7">
<li class="calibre8">理解和入门深度学习需要哪些技能？</li>
<li class="calibre8">深度学习需要哪些来自线性代数的核心概念？</li>
<li class="calibre8">深度学习系统的实际实现存在哪些硬件要求？</li>
<li class="calibre8">现在有哪些软件框架可以让开发者轻松开发他们的深度学习应用？</li>
<li class="calibre8">如何在AWS等基于云的<strong class="calibre1">图形处理单元</strong> ( <strong class="calibre1"> GPU </strong>)实例上搭建深度学习系统？</li>
</ul>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Basics of linear algebra</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">线性代数基础</h1>
                
            
            
                
<p class="calibre2">让自己建立深度学习所需的最基本技能之一是对线性代数的基本理解。虽然线性代数本身是一个很大的课题，并且完全涵盖它超出了本书的范围，我们将在本章中讨论线性代数的一些重要方面。希望这将让你充分理解一些核心概念，以及它们如何与深度学习方法相互作用。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Data representation</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">数据表示法</h1>
                
            
            
                
<p class="calibre2">在这一节中，我们将看看不同线性代数任务中最常用的核心数据结构和表示。这并不意味着是一个全面的列表，而只是为了突出一些对理解深度学习概念有用的突出表示:</p>
<ul class="calibre7">
<li class="calibre8"><strong class="calibre1">向量</strong>:线性代数中最基本的表示之一就是向量。向量可以定义为一个对象数组，或者更具体地说，一个保持数字顺序的数字数组。基于索引位置，可以在向量中访问每个数字。例如，考虑一个向量<em class="calibre26"> x </em>，包含从1到7编码的一周七天，其中1代表星期天，7代表星期六。使用这种符号，一周中的某一天，比如说星期三，可以通过向量x [4]直接访问:</li>
</ul>
<div><img class="fm-editor-equation" src="img/18f1bdad-1281-4644-83a9-327c0af21889.png"/></div>
<ul class="calibre7">
<li class="calibre8"><strong class="calibre1">矩阵</strong>:这些是数字的二维表示，或者基本上是向量的向量。每个矩阵，<em class="calibre26"> m，</em>由一定数量的行，<em class="calibre26"> r，</em>和一定数量的列，<em class="calibre26"> c </em>组成。每一个<em class="calibre26"> i </em>行，其中<em class="calibre26"> 1 &lt; = i &lt; = r </em>，是一个<em class="calibre26"> c </em>数的向量。每一个<em class="calibre26"> j </em>列，其中<em class="calibre26"> 1 &lt; =j &lt; = c </em>，也是一个<em class="calibre26"> r </em>数的向量。当我们处理图像时，矩阵是一种特别有用的表示。虽然真实世界的图像本质上是三维的，但是大多数计算机视觉问题都集中在图像的二维表示上。因此，矩阵表示是图像的直观表示:</li>
</ul>
<div><img class="fm-editor-equation1" src="img/d5ce6e64-9ced-4722-b3af-0ff2260bd9d8.png"/></div>
<ul class="calibre7">
<li class="calibre8"><strong class="calibre1">单位矩阵</strong>:单位矩阵被定义为一个矩阵，当它与一个向量相乘时，不改变该向量。通常，单位矩阵的所有元素都是0，除了主对角线上的元素都是1:</li>
</ul>
<div><img class="fm-editor-equation2" src="img/707bc9b9-bf52-4a43-9e14-efba00521172.png"/></div>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Data operations</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">数据操作</h1>
                
            
            
                
<p class="calibre2">在这一节中，我们将看看应用于矩阵的一些最常见的变换。</p>
<ul class="calibre7">
<li class="calibre8"><strong class="calibre1">矩阵转置</strong>:矩阵转置是一种矩阵变换，只是沿着矩阵的主对角线镜像矩阵。数学上定义如下:</li>
</ul>
<div><img class="fm-editor-equation3" src="img/43b39a29-5e36-4295-924b-1b2b9dda514e.png"/></div>
<div><img class="fm-editor-equation4" src="img/b287c350-c007-4020-801e-b0ea06ef4964.png"/></div>
<ul class="calibre7">
<li class="calibre8"><strong xmlns:epub="http://www.idpf.org/2007/ops" class="calibre1">矩阵乘法</strong>:矩阵乘法是最基本的运算之一，可以应用于任意两个矩阵。一个矩阵，形状为<em xmlns:epub="http://www.idpf.org/2007/ops" class="calibre26">的<em xmlns:epub="http://www.idpf.org/2007/ops" class="calibre26"> A、</em>A<sub class="calibre34">r</sub>x A<sub class="calibre34">c</sub>T9】可以乘以另一个矩阵，形状为<em xmlns:epub="http://www.idpf.org/2007/ops" class="calibre26">B<sub class="calibre34">r</sub>x B</em><sub xmlns:epub="http://www.idpf.org/2007/ops" class="calibre34"><em class="calibre26">c</em></sub>当且仅当<em xmlns:epub="http://www.idpf.org/2007/ops" class="calibre26">A<sub class="calibre34">c</sub></em><em xmlns:epub="http://www.idpf.org/2007/ops" class="calibre26">= B</em><sub xmlns:epub="http://www.idpf.org/2007/ops" class="calibre34"><em class="calibre26">r</em></sub>合成矩阵，<em xmlns:epub="http://www.idpf.org/2007/ops" class="calibre26"> C，</em>是形状<em xmlns:epub="http://www.idpf.org/2007/ops" class="calibre26">A<sub class="calibre34">r</sub>x</em>B<sub xmlns:epub="http://www.idpf.org/2007/ops" class="calibre34">C</sub>。乘法运算定义如下:</em></li>
</ul>
<div><img class="fm-editor-equation5" src="img/8f96ca9f-c05a-464b-80b2-acbcb5304c15.png"/></div>
<p class="mce-root2">矩阵乘法通常具有非常有用的性质。例如，矩阵乘法是分布式的:</p>
<div><img class="fm-editor-equation6" src="img/5db172a4-e284-4746-a222-3c0aa4ba1e7b.png"/></div>
<p class="calibre2">矩阵乘法也是关联的:</p>
<div><img class="fm-editor-equation7" src="img/9608777b-7ec6-4347-b98c-9d2512c6b265.png"/></div>
<p class="calibre2">矩阵乘法也有一个非常简单的转置形式:</p>
<div><img class="fm-editor-equation8" src="img/cd208cd4-d60d-4222-a9e1-a5dffafc32b7.png"/></div>
<p class="calibre36">矩阵乘法是不可交换的，也就是说<em class="calibre20"> A x B ≠ B x A </em>。然而，两个向量之间的点积是可交换的:</p>
<div><img class="fm-editor-equation9" src="img/54d3f377-f0e8-4c5f-8d50-b668dc5dac39.png"/>      </div>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Matrix properties</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">矩阵属性</h1>
                
            
            
                
<p class="calibre2">在本节中，我们将了解一些对深度学习应用非常有用的重要属性矩阵。</p>
<ul class="calibre7">
<li class="calibre8"><strong xmlns:epub="http://www.idpf.org/2007/ops" class="calibre1">范数</strong>:范数是向量或矩阵的重要性质，度量向量或矩阵的大小。从几何学上讲，它也可以解释为一个点<em xmlns:epub="http://www.idpf.org/2007/ops" class="calibre26"> x </em>到原点的距离。因此，<em xmlns:epub="http://www.idpf.org/2007/ops" class="calibre26">L<sub class="calibre34">p</sub>T47】定额定义如下:</em></li>
</ul>
<div><img class="fm-editor-equation10" src="img/964c657c-9efe-4c9a-b743-5b44af66325c.png"/></div>
<p class="calibre36">虽然可以为各种阶的<em class="calibre20"> p </em>计算范数，但是最广为人知的范数是L1和L <sub class="calibre34"> 2 </sub>范数。L <sub class="calibre34"> 1 </sub>范数通常被认为是稀疏模型的好选择:</p>
<div><img class="fm-editor-equation11" src="img/c316a0e5-2bcd-4ed7-9185-3923065ca37a.png"/></div>
<p class="calibre36">深度学习社区中流行的另一个规范是<kbd class="calibre12">max</kbd>规范，也被称为<em class="calibre20"> L <sup class="calibre37"> ∞ </sup> </em>。这相当于向量中最大元素的值:</p>
<div><img class="fm-editor-equation12" src="img/d5428f1e-3c69-41cf-9c71-081578780364.png"/></div>
<p class="calibre36">到目前为止，前面提到的所有规范都适用于向量。当我们想要计算矩阵的大小时，我们使用<strong class="calibre13"> Frobenius范数</strong>，定义如下:</p>
<div><img class="fm-editor-equation13" src="img/c04d901c-7251-42ad-9d56-0ed5ca61ac44.png"/></div>
<p class="calibre36">通常使用范数，因为它们可以用来直接计算两个向量的点积:</p>
<div><img class="fm-editor-equation14" src="img/c3708023-7ced-40bc-9c3a-5a0db4de0687.png"/></div>
<ul class="calibre7">
<li class="calibre8"><strong class="calibre1"> Trace </strong> : Trace是一个运算符，定义为一个矩阵的所有对角元素之和:</li>
</ul>
<div><img class="fm-editor-equation15" src="img/41aec126-d1bc-4217-856b-5070fc62a9c5.png"/></div>
<p class="calibre36">追踪运算符在计算矩阵的<strong class="calibre13"> Frobenius范数</strong>时非常有用，如下所示:</p>
<div><img class="fm-editor-equation16" src="img/c91376c4-d80b-4540-b7f6-b4ea71afeda3.png"/></div>
<p class="calibre36">跟踪算子的另一个有趣的性质是它对矩阵转置运算是不变的。因此，它通常用于处理矩阵表达式以产生有意义的恒等式:</p>
<div><img class="fm-editor-equation17" src="img/7d31f89d-5a8e-44cb-94e6-c5464f37af59.png"/></div>
<ul class="calibre7">
<li class="calibre8"><strong class="calibre1">行列式</strong>:矩阵的行列式定义为一个标量值，它只是矩阵所有特征值的乘积。它们通常在线性方程组的分析和求解中非常有用。例如，根据克莱姆法则，当且仅当由线性方程组组成的矩阵的行列式不为零时，线性方程组才有唯一解。</li>
</ul>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Deep learning with GPU</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">利用GPU进行深度学习</h1>
                
            
            
                
<p class="calibre2">顾名思义，深度学习包括学习数据的更深层次的表示，这需要大量的计算能力。如此强大的计算能力通常是现代CPU所无法实现的。另一方面，GPU非常适合这项任务。GPU最初是为实时渲染图形而设计的。典型GPU的设计允许不成比例的大量<strong class="calibre13">算术逻辑单元</strong> ( <strong class="calibre13"> ALU </strong>)，这允许它们实时处理大量计算。</p>
<p class="calibre2">用于通用计算的GPU具有高度的数据并行架构，这意味着它们可以并行处理大量数据点，从而提高计算吞吐量。每个GPU都由数千个内核组成。每一个这样的内核都由许多功能单元组成，这些功能单元包含高速缓存和ALU以及其他模块。这些功能单元中的每一个都执行完全相同的指令集，从而允许GPU中的大规模数据并行。在下一节中，我们将比较GPU和CPU的设计。</p>
<p class="calibre2">下表说明了CPU与GPU设计之间的差异。如图所示，GPU被设计为执行大量线程，这些线程被优化为执行相同的控制逻辑。因此，每个GPU核心的设计都相当简单。另一方面，CPU被设计为使用更少的内核运行，但是更通用。它们的基本核心设计可以处理高度复杂的控制逻辑，这在GPU中通常是不可能的。因此，CPU可以被认为是一种商品处理单元，而GPU是一种专用单元:</p>
<table class="calibre27">
<tbody class="calibre28">
<tr class="calibre29">
<td class="calibre30">
<p class="calibre2"><strong class="calibre13"> GPU </strong></p>
</td>
<td class="calibre30">
<p class="calibre2"><strong class="calibre13"> CPU </strong></p>
</td>
</tr>
<tr class="calibre29">
<td class="calibre30">
<p class="calibre2">大量较简单的内核</p>
</td>
<td class="calibre30">
<p class="calibre2">更少数量的复杂内核</p>
</td>
</tr>
<tr class="calibre29">
<td class="calibre30">
<p class="calibre2">更高级别的多线程优化</p>
</td>
<td class="calibre30">
<p class="calibre2">单线程优化</p>
</td>
</tr>
<tr class="calibre29">
<td class="calibre30">
<p class="calibre2">适合专业计算</p>
</td>
<td class="calibre30">
<p class="calibre2">适用于通用计算</p>
</td>
</tr>
</tbody>
</table>
<p class="calibre2">就相对性能比较而言，在执行高数据并行操作时，GPU的延迟比CPU低得多。如果GPU有足够的设备内存来加载峰值负载计算所需的所有数据，情况尤其如此。然而，对于核心数量的直接比较，CPU的延迟要低得多，因为每个CPU核心都要复杂得多，并且具有先进的状态控制逻辑，而不是GPU。</p>
<p class="calibre2">因此，算法的设计与使用GPU和CPU的潜在优势有很大关系。下表列出了适合GPU实现的算法。Erik Smistad和他们的合著者概述了五个不同的因素，这些因素决定了算法对使用GPU的适用性——数据并行性、线程数量、分支分歧、内存使用和同步。</p>
<p class="calibre2">Dutta-Roy的表格<em class="calibre20">影响GPU计算的因素</em>说明了所有这些因素对使用GPU的适用性的影响。如下所示，任何位于<strong class="calibre13">高</strong>列的算法都比其他算法更适合使用GPU:</p>
<div><img src="img/79d2e9ed-a8f2-4fa3-8059-a9f04610fc06.png" class="calibre38"/></div>
<p>影响GPU计算的因素(来源:Dutta Roy等人https://medium . com/@ taposhdr/GPU-s-have-be-the-new-core-for-image-analytics-b 8 ba 8 BD 8d 8 f 3)</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Deep learning hardware guide</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">深度学习硬件指南</h1>
                
            
            
                
<p class="calibre2">在为深度学习应用程序开发设置自己的硬件时，还有一些其他重要的事情需要注意。在本节中，我们将概述GPU计算的一些最重要的方面。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>CPU cores</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">CPU内核</h1>
                
            
            
                
<p class="calibre2">大多数深度学习应用和库都使用单核CPU，除非它们用在并行化框架中，如<strong class="calibre13">消息传递接口</strong> ( <strong class="calibre13"> MPI </strong>)、MapReduce或Spark。例如，雅虎团队的<strong class="calibre13">咖啡馆</strong>(<a href="https://github.com/yahoo/CaffeOnSpark" class="calibre11">https://github.com/yahoo/CaffeOnSpark</a>)使用Spark和Caffe在多个GPU和CPU之间并行化网络训练。在单个盒子中的大多数正常设置中，一个CPU核心足以用于深度学习应用开发。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>
CPU cache size</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">CPU缓存大小</h1>
                
            
            
                
<p class="calibre2">CPU缓存大小是用于高速计算的重要CPU组件。CPU缓存通常以缓存层的层次结构组织，从L1到L4——L1和L2是较小和较快的缓存层，而不是较大和较慢的L3和L4层。在理想设置中，应用程序所需的每个数据都驻留在缓存中，因此不需要从RAM中读取，从而使整体操作更快。</p>
<p class="calibre2">然而，这几乎不是大多数深度学习应用的场景。例如，对于一个批量为128的典型ImageNet实验，我们需要超过85MB的CPU缓存来存储一个小批量的所有信息[13]。因为这样的数据集不够小，不能只缓存，所以无法避免RAM读取。因此，现代CPU缓存大小对深度学习应用程序的性能几乎没有影响。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>RAM size</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">RAM大小</h1>
                
            
            
                
<p class="calibre2">正如我们在本节前面看到的，大多数深度学习应用程序直接从RAM读取，而不是从CPU缓存读取。因此，保持CPU RAM几乎与GPU RAM一样大(如果不是更大的话)通常是明智的。</p>
<p class="calibre2">GPU RAM的大小取决于你的深度学习模型的大小。例如，基于ImageNet的深度学习模型有大量的参数，占用4 GB到5 GB的空间，因此至少具有6 GB RAM的GPU将是这种应用的理想选择。配有至少8 GB或更多CPU RAM的CPU将允许应用程序开发人员专注于应用程序的关键方面，而不是调试RAM性能问题。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Hard drive</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">硬盘驱动器</h1>
                
            
            
                
<p class="calibre2">典型的深度学习应用需要数百GB的大数据集。由于这些数据不能设置在任何RAM中，因此需要构建一个持续的数据管道。深度学习应用程序从GPU RAM加载小批量数据，GPU RAM反过来继续从CPU RAM读取数据，CPU RAM直接从硬盘加载数据。由于GPU拥有大量内核，并且每个内核都有少量数据，因此它们需要不断从磁盘中读取大量数据，以实现高数据并行性。</p>
<p class="calibre2">例如，在基于AlexNet的<strong class="calibre13">卷积神经网络</strong> ( <strong class="calibre13"> CNN </strong>)的模型中，每秒需要读取大约300 MB的数据。这通常会降低应用程序的整体性能。因此，<strong class="calibre13">固态驱动器</strong> ( <strong class="calibre13"> SSD </strong>)往往是大多数深度学习应用开发者的正确选择。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Cooling systems</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">冷却系统</h1>
                
            
            
                
<p class="calibre2">现代的GPU是节能的，并且有内置的机制来防止它们过热。例如，当GPU提高速度和功耗时，它们的温度也会升高。通常在80°C左右，它们内置的温度控制就会启动，这会降低它们的速度，从而自动冷却GPU。这一过程中的真正瓶颈是风扇速度的预编程时间表的不良设计。</p>
<p class="calibre2">在典型的深度学习应用中，在应用的最初几秒钟内达到80°C的温度，从而从一开始就降低了GPU性能，并提供了较差的GPU吞吐量。让事情变得复杂的是，大多数现有的风扇调度选项在当前大多数深度学习应用工作的Linux中不可用。</p>
<p class="calibre2">目前有许多选择可以缓解这个问题。首先，<strong class="calibre13">基本输入/输出系统</strong> ( <strong class="calibre13"> BIOS </strong>)升级并修改风扇计划可以在过热和性能之间提供最佳平衡。用于外部冷却系统的另一种选择，例如水冷系统。但是，此选项主要适用于运行多个GPU服务器的GPU场。外部冷却系统也有点贵，因此成本也成为为您的应用选择合适的冷却系统的一个重要因素。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Deep learning software frameworks</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">深度学习软件框架</h1>
                
            
            
                
<p class="calibre2">每个好的深度学习应用程序都需要有几个组件才能正确运行。其中包括:</p>
<ul class="calibre7">
<li class="calibre8">模型层，允许开发者更灵活地设计他或她自己的模型</li>
<li class="calibre8">一个GPU层，使应用程序开发人员可以无缝地在GPU/CPU之间为其应用程序进行选择</li>
<li class="calibre8">一个并行化层，允许开发人员扩展他或她的应用程序，以便在多个设备或实例上运行</li>
</ul>
<p class="calibre2">可以想象，实现这些模块并不容易。通常，开发人员需要花更多的时间来调试实现问题，而不是合法的模型问题。令人欣慰的是，当今行业中存在许多软件框架，这使得深度学习应用程序开发几乎成为其编程语言的第一类。</p>
<p class="calibre2">这些框架在架构、设计和特性上各不相同，但几乎所有的框架都为开发者提供了巨大的价值，为他们的应用程序提供了简单快速的实现框架。在这一部分，我们将了解一些流行的深度学习软件框架，以及它们之间的比较。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>TensorFlow – a deep learning library</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">tensor flow——深度学习库</h1>
                
            
            
                
<p class="calibre2"><strong class="calibre13"> TensorFlow </strong>是一个使用数据流图进行数值计算的开源软件库。TensorFlow由Google设计和开发，将完整的数据计算表示为流图。该图中的每个节点都可以表示为一个数学运算符。连接两个节点的边表示在两个节点之间流动的多维数据。</p>
<p class="calibre2">TensorFlow的主要优势之一是它支持CPU和GPU以及移动设备，从而使开发人员几乎可以无缝地针对任何设备架构编写代码。TensorFlow还有一个非常大的开发人员社区，为这个框架提供了巨大的推动力。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Caffe</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">咖啡</h1>
                
            
            
                
<p class="calibre2">Caffe是在<strong class="calibre13">伯克利人工智能研究</strong> ( <strong class="calibre13"> BAIR </strong>)实验室设计开发的。它的设计考虑了表达、速度和模块化。它有一个富有表现力的架构，因为它允许一种非常可配置的方式来定义模型和优化参数，而不需要任何额外的代码。这种配置还允许从CPU模式轻松切换到GPU模式，反之亦然，只需更改一个标志。</p>
<p class="calibre2">在速度方面，Caffe也拥有良好的性能基准数据。例如，在一个NVIDIA K40 GPU上，Caffe每天可以处理超过6000万张图像。Caffe还有一个强大的社区，从学术研究人员到工业研究实验室都在使用Caffe，跨越不同的应用程序堆栈。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>MXNet</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">MXNet</h1>
                
            
            
                
<p class="calibre2"><strong class="calibre13"> MXNet </strong>是一个多语言的机器学习库。它提供了两种计算模式:</p>
<ul class="calibre7">
<li class="calibre8">命令模式:这种模式公开了一个接口，很像常规的NumPy，比如API。例如，要使用MXNet在CPU和GPU上构造零张量，可以使用以下代码块:</li>
</ul>
<pre class="prettyprint1">import mxnet as mx
tensor_cpu = mx.nd.zeros((100,), ctx=mx.cpu())
tensor_gpu = mx.nd.zeros((100,), ctx=mx.gpu(0))<br class="title-page-name"/></pre>
<p class="calibre36">在前面的例子中，MXNet指定了在CPU或GPU设备的位置<kbd class="calibre12">0</kbd>保存张量的位置。MXNet的一个重要区别是所有的计算都是延迟发生的，而不是瞬间发生的。这使得MXNet实现了令人难以置信的设备利用率，不同于其他任何框架。</p>
<ul class="calibre7">
<li class="calibre8"><strong class="calibre1">符号模式</strong>:该模式公开了一个类似TensorFlow的计算图。尽管命令式API非常有用，但它的一个缺点是过于死板。所有计算都需要事先知道，以及预定义的数据结构。符号API旨在通过允许MXNet使用符号或变量而不是固定数据类型来消除这种限制。然后，这些符号可以被编译或解释为一组操作来执行，如下所示:</li>
</ul>
<pre class="prettyprint1">import mxnet as mx
x = mx.sym.Variable("X") # represent a symbol.
y = mx.sym.Variable("Y")
z = (x + y)
m = z / 100</pre>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Torch</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">火炬</h1>
                
            
            
                
<p class="calibre2"><strong class="calibre13"> Torch </strong>是一个基于Lua的深度学习框架，由Ronan Collobert、Clement Farabet和Koray Kavukcuoglu开发。它最初由纽约大学的CILVR实验室使用。Torch由C/C++库提供支持，并使用<strong class="calibre13">计算统一设备架构</strong> ( <strong class="calibre13"> CUDA </strong>)进行GPU交互。它旨在成为最快的深度学习框架，同时还为快速应用开发提供简单的类似C的接口。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Theano</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">Theano</h1>
                
            
            
                
<p class="calibre2"><strong class="calibre13"> Theano </strong>是一个Python库，它允许您高效地定义、优化和评估涉及多维数组的数学表达式。Theano的一些关键特性是它与NumPy的紧密集成，这使得它几乎成为大量Python开发人员的母语。它还提供了一个非常直观的界面来使用GPU或CPU。它有一个<em class="calibre20">有效的符号微分</em>，允许它为具有一个或多个输入的函数提供导数。它在数值上也是稳定的，并且具有动态代码生成能力，从而导致更快的表达式求值。如果你有先进的机器学习专业知识，并且正在寻找一个低级别的API来细粒度控制你的深度学习应用程序，那么Theano是一个很好的框架选择。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Microsoft Cognitive Toolkit</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">微软认知工具包</h1>
                
            
            
                
<p class="calibre2"><strong class="calibre13">微软认知工具包</strong>又称<strong class="calibre13">CNTK</strong>；这是不断增加的深度学习框架集的最新条目。CNTK支持两个主要功能:</p>
<ul class="calibre7">
<li class="calibre8">支持多种功能，例如:<ul class="calibre23">
<li class="calibre8">用于训练和预测的CPU/GPU</li>
<li class="calibre8">Windows和Linux操作系统</li>
<li class="calibre8">通过批处理技术进行有效的循环网络训练</li>
<li class="calibre8">使用一位量化的<strong class="calibre1">奇异值分解</strong> ( <strong class="calibre1"> SVD </strong>)的数据并行化</li>
</ul>
</li>
<li class="calibre8">高效的模块化设计可分离:<ul class="calibre23">
<li class="calibre8">计算机网络</li>
<li class="calibre8">执行引擎</li>
<li class="calibre8">学习算法</li>
<li class="calibre8">模型配置</li>
</ul>
</li>
</ul>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Keras</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">克拉斯</h1>
                
            
            
                
<p class="calibre2">Keras是一个深度学习框架，可能是与之前描述的所有其他框架最不同的。大多数描述的框架都是使用CUDA直接与GPU交互的低级模块。</p>
<p class="calibre2">另一方面，Keras可以被理解为一个元框架，它与其他框架(如Theano或TensorFlow)进行交互，以处理其GPU交互或其他系统级访问管理。因此，它非常灵活，非常用户友好，允许开发人员从各种底层模型实现中进行选择。Keras社区支持也获得了良好的势头，截至2017年9月，TensorFlow团队计划将Keras作为TensorFlow项目的子集进行集成。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Framework comparison</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">框架比较</h1>
                
            
            
                
<p class="calibre2">尽管存在许多深度学习软件框架，但很难理解它们的功能对等性。表格<em class="calibre20">描述了DL框架的特性奇偶校验</em>概述了这些框架的特性奇偶校验:</p>
<table class="calibre27">
<tbody class="calibre28">
<tr class="calibre29">
<td class="calibre30"/>
<td class="calibre30">
<p class="calibre2"><strong class="calibre13">语言</strong></p>
</td>
<td class="calibre30">
<p class="calibre2"><strong class="calibre13">社区支持</strong></p>
</td>
<td class="calibre30">
<p class="calibre2"><strong class="calibre13">建模灵活性</strong></p>
</td>
<td class="calibre30">
<p class="calibre2"><strong class="calibre13">简单配置</strong></p>
</td>
<td class="calibre30">
<p class="calibre2"><strong class="calibre13">速度</strong></p>
</td>
<td class="calibre30">
<p class="calibre2"><strong class="calibre13"> GPU并行化</strong></p>
</td>
<td class="calibre30">
<p class="calibre2"><strong class="calibre13">教程</strong></p>
</td>
</tr>
<tr class="calibre29">
<td class="calibre30">
<p class="calibre2">张量流</p>
</td>
<td class="calibre30">
<p class="calibre2">计算机编程语言</p>
</td>
<td class="calibre30">
<p class="calibre2">优秀的</p>
</td>
<td class="calibre30">
<p class="calibre2">优秀的</p>
</td>
<td class="calibre30">
<p class="calibre2">优秀的</p>
</td>
<td class="calibre30">
<p class="calibre2">强烈的</p>
</td>
<td class="calibre30">
<p class="calibre2">强烈的</p>
</td>
<td class="calibre30">
<p class="calibre2">优秀的</p>
</td>
</tr>
<tr class="calibre29">
<td class="calibre30">
<p class="calibre2">咖啡</p>
</td>
<td class="calibre30">
<p class="calibre2">C++</p>
</td>
<td class="calibre30">
<p class="calibre2">优秀的</p>
</td>
<td class="calibre30">
<p class="calibre2">强烈的</p>
</td>
<td class="calibre30">
<p class="calibre2">强烈的</p>
</td>
<td class="calibre30">
<p class="calibre2">强烈的</p>
</td>
<td class="calibre30">
<p class="calibre2">好的</p>
</td>
<td class="calibre30">
<p class="calibre2">强烈的</p>
</td>
</tr>
<tr class="calibre29">
<td class="calibre30">
<p class="calibre2">MXNet</p>
</td>
<td class="calibre30">
<p class="calibre2">r，Python，Julia，Scala</p>
</td>
<td class="calibre30">
<p class="calibre2">优秀的</p>
</td>
<td class="calibre30">
<p class="calibre2">强烈的</p>
</td>
<td class="calibre30">
<p class="calibre2">强烈的</p>
</td>
<td class="calibre30">
<p class="calibre2">强烈的</p>
</td>
<td class="calibre30">
<p class="calibre2">优秀的</p>
</td>
<td class="calibre30">
<p class="calibre2">优秀的</p>
</td>
</tr>
<tr class="calibre29">
<td class="calibre30">
<p class="calibre2">火炬</p>
</td>
<td class="calibre30">
<p class="calibre2">Lua，Python</p>
</td>
<td class="calibre30">
<p class="calibre2">强烈的</p>
</td>
<td class="calibre30">
<p class="calibre2">优秀的</p>
</td>
<td class="calibre30">
<p class="calibre2">优秀的</p>
</td>
<td class="calibre30">
<p class="calibre2">优秀的</p>
</td>
<td class="calibre30">
<p class="calibre2">强烈的</p>
</td>
<td class="calibre30">
<p class="calibre2">强烈的</p>
</td>
</tr>
<tr class="calibre29">
<td class="calibre30">
<p class="calibre2">Theano</p>
</td>
<td class="calibre30">
<p class="calibre2">Python，C++</p>
</td>
<td class="calibre30">
<p class="calibre2">强烈的</p>
</td>
<td class="calibre30">
<p class="calibre2">强烈的</p>
</td>
<td class="calibre30">
<p class="calibre2">好的</p>
</td>
<td class="calibre30">
<p class="calibre2">强烈的</p>
</td>
<td class="calibre30">
<p class="calibre2">好的</p>
</td>
<td class="calibre30">
<p class="calibre2">优秀的</p>
</td>
</tr>
<tr class="calibre29">
<td class="calibre30">
<p class="calibre2">CNTK</p>
</td>
<td class="calibre30">
<p class="calibre2">C++</p>
</td>
<td class="calibre30">
<p class="calibre2">优秀的</p>
</td>
<td class="calibre30">
<p class="calibre2">强烈的</p>
</td>
<td class="calibre30">
<p class="calibre2">好的</p>
</td>
<td class="calibre30">
<p class="calibre2">强烈的</p>
</td>
<td class="calibre30">
<p class="calibre2">好的</p>
</td>
<td class="calibre30">
<p class="calibre2">强烈的</p>
</td>
</tr>
<tr class="calibre29">
<td class="calibre30">
<p class="calibre2">克拉斯</p>
</td>
<td class="calibre30">
<p class="calibre2">计算机编程语言</p>
</td>
<td class="calibre30">
<p class="calibre2">优秀的</p>
</td>
<td class="calibre30">
<p class="calibre2">优秀的</p>
</td>
<td class="calibre30">
<p class="calibre2">优秀的</p>
</td>
<td class="calibre30">
<p class="calibre2">强烈的</p>
</td>
<td class="calibre30">
<p class="calibre2">强烈的</p>
</td>
<td class="calibre30">
<p class="calibre2">强烈的</p>
</td>
</tr>
</tbody>
</table>
<p>DL框架的功能对等</p>
<p class="calibre2">最近，石少怀和他们的合著者在他们的论文(<a href="https://arxiv.org/pdf/1608.07249.pdf" class="calibre11">的</a>)中也提出了一个全面的性能基准测试，测试了四个流行的框架:Caffe、CNTK、TensorFlow和Torch。他们首先在三种最流行的神经网络类型上对这些框架的性能进行基准测试，这三种神经网络是:<strong class="calibre13">全连接神经网络</strong> ( <strong class="calibre13"> FCN </strong>)、CNN和递归神经网络(RNN)。他们还在使用多个GPU和CPU时对这些系统的性能进行了基准测试。</p>
<p class="calibre2">在他们的论文中，他们概述了所有系统的比较性能。他们的实验结果表明，所有框架都可以非常有效地利用GPU，并显示出优于CPU的性能增益。然而，在所有这些框架中仍然没有明显的赢家，这表明所有这些框架仍然需要改进。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Setting up deep learning on AWS</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">在AWS上设置深度学习</h1>
                
            
            
                
<p class="calibre2">在本节中，我们将展示使用<strong class="calibre13">亚马逊网络服务</strong> ( <strong class="calibre13"> AWS </strong>)建立深度学习系统的两种不同方式。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Setup from scratch</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">从头开始设置</h1>
                
            
            
                
<p class="calibre2">在本节中，我们将说明如何在运行Ubuntu Server 16.04 LTS的AWS EC2 GPU实例g2.2xlarge上设置深度学习环境。对于这个例子，我们将使用一个预烤的<strong class="calibre13">亚马逊机器映像</strong> ( <strong class="calibre13"> AMI </strong>)，它已经安装了许多软件包——这使得建立一个端到端的深度学习系统更加容易。我们将使用一个公开可用的AMI映像ami-b03ffedf，它有以下预安装的包:</p>
<ul class="calibre7">
<li class="calibre22">CUDA 8.0</li>
<li class="calibre22">使用Python 3.0的Anaconda 4.20</li>
<li class="calibre22">喀拉斯/泰阿诺</li>
</ul>
<ol class="calibre15">
<li class="calibre8">设置系统的第一步是设置一个AWS帐户，并使用AWS web控制台旋转一个新的EC2 GPU实例，如图<a href="https://signin.aws.amazon.com/signin?redirect_uri=https%3A%2F%2Fconsole.aws.amazon.com%2Fconsole%2Fhome%3Fstate%3DhashArgs%2523%26isauthcode%3Dtrue&amp;client_id=arn%3Aaws%3Aiam%3A%3A015428540659%3Auser%2Fhomepage&amp;forceMobileApp=0" target="_blank" class="calibre11">http://console.aws.amazon.com/</a>所示<em class="calibre26">选择EC2 AMI </em>:</li>
</ol>
<div><img class="alignnone16" src="img/f4c3a68f-9616-44ad-8f20-a94988a97f12.png"/></div>
<p>选择EC2 AMI</p>
<ol start="2" class="calibre15">
<li class="calibre8">我们从下一页选择一个g2.2xlarge实例类型，如图<em class="calibre26">选择实例类型</em>:</li>
</ol>
<div><img class="alignnone17" src="img/35d88df4-3135-4443-8990-59ba469c66c7.png"/></div>
<p>选择实例类型</p>
<ol start="3" class="calibre15">
<li class="calibre8">在添加了如图所示的<kbd class="calibre12">30</kbd> GB存储后<em class="calibre26">选择存储</em>，我们现在启动一个群集并分配一个EC2密钥对，该密钥对允许我们<kbd class="calibre12">ssh</kbd>使用提供的密钥对文件登录到机器:</li>
</ol>
<div><img class="alignnone18" src="img/f3aa4585-327c-43b0-a7b8-5923d3f6a669.png"/></div>
<p>选择存储</p>
<ol start="4" class="calibre15">
<li class="calibre8">一旦EC2盒子启动，下一步就是安装相关的软件包。为了确保正确利用GPU，确保首先安装图形驱动程序非常重要。我们将升级并安装NVIDIA驱动程序，如下所示:</li>
</ol>
<pre class="prettyprint1"><strong class="calibre1">$ sudo add-apt-repository ppa:graphics-drivers/ppa -y</strong><br class="title-page-name"/><strong class="calibre1">$ sudo apt-get update</strong><br class="title-page-name"/><strong class="calibre1">$ sudo apt-get install -y nvidia-375 nvidia-settings</strong></pre>
<p class="calibre2">虽然NVIDIA驱动程序确保主机GPU现在可以被任何深度学习应用程序利用，但它并没有为应用程序开发人员提供一个简单的接口，以便在设备上轻松编程。</p>
<p class="calibre2">现在有各种不同的软件库帮助可靠地完成这项任务。<strong class="calibre13">开放计算语言</strong> ( <strong class="calibre13"> OpenCL </strong>)和CUDA是工业上比较常用的。在本书中，我们使用CUDA作为访问NVIDIA图形驱动程序的应用程序编程接口。要安装CUDA驱动程序，我们首先SSH到EC2实例，并将CUDA 8.0下载到我们的<kbd class="calibre12">$HOME</kbd>文件夹，然后从那里安装:</p>
<pre class="calibre21"><strong class="calibre1">$ wget https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb</strong><br class="title-page-name"/><strong class="calibre1">$ sudo dpkg -i cuda-repo-ubuntu1604-8-0-local_8.0.44-1_amd64-deb</strong><br class="title-page-name"/><strong class="calibre1">$ sudo apt-get update</strong><br class="title-page-name"/><strong class="calibre1">$ sudo apt-get install -y cuda nvidia-cuda-toolkit</strong></pre>
<p class="calibre2">安装完成后，您可以运行以下命令来验证安装:</p>
<pre class="calibre21"><strong class="calibre1">$ nvidia-smi</strong></pre>
<p class="calibre2">现在，您的EC2盒子已经完全配置好，可以用于深度学习开发。然而，对于不太熟悉深度学习实现细节的人来说，从头构建深度学习系统可能是一项艰巨的任务。</p>
<p class="calibre2">为了简化这种开发，存在许多先进的深度学习软件框架，如Keras和Theano。这两个框架都基于Python开发环境，因此我们首先在机器上安装一个Python发行版，比如Anaconda:</p>
<pre class="calibre21"><strong class="calibre1">$ wget https://repo.continuum.io/archive/Anaconda3-4.2.0-Linux-x86_64.sh</strong><br class="title-page-name"/><strong class="calibre1">$ bash Anaconda3-4.2.0-Linux-x86_64.sh</strong></pre>
<p class="calibre2">最后，使用Python的包管理器<kbd class="calibre12">pip</kbd>安装Keras和Theanos:</p>
<pre class="calibre21"><strong class="calibre1">$ pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git</strong><br class="title-page-name"/><strong class="calibre1">$ pip install keras</strong></pre>
<p class="calibre2">一旦成功完成了<kbd class="calibre12">pip</kbd>的安装，这个盒子现在就完全可以进行深度学习开发了。</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Setup using Docker</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">使用Docker设置</h1>
                
            
            
                
<p class="calibre2">前一节描述了从零开始，这有时会很棘手，因为软件包和网络链接会不断变化。避免依赖链接的一个方法是使用Docker这样的容器技术。</p>
<p class="calibre2">在本章中，我们将使用NVIDIA-Docker官方映像，该映像预打包了所有必要的包和深度学习框架，以帮助您快速开始深度学习应用开发:</p>
<pre class="calibre21"><strong class="calibre1">$ sudo add-apt-repository ppa:graphics-drivers/ppa -y</strong><br class="title-page-name"/><strong class="calibre1">$ sudo apt-get update</strong><br class="title-page-name"/><strong class="calibre1">$ sudo apt-get install -y nvidia-375 nvidia-settings nvidia-modprobe</strong></pre>
<ol class="calibre15">
<li class="calibre8">我们现在安装Docker社区版如下:</li>
</ol>
<pre class="prettyprint1"><strong class="calibre1">$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -</strong><br class="title-page-name"/><strong class="calibre1"># Verify that the key fingerprint is 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88</strong><br class="title-page-name"/><strong class="calibre1">$ sudo apt-key fingerprint 0EBFCD88</strong><br class="title-page-name"/><strong class="calibre1">$ sudo add-apt-repository \</strong><br class="title-page-name"/><strong class="calibre1">  "deb [arch=amd64] https://download.docker.com/linux/ubuntu \</strong><br class="title-page-name"/><strong class="calibre1">  $(lsb_release -cs) \</strong><br class="title-page-name"/><strong class="calibre1">  stable"</strong><br class="title-page-name"/><strong class="calibre1">$ sudo apt-get update</strong><br class="title-page-name"/><strong class="calibre1">$ sudo apt-get install -y docker-ce</strong></pre>
<ol start="2" class="calibre15">
<li class="calibre8">然后我们安装NVIDIA-Docker及其插件:</li>
</ol>
<pre class="prettyprint1"><strong class="calibre1">$ wget -P /tmp https://github.com/NVIDIA/nvidia-docker/releases/download/v1.0.1/nvidia-docker_1.0.1-1_amd64.deb</strong><br class="title-page-name"/><strong class="calibre1">$ sudo dpkg -i /tmp/nvidia-docker_1.0.1-1_amd64.deb &amp;&amp; rm /tmp/nvidia-docker_1.0.1-1_amd64.deb</strong></pre>
<ol start="3" class="calibre15">
<li class="calibre8">为了验证安装是否正确，我们使用以下命令:</li>
</ol>
<pre class="prettyprint1"><strong class="calibre1">$ sudo nvidia-docker run --rm nvidia/cuda nvidia-smi</strong></pre>
<ol start="4" class="calibre15">
<li class="calibre8">一旦设置正确，我们就可以使用官方TensorFlow或Theano Docker图像:</li>
</ol>
<pre class="prettyprint1"><strong class="calibre1">$ sudo nvidia-docker run -it tensorflow/tensorflow:latest-gpu bash</strong></pre>
<ol start="5" class="calibre15">
<li class="calibre8">我们可以运行一个简单的Python程序来检查TensorFlow是否正常工作:</li>
</ol>
<pre class="prettyprint1"><strong class="calibre1">import tensorflow as tf</strong><br class="title-page-name"/><strong class="calibre1">a = tf.constant(5, tf.float32)</strong><br class="title-page-name"/><strong class="calibre1">b = tf.constant(5, tf.float32)</strong><br class="title-page-name"/><strong class="calibre1">with tf.Session() as sess:</strong><br class="title-page-name"/><strong class="calibre1">   sess.run(tf.add(a, b)) # output is 10.0<br class="title-page-name"/>   print("Output of graph computation is = ",output)<br class="title-page-name"/></strong></pre>
<p class="calibre2">您现在应该在屏幕上看到TensorFlow输出，如图<em class="calibre20">所示Tensorflow示例输出:</em></p>
<div><img class="alignnone19" src="img/fb7403d8-3f3d-44b5-889c-761fa4e08c1a.png"/></div>
<p>张量流样本输出</p>


            

            
        
    </body>

</html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Summary</title>
    <meta content="urn:uuid:3fd593c7-d9c4-4d18-84e8-0b6efc257c5b" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body class="calibre">
        

                            
                    <h1 class="header-title">摘要</h1>
                
            
            
                
<p class="calibre2">在这一章中，我们总结了开始实现深度学习系统所需的关键概念。我们描述了线性代数的核心概念，这些概念对于理解深度学习技术的基础至关重要。我们提供了深度学习的硬件指南，涵盖了基于GPU的实现的各个方面，以及对应用程序开发人员来说什么是正确的硬件选择。我们概述了当今最流行的深度学习软件框架的列表，并为它们提供了功能级别的对等性以及性能基准。最后，我们演示了如何在AWS上设置基于云的深度学习应用。</p>
<p class="calibre2">在下一章中，我们将介绍神经网络，并概述一个自启动模块，以便更详细地理解它们。</p>


            

            
        
    </body>

</html>
</body></html>