<title>C13550_02_EPUB_Final_SW</title>

# *第二章*

# 计算机视觉简介

## 学习目标

本章结束时，您将能够:

*   解释人工智能和计算机视觉的影响
*   部署一些基本的计算机视觉算法
*   开发一些基本的机器学习算法
*   构建你的第一个神经网络

本章介绍了计算机视觉，然后是一些重要的基本计算机视觉和机器学习算法。

## 简介

**人工智能** ( **AI** )正在改变一切。它试图模仿人类的智能，以完成不同的任务。

人工智能中处理图像的部分被称为计算机视觉。计算机视觉是一个跨学科的科学领域，试图模仿人类的眼睛。它不仅对从图像中提取的像素有意义，而且通过执行自动化任务和使用算法，从特定图像中获得更高层次的理解。

其中一些算法在物体识别、人脸识别、图像分类、图像编辑甚至生成图像方面更胜一筹。

本章将从计算机视觉的介绍开始，从一些最基本的算法和一个将它们付诸实践的练习开始。稍后将介绍机器学习，从最基本的算法到神经网络，涉及几个练习来加强所学的知识。

## 计算机视觉中的基本算法

在这个主题中，我们将讨论图像是如何形成的。我们将介绍一个对执行计算机视觉任务非常有用的库，我们将了解这些任务和算法的工作原理，以及如何对它们进行编码。

### 图像术语

为了理解计算机视觉，我们首先需要知道图像是如何工作的，以及计算机是如何解释它们的。

计算机将图像理解为一组组合在一起的数字。更具体地说，图像被视为一个二维数组，一个包含从 0 到 255 的值的矩阵(在灰度图像中，0 代表黑色，255 代表白色)，表示图像的像素值(**像素值**)，如下例所示:

![Figure 2.1: Image representation without and with pixel values](img/C13550_02_01.jpg)

###### 图 2.1:没有和有像素值的图像表示

在左侧的图像中，数字 3 以低分辨率显示。在右侧，显示了相同的图像以及每个像素的值。该值越大，显示的颜色越亮，如果该值越小，颜色越暗。

这个特殊的图像是灰度的，这意味着它只是一个从 0 到 255 的二维数组，但是彩色图像呢？彩色图像(或红/绿/蓝(RGB)图像)具有堆叠在一起的三层二维阵列。每一层代表一种颜色，把它们放在一起就形成了一幅彩色图像。

前面的图像矩阵中有 14x14 个像素。在灰度中，它表示为 14x14x1，因为它只有一个矩阵和一个通道。对于 RGB 格式，表示为 14×14×3，因为它有 3 个通道。由此，计算机需要理解的只是图像来自这些像素。

### OpenCV

OpenCV 是一个开源的计算机视觉库，具有 C++、Python 和 Java 接口，支持 Windows、Linux、macOS、iOS 和 Android。

对于本章提到的所有算法，我们将使用 OpenCV。OpenCV 帮助我们使用 Python 执行这些算法。如果你想练习这些算法中的一种，我们推荐使用 Google Colab。您需要安装 Python 3.5 或更高版本、OpenCV 和 NumPy 来继续本章。为了在我们的屏幕上显示它们，我们将使用 Matplotlib。这两个都是很棒的人工智能库。

### 基本图像处理算法

为了让计算机理解图像，必须首先对图像进行处理。有许多算法可用于处理图像，输出取决于手头的任务。

一些最基本的算法是:

*   阈值处理
*   形态转换
*   模糊

### 阈值处理

**阈值**通常用于简化计算机和用户对图像的可视化，以使分析更容易。它基于用户设置的值，并且根据每个像素的值是高于还是低于设置值，将每个像素转换为白色或黑色。如果图像是灰度，输出图像将是白色和黑色，但如果您选择保持图像的 RGB 格式，阈值将应用于每个通道，这意味着它仍将输出彩色图像。

阈值处理有不同的方法，以下是一些最常用的方法:

1.  **Simple Thresholding:** If the pixel value is lower than the threshold set by the user, this pixel will be assigned a 0 value (black), or 255 (white). There are also different styles of thresholding within simple thresholding:

    阈值二进制

    阈值二进制反转

    缩短

    阈值为零

    阈值反转至零

    不同类型的阈值如图 2.2 所示

    ![Figure 2.2: Different types of thresholds](img/C13550_02_02.jpg)

    ###### 图 2.2:不同类型的阈值

    阈值二进制反转的工作方式类似于二进制，但黑色的像素是白色的，反之亦然。全局阈值化是简单阈值化下的二进制阈值化的另一个名称。

    如果像素高于阈值和像素值，则截断显示阈值的精确值。

    如果像素值高于阈值，阈值到零输出像素值(这是像素的实际值)，否则它将输出黑色图像，而阈值到零反转则正好相反。

    #### 注意

    可以根据图像或用户想要达到的目的来修改阈值。

2.  **Adaptive Thresholding**: Simple thresholding uses a global value as the threshold. If the image has different lighting conditions in some parts, the algorithm does not perform that well. In such cases, adaptive thresholding automatically guesses different threshold values for different regions within the image, giving us a better overall result with varying lighting conditions.

    有两种类型的自适应阈值处理:

    自适应均值阈值

    自适应高斯阈值

    自适应阈值和简单阈值之间的区别如图 2.3 所示

    ![Figure 2.3: Difference between adaptive thresholding and simple thresholding](img/C13550_02_03.jpg)

    ###### 图 2.3:自适应阈值和简单阈值的区别

    在自适应均值阈值处理中，阈值是邻域面积的均值，而在自适应高斯阈值处理中，阈值是邻域值的加权和，其中权重是高斯窗口。

3.  **Ots u 的二值化:**在全局阈值化中，我们使用任意值来分配阈值。考虑双峰图像(像素分布在两个主要区域的图像)。你会如何选择正确的值？Otsu 的二值化从双峰图像的图像直方图中自动计算阈值。**图像直方图**是[直方图](https://en.wikipedia.org/wiki/Histogram)的一种，作为[数字图像](https://en.wikipedia.org/wiki/Digital_image)中[色调](https://en.wikipedia.org/wiki/Lightness_(color))分布的[图形表示:](https://en.wikipedia.org/wiki/Graphical_representation)

![Figure 2.4: Otsu’s thresholding](img/C13550_02_04.jpg)

###### 图 2.4: Otsu 的阈值处理

### 对图像应用不同的阈值

#### 注意

由于我们是在 Google Colab 上训练人工神经网络，所以应该使用 Google Colab 提供给我们的 GPU。为了做到这一点，我们必须去`runtime > Change runtime type > Hardware accelerator: GPU > Save`。

所有的练习和活动将主要在谷歌 Colab 开发。建议为不同的作业保留一个单独的文件夹，除非有人建议不要这样做。

GitHub 上的 Lesson02 | Activity02 文件夹中提供了`Dataset`文件夹。

在本练习中，我们将加载一幅地铁图像，并对其应用阈值处理:

1.  打开你的 Google Colab 界面。
2.  为书创建一个文件夹，从 GitHub 下载`Dataset`文件夹，上传到文件夹里。
3.  Import the drive and mount it as follows:

    ```
    from google.colab import drive
    drive.mount('/content/drive')
    ```

    #### 注意

    每次使用新的 collaborator 时，将驱动器安装到所需的文件夹中。

    一旦你第一次安装了你的硬盘，你将不得不输入授权码，你将通过点击谷歌给出的网址并按下键盘上的 **Enter** 键来获得授权码:

    ![Figure 2.5: Image displaying the Google Colab authorization step](img/C13550_02_05.jpg)

    ###### 图 2.5:显示 Google Colab 授权步骤的图像

4.  Now that you have mounted the drive, you need to set the path of the directory:

    ```
    cd /content/drive/My Drive/C13550/Lesson02/Exercise04/
    ```

    #### 注意

    根据您在 Google Drive 上的文件夹设置，第 5 步中提到的路径可能会有所变化。路径总是以`cd /content/drive/My Drive/`开始。

    `Dataset`文件夹必须在你设置的路径中。

5.  现在您需要导入相应的依赖项:OpenCV `cv2`和 Matplotlib:

    ```
    import cv2 from matplotlib import pyplot as plt
    ```

6.  现在键入代码来加载`subway.jpg`图像，我们将使用 OpenCV 对其进行灰度处理，并使用 Matplotlib 显示:

    #### 注意

    ```
    img = cv2.imread('subway.jpg',0) plt.imshow(img,cmap='gray') plt.xticks([]),plt.yticks([]) plt.show()
    ```

    ![Figure 2.6: Result of plotting the loaded subway image](img/C13550_02_06.jpg)

    ###### 图 2.6:绘制加载的地铁图像的结果

7.  Let's apply simple thresholding by using OpenCV methods.

    OpenCV 中这样做的方法称为 **cv2.threshold** ，它有三个参数: **image** (灰度)、 **threshold value** (用于对像素值进行分类)和 **maxVal** ，后者表示像素值大于(有时小于)阈值时要给出的值:

    ```
    _,thresh1 = cv2.threshold(img,107,255,cv2.THRESH_BINARY)
    _,thresh2 = cv2.threshold(img,107,255,cv2.THRESH_BINARY_INV) 
    _,thresh3 = cv2.threshold(img,107,255,cv2.THRESH_TRUNC) 
    _,thresh4 = cv2.threshold(img,107,255,cv2.THRESH_TOZERO)
    _,thresh5 = cv2.threshold(img,107,255,cv2.THRESH_TOZERO_INV) 
    titles = ['Original Image','BINARY', 'BINARY_INV', 'TRUNC','TOZERO','TOZERO_INV']
    images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]
    for i in range(6):
        plt.subplot(2,3,i+1),plt.imshow(images[i],'gray')
        plt.title(titles[i])
        plt.xticks([]),plt.yticks([])
    plt.show()
    ```

    ![Figure 2.7: Simple thresholding using OpenCV](img/C13550_02_07.jpg)

    ###### 图 2.7:使用 OpenCV 的简单阈值处理

8.  We are going to do the same with adaptive thresholding.

    这样做的方法是 **cv2.adaptiveThreshold** ，它有三个特殊的输入参数，只有一个输出参数。自适应方法、块大小(邻域的大小)和 C(从计算的平均值或加权平均值中减去的常数)是输入，而您仅获得阈值图像作为输出。这与全局阈值不同，全局阈值有两个输出:

    ```
    th2=cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,71,7)
    th3=cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,71,7)
    titles = ['Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']
    images = [th2, th3]
    for i in range(2):
        plt.subplot(1,2,i+1),plt.imshow(images[i],'gray')
        plt.title(titles[i])
        plt.xticks([]),plt.yticks([])
    plt.show()
    ```

    ![Figure 2.8: Adaptive thresholding using OpenCV](img/C13550_02_08.jpg)

    ###### 图 2.8:使用 OpenCV 的自适应阈值处理

9.  最后，让我们将 Otsu 的二值化付诸实践。
10.  该方法与简单阈值处理 **cv2.threshold** 相同，但具有额外的标志 **cv2。阈值 _OTU** :

    ```
    ret2,th=cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU) titles = ['Otsu\'s Thresholding'] images = [th] for i in range(1):     plt.subplot(1,1,i+1),plt.imshow(images[i],'gray')     plt.title(titles[i])     plt.xticks([]),plt.yticks([]) plt.show()
    ```

![Figure 2.9: Otsu’s binarization using OpenCV](img/C13550_02_09.jpg)

###### 图 2.9:使用 OpenCV 的 Otsu 二值化

现在，您可以对任何图像应用不同的阈值转换。

### 形态变换

形态变换由一组基于图像形状的简单图像操作组成，通常用于二值图像。它们通常用于将文本与背景或任何其他形状区分开来。它们需要两个输入，一个是原始图像，另一个被称为**结构化元素**或**内核**，它决定了操作的性质。**内核**通常是一个在图像中滑动的矩阵，将它的值乘以图像的像素值。两种基本的形态学算子是腐蚀和膨胀。它们的变体形式是打开和关闭。应该使用哪一种取决于手头的任务:

*   **腐蚀**:当给定一幅二值图像时，它在图像的内部和外部都将厚度缩小一个像素，用白色像素表示。这个方法可以应用几次。它可以用于不同的原因，取决于你想要实现什么，但通常它与膨胀(这在图 2.10 中解释)一起使用，以消除漏洞或噪声。腐蚀的一个例子在这里用同样的数字表示，3:

![Figure 2.10: Example of erosion](img/C13550_02_10.jpg)

###### 图 2.10:侵蚀的例子

*   **扩张** : 这种方法与侵蚀正好相反。它在内部和外部都将二进制图像中的对象的厚度增加一个像素。它也可以多次应用于一个图像。这种方法可以用于不同的原因，这取决于您想要实现的目标，但通常它与腐蚀一起实施，以消除图像中的漏洞或噪声。这里显示了一个膨胀的例子(我们已经对图像实施了几次膨胀):

![Figure 2.11: Example of dilation](img/C13550_02_11.jpg)

###### 图 2.11:膨胀的例子

*   **开** : T 这种方法先进行腐蚀，再进行膨胀，通常用于去除图像中的噪声。
*   **关闭**:该算法与打开相反，因为它在腐蚀之前首先执行膨胀。它通常用于移除对象中的孔:

![Figure 2.12: Examples of opening and closing](img/C13550_02_12.jpg)

###### 图 2.12:打开和关闭的示例

正如你所看到的，打开方法消除了图像中的随机噪声，关闭方法完美地修复了图像中的随机小孔。为了从打开方法中去除输出图像的孔洞，可以应用关闭方法。

还有很多二元运算，但这些是基本的。

### 练习 5:对图像应用各种形态变换

在本练习中，我们将加载一个数字图像，并对其应用我们刚刚学到的形态变换:

1.  打开你的 Google Colab 界面。
2.  Set the path of the directory:

    ```
    cd /content/drive/My Drive/C13550/Lesson02/Exercise05/
    ```

    #### 注意

    根据您在 Google Drive 上的文件夹设置，步骤 2 中提到的路径可能会发生变化。

3.  导入 OpenCV、Matplotlib 和 NumPy 库。NumPy 是用 Python 进行科学计算的基础包，它将帮助我们创建应用的内核:

    ```
    import cv2 import numpy as np from matplotlib import pyplot as plt
    ```

4.  现在输入代码来加载`Dataset/three.png`图像，我们将使用 OpenCV 对其进行灰度处理，并使用 Matplotlib 显示:

    #### 注意

    ```
    img = cv2.imread('Dataset/three.png',0) plt.imshow(img,cmap='gray') plt.xticks([]),plt.yticks([]) plt.savefig('ex2_1.jpg', bbox_inches='tight') plt.show()
    ```

    ![Figure 2.13: Result of plotting the loaded image](img/C13550_02_13.jpg)

    ###### 图 2.13:绘制加载图像的结果

5.  Let's apply erosion by using OpenCV methods.

    这里使用的方法是 **cv2.erode** ，它有三个参数:图像、遍历图像的内核和迭代次数，迭代次数是它被执行的次数:

    ```
    kernel = np.ones((2,2),np.uint8)
    erosion = cv2.erode(img,kernel,iterations = 1)
    plt.imshow(erosion,cmap='gray')
    plt.xticks([]),plt.yticks([])
    plt.savefig('ex2_2.jpg', bbox_inches='tight')
    plt.show()
    ```

    ![Figure 2.14: Output of the erosion method using OpenCV](img/C13550_02_14.jpg)

    ###### 图 2.14:使用 OpenCV 的侵蚀方法的输出

    正如我们所看到的，图形的厚度减少了。

6.  We are going to do the same with dilation.

    这里使用的方法是**cv2 . expand**，它有三个参数:图像、内核和迭代次数:

    ```
    kernel = np.ones((2,2),np.uint8)
    dilation = cv2.dilate(img,kernel,iterations = 1)
    plt.imshow(dilation,cmap='gray')
    plt.xticks([]),plt.yticks([])
    plt.savefig('ex2_3.jpg', bbox_inches='tight')
    plt.show()
    ```

    ![Figure 2.15: Output of the dilation method using OpenCV](img/C13550_02_15.jpg)

    ###### 图 2.15:使用 OpenCV 的膨胀方法的输出

    我们可以看到，图形的厚度增加了。

7.  Finally, let's put opening and closing into practice.

    这里使用的方法是 **cv2.morphologyEx** ，它有三个参数:图像、应用的方法和内核:

    ```
    import random
    random.seed(42)
    def sp_noise(image,prob):
        '''
        Add salt and pepper noise to image
        prob: Probability of the noise
        '''
        output = np.zeros(image.shape,np.uint8)
        thres = 1 - prob 
        for i in range(image.shape[0]):
            for j in range(image.shape[1]):
                rdn = random.random()
                if rdn < prob:
                    output[i][j] = 0
                elif rdn > thres:
                    output[i][j] = 255
                else:
                    output[i][j] = image[i][j]
        return output
    def sp_noise_on_figure(image,prob):
        '''
        Add salt and pepper noise to image
        prob: Probability of the noise
        '''
        output = np.zeros(image.shape,np.uint8)
        thres = 1 - prob 
        for i in range(image.shape[0]):
            for j in range(image.shape[1]):
                rdn = random.random()
                if rdn < prob:
                    if image[i][j] > 100:
                        output[i][j] = 0
                else:
                    output[i][j] = image[i][j]
        return output
    kernel = np.ones((2,2),np.uint8) 
    # Create thicker figure to work with
    dilation = cv2.dilate(img, kernel, iterations = 1)
    # Create noisy image
    noise_img = sp_noise(dilation,0.05)
    # Create image with noise in the figure
    noise_img_on_image = sp_noise_on_figure(dilation,0.15)
    # Apply Opening to image with normal noise
    opening = cv2.morphologyEx(noise_img, cv2.MORPH_OPEN, kernel)
    # Apply Closing to image with noise in the figure
    closing = cv2.morphologyEx(noise_img_on_image, cv2.MORPH_CLOSE, kernel)
    images = [noise_img,opening,noise_img_on_image,closing]
    for i in range(4):
        plt.subplot(1,4,i+1),plt.imshow(images[i],'gray')
        plt.xticks([]),plt.yticks([])
    plt.savefig('ex2_4.jpg', bbox_inches='tight')
    plt.show()
    ```

![Figure 2.16: Output of the opening method (left) and closing method (right) using OpenCV](img/C13550_02_16.jpg)

###### 图 2.16:使用 OpenCV 的打开方法(左)和关闭方法(右)的输出

#### 注意

完整的代码文件可以在 GitHub 的 Lesson02 | Exercise05 文件夹中找到。

### 模糊(平滑)

图像模糊使用滤波器内核对图像执行卷积，简单来说，就是将图像每个部分的特定值矩阵相乘，以使其平滑。这对于去除噪声和边缘很有用:

*   **平均**:在这种方法中，我们考虑一个箱式滤波器或内核，它取内核区域内像素的平均值，通过在整个图像上使用卷积来代替中心元素。
*   **高斯模糊**:这里应用的内核是高斯，而不是盒子滤镜。它用于去除特定图像中的高斯噪声。
*   **中值模糊**:类似于平均，但是这个用内核像素的中值代替了中心元素。它实际上对椒盐噪声(即图像中可见的黑色或白色斑点)有非常好的效果。

在图 2.17 中，我们应用了上述方法:

![Figure 2.17: Result of comparing different blurring methods](img/C13550_02_17.jpg)

###### 图 2.17:不同模糊方法的比较结果

有许多其他算法可以应用，但这些是最重要的。

### 练习 6:对图像应用各种模糊方法

在本练习中，我们将加载一幅地铁图像，并对其应用模糊方法:

1.  打开你的 Google Colab 界面。
2.  Set the path of the directory:

    ```
    cd /content/drive/My Drive/C13550/Lesson02/Exercise06/
    ```

    #### 注意

    根据您在 Google Drive 上的文件夹设置，第 2 步中提到的路径可能会有所不同。

3.  导入 OpenCV、Matplotlib 和 NumPy 库:

    ```
    import cv2 from matplotlib import pyplot as plt import numpy as np
    ```

4.  输入代码，加载我们要使用 OpenCV 进行灰度处理的`Dataset/subway.png`图像，并使用 Matplotlib 显示:

    #### 注意

    ```
    img = cv2.imread('Dataset/subway.jpg') #Method to convert the image to RGB img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) plt.imshow(img) plt.savefig('ex3_1.jpg', bbox_inches='tight') plt.xticks([]),plt.yticks([]) plt.show()
    ```

    ![Figure 2.18: Result of plotting the loaded subway image in RGB](img/C13550_02_18.jpg)

    ###### 图 2.18:用 RGB 绘制加载的地铁图像的结果

5.  Let's apply all the blurring methods:

    应用的方法有 **cv2.blur** 、 **cv2。GaussianBlur** 和 **cv2.medianBlur** 。它们都以一幅图像作为第一个参数。第一种方法只有一个参数，即内核。第二种方法采用核和标准差(sigmaX 和 sigmaY)，如果两者都给定为零，则从核大小计算。最后提到的方法只多了一个参数，即内核大小:

    ```
    blur = cv2.blur(img,(51,51)) # Apply normal Blurring
    blurG = cv2.GaussianBlur(img,(51,51),0) # Gaussian Blurring
    median = cv2.medianBlur(img,51) # Median Blurring
    titles = ['Original Image','Averaging', 'Gaussian Blurring', 'Median Blurring']
    images = [img, blur, blurG, median]
    for i in range(4):
        plt.subplot(2,2,i+1),plt.imshow(images[i])
        plt.title(titles[i])
        plt.xticks([]),plt.yticks([])
    plt.savefig('ex3_2.jpg', bbox_inches='tight')
    plt.show()
    ```

![Figure 2.19: Blurring methods with OpenCV](img/C13550_02_19.jpg)

###### 图 2.19:使用 OpenCV 的模糊方法

现在你知道如何应用几种模糊技术到任何图像。

### 练习 7:加载图像并应用学到的方法

在这个练习中，我们将加载一个数字的图像，我们将应用到目前为止所学的方法。

#### 注意

完整的代码可以在 GitHub 的 Lesson02 | Exercise07-09 文件夹中找到。

1.  打开一个新的 Google Colab 界面，按照本章*练习 4* 、*对图像应用不同的阈值*中提到的方法安装你的硬盘。
2.  Set the path of the directory:

    ```
    cd /content/drive/My Drive/C13550/Lesson02/Exercise07/
    ```

    #### 注意

    根据您在 Google Drive 上的文件夹设置，第 2 步中提到的路径可能会有所不同。

3.  导入相关的依赖项:NumPy、OpenCV 和 Matplotlib:

    ```
    import numpy as np  #Numpy import cv2          #OpenCV from matplotlib import pyplot as plt #Matplotlib count = 0
    ```

4.  键入代码以加载`Dataset/number.jpg`图像，我们将使用 OpenCV 对其进行灰度处理，并使用 Matplotlib 显示:

    #### 注意

    ```
    img = cv2.imread('Dataset/number.jpg',0) plt.imshow(img,cmap='gray') plt.xticks([]),plt.yticks([]) plt.show()
    ```

    ![Figure 2.20: Result of loading the image with the number](img/C13550_02_20.jpg)

    ###### 图 2.20:加载编号为

    的图像的结果
5.  If you want to recognize those digits using machine learning or any other algorithm, you need to simplify the visualization of them. Using thresholding seems to be the first logical step to proceed with this exercise. We have learned some thresholding methods, but the most commonly used one is Otsu's binarization, as it automatically calculates the threshold value without the user providing the details manually.

    对灰度图像应用 Otsu 二值化，并使用 Matplotlib 显示:

    ```
    _,th1=cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU
    th1 = (255-th1) 
    # This step changes the black with white and vice versa in order to have white figures
    plt.imshow(th1,cmap='gray')
    plt.xticks([]),plt.yticks([])
    plt.show()
    ```

    ![Figure 2.21: Using Otsu’s binarization thresholding on the image](img/C13550_02_21.jpg)

    ###### 图 2.21:在图像上使用 Otsu 的二值化阈值

6.  In order to get rid of the lines in the background, we need to do some morphological transformations. First, start by applying the closing method:

    ```
    open1 = cv2.morphologyEx(th1, cv2.MORPH_OPEN, np.ones((4, 4),np.uint8))
    plt.imshow(open1,cmap='gray')
    plt.xticks([]),plt.yticks([])
    plt.show()
    ```

    ![Figure 2.22: Applying the closing method](img/C13550_02_22.jpg)

    ###### 图 2.22:应用关闭方法

    #### 注意

    背景中的线条已被完全删除。现在，数字预测将变得容易得多。

7.  为了填补这些数字中可见的漏洞，我们需要应用打开方法。将打开方法应用到前面的图像:

    ```
    close1 = cv2.morphologyEx(open1, cv2.MORPH_CLOSE, np.ones((8, 8), np.uint8)) plt.imshow(close1,cmap='gray') plt.xticks([]),plt.yticks([]) plt.show()
    ```

    ![Figure 2.23: Applying the opening method](img/C13550_02_23.jpg)

    ###### 图 2.23:应用打开方法

8.  There are still leftovers and imperfections around the digits. In order to remove these, a closing method with a bigger kernel would be the best choice. Now apply the corresponding method:

    ```
    open2 = cv2.morphologyEx(close1, cv2.MORPH_OPEN,np.ones((7,12),np.uint8))
    plt.imshow(open2,cmap='gray')
    plt.xticks([]),plt.yticks([])
    plt.show()
    ```

    ![Figure 2.24: Applying the closing method with a kernel of a bigger size](img/C13550_02_24.jpg)

    ###### 图 2.24:对更大的内核应用关闭方法

    根据您用来预测给定图像的数字或条件的分类器，可能会应用一些其他算法。

9.  If you want to predict the numbers, you will need to predict them one by one. Thus, you should divide the numbers into smaller numbers.

    谢天谢地，OpenCV 有一个方法可以做到这一点，它被称为 **cv2.findContours** 。为了找到轮廓，我们需要把黑人变成白人。这段代码比较长，但是只有当您想要逐个字符地预测时才需要:

    ```
    _, contours, _ = cv2.findContours(open2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) #Find contours
    cntsSorted = sorted(contours, key=lambda x: cv2.contourArea(x), reverse=True) #Sort the contours
    cntsLength = len(cntsSorted)
    images = []
    for idx in range(cntsLength): #Iterate over the contours
    	x, y, w, h = cv2.boundingRect(contour_no) #Get its position and size
    	... # Rest of the code in Github
    	images.append([x,sample_no]) #Add the image to the list of images and the X position
    images = sorted(images, key=lambda x: x[0]) #Sort the list of images using the X position
    {…}
    ```

    #### 注意

    GitHub 的 Lesson02 | Exercise07-09 文件夹中提供了添加了注释的完整代码。

![Figure 2.25: Extracted digits as the output](img/C13550_02_25.jpg)

###### 图 2.25:提取的数字作为输出

在代码的第一部分，我们正在寻找图像的**轮廓**(沿着边界连接所有连续点并且具有相同颜色或强度的曲线)以找到每个数字，然后我们根据每个轮廓(每个数字)的面积对其进行排序。

在这之后，我们在轮廓上循环，用给定的轮廓裁剪原始图像，以不同图像中的每个数字结束。

在这之后，我们需要所有的图像都具有相同的形状，所以我们使用 NumPy 将图像调整为给定的形状，并将图像与 X 位置一起附加到图像列表中。

最后，我们使用 X 位置对图像列表进行排序(从左到右，因此它们保持有序)并绘制结果。我们还将每个数字保存为图像，这样我们就可以在以后的任何任务中单独使用每个数字。

恭喜你！你已经成功地处理了一幅包含文本的图像，获得了文本，提取了每一个字符，现在机器学习的魔力可以开始了。

## 机器学习简介

**机器学习** ( **ML** )是让计算机从数据中学习而不陈述任何规则的科学。ML 主要基于用大量数据训练的模型，例如不同对象的数字或特征的图像，以及它们相应的标签，例如那些数字的数量或对象的类型。这叫做**监督学习**。还有其他类型的学习，如**非监督学习**和**强化学习**，但我们将专注于监督学习。监督学习和非监督学习的主要区别在于，模型从数据中学习分类(取决于您指定的分类数)，这些分类被转换为类。另一方面，强化学习关注的是软件代理应该如何在环境中采取行动，以便增加给予代理的奖励，如果代理执行正确的行动，奖励将是积极的，否则将是消极的。

在本章的这一部分，我们将了解机器学习，并检查各种模型和算法，从最基本的模型到解释人工神经网络。

### 决策树和 Boosting 算法

在这一部分，我们将解释决策树和 boosting 算法是一些最基本的机器学习算法。

**装袋**(决策树和随机森林)和**助推** (AdaBoost)将在本主题中进行解释。

### 装袋:

**决策树**可能是最基本的机器学习算法，用于分类和回归，但在基本层面上，它们用于教学和执行测试。

在决策树中，每个节点代表正在被训练的数据的一个属性(无论某事是真还是假)，其中每个分支(节点之间的线)代表一个决策(如果某事是真，走这条路；否则，另一种方式)，每片叶子都代表一个最终的结果(如果所有条件都满足，那就是向日葵或雏菊)。

我们现在将使用虹膜数据集。该数据集考虑了萼片的宽度和长度，以及花瓣的宽度和长度，以便将鸢尾花分类为刚毛鸢尾、杂色鸢尾或海滨鸢尾。

#### 注意

Iris 数据集可以使用 Python 从 scikit-learn 下载:

[https://sci kit-learn . org/stable/modules/generated/sk learn . datasets . load _ iris . html](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)

Scikit-learn 是一个为数据挖掘和数据分析提供有用工具的库。

以下流程图显示了在此数据集上训练的决策树的学习表示。x 表示数据集中的要素，X0 是萼片长度，X1 是萼片宽度，X2 是花瓣长度，X3 是花瓣宽度。“值”标签是每个类别中有多少样本落入每个节点。我们可以看到，在第一步中，决策树已经通过仅考虑 X2 特征，花瓣长度，将 setosa 与其他两个区分开来:

![Figure 2.26: Graph of a decision tree for the Iris dataset](img/C13550_02_26.jpg)

###### 图 2.26:Iris 数据集的决策树图

多亏了 scikit-learn，决策树可以用 Python 实现，只需要几行代码:

```
from sklearn.tree import DecisionTreeClassifier
dtree=DecisionTreeClassifier()
dtree.fit(x,y)
```

`x`和`y`分别是训练集的特征和标签。

`x`除了只是代表那些长度和宽度的数据列之外，还可以是图像的每个像素。在机器学习中，当输入数据是图像时，每个像素都被视为一个特征。

决策树是为一个特定的任务或数据集训练的，不能转移到另一个类似的问题。然而，为了创建更大的模型并学习如何归纳，可以将几个决策树结合起来。这些被称为**随机森林**。

森林这个名称指的是许多决策树算法的集合，遵循 **bagging** 方法，即几种算法的组合可以获得总体最佳结果。单词“随机”的出现指的是在选择要考虑的特征以分割节点时算法的随机性。

再次感谢 scikit-learn，我们只用几行代码就可以实现随机森林算法，与前面的代码行非常相似:

```
from sklearn.ensemble import RandomForestClassifier
rndForest=RandomForestClassifier(n_estimators=10)
rndForest.fit(x,y)
```

`n_estimators`代表底层决策树的数量。如果你用这种方法测试结果，结果肯定会改善。

还有其他遵循**增强**方法的方法。Boosting 由称为**弱学习器**的算法组成，这些算法被放在一起形成一个加权和，并生成一个强学习器，它给出一个输出。这些弱学习者被顺序训练，这意味着他们每个人都试图解决其前任犯下的错误。

有许多算法使用这种方法。最著名的有 AdaBoost，gradient boosting，XGBoost。我们只看 AdaBoost，因为它最广为人知，也最容易理解。

### 助推

**AdaBoost** 把弱学习者放在一起，形成强学习者。AdaBoost 这个名称代表自适应增强，这意味着这种策略在每个时间点的权重不同。那些在单次迭代中被错误分类的例子，得到比下一次迭代更高的权重，反之亦然。

此方法的代码如下:

```
from sklearn.ensemble import AdaBoostClassifier
adaboost=AdaBoostClassifier(n_estimators=100)
adaboost.fit(x_train, y_train)
```

`n_estimators`是升压完成后估计器的最大数量。

该方法使用下面的决策树进行初始化；因此，性能可能不如随机森林。但是为了制造更好的分类器，应该使用随机森林算法:

```
AdaBoostClassifier(RandomForestClassifier(n_jobs=-1,n_estimators=500,max_features='auto'),n_estimators=100)
```

### 练习 8:使用决策树、随机森林和 AdaBoost 算法预测数字

在这个练习中，我们将使用上一个练习中获得的数字和我们在这个主题中学到的模型来正确预测每个数字。为此，我们将从`Dataset/numbers`文件夹中的一些样本中提取几个数字，以及 MNIST 数据集，以获得足够的数据，从而使模型能够正确学习。MNIST 数据集是手写数字的组合，从 0 到 9，形状为 28 x 28 x 3，主要用于研究人员测试他们的方法或进行试验。然而，它可以帮助预测一些数字，即使它们不是同一类型的。你可以在 http://yann.lecun.com/exdb/mnist/[查看这个数据集。](http://yann.lecun.com/exdb/mnist/)

由于 Keras 的安装需要 TensorFlow，我们建议使用 Google Colab，它就像一个 Jupyter 笔记本，但不同的是您的系统没有被使用。相反，使用远程虚拟机，并且已经安装了机器学习和 Python 的所有东西。

让我们开始练习:

#### 注意

我们将在同一个笔记本中继续练习 7 中的代码。

1.  前往 Google Colab 上的界面，在那里您执行了*练习 7* 、*的代码，加载图像并应用所学的方法。*
2.  Import the libraries:

    ```
    import numpy as np
    import random
    from sklearn import metrics
    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
    from sklearn.tree import DecisionTreeClassifier
    from sklearn.utils import shuffle
    from matplotlib import pyplot as plt
    import cv2
    import os
    import re
    random.seed(42)
    ```

    #### 注意

    我们将随机方法的种子设置为 42，这是为了可重复性:所有随机步骤都具有相同的随机性，并且总是给出相同的输出。它可以被设置为不变的任何数字。

3.  Now we are going to import the MNIST dataset:

    ```
    from keras.datasets import mnist
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    ```

    在代码的最后一行，我们正在加载`x_train`中的数据，这是训练集(6 万个数字的例子)`y_train`，这是那些数字的标签，`x_test`，这是测试集，`y_test`，这是相应的标签。这些是 NumPy 格式的。

4.  Let's show some of those digits using Matplotlib:

    ```
    for idx in range(5):
        rnd_index = random.randint(0, 59999)
        plt.subplot(1,5,idx+1),plt.imshow(x_train[idx],'gray')
        plt.xticks([]),plt.yticks([])
    plt.show()
    ```

    ![Figure 2.27: MNIST dataset](img/C13550_02_27.jpg)

    ###### 图 2.27: MNIST 数据集

    #### 注意

    这些数字看起来不像我们在前面的练习中提取的数字。为了使模型正确预测第一次练习中处理的图像中的数字，我们需要将这些数字中的一些添加到该数据集中。

    下面是添加与我们想要预测的数字相似的新数字的过程:

    添加一个数据集文件夹，子文件夹编号从 0 到 9(已经完成)。

    从前面的练习中获取代码。

    使用代码从保存在'`Dataset/numbers/`'中的图像中提取所有数字(已经完成)。

    将生成的数字粘贴到与生成的数字对应的文件夹中(已经完成)。

    将这些图像添加到原始数据集(本练习中的步骤 5)。

5.  To add those images to your training set, these two methods should be declared:

    ```
    # ---------------------------------------------------------
    def list_files(directory, ext=None):
        return [os.path.join(directory, f) for f in os.listdir(directory)
                if os.path.isfile(os.path.join(directory, f)) and ( ext==None or re.match('([\w_-]+\.(?:' + ext + '))', f) )]
       # -------------------------------------------------------
    def load_images(path,label):
        X = []
        Y = []
        label = str(label)
        for fname in list_files( path, ext='jpg' ): 
            img = cv2.imread(fname,0)
            img = cv2.resize(img, (28, 28))
            X.append(img)
            Y.append(label)
        if maximum != -1 :
            X = X[:maximum]
            Y = Y[:maximum]
        X = np.asarray(X)
        Y = np.asarray(Y)
        return X, Y
    ```

    第一种方法是`list_files()`，列出一个文件夹中具有指定扩展名的所有文件，在本例中是`jpg`。

    在主方法`load_images()`中，我们从那些文件夹中加载图像，它们来自 digit 文件夹，带有相应的标签。如果最大值不等于-1，我们将为每一位设置一个加载数量限制。我们这样做是因为每个数字都应该有相似的样本。最后，我们将列表转换成 NumPy 数组。

6.  Now we need to add these arrays to the training set so that our models can learn how to recognize the extracted digits:

    ```
    print(x_train.shape)
    print(x_test.shape)
    X, Y = load_images('Dataset/%d'%(0),0,9)
    for digit in range(1,10):
      X_aux, Y_aux = load_images('Dataset/%d'%(digit),digit,9)
      print(X_aux.shape)
      X = np.concatenate((X, X_aux), axis=0)
      Y = np.concatenate((Y, Y_aux), axis=0)
    ```

    在使用前面代码中声明的方法添加这些数字之后，我们将这些数组连接到前面提到的 for 循环之前创建的集合:

    ```
    from sklearn.model_selection import train_test_split
    x_tr, x_te, y_tr, y_te = train_test_split(X, Y, test_size=0.2)
    ```

    此后，使用`sklearn`中的`train_test_split`方法来分离这些数字——20%用于测试，其余用于训练:

    ```
    x_train = np.concatenate((x_train, x_tr), axis=0)
    y_train = np.concatenate((y_train, y_tr), axis=0)
    x_test = np.concatenate((x_test, x_te), axis=0)
    y_test = np.concatenate((y_test, y_te), axis=0)
    print(x_train.shape)
    print(x_test.shape)
    ```

    完成后，我们将它们连接到原始的训练和测试集。我们已经打印了 x_train 和 x_test 前后的形状，因此可以看到这些额外的 60 位数字。它从形状(60，000，28 和 28)和(10，000，28 和 28)到形状(60，072，28 和 28)和(10，018，28 和 28)。

7.  For the models imported from sklearn that we are going to use in this exercise, we need to format the arrays to the shape (n samples and array), and now we have (n samples, array_height, and array_width):

    ```
    x_train = x_train.reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2])
    x_test = x_test.reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2])
    print(x_train.shape)
    print(x_test.shape)
    ```

    我们将数组的高度和宽度相乘，以获得数组的总长度，但只是一维的:(28*28) = (784)。

8.  Now we are ready to feed the data into the models. We will start training a decision tree:

    ```
    print ("Applying Decision Tree...")
    dtc = DecisionTreeClassifier()
    dtc.fit(x_train, y_train)
    ```

    为了了解该模型的性能，使用了度量精确度。这表示已经预测的来自`x_test`的样本数，我们已经从`metrics`模块和 sklearn 导入了这些样本。现在，我们将使用该模块中的`accuracy_score()`来计算模型的精度。我们需要使用模型中的`predict()`函数预测`x_test`的结果，并查看输出是否与`y_test`标签匹配:

    ```
    y_pred = dtc.predict(x_test)
    accuracy = metrics.accuracy_score(y_test, y_pred)
    print(accuracy*100)
    ```

    之后，计算并打印精度。得到的准确率百分比是 **87.92%** ，对于一个决策树来说，这个结果还算不错。不过，它还可以改进。

9.  Let's try the random forest algorithm:

    ```
    print ("Applying RandomForest...")
    rfc = RandomForestClassifier(n_estimators=100)
    rfc.fit(x_train, y_train)
    ```

    按照相同的方法计算精度，得到的精度为 **94.75%** ，这是一个好得多的模型，可以归类为好模型。

10.  Now, we will try AdaBoost initialized with random forest:

    ```
    print ("Applying Adaboost...")
    adaboost = AdaBoostClassifier(rfc,n_estimators=10)
    adaboost.fit(x_train, y_train)
    ```

    使用 AdaBoost 获得的精度为 **95.67%** 。这种算法比以前的算法花费更多的时间，但得到更好的结果。

11.  我们现在将随机森林应用于在上一次练习中获得的数字。我们应用这个算法是因为它比 AdaBoost 花费的时间少得多，并且给出了更好的结果。在检查下面的代码之前，您需要为存储在`Dataset/number.jpg`文件夹中的图像运行练习一中的代码，这是第一个练习中使用的图像，并为在`Dataset/testing/`文件夹中提取用于测试的另外两个图像运行代码。一旦你这样做了，你应该有五个数字图像在你的目录中，每一个图像，准备加载。代码如下:

    ```
    for number in range(5):     imgLoaded = cv2.imread('number%d.jpg'%(number),0)     img = cv2.resize(imgLoaded, (28, 28))     img = img.flatten()     img = img.reshape(1,-1)     plt.subplot(1,5,number+1),     plt.imshow(imgLoaded,'gray')     plt.title(rfc.predict(img)[0])     plt.xticks([]),plt.yticks([]) plt.show()
    ```

![Figure 2.28: Random forest prediction for the digits 1, 6, 2, 1, and 6](img/C13550_02_28.jpg)

###### 图 2.28:数字 1、6、2、1 和 6 的随机森林预测

这里，我们应用了随机森林模型的`predict()`函数，将每张图片传递给它。随机森林似乎表现得很好，因为它正确地预测了所有的数字。我们试试另一个没用过的号码(在`Dataset`文件夹里面有一个文件夹，里面有一些测试用的图片):

![Figure 2.29: Random forest prediction for the digits 1, 5, 8, 3, and 4](img/C13550_02_29.jpg)

###### 图 2.29:数字 1、5、8、3 和 4 的随机森林预测

其余数字仍然表现良好。让我们试试另一个数字:

![Figure 2.30: Random forest prediction for the digits 1, 9, 4, 7, and 9](img/C13550_02_30.jpg)

###### 图 2.30:数字 1、9、4、7 和 9 的随机森林预测

对于数字 7，它似乎有问题。这可能是因为我们没有引入足够的样本，以及由于模型的简单性。

#### 注意

本练习的完整代码可在 GitHub 的 Lesson02 | Exercise07-09 文件夹中找到。

现在，在下一个主题中，我们将探索人工神经网络的世界，它更有能力完成这些任务。

### 人工神经网络

**人工神经网络****【ann】**是以人脑为模型并受其启发的信息处理系统，它们试图通过学习如何识别数据中的模式来模仿人脑。他们通过一个结构良好的架构来完成任务。这种架构由几个称为神经元的小处理单元组成，这些单元相互连接以解决主要问题。

人工神经网络通过在它们正在处理的数据集中有足够的例子来学习，足够的例子意味着成千上万的例子，甚至数百万个例子。这里的数据量可能是一个缺点，因为如果你没有这些数据，你将不得不自己创建，这意味着你可能需要很多钱来收集足够的数据。

这些算法的另一个缺点是它们需要在特定的硬件和软件上进行训练。他们在昂贵的高性能 GPU 上训练有素。你仍然可以使用花费不多的 GPU 来做某些事情，但是数据将需要更长的时间来训练。还需要有特定的软件，比如 **TensorFlow** 、 **Keras** 、 **PyTorch** 或者 **Fast。AI** 。对于这本书，我们将使用 TensorFlow 和 Keras，它们运行在 TensorFlow 之上。

这些算法通过将所有数据作为输入来工作，其中第一层神经元充当输入。之后，每个条目都被传递到下一层神经元，在那里，这些条目被乘以某个值，并由激活函数处理，激活函数做出“决策”，并将这些值传递到下一层。网络中间的层称为隐藏层。这个过程一直持续到最后一层，在那里给出输出。当将 MNIST 图像作为输入引入神经网络时，网络的末端应该具有 10 个神经元，每个神经元代表一个数字，并且如果神经网络猜测图像是特定的数字，则相应的神经元将被激活。人工神经网络检查它是否已经成功做出决定，如果没有，它执行一个被称为**反向传播**的校正过程，其中网络的每一次通过都被检查和校正，调整神经元的权重。在图 2.31 中，显示了反向传播:

![Figure 2.31: Backpropagation process](img/C13550_02_31.jpg)

###### 图 2.31:反向传播过程

以下是人工神经网络的图示:

![Figure 2.32: ANN architecture](img/C13550_02_32.jpg)

###### 图 2.32:人工神经网络架构

在上图中，我们可以看到神经元，所有的处理都发生在这里，以及它们之间的连接，这就是网络的权重。

我们将了解如何创建一个这样的神经网络，但首先，我们需要看看我们拥有的数据。

在上一个练习中，我们将形状(60，072 和 784)和(10，018 和 784)作为整数类型，将 0 到 255 作为像素值，分别用于训练和测试。使用**标准化数据**，人工神经网络表现得更好更快，但那是什么？

标准化数据意味着将 0-255 范围的值转换为 0-1 范围的值。这些值必须适合 0 到 1 之间，这意味着它们将是浮点数，因为没有其他方法可以将更大范围的数字适合更小的范围，所以，首先我们需要将数据转换为浮点数，然后将其规范化。下面是这样做的代码:

```
x_train = (x_train.astype(np.float32))/255.0 #Converts to float and then normalize
x_test = (x_test.astype(np.float32))/255.0 #Same for the test set
x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)
x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)
```

对于标签，我们还需要将格式改为一键编码。

为了做到这一点，我们需要使用 Keras 的一个函数，来自它的`utils`包(名字已经改成了`np_utils`)，叫做`to_categorical()`，它将每个标签的数字转换成**一键编码**。代码如下:

```
y_train = np_utils.to_categorical(y_train, 10)
y_test = np_utils.to_categorical(y_test, 10)
```

如果我们打印第一个标签`y_train`，5，然后我们打印转换后的第一个值`y_train`，它将输出[0。0.0.0.0.1.0.0.0.0.].这种格式将 1 放在 10 个位置的数组的第六位(因为有 10 个数字)作为数字 5(放在第六位是因为第一个是 0，而不是 1)。现在，我们已经准备好继续进行神经网络的架构。

对于基本的神经网络，采用密集层(或**全连接层**)。这些神经网络也被称为**全连接神经网络**。这些包含一系列代表人脑神经元的神经元。它们需要指定一个激活函数。激活函数是这样一种函数，它接受输入并计算它的加权和，加上一个偏差并决定它是否应该被激活(分别输出 1 和 0)。

两个最常用的激活函数是 sigmoid 和 ReLU，但 ReLU 总体上表现更好。下图显示了它们:

![Figure 2.33: The sigmoid and ReLU functions](img/C13550_02_33.jpg)

###### 图 2.33:sigmoid 和 ReLU 函数

sigmoid 和 ReLU 函数计算加权和并添加偏差。然后，它们根据该计算的值输出一个值。sigmoid 函数将根据计算值给出不同的值，从 0 到 1。但是 ReLU 会为负值给出 0，或者为正值返回计算的值。

接近神经网络的末端，通常发生 **softmax** 激活函数，其将为每个类输出非概率数，对于具有最高机会对应于输入图像的类，该非概率数更高。还有其他激活函数，但是这个函数最适合用于多分类问题的网络输出。

在 **Keras** 中，神经网络可以编码如下:

```
model = Sequential()
model.add(Dense(16, input_shape=input_shape))
model.add(Activation('relu'))
model.add(Dense(8))
model.add(Activation('relu'))
model.add(Flatten())
model.add(Dense(10, activation="softmax"))
```

随着层的顺序创建，模型被创建为`Sequential()`。首先，我们添加一个具有 16 个神经元的密集层，输入的形状被传递，以便神经网络知道输入的形状。此后，应用`ReLU`激活功能。我们使用这个函数是因为它通常能给出好的结果。我们用八个神经元和相同的激活函数堆叠另一层。

最后，我们使用`Flatten`函数将数组转换为一维，然后堆叠最后一个密集层，其中类的数量应该表示神经元的数量(在这种情况下，MNIST 数据集将有 10 个类)。正如我们之前提到的，应用 softmax 函数是为了获得作为一键编码器的结果。

现在我们必须编译模型。为此，我们使用如下的`compile`方法:

```
model.compile(loss='categorical_crossentropy', optimizer=Adadelta(), metrics=['accuracy'])
```

我们传递损失函数，该函数用于计算反向传播过程的误差。对于这个问题，我们将使用类别交叉熵作为损失函数，因为这是一个类别问题。所使用的优化器是 **Adadelta** ，它在大多数情况下表现非常好。我们将准确性确立为模型中要考虑的主要指标。

我们将使用 Keras 中所谓的回调。这些在训练中的每个时期都会被调用。我们将使用`Checkpoint`功能来保存我们的模型，在每个时期都有最佳验证结果:

```
ckpt = ModelCheckpoint('model.h5', save_best_only=True,monitor='val_loss', mode='min', save_weights_only=False)
```

训练该模型的函数称为`fit()`，实现如下:

```
model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=1, validation_data=(x_test, y_test),callbacks=[ckpt])
```

我们传递带有标签的训练集，并且我们建立 64 的批量大小(这些是在每个时期的每个步骤上传递的图像)，从中我们选择 10 个训练时期(在每个时期处理数据)。验证集也会被传递，以便查看模型如何处理看不见的数据，最后，我们设置之前创建的回调。

所有这些参数都必须根据我们面临的问题进行调整。为了将所有这些付诸实践，我们将进行一个练习——与我们对决策树进行的练习相同，但使用的是神经网络。

### 练习 9:构建你的第一个神经网络

#### 注意

我们将继续练习 8 中的代码。

这个练习的完整代码可以在 GitHub 的 Lesson02 | Exercise07-09 文件夹中找到。

1.  前往 Google Colab 上的界面，在那里您执行了*练习 8* 、*使用决策树、随机森林和 AdaBoost 算法预测数字的代码*。
2.  现在从 Keras 库导入包:

    ```
    from keras.callbacks import ModelCheckpoint from keras.layers import Dense, Flatten, Activation, BatchNormalization, Dropout from keras.models import Sequential from keras.optimizers import Adadelta from keras import utils as np_utils
    ```

3.  We normalize the data as we explained in this part of the chapter. We also declare the `input_shape` instance that will be passed to the neural network, and we print it:

    ```
    x_train = (x_train.astype(np.float32))/255.0
    x_test = (x_test.astype(np.float32))/255.0
    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)
    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)
    y_train = np_utils.to_categorical(y_train, 10)
    y_test = np_utils.to_categorical(y_test, 10)
    input_shape = x_train.shape[1:]
    print(input_shape)
    print(x_train.shape)
    ```

    输出如下所示:

    ![Figure 2.34: Data output when passed for normalization using neural networks](img/C13550_02_34.jpg)

    ###### 图 2.34:使用神经网络进行标准化时的数据输出

4.  Now we are going to declare the model. The model that we built before was never going to perform well enough on this problem, so we have created a deeper model with more neurons and with a couple of new methods:

    ```
    def DenseNN(input_shape):
        model = Sequential()
        model.add(Dense(512, input_shape=input_shape))
        model.add(Activation('relu'))
        model.add(BatchNormalization())
        model.add(Dropout(0.2))
        model.add(Dense(512))
        model.add(Activation('relu'))
        model.add(BatchNormalization())
        model.add(Dropout(0.2))
        model.add(Dense(256))
        model.add(Activation('relu'))
        model.add(BatchNormalization())
        model.add(Dropout(0.2))
        model.add(Flatten())
        model.add(Dense(256))
        model.add(Activation('relu'))
        model.add(BatchNormalization())
        model.add(Dropout(0.2))
        model.add(Dense(10, activation="softmax"))
    ```

    我们添加了一个`BatchNormalization()`方法，它有助于网络更快地收敛，并且总体上可能会给出更好的结果。

    我们还增加了`Dropout()`方法，帮助网络避免**过拟合**(训练集的精度远高于验证集的精度)。它通过在训练期间断开一些神经元(0.2 - > 20%的神经元)来做到这一点，这允许更好地概括问题(更好地分类看不见的数据)。

    此外，神经元的数量急剧增加。此外，层数也增加了。增加的层数和神经元越多，理解越深，学到的特征也越复杂。

5.  现在，我们使用分类交叉熵编译模型，因为有几个类，我们使用 Adadelta，这对于这类任务来说是很好的。此外，我们使用准确性作为主要指标:

    ```
    model.compile(loss='categorical_crossentropy', optimizer=Adadelta(), metrics=['accuracy'])
    ```

6.  让我们创建一个`Checkpoint`回调，模型将被存储在名为`model.h5`的`Models`文件夹中。我们将使用验证损失作为要跟踪的主要方法，并将完整保存模型:

    ```
    ckpt = ModelCheckpoint('Models/model.h5', save_best_only=True,monitor='val_loss', mode='min', save_weights_only=False)
    ```

7.  Start to train the network with the `fit()` function, just like we explained before. We use 64 as the batch size, 10 epochs (which is enough as every epoch is going to last a very long time and between epochs it will not improve that much), and we will introduce the Checkpoint callback:

    ```
    model.fit(x_train, y_train, 
              batch_size=64,
              epochs=10,
              verbose=1,
              validation_data=(x_test, y_test),
              callbacks=[ckpt])
    ```

    这需要一段时间。

    输出应该如下所示:

    ![Figure 2.35: Neural network output](img/C13550_02_35.jpg)

    ###### 图 2.35:神经网络输出

    模型最终精度对应最后的`val_acc`，为 **97.83%。**这比我们使用 AdaBoost 或随机森林得到的结果要好。

8.  Now let's make some predictions:

    ```
    for number in range(5):
        imgLoaded = cv2.imread('number%d.jpg'%(number),0)
        img = cv2.resize(imgLoaded, (28, 28))
        img = (img.astype(np.float32))/255.0
        img = img.reshape(1, 28, 28, 1)
        plt.subplot(1,5,number+1),plt.imshow(imgLoaded,'gray')
        plt.title(np.argmax(model.predict(img)[0]))
        plt.xticks([]),plt.yticks([])
    plt.show()
    ```

    该代码看起来与上一个练习中使用的代码相似，但有一些细微的区别。一个是，当我们改变输入格式时，我们也必须改变输入图像的格式(浮动和标准化)。另一个是预测是在一位热码编码中，所以我们使用`argmax()` NumPy 函数来获得一位热码输出向量的最大值的位置，这将是预测的数字。

    让我们看看我们使用随机森林尝试的最后一个数字的输出:

![Figure 2.36: Prediction of numbers using neural networks](img/C13550_02_36.jpg)

###### 图 2.36:使用神经网络预测数字

输出是成功的——甚至连随机森林模型都难以对付的 7。

#### 注意

完整的代码可以在 GitHub 的 Lesson02 | Exercise07-09 文件夹中找到。

如果你尝试其他的数字，它会把它们分类得很好——它已经学会了如何分类。

恭喜你！您已经建立了您的第一个神经网络，并将其应用于现实世界的问题！现在，您已经准备好完成本章的活动。

### 活动 2:从时尚 MNIST 数据库中为 10 种服装分类

现在你将面临一个与前一个相似的问题，但是是关于衣服的类型。这个数据库与最初的 MNIST 非常相似。它有 60，000 张图片——28 x28 灰度——用于训练，10，000 张用于测试。你必须遵循第一个练习中提到的步骤，因为这个活动并不关注真实世界。你必须通过自己建立一个神经网络，将上次练习中学到的能力付诸实践。为此，你必须打开一个谷歌 Colab 笔记本。以下步骤将引导您朝着正确的方向前进:

1.  Load the dataset from Keras:

    ```
    from keras.datasets import fashion_mnist
    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()
    ```

    #### 注意

    像 MNIST 一样对数据进行预处理，因此接下来的步骤应该类似于*练习 5* 、*对图像应用各种形态变换*。

2.  导入`random`并将种子设置为 42。导入`matplotlib`并绘制数据集的五个随机样本，就像我们在上一个练习中所做的那样。
3.  现在将数据标准化并重新整形以适合神经网络，并将标签转换为一键编码器。
4.  Start to build the architecture of the neural network by using dense layers. You have to build it inside a method that will return the model.

    #### 注意

    我们建议从构建一个非常小、简单的架构开始，并通过用给定的数据集测试来改进它。

5.  用适当的参数编译模型，并开始训练神经网络。
6.  Once trained, we should make some predictions in order to test the model. We have uploaded some images into the same `testing` folder inside the `Dataset` folder of the last exercise. Make predictions using those images, just as we did in the last exercise.

    #### 注意

    你必须考虑到输入神经网络的图像背景是黑色的，而衣服是白色的，所以你应该做出相应的调整，使图像看起来像那些。如果需要，您应该将白色反转为黑色，反之亦然。NumPy 有一个方法可以做到这一点:`image = np.invert(image)`。

7.  检查结果:

![Figure 2.37: The output of the prediction is the index of the position in this list](img/C13550_02_37.jpg)

###### 图 2.37:预测的输出是列表中位置的索引

#### 注意

这项活动的解决方案在第 302 页。

## 总结

计算机视觉是人工智能中一个很大的领域。通过了解这一领域，您可以实现从图像中提取信息或生成看起来就像真实生活中一样的图像。本章介绍了使用 OpenCV 库进行特征提取的图像预处理，OpenCV 库允许对机器学习模型进行简单的训练和预测。还涉及了一些基本的机器学习模型，比如决策树和 boosting 算法。这些作为机器学习的入门，主要用于玩耍。最后，使用 Keras 和 TensorFlow 作为后端来引入和编码神经网络。归一化与密集图层一起被解释并付诸实践，尽管已知卷积图层比密集图层更好地处理图像，它们将在本书的后面解释。

避免过度拟合的概念也包括在内，最后，我们使用该模型进行预测，并使用真实世界的图像将其付诸实践。

在下一章中，将介绍**自然语言处理** ( **NLP** )的基础知识，以及从语料库中提取信息以创建语言预测的基本模型的最广泛使用的技术。