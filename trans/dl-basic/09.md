

# 八、深度学习

深度学习是一种基于深度神经网络的机器学习方法。您可以通过向我们目前描述的网络添加层来创建深度网络。然而，深层网络存在问题。本章将描述深度学习的特征、问题和可能性，以及当前深度学习实践的概述。

## 加深关系网

通过这本书，我们了解了许多关于神经网络的知识，包括构成神经网络的各个层，训练中使用的有效技术，对处理图像特别有效的 CNN，以及如何优化参数。这些都是深度学习的重要技术。在这里，我们将整合我们迄今为止所学的技术来创建一个深度网络。然后，我们将尝试使用 MNIST 数据集进行手写数字识别。

### 更深层次的关系网

首先，我们将创建一个 CNN，其网络架构如图 8.1 所示。该网络基于 VGG 网络，将在下一节描述。

如*图 8.1* 所示，该网络比我们迄今实施的网络更深。这里使用的所有卷积层都是小型 3x3 滤镜。这里，通道的数量随着网络的加深而变大(随着卷积层中的通道数量从第一层中的 16 个增加到 16、32、32、64 和 64 个)。如您所见，插入池层是为了逐渐减小中间数据的空间大小，而丢弃层用于后面的完全连接层:

![Figure 8.1: Deep CNN for handwritten digit recognition
](img/fig08_1.jpg)

###### 图 8.1:用于手写数字识别的深度 CNN

该网络使用“he 初始化器”来初始化权重，并使用 Adam 来更新权重参数，从而产生以下特征:

*   使用小型 3×3 滤波器的卷积层
*   ReLU 作为激活函数
*   在完全连接层之后使用的脱落层
*   优化由 Adam 完成
*   初始权重值的“初始化程序”

正如这些特征所表明的，图 8.1 中的网络使用了许多我们到目前为止学到的神经网络技术。现在，让我们使用这个网络进行训练。结果表明，该网络的识别准确率为 99.38%(最终识别准确率略有差异，但该网络一般会超过 99%)。

#### 注意

实现图 8.1 所示网络的源代码位于`ch08/deep_convnet.py`。培训代码在`ch08/train_deepnet.py`提供。您可以使用此代码来重现将在此进行的培训。深网训练需要很多时间(大概半天以上)。这本书提供了在`ch08/deep_conv_net_params.pkl`训练过的体重参数。`deep_convnet.py`代码文件提供了加载训练参数的功能。你可以根据需要使用它。

*图 8.1* 所示网络的错误率仅为 0.62%。在这里，我们可以看到哪些图像被错误地识别。*图 8.2* 显示了识别错误示例:

![Figure 8.2: Sample images that were recognized incorrectly – the upper left of each image shows the correct label, while the lower right shows the result of prediction by this network
](img/fig08_2.jpg)

###### 图 8.2:被错误识别的样本图像–每幅图像的左上角显示了正确的标签，而右下角显示了该网络的预测结果

如*图 8.2* 所示，这些图像即使是我们人类也很难识别。左上角的图像看起来像一个“0”(正确答案是“6”)，旁边的一个看起来肯定是一个“5”(正确答案是“3”)。一般来说，“1”和“7”，“0”和“6”，“3”和“5”之间的区别是很难的。这些例子解释了为什么它们被错误地识别。

虽然这个深度 CNN 非常精确，但它会像人类一样错误地识别图像。这也向我们展示了一个深度 CNN 的巨大潜力。

### Im 证明识别准确性

该网站名为“这个图像是什么类的？” *(Rodrigo Benenson 的博客* " *分类数据集结果*"([http://rodrigob . github . io/are _ we _ there _ yet/build/Classification _ datasets _ results . html](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html)))通过相关文献中公布的技术对各种数据集的识别准确率进行排名(*图 8.3* ):

![Figure 8.3: Ranking techniques for the MNIST dataset
](img/fig08_3.jpg)

###### 图 8.3:MNIST 数据集的排名技术

#### 注意

*图 8.3* 引自参考， *Rodrigo Benenson 的博客*“*分类数据集结果*”([http://rodrigob . github . io/are _ we _ there _ yet/build/Classification _ datasets _ results . html](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html))截止 2016 年 6 月。

在*图 8.3* 所示的排名中，“神经网络”、“深度”和“卷积”等关键词很明显。许多排名靠前的技术都是基于 CNN 的。截至 2016 年 6 月，MNIST 数据集的最高识别准确率为 99.79%(错误率为 0.21%)，该技术也是基于 CNN 的(*李万，马修泽勒，张思欣，Yann L. Cun，和 Rob Fergus (2013):使用 DropConnect 正则化神经网络。大卫·麦卡勒斯特编辑。第 30 届机器学习国际会议论文集(ICML2013)。JMLR 研讨会和会议记录，1058–1066*。这里使用的 CNN 不是很深(两个卷积层和两个全连接层)。

#### 注意

对于 MNIST 数据集，即使网络不是很深，也可以立即获得最高的精度。对于相对简单的问题如手写数字识别，网络的表示不需要很高。所以加层不是很有好处。在大规模通用对象识别过程中，添加层大大提高了识别精度，因为这是一个复杂的问题。

通过检查前面提到的高级技术，我们可以找到进一步提高识别准确性的技术和提示。例如，我们可以看到集成学习、学习率衰减和**数据扩充**有助于识别准确率的提高。数据扩充是一种简单但特别有效的提高识别准确度的方法。

数据增强使用一种算法来人工扩展输入图像(训练图像)。如图*图 8.4* 所示，通过旋转或垂直/水平移动稍微改变输入图像来添加图像。当数据集中的图像数量有限时，这一点尤其有效:

![Figure 8.4: Sample data augmentation
](img/Figure_8.4.jpg)

###### 图 8.4:样本数据扩充

除了*图 8.4* 中所示的修改之外，您可以使用数据增强以各种方式扩展图像。例如，您可以剪切图像的一部分(或裁剪)或水平反转图像(称为翻转，尽管这仅在不需要考虑图像的对称性时有效)。对于普通图像，改变它们的外观(例如，通过增加亮度和放大或缩小它们)也是有效的。如果可以使用数据增强来增加训练图像的数量，就可以通过使用深度学习来提高识别精度。这似乎是一个简单的技巧，但它往往会带来良好的效果。我们不会在这里实现数据扩充。既然实现这个很容易，那么如果你有兴趣的话，请自己尝试一下。

### 默蒂开拓更深层次的网络

关于加深人际网络的重要性，还有很多不为人知的地方。虽然现在理论发现不足，但过去的研究和实验可以解释一些事情(相当直观)。这一部分将提供一些数据和解释来支持“加深关系网”的重要性

首先，围绕大规模图像识别(如 ILSVRC)的比赛结果表明了“使网络变得更深”的重要性(详情请参见下一节)。他们指出，最近许多排名靠前的技术都是基于深度学习的，网络往往会更深入。网络越深，识别性能越好。

这样做的一个好处是可以减少网络中的参数数量。当网络更深时，它可以用更少的参数实现相似(或更高)的表示。当您考虑卷积运算中的滤波器大小时，这很容易理解。*图 8.5* 显示了一个带有 5x5 过滤器的卷积层。

请注意计算输出数据的每个节点的输入数据的面积。当然，在*图 8.5* 所示的例子中，每个输出节点都是基于输入数据的 5x5 区域。现在，我们来考虑一个 3×3 卷积运算重复两次的情况，如图*图 8.6* 所示。在这种情况下，中间数据基于每个输出节点的 3x3 区域。那么，中间数据的 3x3 区域是基于之前输入数据的哪个区域呢？当你仔细观察*图 8.6* 时，你会注意到它是基于一个 5×5 的区域。因此，*图 8.6* 的输出数据“看着”一个 5×5 区域的输入数据进行计算:

![Figure 8.5: Example of a 5x5 convolution operation
](img/Figure_8.5.jpg)

###### 图 8.5:一个 5x5 卷积运算的例子

![Figure 8:6: Example of when 3x3 convolution operations are repeated twice
](img/Figure_8.6.jpg)

###### 图 8:6:3×3 卷积运算重复两次的示例

一次 5x5 卷积运算的面积相当于两次 3x3 卷积运算的面积。前者使用 25 个参数(5x5)，后者总共使用 18 个参数(2x3x3)。因此，多个卷积层减少了参数的数量。随着网络越来越深，减少的参数数量变得越来越大。例如，当 3×3 卷积运算重复三次时，参数的数量总共是 27。为了用一次卷积运算“观察”相同的区域，需要一个 7×7 滤波器，这意味着参数的数量达到 49。

#### 注意

通过多次应用小滤波器使网络变得更深的好处是可以减少参数数量，扩大**感受野**(改变神经元的局部空间区域)。添加图层时，会在卷积图层之间放置一个激活函数(如 ReLU ),从而改善网络表示。这是因为激活函数对网络施加了一个“非线性”力。多个非线性函数支持更复杂的表达式。

训练效率是把网络做深的另一个优势。更深的网络可以减少训练数据，快速进行训练。你可以通过记住*中提供的描述来直观地理解这一点，可视化*第 7 章*、*卷积神经网络*中的一个 CNN* 部分。在这一节中，您了解了 CNN 中的卷积层分层提取信息。在前卷积层，神经元对边缘等简单形状做出反应。随着层变得更深，神经元对层次更复杂的形状做出反应，如纹理和物体部分。

考虑到网络的这种层次结构，考虑识别“狗”的问题为了在浅层网络中解决这个问题，卷积层必须一次“理解”一只狗的许多特征。有各种各样的狗，它们的样子也各不相同，这取决于图像拍摄的环境。因此，了解一只狗的特征需要多种多样的训练数据和大量的训练时间。

但是，你可以通过把一个网络做得更深来把问题分层次学习。然后，每一层要学习的问题就变得简单了。比如第一层可以集中学习边缘。因此，网络可以用少量的训练数据有效地学习。这是因为包含边缘的图像的数量大于狗的图像的数量，并且边缘的图案比狗的图案简单。

同样重要的是，你可以通过加深关系网来传递信息。例如，提取边缘的层旁边的层可以使用边缘信息，因此我们可以期望它高效地学习更高级的模式。简而言之，通过将网络变得更深，你可以将每一层要学习的问题分成“容易解决的简单问题”，这样你就可以期待高效的培训。

这就是支持“让网络更深”重要性的解释。请注意，近年来，新的技术和环境(如大数据和计算机能力)提供了更深的网络，这使得能够在深度网络中进行正确的训练。

## 深度学习简史

据说深度学习开始在大规模图像识别的比赛中引起广泛关注是因为 2012 年举办的 **ImageNet 大规模视觉识别挑战赛** ( **ILSRVC** )。在比赛中，一种名为 AlexNet 的深度学习技术取得了压倒性的胜利，颠覆了传统的图像识别方法。自 2012 年深度学习发起反击以来，一直在后续比赛中扮演主角。在这里，我们将围绕大规模图像识别的竞争来看当前深度学习的趋势，称为 ILSVRC。

### ImageNet

ImageNet ( *邓，董，索彻，李，，，2009): ImageNet:一个大规模的层次图像数据库*。在 2009 年 IEEE 计算机视觉和模式识别会议上。CVPR 2009。248 – 255.DOI:([http://dx.doi.org/10.1109/CVPR.2009.5206848](http://dx.doi.org/10.1109/CVPR.2009.5206848)))是一个包含超过一百万张图片的数据集。如图*图 8.7* 所示，它包含了各种类型的图像，每个图像都与一个标签(类名)相关联。每年都会举办一场名为 ILSVRC 的图像识别比赛，使用的就是这个庞大的数据集:

![Figure 8.7: Sample data in the large-scale ImageNet dataset
](img/Figure_8.7.jpg)

###### 图 8.7:大规模 ImageNet 数据集中的样本数据

#### 注意

*图 8.7* 引自参考文献，*邓，董，索彻，李，，李菲菲(2009): ImageNet:一个大规模分层图像数据库*。在 2009 年 IEEE】计算机视觉和模式识别会议上。CVPR 2009。248 – 255.土井:([http://dx.doi.org/10.1109/CVPR.2009.5206848](http://dx.doi.org/10.1109/CVPR.2009.5206848))。

ILSVRC 竞赛提供了一些测试项目，其中一项是“分类”(在“分类”部分，对 1000 个类进行分类，以竞争识别准确率)。*图 8.8* 显示了自 2010 年以来 ILSVRC 分类部门获胜团队的结果。这里，如果前 5 个预测包含正确的类别，则认为分类是“正确的”。以下条形图显示了错误率:

![Figure 8.8: The results of the winning teams in ILSVRC – the vertical axis shows error rates, 
while the horizontal axis shows years. Team names or technique names are shown in the 
parentheses on the horizontal axis.
](img/Figure_8.8.jpg)

###### 图 8.8:ils vrc 中获胜团队的结果——纵轴显示错误率，横轴显示年份。团队名称或技术名称显示在横轴的括号中。

请注意，从上图中可以看出，自 2012 年以来，深度学习技术一直处于领先地位。实际上，我们可以看到，在 2012 年，AlexNet 显著降低了错误率。从那以后，深度学习技术在准确性方面稳步提高。这一点在 2015 年的 ResNet 中尤为明显，这是一个超过 150 层的深度网络，并将错误率降低到了 3.5%。甚至有人说这个结果超过了普通人类的识别能力。

在过去几年取得巨大成果的深度学习网络中，VGG、谷歌网和 ResNet 是最著名的。你会在各种与深度学习相关的地方碰到它们。接下来我简单介绍一下这三个著名的网络。

### VGG

VGG 是一个“基本”CNN，由卷积层和池层组成。如*图 8.9* 所示，它可以有多达 16 层(或 19 层)的权重(卷积层和全连通层)使其自身变深，根据层数有时被称为“VGG16”或“VGG19”:

![Figure 8.9: VGG
](img/fig08_9.jpg)

###### 图 8.9: VGG

#### 注意

*图 8.9* 引自参考文献，*卡伦·西蒙扬和安德鲁·齐泽曼(2014):用于大规模图像识别的极深卷积网络。arXiv:1409.1556[cs](2014 年 9 月)*。

VGG 包含连续的卷积层与一个小的 3x3 过滤器。如上图所示，两个或四个连续的卷积层和一个合并层将大小减半，并且重复此过程。最后，通过完全连接的层提供结果。

#### 注意

VGG 在 2014 年的比赛中获得了二等奖(GoogLeNet，将在下面介绍，在 2014 年获得)。它的性能不如第一名的网络，但许多工程师更喜欢使用基于 VGG 的网络，因为它们的结构非常简单，功能多样。

### 谷歌网

*图 8.10* 显示了 GoogLeNet 的网络架构。矩形表示各种层，如卷积层和池层:

![Figure 8.10: GoogLeNet
 
](img/fig08_10.jpg)

###### 图 8.10:谷歌网络

#### 注意

*图 8.10* 和*图 8.11* 引自 *Christian Szegedy 等人(2015):用卷积更深入。在 IEEE 计算机视觉和模式识别会议(CVPR)* 。

它的网络架构看起来似乎很复杂，但基本上和一个 CNN 是一样的。GoogLeNet 的与众不同之处在于，网络不仅在垂直方向上有深度，在水平方向上也有深度(spread)。

GoogLeNet 在水平方向有“宽度”。它被称为“初始架构”，基于图 8.11 所示的结构:

![Figure 8.11: Inception architecture of GoogLeNet
](img/Figure_8.11.jpg)

###### 图 8.11:Google net 的初始架构

如*图 8.11* 所示，初始架构应用了多个不同大小的过滤器(和池)并组合结果。使用这个初始架构作为一个构建块(组件)是 GoogLeNet 的主要特点。

GoogLeNet 在许多地方使用带有 1x1 滤镜的卷积图层。这种 1x1 卷积运算减小了通道方向上的尺寸，从而减少了参数数量并加速了处理。

### ResNet

ResNet ( *何，，，任，(2015):深度残差学习用于图像识别。arXiv:1512.03385[cs](2015 年 12 月)*)是微软的一个团队开发的网络。它的特点是有一种“机制”，可以让网络变得比以往更深。

加深网络对提高网络性能很重要。然而，当一个网络变得太深时，深度学习就会失败，最终的性能往往很差。为了解决这个问题，ResNet 引入了“跳过架构”(也称为“捷径”或“旁路”)。通过引入这种跳过架构，随着网络变得更深，性能可以得到提高(尽管允许的深度是有限制的)。

skip 架构跳过输入数据中的卷积层，将输入数据添加到输出中，如图*图 8.12* 所示:

![Figure 8.12: Components of ResNet – the "weight layer" here indicates a convolution layer
](img/fig08_12.jpg)

###### 图 8.12:ResNet 的组件–这里的“权重层”表示卷积层

#### 注意

*图 8.12* 、*图 8.13* 引自参考文献，*何、、任、(2015):深度残差学习用于图像识别。arXiv:1512.03385[cs](2015 年 12 月)*。

在*图 8.12* 中，输入 *x* 通过跳过两个连续卷积层连接到输出。两个卷积层的输出原本是 *F(x)* ，而 skip 架构将其改为 *F(x) + x* 。

采用这种 skip 架构可以实现高效的学习，即使网络很深。这是因为 skip 架构在反向传播期间无衰减地传输信号。

#### 注意

skip 架构只“按原样”传递输入数据在反向传播中，它还将梯度从上游“按原样”传递到下游，而不改变它们。因此，使用 skip 架构，您不必担心梯度变小(或变大)。你可以期待“有意义的梯度”被传输到前面的层。您还可以期待 skip 架构缓解传统的梯度消失问题，该问题会随着网络变深而降低梯度。

ResNet 基于我们之前描述的 VGG 网络，采用了 skip 架构，使网络更加深入。*图 8.13* 显示了这样的结果:

![Figure 8.13: ResNet – blocks support 3x3 convolution layers. Its characteristic is the skip 
architecture, which skips layers.
](img/fig08_13.jpg)

###### 图 8.13:ResNet–块支持 3x3 卷积层。它的特点是跳过层的 skip 架构。

如图*图 8.13* 所示，ResNet 跳过两个卷积层，使网络更深。实验表明，即使当网络包含 150 层或更多层时，识别精度也在继续提高。在 ILSVRC 的比赛中，它取得了错误率(没有被列入前 5 名预测的正确类别的百分比)3.5%的惊人成绩。

#### 注意

通过使用庞大的 ImageNet 数据集训练的重量数据经常被有效地使用。这叫做**迁移学习**。一部分训练好的权重被复制到另一个神经网络进行微调。例如，提供了具有与 VGG 相同结构的网络。训练的权重被用作初始值，并且对新的数据集进行微调。当你手头有几个数据集时，迁移学习尤其有效。

## 加速深度学习

大数据和大规模网络需要深度学习的海量运算。到目前为止，我们已经使用 CPU 进行计算，但仅靠 CPU 不足以解决深度学习。其实很多深度学习框架都支持**图形处理单元**(**GPU**)快速处理大量运算。最近的框架开始通过使用多个 GPU 或机器来支持分布式学习。本节描述了在深度学习中加速计算。我们深度学习的实现在 8.1 节结束。这里描述的加速(比如支持 GPU)我们就不实现了。

### 需要克服的挑战

在讨论深度学习的加速之前，我们先来看看深度学习中哪些过程是需要时间的。*图 8.14* 中的饼状图显示了 AlexNet 转发处理中每个类花费的时间:

![Figure 8.14: Percentage of time that each layer spends in the forward processing of AlexNet – the left-hand chart shows GPU time, while the right-hand one shows CPU time
](img/Figure_8.14.jpg)

###### 图 8.14:每一层花费在 AlexNet 的前向处理中的时间百分比——左边的图表显示 GPU 时间，而右边的图表显示 CPU 时间

这里，“conv”表示卷积层，“pool”表示汇集层，“fc”表示全连通层，“norm”表示归一化层(引自*贾(2014):大规模学习语义图像表征)。加州大学伯克利分校 EECS 系博士论文，2014 年 5 月*，([http://www . eecs . Berkeley . edu/Pubs/tech rpts/2014/EECS-2014-93 . html](http://www.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-93.html)))。

如你所见，卷积层在 AlexNet 中花费了大量的时间。实际上卷积层的总处理时间达到了 GPU 时间的 95%和 CPU 时间的 89%！因此，在卷积层中进行快速高效的操作是深度学习的主要挑战。*图 8.14* 显示了推断阶段的结果，但卷积层在训练阶段也花费了大量时间。

#### 注意

如第 7 章、*卷积神经网络*中*卷积层*主题所述，卷积层中的运算基本上是“乘-累加运算”因此，加速深度学习取决于如何快速高效地计算海量的“乘累加运算”。

### 使用 GPU 进行加速

最初，GPU 专门用于图形。最近，它们已被用于一般的数值计算，以及图形处理。由于 GPU 可以快速进行并行算术运算，GPU 计算将其压倒性的能力用于各种目的。

深度学习需要大规模的乘累加运算(或者大矩阵的乘积)。GPU 擅长这种海量并行运算，而 CPU 擅长连续复杂的计算。与只使用 CPU 相比，你可以使用 GPU 来加速深度学习操作，这令人惊讶。*图 8.15* 比较了 AlexNet 在 CPU 和 GPU 之间学习所用的时间:

![Figure 8.15: Comparing the time that AlexNet took for learning between a "16-core Xeon CPU" 
and a "Titan series" GPU
](img/Figure_8.15.jpg)

###### 图 8.15:比较 AlexNet 在“16 核至强 CPU”和“泰坦系列”GPU 之间的学习时间

#### 注意

*图 8.15* 引自参考， *NVIDIA 博客《NVIDIA 用 TITAN X、New DIGITS 训练系统和 DevBox 推进深度学习》*([https://blogs.nvidia.com/blog/2015/03/17/digits-devbox/](https://blogs.nvidia.com/blog/2015/03/17/digits-devbox/))。

可以看到，CPU 用了 40 多天，而 GPU 只用了 6 天。我们还可以看到，使用针对深度学习优化的 cuDNN 库，进一步加速了训练。

GPU 主要由英伟达和 AMD 两家公司提供。虽然你可以使用他们的两个 GPU 进行一般的算术运算，但英伟达的 GPU 更“熟悉”深度学习。实际上，许多深度学习框架只能受益于英伟达的 GPU。这是因为深度学习框架中使用了 NVIDIA 提供的 GPU 计算集成开发环境 CUDA。cuDNN，可以在*图 8.15* 中看到，是一个运行在 CUDA 上的库，其中实现了针对深度学习优化的功能。

#### 注意

我们使用`im2col`将卷积层中的运算转换成大矩阵的乘积。实现这个`im2col`方法适合 GPU。GPU 擅长一口气计算一个大批量，而不是一个个计算小批量。使用`im2col`来计算巨大矩阵的乘积，可以很容易地展示 GPU 的真正力量。

### 分布式培训

你可以通过使用 GPU 来加速深度学习操作，但深度网络仍然需要几天或几周的训练。正如我们到目前为止所看到的，深度学习涉及大量的尝试和错误。你必须尝试许多事情来创建一个良好的网络。你自然想尽可能减少训练所需的时间。然后，扩展深度学习或“分布式训练”变得很重要。

为了进一步加速深度学习所需的计算，您可能希望将它们分布在多个 GPU 或机器中。现在，一些深度学习框架支持多个 GPU 或机器进行分布式训练。其中，Google 的 TensorFlow 和微软的**计算网络工具包** ( **CNTK** )都被开发出来专注于分布式训练。基于大型数据中心的低延迟和高吞吐量网络，这些框架的分布式训练取得了令人惊讶的结果。

分布式训练能在多大程度上加速深度学习？答案是 GPU 数量越大，训练速度越快。事实上，100 个 GPU(多台机器上总共安装了 100 个 GPU)比一个 GPU 实现了 56 倍的加速。举例来说，这意味着通常需要 7 天的培训在 3 小时内就完成了，这表明了分布式培训的惊人效果。

分布式训练中的“如何分配计算”是一个非常困难的问题。它包含了很多不容易解决的问题，比如机器之间的通信和数据同步。可以把这么难的问题留给 TensorFlow 等优秀的框架。这里就不讨论分布式训练的细节了。分布式训练的技术细节请参见关于 TensorFlow 的技术论文(白皮书)(*Martín Abadi et al .(2016):tensor flow:异构分布式系统上的大规模机器学习。arXiv:1603.04467[cs](2016 年 3 月)*。

### 为算术精度减少位数

内存空间和总线带宽，以及计算复杂度，都可能成为加速深度学习的瓶颈。对于内存空间，必须在内存中存储大量的权重参数和中间数据。对于总线带宽，当流经 GPU(或 CPU)总线的数据增加超过限制时，就会出现瓶颈。在这些情况下，您希望网络中流动的数据位数尽可能小。

计算机主要使用 64 位或 32 位浮点数来表示实数。使用许多位来表示一个数减少了数值计算中误差的影响，但是增加了处理成本和存储器的使用，给总线带宽带来了负担。

从我们所知道的深度学习关于数值精度(用多少位来表示一个数值)，它不需要非常高的精度。由于其鲁棒性，这是神经网络最重要的特征之一。这里的鲁棒性意味着，例如，即使输入图像包含少量噪声，输出结果在神经网络中也不会改变。考虑到健壮性，即使网络中流动的数据“恶化”，它对输出结果的影响也很小

计算机通常使用 32 位单精度浮点表示或 64 位双精度浮点表示来表示小数。实验表明，16 位`float`在深度学习中已经足够( *Suyog Gupta，Ankur Agrawal，Kailash Gopalakrishnan，Pritish Narayanan (2015):数值精度有限的深度学习。更正，abs/1502.02551 392 (2015)* 。其实 NVIDIA 那一代 GPU 用的 Pascal 架构是支持半精度浮点数运算的。据认为，半格式将被用作未来的标准。

#### 注意

NVIDIA 的 Maxwell 一代 GPU 支持半精度浮点数的存储(维护数据)，但不进行 16 位运算。下一代 Pascal 架构也进行 16 位运算。我们可以预计，只使用半精度浮点数进行计算将加快处理速度，使其速度大约是上一代 GPU 的两倍。

在深度学习的前面实现中，我们没有涉及数字精度。Python 一般使用 64 位浮点数。NumPy 提供了一种 16 位半精度浮点数据类型(不过，它只用于存储，不用于运算)。我们可以很容易地证明，使用 NumPy 的半精度浮点数不会降低识别精度。有兴趣的请看`ch08/half_float_network.py`。

已经进行了一些研究来减少深度学习中的位数。在最近的研究中，提出了一种称为“二值化神经网络”的技术(*Matthieu Courbariaux and yo shua beng io(2016):二值化神经网络:训练深度神经网络，权重和激活约束为+1 或-1。arXiv 预印本 arXiv:1602.02830 (2016)* 。它用 1 位表示权重和中间数据。减少比特数来加速深度学习是我们应该关注的话题。当我们考虑将深度学习用于嵌入式设备时，这一点尤为重要。

## 深度学习的实际用途

作为使用深度学习的一个例子，我们主要讨论了图像分类，例如手写数字识别，这被称为“对象识别”。然而，我们可以将深度学习应用于物体识别之外的许多问题。深度学习在图像识别、声音(语音识别)和自然语言处理等许多问题上表现出色。本节将介绍深度学习在计算机视觉领域能做什么(它的应用)。

### 物体检测

对象检测识别图像中对象的位置并对它们进行分类。物体检测比物体识别更难。虽然对象识别以整个图像为目标，但是对象检测必须识别图像中类别的位置，并且可能存在多个对象。

一些基于 CNN 的技术已经被提出用于目标检测。它们表现出优异的性能，这表明深度学习对于对象检测也是有效的。

在基于 CNN 的对象检测技术中，一种称为 R-CNN 的技术( *Ross Girshick、Jeff Donahue、Trevor Darrell 和 Jitendra Malik (2014):用于精确对象检测和语义分割的丰富特征层次。在 580–587 年*)比较出名。*图 8.16* 显示了 R-CNN 的工艺流程:

![Figure 8.16: Process flow of R-CNN
](img/Figure_8.16.jpg)

###### 图 8.16:R-CNN 的流程图

#### 注意

*图 8.16* 引自参考文献， *Ross Girshick、Jeff Donahue、Trevor Darrell 和 Jitendra Malik (2014):用于精确对象检测和语义分割的丰富特征层次。在 580–587*中。

在*图 8.16* 中，注意 *2。提取区域建议*和 *3。计算 CNN 特征*部分。第一种技术检测似乎是物体的区域(以某种方式)，然后将 CNN 应用于提取的区域以对它们进行分类。R-CNN 将图像转换成正方形，并使用**支持向量机** ( **SVMs** )进行分类。它的实际处理流程稍微复杂一些，但是主要由前述过程组成:候选区域的提取和计算 CNN 特征。

在 R-CNN 的“提取区域提议”过程中，检测目标的候选对象，这是可以使用计算机视觉中开发的各种技术的地方。在关于 R-CNN 的论文中，使用了一种称为选择性搜索的技术。最近，一种称为“更快的 R-CNN”的技术(*任，何，Ross Girshick，和(2015):更快的 R-CNN:利用区域提议网络实现实时对象检测。在 c .科尔特斯、N. D .劳伦斯、D. D .李、m .杉山、神经信息处理系统进展。Curran Associates，Inc .，91–99*)已被提出。它甚至使用 CNN 来提取地区提案。更快的 R-CNN 在整个过程中使用一个 CNN，这实现了快速处理。

### 分割

分割以像素为基础对图像进行分类。它通过使用训练数据来学习，其中对象以像素为基础着色，并在推断期间对输入图像的所有像素进行分类。到目前为止，我们实现的神经网络对整个图像进行分类。那么，如何才能以像素为单位进行分类呢？

用神经网络执行分割的最简单方法是对每个像素进行预测。例如，您可以提供一个对矩形区域中心的像素进行分类的网络，以便对所有像素进行预测。如您所见，这需要与像素数一样多的前向过程，因此需要大量时间来完成(问题是卷积运算会无用地重新计算许多区域)。为了减少这种无用的计算，一种被称为**完全卷积网络** ( **FCN** )的技术已经被提出( *Jonathan Long，Evan Shelhamer，和 Trevor Darrell (2015):用于语义分割的完全卷积网络。在 IEEE 计算机视觉和模式识别会议(CVPR)* 。它在一个正向过程中对所有像素进行分类(参见*图 8.20* )。

FCN 是仅由卷积图层组成的网络。虽然普通的 CNN 包含完全连接的层，但 FCN 用扮演相同角色的*卷积层来代替完全连接的层*。在用于对象识别的网络的完全连接的层中，中间数据的空间体积被处理为排成一行的节点。另一方面，在仅包含卷积图层的网络中，空间体积可以在处理过程中保持不变，直到最后一次输出。

FCN 的主要特点是空间尺寸在末端扩大。这种扩展可以放大缩小的中间数据，使其立刻与输入图像的大小相同。FCN 末端的扩展是通过双线性插值的扩展(双线性扩展)。FCN 使用去卷积来进行双线性扩展(详细信息，请参见论文( *Jonathan Long，Evan Shelhamer，和 Trevor Darrell (2015):语义分割的完全卷积网络)。在 IEEE 计算机视觉和模式识别会议(CVPR)* 关于 FCN)。

#### 注意

在全连接层中，输出连接到所有输入。您还可以在卷积图层中创建结构相同的连接。例如，输入数据大小为 32x10x10(通道数为 32，高度为 10，宽度为 10)的全连接图层可以替换为过滤器大小为 32x10x10 的卷积图层。如果完全连接的层具有 100 个输出节点，则卷积层可以通过提供 100 个 32x10x10 滤波器来实现完全相同的处理。通过这种方式，完全连接的层可以替换为执行等效处理的卷积层。

### 生成图像字幕

有一些有趣的研究正在进行，结合了自然语言和计算机视觉。当提供图像时，解释图像的文本(图像标题)被自动生成。

例如，越野自行车比赛中的摩托车图像可以包含标题:“一个人在土路上骑摩托车”(该文本是从图像中自动生成的)。令人惊讶的是，该系统甚至“理解”它正在一条土路上，一个人正在骑摩托车。

一种称为**神经图像字幕** ( **NIC** )的模型通常用于生成深度学习的图像字幕。NIC 由一个深度 CNN 和一个用于处理自然语言的**循环神经网络** ( **RNN** )组成。RNN 具有递归连接，通常用于自然语言和时序数据等序列数据。

NIC 使用 CNN 从图像中提取特征，并将它们传递给 RNN。RNN 使用 CNN 提取的特征作为初始值来“递归地”生成文本这里就不讨论技术细节了。基本上，NIC 有一个简单的架构，结合了两个神经网络:一个 CNN 和一个 RNN。它可以生成惊人精确的图像标题。处理各种类型的信息，如图像和自然语言，称为**多模态处理**。近年来，多模态处理获得了很多关注:

#### 注意

RNN 其余部分代表经常性。“递归”表示神经网络的循环网络架构。由于重复出现的架构，RNN 受到之前产生的信息的影响——换句话说，它记得过去的信息。这是 RNN 的主要特征。例如，在生成单词“I”之后，它会受到该单词的影响，并生成下一个单词“am”。然后，它受到先前生成的“我是”的词的影响，生成“睡觉”的词。对于连续数据，如自然语言和时间序列数据，RNN 的行为就好像它记住了过去的信息。

## 深度学习的未来

深度学习现在被用在各个领域，传统领域也是如此。这一部分描述了深度学习的可能性和一些显示深度学习未来的研究。

### 转换图像样式

正在进行的研究使用深度学习像艺术家一样“画”一幅画。神经网络的一个流行用例是基于两个提供的图像创建一个新图像。其中一个称为“内容图像”，而另一个称为“样式图像”基于这两个图像创建新的图像。

在一个示例中，您可以指定梵高的绘画风格作为将应用于内容图像的风格，深度学习按照指定绘制新的图片。这项研究发表在论文《艺术风格的神经算法》( *Leon A. Gatys，Alexander S. Ecker，and Matthias Bethge (2015):艺术风格的神经算法)。arXiv:1508.06576[cs，q-bio](2015 年 8 月)*)并且一出版就受到了全世界的大量关注。

粗略地说，在该技术中，网络中的中间数据进行学习，以便接近“内容图像”的中间数据通过这样做，可以转换输入图像，使得它在形状上与内容图像相似。为了从“风格图像”中吸收风格，引入了风格矩阵的概念。通过训练使得风格矩阵的间隙较小，输入图像可以接近梵高的风格。

### 生成图像

前面的图像样式转换示例需要两个图像来生成一个新图像。另一方面，一些研究试图在不需要任何图像的情况下生成新图像(该技术通过预先使用许多图像来训练，但是不需要图像来“绘制”新图像。)例如，你可以使用深度学习从零开始生成“卧室”的图像

它们可能看起来是真实的照片，但它们是由 DCGAN 新生成的。由 DCGAN 生成的图像是没有人见过的图像(那些不存在于训练数据中的图像)，并且是从零开始新创建的。

当 DCGAN 生成看起来像真的图像时，它会创建一个图像生成过程的模型。该模型通过使用许多图像(例如卧室的图像)来学习。训练完成后，您可以使用该模型生成新图像。

DCGANs 使用深度学习。DCGAN 技术的要点是它使用两个神经网络:一个生成器和一个鉴别器。生成器生成看似真实的图像，而鉴别器确定它是否真实，即它是由生成器生成的还是真的被拍摄的。这样，通过使两个网络相互竞争来训练它们。

生成器学习一种更精细的技术来创建假图像，而鉴别器像鉴定师一样成长，能够以更高的精度检测假货。有趣的是，在一种叫做**生成对抗网络** ( **甘**)的技术中，两者都在竞争中成长。最后，通过竞争成长起来的生成器可以绘制出看起来真实的图像(或者可能成长得更快)。

#### 注意

到目前为止我们看到的机器学习问题被称为**监督学习**问题。他们使用包含成对图像数据和标签的数据集，例如在手写数字识别中。同时，这里的问题没有提供标签数据。仅提供图像(一组图像)。这叫做**无监督学习**。无监督学习已经研究了相对长的时间(**深度信念网络**和**深度玻尔兹曼机器**很有名)，但似乎这些天来，对它的研究不是很积极。由于使用深度学习的技术，如 DCGANs，正在吸引越来越多的关注，预计无监督学习将在未来得到进一步发展。

### 自动驾驶

“自动驾驶”技术，即计算机代替人驾驶汽车，可能很快就会实现。IT 公司、大学和研究机构以及汽车制造商都在竞相实现自动驾驶。这只有在各种技术(如确定交通路线的路径规划技术和包括相机和激光在内的传感技术)相结合时才会发生。据说用来正确识别周围环境的技术是最重要的。很难识别每天每时每刻都在变化的环境，以及自由移动的汽车和人。

如果系统能够鲁棒、可靠地正确识别行驶区域，甚至在各种环境中，自动驾驶可能会在不久的将来实现——这是一项深度学习应该证明是非常宝贵的任务。

比如一个基于 CNN 的网络叫做 SegNet(*Vijay Badrinarayanan，Kendall，Roberto Cipolla (2015): SegNet:一个用于图像分割的深度卷积编码器-解码器架构。arXiv 预印本 arXiv:1511.00561 (2015)* )可以准确识别道路环境，如图*图 8.17* :

![Figure 8.17: Example of segmenting an image by using deep learning – the road, cars, buildings, and sidewalks are recognized accurately
](img/fig08_17.jpg)

###### 图 8.17:使用深度学习分割图像的示例-道路、汽车、建筑物和人行道被准确识别

#### 注意

*图 8.17* 引自参考文献， *SegNet 演示页*(【http://mi.eng.cam.ac.uk/projects/segnet/】T21)。

对输入图像进行分割(像素级评估)，如图*图 8.17* 所示。结果表明，道路、建筑物、人行道、树木、汽车和摩托车得到了一定程度的准确区分。如果深度学习从现在开始提高这些识别技术的准确性和速度，自动驾驶可能会在不太遥远的将来投入实际使用。

### 深度 Q 网络(强化学习)

有一个研究领域叫做**强化学习**在这个领域中，计算机通过试错来独立学习，就像人类学习骑自行车一样，例如。这与“监督学习”不同，在“监督学习”中，“监督者”面对面授课。

强化学习的基本框架是一个主体根据环境的情况选择动作，它的动作改变环境。采取行动后，环境会给代理人一些奖励。强化学习的目的是确定代理人的行动策略，使其能够获得更好的回报，如下所示:

![Figure 8.18: Basic framework of reinforcement learning – the agent learns independently 
to obtain a better reward
](img/Figure_8.18.jpg)

###### 图 8.18:强化学习的基本框架——代理人独立学习以获得更好的回报

*图 8.18* 中的图表显示了强化学习的基本框架。请注意，奖励不是标记为数据，因为它是在监督学习。例如，在电子游戏“超级马里奥兄弟”中，将马里奥向右移动所获得的确切奖励数量不一定清楚。在这种情况下，“预期”奖励必须由明确的指标决定，如游戏分数(获得硬币、击败敌人等)和游戏结束逻辑。在监督学习中，每个动作都可以被“监督者”正确地评估

一种**深度 Q-网络** ( **DQN** )是一种强化学习技术( *Volodymyr Mnih et al (2015):通过深度强化学习实现人类水平的控制。使用深度学习的 Nature 518，7540 (2015)，529–533*)。它基于被称为 Q-learning 的强化学习算法。Q-learning 确定了一个称为最优动作值函数的函数来确定最优动作。DQN 使用深度学习(CNN)来逼近该函数。

一些研究表明，dqn 可以自动学习视频游戏，以获得比人类更成功的游戏。如图*图 8.19* 所示，CNN 在 DQN 中使用时，接收四帧连续的游戏图像作为输入，输出游戏控制器运动的“值”(操纵杆的移动和按钮操作)。

传统上，当网络学习视频游戏时，通常预先提取并提供游戏的状态(例如角色的位置)。同时，DQN 只接收视频游戏的图像作为输入数据，如图*图 8.19* 所示。这是 DQN 值得注意的地方，大大提高了它的适用性。这是因为您不需要更改每个游戏的设置，您只需要向 DQN 提供游戏图像。事实上，DQNs 已经学习了很多游戏，比如同样配置的“吃豆人”和“雅达利 2600”并取得了比人类更好的成绩:

![Figure 8.19: Using a Deep Q-Network to learn the operations of a video game. Here, the 
network receives the images of a video game as an input and learns the operation of the game 
controller (joystick) through trial and error
](img/fig08_19.jpg)

###### 图 8.19:使用深度 Q 网络学习视频游戏的操作。这里，网络接收视频游戏的图像作为输入，并通过反复试验来学习游戏控制器(操纵杆)的操作

#### 注意

*图 8.17* 引自参考文献， *Volodymyr Mnih et al. (2015):通过深度强化学习的人类级控制。性质 518、7540 (2015)、529–533*。

#### 注意

一个 AI 叫 AlphaGo 的新闻( *David Silver 等人(2016):用深度神经网络和树搜索掌握围棋的博弈。自然 529，7587 (2016)，484–489*)击败围棋冠军备受关注。AlphaGo 中也使用了深度学习和强化学习。它从专业人士创造的 3000 万场比赛记录中学习，并与自己多次对战，积累了足够的知识。AlphaGo 和 DQNs 都被谷歌的 DeepMind 研究过。我们今后必须密切注意他们的活动。

## 摘要

在本章中，我们实现了一个深度细胞神经网络，并获得了超过 99%的手写数字识别率。我们还讨论了使网络更深的动机以及当前向更深网络发展的趋势。我们还研究了深度学习的趋势和应用，这项研究正在加速它，这将推动这项技术走向未来。

在深度学习领域，还有许多未知的东西，新的研究一直在发表。世界各地的研究人员和工程师继续积极研究，并将实现我们甚至无法想象的技术。

本章包括以下几点:

*   使网络更深将提高许多深度学习问题的性能。
*   在图像识别比赛中，使用深度学习的技术获得了很高的排名，并且当前的网络比它们的前辈更深
*   著名的网络包括 VGG、谷歌网和瑞思网。
*   GPU，分布式训练，比特精度的降低，可以加速深度学习。
*   深度学习(神经网络)可以用于对象检测和分割，也可以用于对象识别。
*   使用深度学习的应用包括图像标题的生成、图像的生成和强化学习。如今，深度学习用于自动驾驶也在意料之中。

感谢您阅读这本书。我们希望你对深度学习有了更好的理解，并发现这是一次有趣的旅程。