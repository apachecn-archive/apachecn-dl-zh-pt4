<html><head/><body><html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Creating New Images Using Generative Adversarial Networks</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">使用生成性对抗网络创建新图像</h1>

                

            

            

                

<p>本章通过一个实例说明了<strong>生成对抗网络</strong> ( <strong> GANs </strong>)在生成新图像中的应用。到目前为止，在本书中，我们使用图像数据说明了深度网络在图像分类任务中的应用。然而，在这一章中，我们将探索一种有助于创建新图像的有趣且受欢迎的方法。生成对抗网络已经被应用于生成新图像、提高图像质量以及生成新文本和新音乐。GANs的另一个有趣的应用是在异常检测领域。在这里，GAN被训练来生成被认为是正常的数据。当该网络用于重建被认为不正常或异常的数据时，结果的差异可以帮助我们检测异常的存在。在本章中，我们将看一个生成新图像的例子。</p>

<p>更具体地说，在本章中，我们将讨论以下主题:</p>

<ul>

<li>生成性对抗网络概述</li>

<li>处理MNIST图像数据</li>

<li>开发发电机网络</li>

<li>开发鉴别器网络</li>

<li>训练网络</li>

<li>查看结果</li>

<li>性能优化技巧和最佳实践</li>

</ul>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Generative adversarial network overview</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">生成性对抗网络概述</h1>

                

            

            

                

<p>gan利用两个网络:</p>

<ul>

<li>发电机网络</li>

<li>鉴别器网络</li>

</ul>

<p>对于发电机网络，提供噪声数据作为输入，噪声数据通常是从标准正态分布生成的随机数。显示生成性对抗网络的概述的流程图如下:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/02dd32ee-b66b-462b-9b75-8fc5ec56a546.png" style="width:22.92em;height:12.67em;"/></p>

<p>如前面的流程图所示，生成器网络使用噪声数据作为输入，并试图创建一个我们可以标记为假的图像。这些假图像，连同表示它们是假的标签，被作为输入提供给鉴别器网络。除了标记的假图像，我们还可以提供带有标签的真实图像作为鉴别器网络的输入。</p>

<p>在训练过程中，鉴别器网络试图区分由生成器网络创建的假图像和真实图像。当开发生成性对抗网络时，该过程继续，使得生成器网络尽最大努力生成鉴别器网络不能归类为假的图像。与此同时，鉴别器网络在正确区分真假图像方面变得越来越好。</p>

<p>当生成器网络学会一致地产生在训练数据中不可用的图像并且鉴别器网络不能将它们分类为假的时，就实现了成功。对于本章中的真实图像，我们将使用包含手写数字图像的MNIST训练数据。</p>

<p>在接下来的部分中，我们将说明为了开发手写数字五的生成性对抗网络，我们需要遵循的步骤，该网络在MNIST数据中可用。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Processing MNIST image data</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">处理MNIST图像数据</h1>

                

            

            

                

<p>在本节中，将使用Keras库，其中也包括MNIST数据。我们还将利用EBImage库，它对处理图像数据很有用。MNIST数据包含从0到9的手写图像。让我们看一下下面的代码来理解这些数据:</p>

<pre># Libraries and MNIST data<br/>library(keras)<br/>library(EBImage)<br/>mnist &lt;- dataset_mnist()<br/>str(mnist)<br/>List of 2<br/> $ train:List of 2<br/> ..$ x: int [1:60000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...<br/> ..$ y: int [1:60000(1d)] 5 0 4 1 9 2 1 3 1 4 ...<br/> $ test :List of 2<br/> ..$ x: int [1:10000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...<br/> ..$ y: int [1:10000(1d)] 7 2 1 0 4 1 4 9 5 9 ...</pre>

<p>从前面的代码中，我们可以观察到以下情况:</p>

<ul>

<li>查看这些数据的结构，我们可以看到训练数据中有60，000幅图像，测试数据中有10，000幅图像。</li>

<li>这些手写图像的大小为28 x 28，颜色为黑白。这意味着只有一个频道。</li>

</ul>

<p>在这一章中，我们将仅使用来自训练数据的数字5来训练生成性对抗网络并生成数字5的新图像。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Digit five from the training data</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">训练数据中的第五个数字</h1>

                

            

            

                

<p>虽然可以开发一个生成性对抗网络来生成所有10个数字，但对于刚入门的人来说，建议只从一个数字开始。让我们来看看下面的代码:</p>

<pre># Data on digit five<br/>c(c(trainx, trainy), c(testx, testy)) %&lt;-% mnist<br/>trainx &lt;- trainx[trainy==5,,]<br/>str(trainx)<br/> int [1:5421, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...<br/>summary(trainx)<br/>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. <br/>   0.00    0.00    0.00   33.32    0.00  255.00 <br/><br/>par(mfrow = c(8,8), mar = rep(0, 4))<br/>for (i in 1:64) plot(as.raster(trainx[i,,], max = 255))<br/>par(mfrow = c(1,1))<br/><br/></pre>

<p>如前面的代码所示，我们选择了包含数字五的图像，并将其保存在<kbd>trainx</kbd>中。<kbd>trainx</kbd>的结构向我们展示了5421幅这样的图像，它们的尺寸都是28×28。汇总函数显示<kbd>trainx</kbd>中的值范围从0到255。在下图中可以看到训练数据中手写数字五的前64个图像:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/b27ce764-d851-46b1-a947-b51b206bc129.png" style="width:26.67em;height:36.92em;"/></p>

<p>这些手写图像显示出很大的可变性。由于不同的人有不同的书写风格，这种可变性是可以预料的。虽然这些数字大部分都写得很清楚，很容易辨认，但也有一些不太清楚。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Data processing</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">数据处理</h1>

                

            

            

                

<p>为了给后面的步骤准备数据，我们将调整<kbd>trainx</kbd>的形状，使其尺寸为5，421 x 28 x 28 x 1，如以下代码所示:</p>

<pre># Reshaping data<br/>trainx &lt;- array_reshape(trainx, c(nrow(trainx), 28, 28, 1))<br/>trainx &lt;- trainx / 255</pre>

<p>这里，我们还将<kbd>trainx</kbd>中的值除以255，以获得0到1之间的值范围。数据按照要求的格式处理后，我们可以继续开发发电机网络的架构。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Developing the generator network</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">开发发电机网络</h1>

                

            

            

                

<p>生成器网络将用于从以噪声形式提供的数据中生成假图像。在本节中，我们将开发发电机网络的架构，并通过总结网络来了解相关参数。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Network architecture</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">网络体系结构</h1>

                

            

            

                

<p>让我们看看开发生成器网络架构的代码:</p>

<pre># Generator network<br/>h &lt;- 28; w &lt;- 28; c &lt;- 1; l &lt;- 28  <br/>gi &lt;- layer_input(shape = l)<br/>go &lt;- gi %&gt;% layer_dense(units = 32 * 14 * 14) %&gt;%<br/>         layer_activation_leaky_relu() %&gt;% <br/>         layer_reshape(target_shape = c(14, 14, 32)) %&gt;% <br/>         layer_conv_2d(filters = 32, <br/>                       kernel_size = 5,<br/>                       padding = "same") %&gt;% <br/>         layer_activation_leaky_relu() %&gt;% <br/>         layer_conv_2d_transpose(filters = 32, <br/>                                 kernel_size = 4,<br/>                                 strides = 2,<br/>                                 padding = "same") %&gt;% <br/>         layer_activation_leaky_relu() %&gt;% <br/>         layer_conv_2d(filters = 1, <br/>                       kernel_size = 5,<br/>                       activation = "tanh", <br/>                       padding = "same")<br/>g &lt;- keras_model(gi, go)</pre>

<p>在前面的代码中，我们可以观察到以下情况:</p>

<ul>

<li>我们指定高度(h)、宽度(w)、通道数量(c)和潜在尺寸(l)分别为28、28、1和28。</li>

<li>我们将生成器输入(gi)的输入形状指定为28。在训练时，将向发生器网络提供28个随机数的输入，这些随机数是从标准正态分布获得的，标准正态分布仅仅是噪声。</li>

<li>接下来，我们指定了发电机网络输出(go)的架构。</li>

<li>最后一层是具有<kbd>tanh</kbd>激活函数的卷积2D层。在最后一层，我们已经设置过滤器为1，因为我们将不使用彩色图像。</li>

<li>注意<kbd>layer_conv_2d_transpose</kbd>要求尺寸为28 x 28。</li>

<li>发电机输出的输出尺寸将为28 x 28 x 1。</li>

<li>使用的其他值，如过滤器数量、<kbd>kernel_size</kbd>或步幅，如果您希望探索改进结果，可以在以后进行试验。</li>

<li><kbd>gi</kbd>和<kbd>go</kbd>用于发电机网络(g)。</li>

</ul>

<p>现在，我们来看看这个网络的总结。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Summary of the generator network</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">发电机网络概述</h1>

                

            

            

                

<p>发电机网络概述如下:</p>

<pre># Summary of generator network model <br/>summary(g)<br/><strong>____________________________________________________________________________</strong><br/><strong>Layer (type)                      Output Shape                 Param #       </strong><br/><strong>============================================================================</strong><br/><strong>input_7 (InputLayer)              [(None, 28)]                   0             </strong><br/><strong>____________________________________________________________________________</strong><br/><strong>dense_4 (Dense)                   (None, 6272)                181888        </strong><br/><strong>____________________________________________________________________________</strong><br/><strong>leaky_re_lu_8 (LeakyReLU)         (None, 6272)                   0             </strong><br/><strong>____________________________________________________________________________</strong><br/><strong>reshape_2 (Reshape)               (None, 14, 14, 32)             0             </strong><br/><strong>____________________________________________________________________________</strong><br/><strong>conv2d_6 (Conv2D)                 (None, 14, 14, 32)            25632         </strong><br/><strong>____________________________________________________________________________</strong><br/><strong>leaky_re_lu_9 (LeakyReLU)          (None, 14, 14, 32)             0             </strong><br/><strong>____________________________________________________________________________</strong><br/><strong>conv2d_transpose_2 (Conv2DTranspose) (None, 28, 28, 32)         16416         </strong><br/><strong>____________________________________________________________________________</strong><br/><strong>leaky_re_lu_10 (LeakyReLU)          (None, 28, 28, 32)            0             </strong><br/><strong>____________________________________________________________________________</strong><br/><strong>conv2d_7 (Conv2D)                    (None, 28, 28, 1)           801           </strong><br/><strong>============================================================================</strong><br/><strong>Total params: 224,737</strong><br/><strong>Trainable params: 224,737</strong><br/><strong>Non-trainable params: 0</strong><br/><strong>_______________________________________________________________________________________</strong></pre>

<p>生成器网络的摘要显示了输出的形状和每层的参数数量。请注意，最终的输出形状是28 x 28 x 1。将要生成的假图像将具有这些尺寸。总的来说，对于这个网络，我们有224，737个参数。</p>

<p>现在我们已经指定了发生器网络的结构，我们可以开发鉴别器网络的架构。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Developing the discriminator network</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">开发鉴别器网络</h1>

                

            

            

                

<p>鉴别器网络将用于对假图像和真图像进行分类。本节将讨论网络的体系结构和总结。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Architecture</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">体系结构</h1>

                

            

            

                

<p>用于开发鉴别器网络架构的代码如下:</p>

<pre># Discriminator network<br/>di &lt;- layer_input(shape = c(h, w, c))<br/>do &lt;- di %&gt;% <br/>         layer_conv_2d(filters = 64, kernel_size = 4) %&gt;% <br/>         layer_activation_leaky_relu() %&gt;% <br/>         layer_flatten() %&gt;%<br/>         layer_dropout(rate = 0.3) %&gt;%  <br/>         layer_dense(units = 1, activation = "sigmoid")<br/>d &lt;- keras_model(di, do)</pre>

<p>从前面的代码中，我们可以观察到以下内容:</p>

<ul>

<li>我们提供了一个输入形状(di ), h = 28，w = 28，c = 1。这是训练网络时会用到的虚实图像的维度。</li>

<li>在鉴别器输出(do)的最后一层，我们将激活函数指定为<kbd>sigmoid</kbd>，单位指定为1，因为图像被区分为真或假。</li>

<li><kbd>di</kbd>和<kbd>do</kbd>用于鉴别器网络模型(d)。</li>

</ul>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Summary of the discriminator network</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">鉴频器网络概述</h1>

                

            

            

                

<p>鉴别器网络的总结显示了每层的输出形状和参数数量:</p>

<pre># Summary of discriminator network model <br/>summary(d)<br/>___________________________________________________<br/><strong>Layer (type) Output Shape Param # </strong><br/><strong>===================================================</strong><br/><strong>input_10 (InputLayer) [(None, 28, 28, 1)] 0 </strong><br/><strong>___________________________________________________</strong><br/><strong>conv2d_12 (Conv2D) (None, 25, 25, 64) 1088 </strong><br/><strong>____________________________________________________</strong><br/><strong>leaky_re_lu_17 (LeakyReLU) (None, 25, 25, 64) 0 </strong><br/><strong>____________________________________________________</strong><br/><strong>flatten_2 (Flatten) (None, 40000) 0 </strong><br/><strong>____________________________________________________</strong><br/><strong>dropout_2 (Dropout) (None, 40000) 0 </strong><br/><strong>____________________________________________________</strong><br/><strong>dense_7 (Dense) (None, 1) 40001 </strong><br/><strong>====================================================</strong><br/><strong>Total params: 41,089</strong><br/><strong>Trainable params: 41,089</strong><br/><strong>Non-trainable params: 0</strong><br/><strong>_____________________________________________________</strong></pre>

<p>这里，第一层的输出大小为28 x 28 x 1，这与伪图像和真实图像的尺寸相匹配。参数总数为41，089。</p>

<p>现在，我们可以使用以下代码编译鉴别器网络模型:</p>

<pre># Compile discriminator network<br/>d %&gt;% compile(optimizer = 'rmsprop',<br/>         loss = "binary_crossentropy")</pre>

<p>这里，我们使用<kbd>rmsprop</kbd>优化器编译了鉴别器网络。对于损失，我们指定了<kbd>binary_crossentropy</kbd>。</p>

<p>接下来，我们冻结鉴频器网络的权重。请注意，我们在编译鉴别器网络后冻结了这些权重，以便它仅将它们应用于<kbd>gan</kbd>模型:</p>

<pre># Freeze weights and compile<br/>freeze_weights(d) <br/>gani &lt;- layer_input(shape = l)<br/>gano &lt;- gani %&gt;% g %&gt;% d<br/>gan &lt;- keras_model(gani, gano)<br/>gan %&gt;% compile(optimizer = 'rmsprop', <br/>                loss = "binary_crossentropy")</pre>

<p>这里，生成对抗网络的输出(gano)使用具有固定权重的生成器网络和鉴别器网络。生成对抗网络(gan)以<kbd>gani</kbd>和<kbd>gano</kbd>为基础。然后用<kbd>rmsprop</kbd>优化器和指定为<kbd>binary_crossentropy</kbd>的损耗编译网络。</p>

<p>现在，我们准备训练网络。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Training the network</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">训练网络</h1>

                

            

            

                

<p>在本节中，我们将对网络进行培训。在训练网络时，我们将保存假图像并存储损失值，以查看训练进度。它们将帮助我们在创建逼真的假图像时评估网络的有效性。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Initial setup for saving fake images and loss values</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">保存假图像和损失值的初始设置</h1>

                

            

            

                

<p>我们将从指定培训过程中需要的一些东西开始。让我们来看看下面的代码:</p>

<pre># Initial settings<br/>b &lt;- 50  <br/>setwd("~/Desktop/")<br/>dir &lt;- "FakeImages"<br/>dir.create(dir)<br/>start &lt;- 1; dloss &lt;- NULL; gloss &lt;- NULL</pre>

<p>从前面的代码中，我们可以观察到以下内容:</p>

<ul>

<li>我们将使用50的批量(b)。</li>

<li>我们将把假图像保存在<kbd>FakeImages</kbd>目录中，这个目录是在我们的电脑桌面上创建的。</li>

<li>我们还将利用鉴频器损耗值(dloss)和GAN损耗值(gloss)，它们由<kbd>NULL</kbd>初始化。</li>

</ul>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Training process</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">培训过程</h1>

                

            

            

                

<p>接下来，我们将训练模型。这里，我们将使用100次迭代。让我们回顾一下这方面的代码，代码被总结为五点:</p>

<pre># 1. Generate 50 fake images from noise<br/>for (i in 1:100) {noise &lt;- matrix(rnorm(b*l), nrow = b, ncol= l)}<br/>fake &lt;- g %&gt;% predict(noise)<br/><br/># 2. Combine real &amp; fake images<br/>stop &lt;- start + b - 1 <br/>real &lt;- trainx[start:stop,,,]<br/>real &lt;- array_reshape(real, c(nrow(real), 28, 28, 1))<br/>rows &lt;- nrow(real)<br/>both &lt;- array(0, dim = c(rows * 2, dim(real)[-1]))<br/>both[1:rows,,,] &lt;- fake<br/>both[(rows+1):(rows*2),,,] &lt;- real<br/>labels &lt;- rbind(matrix(runif(b, 0.9,1), nrow = b, ncol = 1),<br/> matrix(runif(b, 0, 0.1), nrow = b, ncol = 1))<br/>start &lt;- start + b<br/><br/># 3. Train discriminator<br/>dloss[i] &lt;- d %&gt;% train_on_batch(both, labels) <br/><br/># 4. Train generator using gan <br/>fakeAsReal &lt;- array(runif(b, 0, 0.1), dim = c(b, 1))<br/>gloss[i] &lt;- gan %&gt;% train_on_batch(noise, fakeAsReal) <br/><br/># 5. Save fake image<br/>f &lt;- fake[1,,,] <br/>dim(f) &lt;- c(28,28,1)<br/>image_array_save(f, path = file.path(dir, paste0("f", i, ".png")))}</pre>

<p>在前面的代码中，我们可以观察到以下情况:</p>

<ol>

<li>我们从模拟标准正态分布的随机数据点开始，并将结果保存为噪声。然后，我们使用生成器网络<kbd>g</kbd>从包含随机噪声的数据中创建假图像。注意<kbd>noise</kbd>的尺寸是50 x 28，而<kbd>fake</kbd>的尺寸是50 x 28 x 28 x 1，并且在每次迭代中包含50个假图像。</li>

<li>我们根据批量大小更新开始和停止的值。对于第一次迭代，start和stop的值分别为1和50。对于第二次迭代，start和stop的值分别为51和100。同样，对于第100次迭代，start和stop的值分别为4，951和5，000。因为包含手写数字五的<kbd>trainx</kbd>有超过5000个图像，所以在这100次迭代中没有图像是重复的。因此，在每次迭代中，选择50个真实图像并存储在<kbd>real</kbd>中，其大小为50×28×28。我们使用reshape将尺寸更改为50 x 28 x 28 x 1，以便它们与假图像的尺寸相匹配。</li>

<li>然后，我们创建一个名为<kbd>both</kbd>的空数组，大小为100 x 28 x 28 x 1，用于存储真实和伪造的图像数据。<kbd>both</kbd>中的前50幅图像包含伪数据，而接下来的50幅图像包含真实图像。我们还使用均匀分布生成50个介于0.9和1之间的随机数作为伪图像的标签，并生成类似的介于0和0.1之间的随机数作为真实图像的标签。请注意，我们没有使用0来表示真实图像，使用1来表示虚假图像，而是引入了一些随机性或噪声。在标签值中人为引入一些噪声有助于训练网络。</li>

<li>我们使用<kbd>both</kbd>中包含的图像数据和<kbd>labels</kbd>中包含的正确类别信息来训练鉴别器网络。我们还将所有100次迭代的鉴别器损耗值存储在<kbd>dloss</kbd>中。如果鉴别器网络学会很好地对假图像和真图像进行分类，那么这个损失值将会很低。</li>

<li>我们试图通过标记包含0到0.1之间的随机值的噪声来欺骗网络，这是我们用于真实图像的。所有100次迭代的结果损失值存储在<kbd>gloss</kbd>中。如果网络学会在呈现虚假图像方面做得很好，让网络把它们归类为真实的，那么这个损失值就低了。</li>

<li>我们保存100次迭代中每一次迭代的第一个假图像，以便我们可以检查它并观察训练过程的影响。</li>

</ol>

<p>注意，通常，生成性对抗网络的训练过程需要大量的计算资源。然而，我们在这里使用的例子是为了快速说明这个过程是如何工作的，并在合理的时间内完成培训过程。对于100次迭代和8 GB内存的计算机，运行所有代码应该不到一分钟。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Reviewing results</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">查看结果</h1>

                

            

            

                

<p>在本节中，我们将回顾从100次迭代中获得的网络损耗。我们还将看看从迭代1到100使用假图像的进展。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Discriminator and GAN losses</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">鉴频器和GAN损耗</h1>

                

            

            

                

<p>从我们的100次迭代中获得的鉴别器和GAN损耗值可以绘制如下。鉴别器损耗基于伪图像和真实图像的损耗值:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/92ead08f-6541-4a19-8d5c-04d2fb0da7ea.png" style="width:28.17em;height:29.17em;"/></p>

<p>从前面的图中，我们可以得出以下结论:</p>

<ul>

<li>鉴频器网络和GAN的损耗值在前20次迭代中表现出很高的可变性。这种可变性是学习过程的结果。</li>

<li>鉴别器网络和发电机网络相互竞争，试图比对方做得更好。当一个网络表现更好时，它是以另一个网络为代价的。这就是为什么如果<kbd>dloss</kbd>和<kbd>gloss</kbd>被绘制在散点图上，我们会期望看到它们之间的一些负相关。这种相关性不一定是完全负相关的，但总体模式应该是负相关的。从长远来看，这两个损失值预计会趋同。</li>

<li>与从鉴频器网络获得的损耗值相比，从GAN获得的损耗值显示出更高的波动。</li>

<li>在大约50次迭代之后，我们注意到鉴频器损耗值显示出一个小的但是逐渐的增加。这表明鉴别器网络发现越来越难以区分由发生器网络产生的真实和伪造图像。</li>

<li>请注意，损失值的增加不一定是负面结果。在这种情况下，这是正反馈，它表明发生器网络与鉴别器网络的对抗正在产生结果。这意味着生成器网络能够创建越来越像真实图像的假图像，并帮助我们实现我们的主要目标。</li>

</ul>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Fake images</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">虚假图像</h1>

                

            

            

                

<p>我们将使用以下代码读取假图像，然后绘制它们:</p>

<pre># Fake image data<br/>library(EBImage)<br/>setwd("~/Desktop/FakeImages")<br/>temp = list.files(pattern = "*.png")<br/>mypic &lt;- list()<br/>for (i in 1:length(temp)) {mypic[[i]] &lt;- readImage(temp[[i]])}<br/>par(mfrow = c(10,10))<br/>for (i in 1:length(temp)) plot(mypic[[i]])</pre>

<p>在前面的代码中，我们利用e image库来处理假图像数据。我们已经阅读了保存在<kbd>FakeImages</kbd>目录中的所有100张图片。现在，我们可以在10 x 10的网格中绘制所有图像，如下图所示:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/c9b410e9-63fd-494b-8546-e948b8536f4e.png" style="width:27.25em;height:29.42em;"/></p>

<p>在前面的图像中，显示了100次迭代中的第一个伪图像。由此，我们可以做出如下观察:</p>

<ul>

<li>第一行中的前十个图像代表前10次迭代。</li>

<li>第一幅图像只是反映了随机噪声。当我们达到10次迭代时，图像开始捕捉手写数字5的本质。</li>

<li>当网络训练经历迭代91到100时，数字5在视觉上变得更加清晰。</li>

</ul>

<p>在下一节中，我们将通过对网络进行一些更改并观察其对网络训练过程的影响来进行实验。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Performance optimization tips and best practices</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">性能优化技巧和最佳实践</h1>

                

            

            

                

<p>在本节中，我们将通过在发生器网络和鉴别器网络中插入额外的卷积层来进行实验。通过这个实验，我们将传达性能优化技巧和最佳实践。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Changes in the generator and discriminator network</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">发生器和鉴别器网络的变化</h1>

                

            

            

                

<p>发电机网络中的变化显示在以下代码中:</p>

<pre># Generator network<br/>gi &lt;- layer_input(shape = l)<br/>go &lt;- gi %&gt;% layer_dense(units = 32 * 14 * 14) %&gt;%<br/>         layer_activation_leaky_relu() %&gt;% <br/>         layer_reshape(target_shape = c(14, 14, 32)) %&gt;% <br/>         layer_conv_2d(filters = 32, <br/>                       kernel_size = 5,<br/>                       padding = "same") %&gt;% <br/>         layer_activation_leaky_relu() %&gt;% <br/>         layer_conv_2d_transpose(filters = 32, <br/>                                 kernel_size = 4,<br/>                                 strides = 2, <br/>                                 padding = "same") %&gt;% <br/>         layer_activation_leaky_relu() %&gt;%      <br/>         layer_conv_2d(filters = 64, <br/>                      kernel_size = 5, <br/>                      padding = "same") %&gt;% <br/>         layer_activation_leaky_relu() %&gt;% <br/>         layer_conv_2d(filters = 1, <br/>                       kernel_size = 5,<br/>                       activation = "tanh", <br/>                       padding = "same")<br/>g &lt;- keras_model(gi, go)</pre>

<p>在这里，我们可以看到，在发电机网络中，我们在最后一层之前添加了<kbd>layer_conv_2d</kbd>和<kbd>layer_activation_leaky_relu</kbd>层。发电机网络的参数总数已增加到276，801。</p>

<p>鉴别器网络中的变化如以下代码所示:</p>

<pre># Discriminator network<br/>di &lt;- layer_input(shape = c(h, w, c))<br/>do &lt;- di %&gt;% <br/>         layer_conv_2d(filters = 64, kernel_size = 4) %&gt;% <br/>         layer_activation_leaky_relu() %&gt;% <br/>         layer_conv_2d(filters = 64, kernel_size = 4, strides = 2) %&gt;% <br/>         layer_activation_leaky_relu() %&gt;% <br/>         layer_flatten() %&gt;%<br/>         layer_dropout(rate = 0.3) %&gt;%  <br/>         layer_dense(units = 1, activation = "sigmoid")<br/>d &lt;- keras_model(di, do)</pre>

<p>这里，我们在鉴频器网络的平坦层之前添加了<kbd>layer_conv_2d</kbd>和<kbd>layer_activation_leaky_relu</kbd>层。鉴别器网络中的参数数量增加到148，866个。我们保持其他一切不变，然后再次训练网络100次迭代。</p>

<p>现在，我们可以评估这些变化的影响。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Impact of these changes on the results</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">这些变化对结果的影响</h1>

                

            

            

                

<p>100次迭代的鉴频器和GAN损耗值可绘制如下:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/f0b7934c-683d-488a-b9de-b4375b35f698.png" style="width:30.50em;height:23.75em;"/></p>

<p>从前面的图中，我们可以观察到以下情况:</p>

<ul>

<li>通过增加层数，与我们之前获得的结果相比，鉴别器和GAN网络的损耗值的波动已经减小。</li>

<li>在一些迭代中观察到的尖峰或高损耗值指示相应的网络在与另一个网络竞争时处于困境。</li>

<li>与鉴频器网络相关损耗相比，GAN损耗值的可变性仍然较高。</li>

</ul>

<p>下面的图是100次迭代中每一次迭代的第一个伪图像:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/6ea51275-7d28-4f89-ae28-e8054420bf78.png" style="width:25.75em;height:22.50em;"/></p>

<p>从前面的图像中，我们可以观察到以下情况:</p>

<ul>

<li>通过在生成器和鉴别器网络中添加额外的卷积层，网络开始生成五年前复制手写数字的图像。</li>

<li>在之前的网络中，持续看起来像手写数字5的假图像直到大约70-80次迭代才出现。</li>

<li>由于使用了额外的层，我们可以看到数字5在大约20-30次迭代后或多或少地形成，这表明有所改进。</li>

</ul>

<p>接下来，我们将尝试使用这个网络来生成另一个手写数字。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Generating a handwritten image of digit eight</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">生成数字八的手写图像</h1>

                

            

            

                

<p>在本实验中，我们将使用与上一个实验相同的网络体系结构。但是，我们将使用它来生成数字8的手写图像。该实验中100次迭代的鉴别器和GAN损耗值可绘制如下:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/69db0b7a-6a39-40c3-906a-54311552e074.png" style="width:35.33em;height:31.17em;"/></p>

<p>从前面的图中，我们可以得出以下结论:</p>

<ul>

<li>鉴别器和GAN损耗值显示出随着迭代次数从1到100而减少的可变性。</li>

<li>随着网络训练的进行，GAN损耗在一定间隔内的高峰值正在减少。</li>

</ul>

<p>每次迭代的第一个伪图像的图如下:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/28729cfc-3050-4fc5-bfcc-bd9a0f23691e.png" style="width:24.58em;height:24.58em;"/></p>

<p>与数字五相比，数字八在开始形成可识别的模式之前需要更多的迭代。</p>

<p>在本节中，我们在发生器和鉴频器网络中试验了额外的卷积层。由于这一点，我们可以作出以下观察:</p>

<ul>

<li>额外的卷积层似乎对伪图像的生成有积极的影响，伪图像开始看起来更像数字5的手写图像。</li>

<li>尽管我们在本章中提到的数据的结果还不错，但是对于其他数据，我们可能需要对模型架构进行其他的修改。</li>

<li>我们还使用具有相同架构的网络来生成逼真的手写数字8的假图像。据观察，对于数字8，在可识别的模式开始出现之前，训练网络需要更多的迭代。</li>

<li>注意，用于同时生成所有10个手写数字的网络可能更复杂，并且可能需要更多的迭代。</li>

<li>类似地，如果我们的彩色图像的尺寸明显大于28 x 28，这是我们在本章中使用的尺寸，我们将需要更多的计算资源，任务将更具挑战性。</li>

</ul>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Summary</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">摘要</h1>

                

            

            

                

<p class="mce-root">在这一章中，我们使用了一个生成对抗网络来说明如何生成单个手写数字的图像。生成对抗网络利用两个网络:生成器和鉴别器网络。生成器网络从包含随机噪声的数据中创建假图像，而鉴别器网络被训练来区分假图像和真实图像。这两个网络相互竞争，从而可以创建逼真的假图像。虽然在这一章中，我们提供了一个使用生成对抗网络来生成新图像的例子，但是这些网络也已知在生成新文本或新音乐以及异常检测中具有应用。</p>

<p>在这一部分，我们讨论了各种用于处理图像数据的深度学习网络。在下一节中，我们将讨论自然语言处理的深度学习网络。</p>





            



            

        

    </body>



</html></body></html>