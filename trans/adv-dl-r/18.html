<html><head/><body><html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Tips, Tricks, and the Road Ahead</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">提示、技巧和未来之路</h1>

                

            

            

                

<p class="mce-root">在本书中，我们讲述了如何应用各种深度学习网络来开发预测和分类模型。我们介绍的几个技巧和诀窍是特定应用领域特有的，它们帮助我们为我们开发的模型获得更好的预测或分类性能。</p>

<p class="mce-root">在这一章中，我们将回顾一些技巧和窍门，当你继续将这些方法应用于新数据和不同问题时，它们将会非常有用。我们将总共涵盖四个主题。请注意，这些方法在前面的章节中没有涉及到，但是我们将利用其中的一些例子来说明它们的用法。</p>

<p>在本章中，我们将讨论以下主题:</p>

<ul>

<li>用于训练表现可视化的张量板</li>

<li>用石灰可视化深层网络模型</li>

<li>使用tfruns可视化模型训练</li>

<li>网络训练提前停止</li>

</ul>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>TensorBoard for training performance visualization</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">用于训练表现可视化的张量板</h1>

                

            

            

                

<p>对于可视化深度网络训练表现，TensorBoard是一个有用的工具，作为TensorFlow软件包的一部分提供。我们将重新运行我们在<a href="c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml">第2章</a>、<em>用于多类分类的深度神经网络</em>中使用的深度网络模型，其中我们使用CTG数据为患者开发了一个多类分类模型。有关数据处理、模型架构和编译模型的代码，可以参考<a href="c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml">第二章</a>、<em>多类分类的深度神经网络</em>。</p>

<p>以下是<a href="c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml">第二章</a>、<em>多类分类深度神经网络</em>中<kbd>model_one</kbd>的代码:</p>

<pre># Fitting model and TensorBoard<br/>setwd("~/Desktop/")<br/>model_one &lt;- model %&gt;% fit(training, <br/>                         trainLabels, <br/>                         epochs = 200,  <br/>                         batch_size = 32,<br/>                         validation_split = 0.2,<br/>                         callbacks = callback_tensorboard('ctg/one'))<br/>tensorboard('ctg/one')</pre>

<p>从前面的代码中，我们可以观察到以下内容:</p>

<ul>

<li>我们已经设置了一个工作目录，这将是一个桌面，用于存储模型的训练结果，以便在TensorBoard上可视化。</li>

<li>使用附加的特性回调来拟合模型，其中我们使用<kbd>callback_tensorboard</kbd>函数将数据存储在桌面上的<kbd>ctg/one</kbd>文件夹中，以便以后可视化。</li>

<li>注意，<kbd>ctg</kbd>目录是在拟合模型时自动创建的。</li>

<li>最后，<kbd>tensorboard</kbd>功能用于使用存储在<kbd>ctg/one</kbd>文件夹中的数据进行可视化。</li>

</ul>

<p>以下截图是TensorBoard的:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/168b0adc-e8e8-4b73-8638-39038396e058.png"/></p>

<p>前面的屏幕截图显示了200个时期的训练和验证数据的损失和准确度图。这用于训练模型。TensorBoard上的这种可视化本质上是交互式的，并为用户提供了额外的选项，以便他们可以在训练过程中探索和理解模型性能。</p>

<p>正如我们在本书的所有章节中看到的，这些章节阐释了各种深度学习方法的使用，提高分类或预测模型的性能需要大量的实验。为了帮助进行这样的实验，使用张量板的一个主要好处是它允许使用交互式可视化非常容易地比较模型性能。</p>

<p>我们运行了来自第二章<a href="c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml">和<em>的三个模型，用于多类分类</em>，并将模型训练数据存储在<kbd>ctg</kbd>文件夹的子文件夹<kbd>two</kbd>、<kbd>three</kbd>和<kbd>four</kbd>中。运行以下代码进行TensorBoard可视化:</a></p>

<pre># TensorBoard visualization for multiple models<br/>tensorboard(c('ctg/one', 'ctg/two', 'ctg/three', 'ctg/four'))</pre>

<p>前面的代码为所有四个模型创建了TensorBoard可视化。生成的TensorBoard页面的屏幕截图如下:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/a6774e36-15d5-47be-acb2-9b3164f5ecee.png"/></p>

<p>前面的可视化显示了所有四个模型的训练和验证数据的损失和准确性值。以下是我们对这个情节的一些观察:</p>

<ul>

<li>运行的四个模型的结果以不同的颜色显示，以便我们快速识别它们并进行比较。</li>

<li>与通过训练数据观察到的结果相比，基于验证数据的损失和准确度值在结果中显示出更高的可变性。</li>

<li>还提供了下载任何图或相关数据的选项。</li>

</ul>

<p>当我们选择用于深度网络的架构类型、历元数、批量大小和其他感兴趣的模型相关属性时，可视化具有不同参数值的不同模型的能力会很有用。如果需要，它还可以为我们提供进一步实验的方向，并帮助我们比较当前和过去的结果。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Visualizing deep network models with LIME</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">用石灰可视化深层网络模型</h1>

                

            

            

                

<p>在本书到目前为止提供的应用示例中，在我们开发了分类或预测深度网络模型之后，我们进行了可视化以查看模型的整体性能。这些评估是使用训练和测试数据完成的。这种评估背后的主要思想是获得对模型性能的整体或全局理解。然而，在某些情况下，我们希望获得更深入的理解，以及对特定预测的解释。例如，我们可能对理解影响测试数据中特定预测的主要特征或变量感兴趣。这种“局部”解释是一个名为<strong>局部可解释模型不可知解释</strong>或<strong> LIME </strong>的包的焦点。LIME有助于对每个预测提供更深入的见解。</p>

<p>对于我们在Keras中开发的模型，使用LIME执行可视化的代码如下:</p>

<pre># LIME package<br/>library(lime)<br/><br/># Using LIME with keras<br/>model_type.keras.engine.sequential.Sequential &lt;- <br/>function(x, ...) {"classification"}<br/>predict_model.keras.engine.sequential.Sequential &lt;- <br/>  function(x,newdata,type, ...) {p &lt;- predict_proba(object=x, x=as.matrix(newdata))<br/>         data.frame(p)}<br/><br/># Create explainer using lime<br/>explainer &lt;- lime(x = data.frame(training), <br/>             model = model, <br/>             bin_continuous = FALSE)<br/><br/># Create explanation<br/>explanation &lt;- explain(data.frame(test)[1:5,],  <br/>                  explainer    = explainer, <br/>                  n_labels     = 1,  <br/>                  n_features   = 4,  <br/>                  kernel_width = 0.5)<br/>testtarget[1:5]<br/>[1] 0 0 0 2 2</pre>

<p>如前面的代码所示，我们使用两个函数来将LIME与Keras模型结合使用。在第一个函数中，我们指出我们将使用一个分类模型。第二个函数获取预测概率。在本节中，我们将使用第二章、<em>中的<kbd>model_one</kbd>进行多类分类</em>。然后，我们将对训练数据、模型(即<kbd>model_one</kbd>)使用<kbd>lime</kbd>函数，并将连续变量的宁滨指定为<kbd>FALSE</kbd>。产生的解释器与<kbd>explain</kbd>函数一起使用，其中我们将指定标签的数量为一个，并将每种情况下使用的最重要的特征的数量指定为四个。我们指定内核宽度为0.5。我们还可以看到，测试数据中的前三位患者，其类别被标记为0，表明他们属于正常患者类别。同样，测试数据中的第4个和第5个患者已被标记为2，表明他们属于病理患者类别。</p>

<p>我们使用<kbd>plot_features(explanation)</kbd>获得了以下图:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/bbe08ddc-d37e-47b8-9e18-5da306e3e34c.png"/></p>

<p>前面的图为测试数据中的前五名患者提供了单独的图。以下是从该图中可以得出的一些观察结果:</p>

<ul>

<li>五个病人都被正确分类了。</li>

<li>前三个患者已经被分类为属于标记为0的类别，代表正常患者。</li>

</ul>

<ul>

<li>剩余的两个患者被分类为属于标记为2的类别，代表病理患者。</li>

<li>前三个病例的预测概率为0.97或以上，第四和第五个患者的预测概率为0.72或以上。</li>

<li>该图描述了对每个患者进行具体分类的四个最重要的特征。</li>

<li>对于每个患者，带有蓝色条的特征支持模型的结论，而带有红色条的特征与模型的结论相矛盾。</li>

<li>X8、X10和X20变量的较高值似乎对被分类为病理性的患者具有较高的影响。</li>

<li>X12变量的较高值似乎影响被分类为正常的患者。</li>

</ul>

<p>使用<kbd>plot_explanations(explanation)</kbd>可以获得以下热图:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/72a2ebcc-8dd6-4cb3-addb-f361fa0fcd95.png" style="width:46.83em;height:25.75em;"/></p>

<p>我们可以从前面的热图中观察到以下情况:</p>

<ul>

<li>热图使得比较每个患者的不同变量更容易，从而有助于解释。</li>

<li>它总结了案例、特征和标签组合的结果，但不像前面的图提供那么多细节。</li>

<li>对于X1类或标记为正常的患者(1、2和3)，所有四个特征(X8、X10、X12和X20)具有非常相似的权重。</li>

<li>对于X3分类，或标记为病理性(4和5)的患者，所有四个特征(X8、X10、X13和X20)再次具有近似相似的权重。</li>

</ul>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Visualizing model training with tfruns</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">使用tfruns可视化模型训练</h1>

                

            

            

                

<p>当我们使用Keras运行深度网络模型时，我们可以利用<kbd>tfruns</kbd>来可视化损失和准确度图，以及其他与模型相关的摘要。虽然我们也可以在需要时获取剧情和相关摘要，但是使用<kbd>tfruns</kbd>的主要优势是我们可以在一个地方获取所有内容。我们可以利用下面的代码来实现这一点:</p>

<pre>library(tfruns)<br/>training_run("mlp_ctg.R")</pre>

<p>在前面的代码中，被引用的<kbd>R</kbd>文件包含运行<a href="c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml">第2章</a>、<em>中的<kbd>model_one</kbd>用于多类分类的深度神经网络</em>的代码。当我们运行代码时，<kbd>mlp_ctg.R</kbd>文件可能存储在计算机上。一旦我们运行了代码，就会自动出现以下交互式屏幕:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/b1ad8926-326d-482f-bc21-a0938e178876.png"/></p>

<p>前面屏幕截图中显示的页面提供了以下内容:</p>

<ul>

<li>训练和验证数据的损失和准确度值的交互图</li>

<li>基于模型架构的模型摘要</li>

<li>关于运行的信息，包括完成所有时期所用的时间</li>

<li>基于训练和验证数据的准确性和损失形式的数字摘要</li>

<li>使用的样本、时期数和指定的批次大小</li>

</ul>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Early stopping of network training</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">网络训练提前停止</h1>

                

            

            

                

<p>当训练一个网络时，我们预先指定需要的历元数，而不知道实际需要多少个历元。如果我们指定的历元数与实际需要的相比太少，我们可能必须通过指定更多的历元来再次训练网络。另一方面，如果我们指定了比实际需要的更多的时期，那么这可能导致过度拟合的情况，并且我们可能必须通过减少时期的数量来重新训练网络。对于每个历元都需要很长时间才能完成的应用来说，这种试错法非常耗时。在这种情况下，我们可以利用回调来帮助在适当的时候停止网络训练。</p>

<p>为了说明这个问题，让我们使用来自第2章、<em>的<a href="c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml">的CTG数据开发一个分类模型，用于多类分类的深度神经网络</a></em>，使用以下代码:</p>

<pre># Training network for classification with CTG data (chapter-2)<br/>model &lt;- keras_model_sequential()<br/>model %&gt;% <br/>  layer_dense(units = 25, activation = 'relu', input_shape = c(21)) %&gt;%<br/>  layer_dense(units = 3, activation = 'softmax') <br/>model %&gt;% compile(loss = 'categorical_crossentropy', <br/>                  optimizer = 'adam',<br/>                  metrics = 'accuracy')<br/>history &lt;- model %&gt;% fit(training, <br/>                         trainLabels, <br/>                         epochs = 50,  <br/>                         batch_size = 32,<br/>                         validation_split = 0.2)<br/>plot(history)</pre>

<p>在前面的代码中，我们指定了50个时期。训练过程完成后，我们可以绘制训练和验证数据的损失和准确度值，如下所示:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/0c6c3241-00be-4b66-bf2c-429bd7d761f7.png" style="width:34.83em;height:30.00em;"/></p>

<p>从前面的图中，我们可以观察到以下情况:</p>

<ul>

<li>我们可以观察到，验证数据的损失值最初在最初的几个时期减少，然后开始增加。</li>

<li>该图还显示，在最初的几个时期之后，训练和验证数据的损失值显示出差异，并且趋向于相反的方向。</li>

<li>如果我们想更早地停止训练过程，而不是等待所有50个纪元完成，那么我们可以利用Keras中可用的回调功能。</li>

</ul>

<p>以下代码包括在训练网络时<kbd>fit</kbd>函数中的回调功能:</p>

<pre># Training network with callback<br/>model &lt;- keras_model_sequential()<br/>model %&gt;% <br/>  layer_dense(units = 25, activation = 'relu', input_shape = c(21)) %&gt;%<br/>  layer_dense(units = 3, activation = 'softmax') <br/>model %&gt;% compile(loss = 'categorical_crossentropy', <br/>                  optimizer = 'adam',<br/>                  metrics = 'accuracy')<br/>history &lt;- model %&gt;% fit(training, <br/>                         trainLabels, <br/>                         epochs = 50,  <br/>                         batch_size = 32,<br/>                         validation_split = 0.2,<br/>                         callbacks = callback_early_stopping(monitor = "val_loss", <br/>                                                   patience = 10))<br/>plot(history)</pre>

<p>在前面的代码中，回调包含了提前停止:</p>

<ul>

<li>我们用于监控的指标是验证损失值。在这种情况下，可以尝试的另一个度量是验证准确性，因为我们正在开发一个分类模型。</li>

<li>我们已经将耐心指定为10，这意味着当10个时期没有改进时，训练过程将自动停止。</li>

</ul>

<p>损失图和精确度图也有助于我们决定适当的耐心值。以下是损失和准确度的曲线图:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/2bff25de-803a-486c-b48f-da342857f91d.png" style="width:31.92em;height:27.50em;"/></p>

<p>正如我们所看到的，这一次，训练过程没有运行所有50个时期，并且一旦10个时期的损失值没有改善就停止。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Summary</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">摘要</h1>

                

            

            

                

<p>使用深度学习网络开发分类和预测模型涉及大量实验，以获得具有高质量性能的模型。为了有助于这一过程，有各种方法对可视化和控制网络训练非常有用。在这一章中，我们讨论了四种有用的方法。我们看到TensorBoard提供了一个工具，在用不同的架构和模型中的其他变化训练网络之后，我们可以使用它来评估和比较模型性能。使用TensorBoard的优势在于它以一种用户友好的方式将所有必要的信息集中在一个地方。在某些情况下，我们希望了解在使用分类或预测模型时，特定预测的主要特征或变量是如何受到影响的。在这种情况下，我们可以使用LIME来想象主要特性的影响。</p>

<p>我们在本章举例说明的另一个有用的技巧是借助tfruns的可视化。在开发深度网络模型时，我们会遇到与特定模型相关的各种情节和摘要。使用tfruns，我们可以借助交互式屏幕在一个地方可视化所有信息。在接下来的旅程中非常有用的另一个技巧是，当开发出合适的分类或预测模型时，使用回调来自动停止训练过程。本章讨论的所有方法对未来的旅程都非常有用，尤其是当你在处理复杂而具有挑战性的问题时。</p>





            



            

        

    </body>



</html></body></html>