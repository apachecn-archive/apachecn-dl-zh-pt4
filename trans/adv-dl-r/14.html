<html><head/><body><html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Text Classification Using Recurrent Neural Networks</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">基于递归神经网络的文本分类</h1>

                

            

            

                

<p class="mce-root">递归神经网络对于解决数据涉及序列的问题很有用。在文本分类、时间序列预测、视频中的帧序列、DNA序列和语音识别中可以看到一些涉及序列的应用示例。</p>

<p>在本章中，我们将使用递归神经网络开发一个情感(积极或消极)分类模型。我们将首先准备用于开发文本分类模型的数据，然后开发顺序模型、编译模型、拟合模型、评估模型、预测，以及使用混淆矩阵进行模型性能评估。我们还将回顾一些情感分类性能优化的技巧。</p>

<p>更具体地说，在本章中，我们将讨论以下主题:</p>

<ul>

<li class="mce-root">为模型构建准备数据</li>

<li>开发递归神经网络模型</li>

<li>拟合模型</li>

<li>模型评估和预测</li>

<li>性能优化技巧和最佳实践</li>

</ul>

<p class="mce-root"/>

<p class="mce-root"/>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Preparing data for model building</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">为模型构建准备数据</h1>

                

            

            

                

<p>在本章中，我们将使用Keras包中的<strong>互联网电影数据库</strong> ( <strong> IMDb </strong>)电影评论文本数据。请注意，没有必要从任何地方下载这些数据，因为可以使用我们将很快讨论的代码从Keras库中轻松访问这些数据。此外，该数据集经过预处理，以便将文本数据转换为整数序列。我们不能直接使用文本数据来建立模型，在数据可以用作开发深度学习网络的输入之前，将文本数据预处理成整数序列是必要的。</p>

<p>我们将从使用<kbd>dataset_imdb</kbd>函数加载<kbd>imdb</kbd>数据开始，在这里我们还将使用<kbd>num_words</kbd>指定最常用单词的数量为500。然后，我们将把<kbd>imdb</kbd>数据分成<kbd>train</kbd>和<kbd>test</kbd>数据集。让我们看一下下面的代码来理解这个数据:<br/></p>

<pre># IMDB data<br/>imdb &lt;- dataset_imdb(num_words = 500)<br/>c(c(train_x, train_y), c(test_x, test_y)) %&lt;-% imdb<br/>length(train_x); length(test_x)<br/>[1] 25000<br/>[1] 25000<br/><br/>table(train_y)<br/>train_y<br/>    0     1 <br/>12500 12500 <br/><br/>table(test_y)<br/>test_y<br/>    0     1 <br/>12500 12500</pre>

<p>让我们看一下前面的代码:</p>

<ul>

<li><kbd>train_x</kbd>和<kbd>test_x</kbd>分别包含表示训练和测试数据中的评论的整数。</li>

<li>同样，<kbd>train_y</kbd>和<kbd>test_y</kbd>包含<kbd>0</kbd>和<kbd>1</kbd>标签，分别代表消极情绪和积极情绪。</li>

<li>使用<kbd>length</kbd>函数，我们可以看到<kbd>train_x</kbd>和<kbd>test_x</kbd>都是基于各25，000条电影评论。</li>

<li><kbd>train_y</kbd>和<kbd>test_y</kbd>的表格显示，在训练和测试数据中有相同数量的正面(12，500)和负面(12，500)评价。</li>

</ul>

<p class="mce-root"/>

<p>拥有这样一个平衡的数据集有助于避免由于类不平衡问题造成的任何偏差。</p>

<p>电影评论中的单词由唯一的整数表示，分配给单词的每个整数基于其在数据集中的总频率。例如，整数1代表最常用的单词，整数2代表第二常用的单词，依此类推。此外，整数0不用于任何特定的单词，而是表示未知的单词。</p>

<p>让我们使用以下代码来看看<kbd>train_x</kbd>数据中的第三和第六个序列:</p>

<pre># Sequence of integers<br/>train_x[[3]]<br/>  [1]   1  14  47   8  30  31   7   4 249 108   7   4   2  54  61 369<br/> [17]  13  71 149  14  22 112   4   2 311  12  16   2  33  75  43   2<br/> [33] 296   4  86 320  35   2  19 263   2   2   4   2  33  89  78  12<br/> [49]  66  16   4 360   7   4  58 316 334  11   4   2  43   2   2   8<br/> [65] 257  85   2  42   2   2  83  68   2  15  36 165   2 278  36  69<br/> [81]   2   2   8 106  14   2   2  18   6  22  12 215  28   2  40   6<br/> [97]  87 326  23   2  21  23  22  12 272  40  57  31  11   4  22  47<br/>[113]   6   2  51   9 170  23   2 116   2   2  13 191  79   2  89   2<br/>[129]  14   9   8 106   2   2  35   2   6 227   7 129 113<br/><br/>train_x[[6]]<br/> [1]   1   2 128  74  12   2 163  15   4   2   2   2   2  32  85 156  45<br/>[18]  40 148 139 121   2   2  10  10   2 173   4   2   2  16   2   8   4<br/>[35] 226  65  12  43 127  24   2  10  10<br/><br/>for (i in 1:6) print(length(train_x[[i]]))<br/><br/>Output<br/><br/><strong>[1] 218</strong><br/><strong>[1] 189</strong><br/><strong>[1] 141</strong><br/><strong>[1] 550</strong><br/><strong>[1] 147</strong><br/><strong>[1] 43</strong></pre>

<p>从前面的代码和输出中，我们可以观察到以下内容:</p>

<ul>

<li>从第三个电影评论相关的整数序列的输出中，我们可以观察到第三个评论包含了1(第1个整数)到369(第16个整数)之间的141个整数。</li>

<li>由于我们把使用最频繁的词限制在500，所以对于第三次复习，没有大于500的整数。</li>

<li>同样，从第六条评论的相关整数序列的输出中，我们可以观察到第六条评论包含43个介于1(第1个整数)和226(第35个整数)之间的整数。</li>

<li>查看<kbd>train_x</kbd>数据中前六个序列的长度，我们可以观察到电影评论的长度在43(列车数据中的第6个评论)和550(列车数据中的第4个评论)之间变化。电影评论长度的这种变化是正常的，也是意料之中的。</li>

</ul>

<p class="mce-root">在我们开发一个电影评论情感分类模型之前，我们需要找到一种方法使所有电影评论的整数序列长度相同。我们可以通过填充序列来实现这一点。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Padding sequences</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">填充序列</h1>

                

            

            

                

<p>对文本序列进行填充是为了确保所有的序列具有相同的长度。让我们来看看下面的代码:</p>

<pre># Padding and truncation<br/>train_x &lt;- pad_sequences(train_x, maxlen = 100)<br/>test_x &lt;- pad_sequences(test_x, maxlen = 100)</pre>

<p>从前面的代码中，我们可以观察到以下内容:</p>

<ul>

<li>在<kbd>pad_sequences</kbd>函数的帮助下，通过为<kbd>maxlen</kbd>指定一个值，我们可以实现所有整数序列的长度相等。</li>

<li>在这个例子中，我们将训练和测试数据中每个电影评论序列的长度限制为100。注意，在填充序列之前，<kbd>train_x</kbd>和<kbd>test_x</kbd>的结构是25000条评论的列表。</li>

<li>然而，在填充序列之后，两者的结构都变成25，000 x 100的矩阵。这可以通过在填充前后运行<kbd>str(train_x)</kbd>来轻松验证。</li>

</ul>

<p>为了观察填充对整数序列的影响，让我们看看下面的代码及其输出:</p>

<pre># Sequence of integers<br/>train_x[3,]<br/>  [1]   2   4   2  33  89  78  12  66  16   4 360   7   4  58 316 334<br/> [17]  11   4   2  43   2   2   8 257  85   2  42   2   2  83  68   2<br/> [33]  15  36 165   2 278  36  69   2   2   8 106  14   2   2  18   6<br/> [49]  22  12 215  28   2  40   6  87 326  23   2  21  23  22  12 272<br/> [65]  40  57  31  11   4  22  47   6   2  51   9 170  23   2 116   2<br/> [81]   2  13 191  79   2  89   2  14   9   8 106   2   2  35   2   6<br/> [97] 227   7 129 113<br/><br/>train_x[6,]<br/>  [1]   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0<br/> [17]   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0<br/> [33]   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0<br/> [49]   0   0   0   0   0   0   0   0   0   1   2 128  74  12   2 163<br/> [65]  15   4   2   2   2   2  32  85 156  45  40 148 139 121   2   2<br/> [81]  10  10   2 173   4   2   2  16   2   8   4 226  65  12  43 127<br/> [97]  24   2  10  10</pre>

<p>在前面的代码中可以看到填充<kbd>train_x</kbd>后第三个整数序列的输出。在这里，我们可以观察到以下情况:</p>

<ul>

<li>第三个序列现在的长度为100。第三个序列最初有141个整数，我们可以观察到位于序列开头的41个整数被截断了。</li>

<li>另一方面，第六个序列的输出显示了不同的模式。</li>

<li>第六个序列最初的长度为43，但现在在序列的开头添加了57个零，以人为地将长度扩展到100。</li>

<li>在每个训练和测试数据中，与电影评论相关的所有25，000个整数序列都以类似的方式受到影响。</li>

</ul>

<p>在下一部分中，我们将开发一个递归神经网络的架构，该架构将用于开发一个电影评论情感分类模型。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Developing a recurrent neural network model</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">开发递归神经网络模型</h1>

                

            

            

                

<p>在本节中，我们将开发递归神经网络的体系结构并编译它。让我们看看下面的代码:</p>

<pre># Model architecture<br/>model &lt;- keras_model_sequential() <br/>model %&gt;% <br/>         layer_embedding(input_dim = 500, output_dim = 32) %&gt;%<br/>         layer_simple_rnn(units = 8) %&gt;%  <br/>         layer_dense(units = 1, activation = "sigmoid")</pre>

<p class="mce-root"/>

<p class="mce-root"/>

<p class="mce-root"/>

<p class="mce-root"/>

<p class="mceNonEditable"/>

<p class="mceNonEditable"/>

<p>我们从使用<kbd>keras_model_sequential</kbd>函数初始化模型开始。然后，我们添加嵌入和简单的<strong>递归神经网络</strong> ( <strong> RNN </strong>)层。对于嵌入层，我们将<kbd>input_dim</kbd>指定为500，这与我们之前指定的最常用单词的数量相同。下一层是一个简单的RNN层，隐藏单元的数量指定为8。</p>

<p>注意，<kbd>layer_simple_rnn</kbd>层的默认激活函数是双曲正切(tanh)，这是一条S形曲线，输出范围从-1到+1。</p>

<p>最后的密集层具有一个单元，以利用激活函数sigmoid来捕捉电影评论情绪(正面或负面)。当输出位于0和1之间时，就像在这种情况下，它便于解释，因为它可以被认为是一种概率。<br/></p>

<p>注意，sigmoid激活函数是一条S形曲线，输出范围在0和1之间。</p>

<p class="mce-root">现在，让我们看看模型摘要，并了解我们如何计算所需的参数数量。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Calculation of parameters</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">参数计算</h1>

                

            

            

                

<p>RNN模式的概要如下:</p>

<pre># Model summary<br/>model<br/><br/>OUTPUT<br/><br/><strong>Model</strong><br/><strong>________________________________________________________________________</strong><br/><strong>Layer (type)                    Output Shape                 Param #    </strong><br/><strong>========================================================================</strong><br/><strong>embedding_21 (Embedding)        (None, None, 32)             16000      </strong><br/><strong>________________________________________________________________________</strong><br/><strong>simple_rnn_23 (SimpleRNN)       (None, 8)                    328        </strong><br/><strong>________________________________________________________________________</strong><br/><strong>dense_24 (Dense)                (None, 1)                    9          </strong><br/><strong>========================================================================</strong><br/><strong>Total params: 16,337</strong><br/><strong>Trainable params: 16,337</strong><br/><strong>Non-trainable params: 0</strong><br/><strong>________________________________________________________________________</strong></pre>

<p>嵌入层的参数数量是通过将500(最频繁出现的单词的数量)乘以32(输出维度)得到16，000。为了得到简单RNN层的参数数量，我们使用<em> (h(h+i) + h) </em>，其中<em> h </em>表示隐藏单元的数量，而<em> i </em>表示该层的输入尺寸。在这种情况下，这是32。</p>

<p>因此，我们有(8(8 + 32)+8) = 328个参数。</p>

<p>请注意，如果我们在这里考虑一个完全连接的密集层，我们将得到(8 x 32 + 8) = 264。然而，额外的64个参数是因为我们使用循环层来捕获文本数据中的序列。</p>

<p>在循环层中，还使用了来自先前输入的信息，这导致了我们在这里可以看到的这些额外参数。这就是为什么与常规的密集连接的神经网络层相比，rnn更适合处理序列数据的原因。对于最后一层，即密集层，我们有(1 x 8 + 1) = 9个参数。总的来说，这个架构有16，337个参数。</p>

<p>在循环层中，使用先前输入的信息有助于更好地表示文本或包含某种序列的类似数据中出现的序列。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Compiling the model</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">编译模型</h1>

                

            

            

                

<p>编译模型的代码如下:</p>

<pre># Compile model<br/>model %&gt;% compile(optimizer = "rmsprop",<br/>         loss = "binary_crossentropy",<br/>         metrics = c("acc"))</pre>

<p class="mce-root"/>

<p>我们用<kbd>rmsprop</kbd>优化器编译模型，这是推荐给递归神经网络的。由于电影评论要么是正面的要么是负面的，因此我们利用<kbd>binary_crossentropy</kbd>作为二进制类型响应的损失函数。最后，对于度量标准，我们指定了精确度。</p>

<p>在下一节中，我们将使用该架构开发一个使用递归神经网络的电影评论情感分类模型。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Fitting the model</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">拟合模型</h1>

                

            

            

                

<p>拟合模型的代码如下:</p>

<pre># Fit model<br/>model_one &lt;- model %&gt;% fit(train_x, train_y,<br/>         epochs = 10,<br/>         batch_size = 128,<br/>         validation_split = 0.2)</pre>

<p>为了拟合模型，我们将利用20%的验证分割，这使用来自训练数据的20，000个电影评论数据来构建模型。剩余的5000个电影评论训练数据用于评估损失和准确性形式的验证。我们运行10个epochs，批量大小为128。</p>

<p>使用验证拆分时，需要注意的是，对于20%，它使用前80%的定型数据进行定型，后20%的定型数据进行验证。因此，如果审查数据的前50%是负面的，后50%是正面的，20%的验证分割将导致模型验证仅基于正面的审查。因此，在使用验证分割之前，我们必须验证情况并非如此；否则，它将引入显著的偏差。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Accuracy and loss</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">准确性和损失</h1>

                

            

            

                

<p>下图显示了使用<kbd>plot(model_one)</kbd>的训练和验证数据在10个时期后的准确度和损失值:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/296b64bb-74b6-4079-b07d-d50070d75845.png"/></p>

<p>从上图中，可以观察到以下情况:</p>

<ul>

<li>从时段1到10，训练损失继续减少。</li>

<li>验证损失最初减少，但在3个时期后开始变得平缓。</li>

<li>在相反的方向上也观察到类似的精确度模式。</li>

</ul>

<p>在下一节中，我们将评估分类模型，并在训练和测试数据的帮助下评估模型预测性能。</p>

<p class="mce-root"/>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Model evaluation and prediction</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">模型评估和预测</h1>

                

            

            

                

<p>首先，我们将评估基于列车数据的模型的损失和准确性。我们还将基于训练数据获得混淆矩阵。应使用测试数据重复相同的过程。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Training the data</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">训练数据</h1>

                

            

            

                

<p>我们将使用<kbd>evaluate</kbd>函数来获取损耗和精度值，如以下代码所示:</p>

<pre># Loss and accuracy<br/>model %&gt;% evaluate(train_x, train_y)<br/>$loss<br/>[1] 0.4057531<br/><br/>$acc<br/>[1] 0.8206</pre>

<p>从前面的输出可以看出，基于训练数据的损失值和准确度值分别为0.406和0.821。</p>

<p>使用训练数据的预测用于开发混淆矩阵，如以下代码所示:</p>

<pre># Prediction and confusion matrix<br/>pred &lt;- model %&gt;% predict_classes(train_x)<br/>table(Predicted=pred, Actual=imdb$train$y)<br/> Actual<br/>Predicted 0 1<br/> 0 9778 1762<br/> 1 2722 10738</pre>

<p>通过查看前面的混淆矩阵，可以得出以下观察结果:</p>

<ul>

<li>有9，778个电影评论被正确分类为负面的，并且有10，738个电影评论被正确分类为正面的。我们可以观察到，该模型很好地将评论分为正面或负面。</li>

<li>查看错误分类，我们还可以观察到，在2722个场合，负面电影评论被错误分类为正面电影评论。与分类模型将正面评论错误分类为负面(1，762次)相比，这相对较高。</li>

</ul>

<p class="mce-root"/>

<p>接下来，让我们根据测试数据做一个类似的评估。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Testing the data</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">测试数据</h1>

                

            

            

                

<p>获取损耗和精度值的代码如下:</p>

<pre># Loss and accuracy<br/>model %&gt;% evaluate(test_x, test_y)<br/>$loss<br/>[1] 0.4669374<br/><br/>$acc<br/>[1] 0.77852</pre>

<p>在这里，我们可以看到基于测试数据的损失和准确度分别为0.467和0.778。这些结果比我们从训练数据中观察到的稍差。</p>

<p>接下来，我们将预测测试数据的类，并使用结果来获得混淆矩阵，如以下代码所示:</p>

<pre># Prediction and confusion matrix<br/>pred1 &lt;- model %&gt;%   predict_classes(test_x)<br/>table(Predicted=pred1, Actual=imdb$test$y)<br/>         Actual<br/>Predicted     0     1<br/>        0  9134  2171<br/>        1  3366 10329</pre>

<p>除了总体结果比我们从训练数据中获得的结果稍差之外，我们看不出训练数据和测试数据之间有任何重大差异。</p>

<p>在下一节中，我们将探索一些提高模型性能的策略。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Performance optimization tips and best practices</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">性能优化技巧和最佳实践</h1>

                

            

            

                

<p>在开发递归神经网络模型时，我们会遇到需要做出几个与网络相关的决策的情况。这些决定可能包括尝试不同的激活功能，而不是我们使用的默认激活功能。我们来做这样的改动，看看它们对模型的影评情感分类性能有什么影响。</p>

<p class="mce-root"/>

<p class="mce-root"/>

<p>在本节中，我们将尝试以下四个因素:</p>

<ul>

<li>简单RNN图层中的单元数量</li>

<li>在简单的RNN层中使用不同的激活函数</li>

<li>添加更多循环层</li>

<li>填充序列最大长度的变化</li>

</ul>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Number of units in the simple RNN layer</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">简单RNN图层中的单元数量</h1>

                

            

            

                

<p>合并这一更改，然后编译/拟合模型的代码如下:</p>

<pre># Model architecture<br/>model &lt;- keras_model_sequential() <br/>model %&gt;% <br/>         layer_embedding(input_dim = 500, output_dim = 32) %&gt;%<br/>         layer_simple_rnn(units = 32) %&gt;% <br/>         layer_dense(units = 1, activation = "sigmoid")<br/><br/># Compile model<br/>model %&gt;% compile(optimizer = "rmsprop",<br/>         loss = "binary_crossentropy",<br/>         metrics = c("acc"))<br/><br/># Fit model<br/>model_two &lt;- model %&gt;% fit(train_x, train_y,<br/>         epochs = 10,<br/>         batch_size = 128,<br/>         validation_split = 0.2)</pre>

<p>这里，我们通过将简单RNN层中的单元数量从8个增加到32个来改变架构。其他一切都保持不变。然后，我们编译并拟合模型，如前面的代码所示。</p>

<p class="mce-root"/>

<p>10个时期后的准确度和损失值可在下图中看到:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/a5f3db7e-27c4-4c12-a305-528783ec3d78.png"/></p>

<p class="mce-root"/>

<p class="mce-root"/>

<p>前面的图表明了以下情况:</p>

<ul>

<li>epoch 3以后的训练和验证数据之间的差距明显加大。</li>

<li>这清楚地表明，与前面的图相比，过度拟合的水平增加了，在前面的图中，简单RNN中的单元数是8。</li>

<li>这也反映在较高的损失值0.585和较低的精度值0.757中，我们根据这一新模型获得了测试数据。</li>

</ul>

<p>现在，让我们在简单的RNN层中试验一个不同的激活函数，看看这个过度拟合问题是否可以解决。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Using different activation functions in the simple RNN layer</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">在简单的RNN层中使用不同的激活函数</h1>

                

            

            

                

<p>这种变化可以在下面的代码中看到:</p>

<pre># Model architecture<br/>model &lt;- keras_model_sequential() <br/>model %&gt;% <br/>         layer_embedding(input_dim = 500, output_dim = 32) %&gt;%<br/>         layer_simple_rnn(units = 32, activation = "relu") %&gt;% <br/> layer_dense(units = 1, activation = "sigmoid")<br/><br/># Compile model<br/>model %&gt;% compile(optimizer = "rmsprop",<br/> loss = "binary_crossentropy",<br/> metrics = c("acc"))<br/><br/># Fit model<br/>model_three &lt;- model %&gt;% fit(train_x, train_y,<br/> epochs = 10,<br/> batch_size = 128,<br/> validation_split = 0.2)</pre>

<p>在前面的代码中，我们将简单RNN层中的默认激活函数更改为ReLU激活函数。我们保持其他所有东西和之前实验中的一样。</p>

<p class="mce-root"/>

<p class="mce-root"/>

<p class="mce-root"/>

<p>10个时期后的准确度和损失值可在下图中看到:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/381e8b5e-2d09-42d2-bdce-ff8d0b3feb7c.png"/></p>

<p class="mce-root"/>

<p>从前面的图中，我们可以观察到以下情况:</p>

<ul>

<li>损耗和精度值现在看起来好多了。</li>

<li>基于训练和验证的损失和准确度曲线现在彼此更接近。</li>

<li>基于我们获得的测试数据，我们使用该模型找到了损失值和精度值，即分别为0.423和0.803。与我们目前获得的结果相比，这显示了更好的结果。</li>

</ul>

<p>接下来，我们将通过添加更多的循环层进行进一步的实验。这将有助于我们建立更深层次的递归神经网络模型。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Adding more recurrent layers </title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">添加更多循环层</h1>

                

            

            

                

<p>现在，我们将通过向当前网络添加两个额外的循环层来进行实验。包含这一更改的代码如下:</p>

<pre># Model architecture<br/>model &lt;- keras_model_sequential() %&gt;% <br/>         layer_embedding(input_dim = 500, output_dim = 32) %&gt;% <br/>         layer_simple_rnn(units = 32, <br/>                          return_sequences = TRUE, <br/>                          activation = 'relu') %&gt;% <br/>         layer_simple_rnn(units = 32, <br/>                          return_sequences = TRUE, <br/>                          activation = 'relu') %&gt;% <br/>         layer_simple_rnn(units = 32, <br/>                          activation = 'relu') %&gt;%<br/>         layer_dense(units = 1, activation = "sigmoid")<br/><br/># Compile model<br/>model %&gt;% compile(optimizer = "rmsprop",<br/> loss = "binary_crossentropy",<br/> metrics = c("acc"))<br/><br/># Fit model<br/>model_four &lt;- model %&gt;% fit(train_x, train_y,<br/>0 epochs = 10,<br/> batch_size = 128,<br/> validation_split = 0.2)</pre>

<p class="mce-root"/>

<p class="mce-root"/>

<p class="mce-root"/>

<p class="mceNonEditable"/>

<p>当我们添加这些额外的循环层时，我们也将<kbd>return_sequences</kbd>设置为<kbd>TRUE</kbd>。我们保持其他一切不变，并编译/拟合模型。基于训练和验证数据的损失和准确度值的曲线如下:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/82787f84-dbc6-4bba-a200-7fe4294bfbf3.png"/></p>

<p class="mce-root"/>

<p>从前面的图中，我们可以观察到以下情况:</p>

<ul>

<li>10个时期后，训练和验证的损失和准确度值显示出合理的接近水平，表明不存在过度拟合。</li>

<li>基于我们计算的测试数据的损失和精度显示出结果中的适当改进，分别为0.403和0.816。</li>

<li>这表明，更深的循环层确实有助于以更好的方式捕捉电影评论中的单词序列。反过来，这使得电影评论中的情绪分类变得更好，如积极或消极。</li>

</ul>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>The maximum length for padding sequences</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">填充序列的最大长度</h1>

                

            

            

                

<p>到目前为止，对于训练和测试数据中的电影评论填充序列，我们使用的最大长度是100。让我们使用下面的代码来看看<kbd>train</kbd>和<kbd>test</kbd>数据中的电影评论长度汇总:</p>

<pre># Summary of padding sequences<br/>z &lt;- NULL<br/>for (i in 1:25000) {z[i] &lt;- print(length(train_x[[i]]))}<br/>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. <br/>   11.0   130.0   178.0   238.7   291.0  2494.0 <br/><br/>z &lt;- NULL<br/>for (i in 1:25000) {z[i] &lt;- print(length(test_x[[i]]))}<br/>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. <br/>    7.0   128.0   174.0   230.8   280.0  2315.0</pre>

<p>从前面的代码中，我们可以观察到以下情况:</p>

<ul>

<li>从列车数据中的影评长度汇总可以看出，最小长度为11，最大长度为2494，中值长度为178。</li>

<li>同样，测试数据的最小审查长度为7，最大长度为2，315，中值长度为174。</li>

</ul>

<p>请注意，当最大填充长度低于中值时(最大长度为100)，我们倾向于通过删除超过100的单词来截断更多的电影评论。同时，当我们选择填充的最大长度明显高于中值时，我们将会遇到这样的情况:更多的电影评论需要包含零，而更少的评论将被截断。</p>

<p class="mce-root"/>

<p>在这一节中，我们将探讨将电影评论中单词序列的最大长度保持在中间值附近的影响。合并这一更改的代码如下:</p>

<pre># IMDB data<br/>c(c(train_x, train_y), c(test_x, test_y)) %&lt;-% imdb<br/>train_x &lt;- pad_sequences(train_x, maxlen = 200)  <br/>test_x &lt;- pad_sequences(test_x, maxlen = 200)<br/><br/># Model architecture<br/>model &lt;- keras_model_sequential() %&gt;% <br/>         layer_embedding(input_dim = 500, output_dim = 32) %&gt;% <br/>         layer_simple_rnn(units = 32, <br/>                          return_sequences = TRUE, <br/>                          activation = 'relu') %&gt;% <br/>         layer_simple_rnn(units = 32, <br/>                          return_sequences = TRUE, <br/>                          activation = 'relu') %&gt;% <br/>         layer_simple_rnn(units = 32, <br/>                          return_sequences = TRUE, <br/>                          activation = 'relu') %&gt;% <br/>         layer_simple_rnn(units = 32, <br/>                          activation = 'relu') %&gt;%<br/>         layer_dense(units = 1, activation = "sigmoid")<br/><br/># Compile model<br/>model %&gt;% compile(optimizer = "rmsprop",<br/>         loss = "binary_crossentropy",<br/>         metrics = c("acc"))<br/><br/># Fit model<br/>model_five &lt;- model %&gt;% fit(train_x, train_y,<br/>         epochs = 10,<br/>         batch_size = 128,<br/>         validation_split = 0.2)</pre>

<p>从前面的代码中，我们可以看到，我们在将<kbd>maxlen</kbd>指定为200之后运行模型。我们保持其他一切都和我们在<kbd>model_four</kbd>时一样。</p>

<p class="mce-root"/>

<p>训练和验证数据的损失和准确性曲线如下:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/43039c1f-594a-45eb-861a-3800e19aab7a.png"/></p>

<p>从前面的图中，我们可以得出以下结论:</p>

<ul>

<li>不存在过度拟合的问题，因为训练和验证数据点彼此非常接近。</li>

<li>基于测试数据的损失和精度分别计算为0.383和0.830。</li>

<li>在此阶段，损耗和精度值处于最佳水平。</li>

</ul>

<p class="mce-root"/>

<p>基于测试数据的混淆矩阵如下:</p>

<pre># Prediction and confusion matrix<br/>pred1 &lt;- model %&gt;%   predict_classes(test_x)<br/>table(Predicted=pred1, Actual=imdb$test$y)<br/>         Actual<br/>Predicted     0     1<br/>        0 10066  1819<br/>        1  2434 10681</pre>

<p>从混淆矩阵中，我们可以得出以下结论:</p>

<ul>

<li>当正确地将电影评论分类为正面(10，681)时，与正确地将负面(10，066)评论分类时相比，该分类模型似乎表现得稍好。</li>

<li>至于分类不正确的评论，我们之前观察到的趋势，即负面的电影评论被模型错误地分类为正面的更高，在这种情况下也存在。</li>

</ul>

<p>在这一部分中，我们对多个单元、激活函数、网络中的循环层数以及填充量进行了实验，以便改进电影评论情感分类模型。您可以进一步研究的一些其他因素包括要包含的最常用单词的数量，以及在填充序列时更改最大长度。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Summary</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">摘要</h1>

                

            

            

                

<p>在这一章中，我们使用IMDb电影评论数据说明了用于文本情感分类的递归神经网络模型的使用。与常规的密集连接网络相比，递归神经网络更适合处理其中有序列的数据。文本数据就是我们在本章中用到的一个例子。</p>

<p class="mce-root"/>

<p>一般来说，深层网络涉及许多因素或变量，这需要一些实验，包括在得到有用的模型之前改变这些因素的水平。在这一章中，我们还开发了五种不同的电影评论情感分类模型。</p>

<p>一种流行的循环神经网络是<strong>长短期记忆</strong> ( <strong> LSTM </strong>)网络。LSTM网络能够学习长期依赖性，并帮助递归网络更长时间地记住输入。</p>

<p>在下一章中，我们将查看一个使用LSTM网络的应用示例，在该示例中，我们将继续使用IMDb电影评论数据，并探索可以对情感分类模型的性能做出的进一步改进。</p>





            



            

        

    </body>



</html></body></html>