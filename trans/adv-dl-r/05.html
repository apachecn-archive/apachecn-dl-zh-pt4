<html><head/><body>

    

        <title>Deep Neural Networks for Regression</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">用于回归的深度神经网络</h1>

                

            

            

                

<p>在上一章中，我们使用了一个包含分类目标变量的数据集，并回顾了使用Keras开发分类模型的步骤。在响应变量是数字的情况下，监督学习问题被归类为回归问题。在本章中，我们将开发一个数字响应变量的预测模型。为了说明开发预测模型的过程，我们将使用波士顿住房数据集，该数据集在<kbd>mlbench</kbd>包中提供。</p>

<p>在本章中，我们将讨论以下主题:</p>

<ul>

<li>了解波士顿住房数据集</li>

<li>准备数据</li>

<li>创建和拟合用于回归的深度神经网络模型</li>

<li>模型评估和预测</li>

<li>性能优化技巧和最佳实践</li>

</ul>





            



            

        

    






    

        <title>Understanding the Boston Housing dataset</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">了解波士顿住房数据集</h1>

                

            

            

                

<p>在本章中，我们将使用六个库。这些库在下面的代码中列出:</p>

<pre># Libraries<br/>library(keras)<br/>library(mlbench)<br/>library(psych)<br/>library(dplyr)<br/>library(magrittr)<br/>library(neuralnet)</pre>

<p><kbd>BostonHousing</kbd>数据的结构如下:</p>

<pre># Data structure<br/>data(BostonHousing)<br/>str(BostonHousing)<br/><br/>OUTPUT<br/><strong>'data.frame':        506 obs. of  14 variables:

 $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...

 $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...

 $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...

 $ chas   : Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...

 $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...

 $ rm     : num  6.58 6.42 7.18 7 7.15 ...

 $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 100 85.9 ...

 $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...

 $ rad    : num  1 2 2 3 3 3 5 5 5 5 ...

 $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...

 $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...

 $ b      : num  397 397 393 395 397 ...

 $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...

 $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 ...</strong></pre>

<p>正如您在前面的输出中看到的，这个数据集有<kbd>506</kbd>观察值和<kbd>14</kbd>变量。在这14个变量中，13个是数字变量，1个(<kbd>chas</kbd>)是因子类型的变量。最后一个变量<kbd>medv</kbd>(以千美元为单位的自有住房的中值)是因变量或目标变量。其余13个变量是独立的。以下是所有变量的简要说明，以表格形式列出，便于参考:</p>

<table border="1" style="border-collapse: collapse;width: 100%">

<tbody>

<tr>

<td class="CDPAlignCenter CDPAlign"><strong>变量</strong></td>

<td class="CDPAlignCenter CDPAlign"><strong>描述</strong></td>

</tr>

<tr>

<td class="CDPAlignCenter CDPAlign"><kbd>crim</kbd></td>

<td class="CDPAlignCenter CDPAlign">按城镇分列的人均犯罪率</td>

</tr>

<tr>

<td class="CDPAlignCenter CDPAlign"><kbd>zn</kbd></td>

<td class="CDPAlignCenter CDPAlign">面积超过25，000平方英尺的住宅用地比例</td>

</tr>

<tr>

<td class="CDPAlignCenter CDPAlign"><kbd>indus</kbd></td>

<td class="CDPAlignCenter CDPAlign">每个城镇的非零售商业用地比例</td>

</tr>

<tr>

<td class="CDPAlignCenter CDPAlign"><kbd>chas</kbd></td>

<td class="CDPAlignCenter CDPAlign">查尔斯河虚拟变量(1，如果该区域以河流为界；否则为0)</td>

</tr>

<tr>

<td class="CDPAlignCenter CDPAlign"><kbd>nox</kbd></td>

<td class="CDPAlignCenter CDPAlign">氮氧化物浓度(百万分之一)</td>

</tr>

<tr>

<td class="CDPAlignCenter CDPAlign"><kbd>rm</kbd></td>

<td class="CDPAlignCenter CDPAlign">每所住宅的平均房间数</td>

</tr>

<tr>

<td class="CDPAlignCenter CDPAlign"><kbd>age</kbd></td>

<td class="CDPAlignCenter CDPAlign">1940年以前建造的自有住房比例</td>

</tr>

<tr>

<td class="CDPAlignCenter CDPAlign"><kbd>dis</kbd></td>

<td class="CDPAlignCenter CDPAlign">到五个波士顿就业中心的加权距离</td>

</tr>

<tr>

<td class="CDPAlignCenter CDPAlign"><kbd>rad</kbd></td>

<td class="CDPAlignCenter CDPAlign">放射状公路可达性指数</td>

</tr>

<tr>

<td class="CDPAlignCenter CDPAlign"><kbd>tax</kbd></td>

<td class="CDPAlignCenter CDPAlign">每万美元的全价值财产税税率</td>

</tr>

<tr>

<td class="CDPAlignCenter CDPAlign"><kbd>ptratio</kbd></td>

<td class="CDPAlignCenter CDPAlign">按城镇分列的学生-教师比率</td>

</tr>

<tr>

<td class="CDPAlignCenter CDPAlign"><kbd>lstat</kbd></td>

<td class="CDPAlignCenter CDPAlign">人口中低收入成员的百分比</td>

</tr>

<tr>

<td class="CDPAlignCenter CDPAlign"><kbd>medv</kbd></td>

<td class="CDPAlignCenter CDPAlign">以千美元为单位的自有住房的中值</td>

</tr>

</tbody>

</table>

<p> </p>

<p class="mce-root">这一数据基于1970年的人口普查。Harrison和Rubinfeld于1978年发表了一份使用该数据的详细统计研究(参考:<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.926.5532&amp;rep=rep1&amp;type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download?doi = 10 . 1 . 1 . 926 . 5532&amp;rep = rep 1&amp;type = pdf</a>。</p>





            



            

        

    






    

        <title>Preparing the data</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">准备数据</h1>

                

            

            

                

<p>为了便于使用，我们首先将<kbd>BostonHousing</kbd>数据的名称改为简单的<kbd>data</kbd>。然后使用<kbd>lapply</kbd>函数将因子类型的独立变量转换为数值类型。</p>

<p>注意，对于这个数据，唯一的因子变量是<kbd>chas</kbd>；然而，对于任何其他包含更多因子变量的数据集，这段代码都可以很好地工作。</p>

<p>看一下下面的代码:</p>

<pre># Converting factor variables to numeric<br/>data &lt;- BostonHousing<br/>data %&gt;% lapply(function(x) as.numeric(as.character(x)))<br/>data &lt;- data.frame(data)</pre>

<p>在前面的代码中，在将因子变量转换为<kbd>numeric</kbd>类型后，我们还将<kbd>data</kbd>的格式更改为<kbd>data.frame</kbd>。</p>





            



            

        

    






    

        <title>Visualizing the neural network</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">可视化神经网络</h1>

                

            

            

                

<p>为了可视化带有隐藏层的神经网络，我们将使用<kbd>neuralnet</kbd>函数。为了便于说明，在本例中将使用两个具有10个和5个单位的隐藏层。输入层有13个节点，基于13个独立变量。对于目标变量<kbd>medv</kbd>，输出层只有一个节点。使用的代码如下:</p>

<pre># Neural network<br/>n &lt;- neuralnet(medv~crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+b+lstat,<br/>                data = data,<br/>                hidden = c(10,5),<br/>                linear.output = F,<br/>                lifesign = 'full',<br/>                rep=1)<br/><br/># Plot<br/>plot(n, col.hidden = "darkgreen", <br/>      col.hidden.synapse = 'darkgreen',<br/>      show.weights = F, <br/>      information = F, <br/>      fill = "lightblue")</pre>

<p>如前面的代码所示，结果保存在<kbd>n</kbd>中，然后用于绘制神经网络的架构，如下图所示:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/411058c3-98fe-4dd2-b54c-865c61368359.png" style="width:36.50em;height:21.00em;"/></p>

<p>从上图中可以看出，输入层有13个节点，对应13个独立变量。有两个隐藏层:第一个隐藏层有10个节点，第二个隐藏层有5个节点。隐藏层中的每个节点都连接到上一层和下一层中的所有节点。输出层有一个响应变量节点<kbd>medv</kbd>。</p>





            



            

        

    






    

        <title>Data partitioning</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">数据划分</h1>

                

            

            

                

<p>接下来，我们将数据转换成矩阵格式。我们还将维度名称设置为<kbd>NULL</kbd>，这将变量的名称更改为默认名称<kbd>V1</kbd>、<kbd>V2</kbd>、<kbd>V3</kbd>、...，<kbd>V14</kbd>:</p>

<pre>data &lt;- as.matrix(data)<br/>dimnames(data) &lt;- NULL </pre>

<p>然后，我们使用以下代码将数据划分为训练和测试数据集:</p>

<pre># Data partitioning<br/>set.seed(1234)<br/>ind &lt;- sample(2, nrow(data), replace = T, prob=c(.7, .3))<br/>training &lt;- data[ind==1, 1:13]<br/>test &lt;- data[ind==2, 1:13]<br/>trainingtarget &lt;- data[ind==1, 14]<br/>testtarget &lt;- data[ind==2, 14]</pre>

<p>本例中使用了70:30的数据分割。为了保持数据分割的可重复性，我们使用一个随机种子<kbd>1234</kbd>。这将允许每次在任何计算机上执行数据划分时，在训练和测试数据中包含相同的样本。独立变量的数据存储在<kbd>training</kbd>中用于训练数据，存储在<kbd>test</kbd>中用于测试数据。类似地，基于相应分割数据的因变量<kbd>medv</kbd>的数据存储在<kbd>trainingtarget</kbd>和<kbd>testtarget</kbd>中。</p>





            



            

        

    






    

        <title>Normalization</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">正常化</h1>

                

            

            

                

<p>为了使数据标准化，需要获得训练数据中所有独立变量的平均值和标准偏差。然后使用<kbd>scale</kbd>功能进行标准化:</p>

<p>对于训练和测试数据，平均值和标准偏差都基于所使用的训练数据。</p>

<pre># Normalization<br/>m &lt;- colMeans(training)<br/>sd &lt;- apply(training, 2, sd)<br/>training &lt;- scale(training, center = m, scale = sd)<br/>test &lt;- scale(test, center = m, scale = sd)</pre>

<p>该数据的数据准备步骤到此结束。应当注意的是，不同的数据集可能需要该数据集特有的额外步骤，例如，许多大型数据集可能具有非常大量的缺失数据值，并且它们可能需要额外的数据准备步骤，以达成处理缺失值的策略并在必要时输入缺失值。</p>

<p>在下一节中，我们将创建一个深度神经网络架构，然后拟合一个模型来准确预测数字目标变量。</p>





            



            

        

    






    

        <title>Creating and fitting a deep neural network model for regression</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">创建和拟合用于回归的深度神经网络模型</h1>

                

            

            

                

<p>为了创建和拟合回归问题的深度神经网络模型，我们将利用Keras。用于模型架构的代码如下:</p>

<p>注意，基于数据，具有13个单位的输入层和具有1个单位的输出层是固定的；但是，要获得合适的隐藏层数和每层中的单元数，您需要进行实验。</p>

<pre class="mce-root"># Model architecture<br/>model &lt;- keras_model_sequential()<br/>model %&gt;%<br/>   layer_dense(units = 10, activation = 'relu', input_shape = c(13)) %&gt;%  <br/>   layer_dense(units = 5, activation = 'relu') %&gt;%<br/>   layer_dense(units = 1) <br/>summary(model)<br/><br/>OUTPUT<br/><strong>___________________________________________________________________________

Layer (type)                     Output Shape                Param #      

===========================================================================

dense_1 (Dense)                   (None, 10)                   140          

___________________________________________________________________________

dense_2 (Dense)                   (None, 5)                    55           

___________________________________________________________________________

dense_3 (Dense)                   (None, 1)                     6            

===========================================================================

Total params: 201

Trainable params: 201

Non-trainable params: 0

___________________________________________________________________________</strong></pre>

<p>从前面的代码中可以看出，我们使用了<kbd>keras_model_sequential</kbd>函数来创建一个顺序模型。使用<kbd>layer_dense</kbd>功能定义神经网络的结构。由于有13个独立变量，<kbd>input_shape</kbd>用于指定13个单位。第一隐藏层具有<kbd>10</kbd>个单元，并且整流线性单元或<kbd>relu</kbd>被用作该第一隐藏层中的激活函数。第二个隐藏层有<kbd>5</kbd>个单元，用<kbd>relu</kbd>作为激活函数。最后一个<kbd>layer_dense</kbd>，有<kbd>1</kbd>单位，代表一个因变量<kbd>medv</kbd>。使用<kbd>summary</kbd>功能，您可以打印显示201个参数的模型摘要。</p>





            



            

        

    






    

        <title>Calculating the total number of parameters</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">计算参数的总数</h1>

                

            

            

                

<p class="mce-root">现在让我们看看如何获得这个模型的总共201个参数。<kbd>dense_1</kbd>层显示<kbd>140</kbd>参数。这些参数基于输入层中有13个单元与第一个隐藏层中的10个单元中的每一个相连，这意味着有130个参数(13 x 10)。剩余的10个参数来自第一个隐藏层中10个单元中每个单元的偏差项。类似地，50个参数(10×5)来自两个隐藏层之间的连接，剩余的5个参数来自第二个隐藏层中5个单元中的每一个的偏差项。最后，<kbd>dense_3</kbd>有<kbd>6</kbd>参数((5 x 1) + 1)。因此，总共有201个参数基于在这个例子中选择的神经网络模型的结构。</p>





            



            

        

    






    

        <title>Compiling the model</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">编译模型</h1>

                

            

            

                

<p class="mce-root">定义模型架构后，使用以下代码编译模型以配置学习过程:</p>

<pre class="mce-root"># Compile model<br/>model %&gt;% compile(loss = 'mse', <br/>   optimizer = 'rmsprop', <br/>   metrics = 'mae')</pre>

<p>如前面的代码所示，我们将损失函数定义为均方误差，即<kbd>mse</kbd>。在这一步，还定义了<kbd>rmsprop</kbd>优化器和平均绝对误差或<kbd>mae</kbd>指标。我们选择这些是因为我们的响应变量是数字。</p>

<p class="mce-root"/>

<p class="mce-root"/>





            



            

        

    






    

        <title>Fitting the model</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">拟合模型</h1>

                

            

            

                

<p>接下来，使用<kbd>fit</kbd>功能训练模型。请注意，随着模型训练的进行，我们在每个时期后都会得到一个视觉和数字摘要。下面的代码显示了最后三个时期的输出。我们得到了训练和验证数据的平均绝对误差和损失值。注意，正如<a href="db6a812d-2bad-4f40-9e99-0e20abbe665c.xhtml">第一章</a>、<em>重温深度学习架构和技术</em>中指出的，每次我们训练一个网络，训练和验证误差都会因为网络权重的随机初始化而变化。即使使用相同的随机种子对数据进行分区，这样的结果也是意料之中的。为了获得可重复的结果，最好使用<kbd>save_model_hdf5</kbd>功能保存模型，然后在需要时重新加载。</p>

<p>用于训练网络的代码如下:</p>

<pre class="mce-root"># Fit model<br/>model_one &lt;- model %&gt;%  <br/>   fit(training,<br/>   trainingtarget,<br/>   epochs = 100,<br/>   batch_size = 32,<br/>   validation_split = 0.2)<br/><br/>OUTPUT from last 3 epochs

<strong>Epoch 98/100

284/284 [==============================] - 0s 74us/step - loss: 24.9585 - mean_absolute_error: 3.6937 - val_loss: 86.0545 - val_mean_absolute_error: 8.2678

Epoch 99/100

284/284 [==============================] - 0s 78us/step - loss: 24.6357 - mean_absolute_error: 3.6735 - val_loss: 85.4038 - val_mean_absolute_error: 8.2327

Epoch 100/100

284/284 [==============================] - 0s 92us/step - loss: 24.3293 - mean_absolute_error: 3.6471 - val_loss: 84.8307 - val_mean_absolute_error: 8.2015</strong></pre>

<p>从前面的代码中可以看出，模型是以小批量<kbd>32</kbd>的方式进行训练的，20%的数据被保留用于验证，以避免过度拟合。这里，运行<kbd>100</kbd>个时期或迭代来训练网络。一旦训练过程完成，与训练过程相关的信息保存在<kbd>model_one</kbd>中，然后可用于根据所有时期的训练和验证数据绘制损失和平均绝对误差:</p>

<pre>plot(model_one)</pre>

<p>前面的代码行将返回以下输出。让我们看看训练和验证数据的损失和平均绝对误差(<kbd>model_one</kbd>)图:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/37680ec9-e55b-4c9a-9f21-607ae941db74.png"/></p>

<p>从前面的图中，我们可以得出以下结论:</p>

<ul>

<li>随着训练的进行，训练和验证数据的<kbd>mae</kbd>和<kbd>loss</kbd>值都减小。</li>

<li>训练数据的误差减少率在大约60个时期后降低。</li>

</ul>

<p>开发预测模型后，我们可以通过评估模型的预测质量来评估其性能，这将在下一节中讨论。</p>





            



            

        

    






    

        <title>Model evaluation and prediction</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">模型评估和预测</h1>

                

            

            

                

<p>模型评估是获得合适预测模型过程中的一个重要步骤。使用用于开发模型的训练数据，模型可能表现出良好的性能；然而，对模型的真正测试是用模型还没有见过的数据。让我们看看基于测试数据的模型性能。</p>





            



            

        

    






    

        <title>Evaluation</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">估价</h1>

                

            

            

                

<p>使用<kbd>evaluate</kbd>函数，在以下代码所示测试数据的帮助下，评估模型的性能:</p>

<pre># Model evaluation<br/>model %&gt;%  evaluate(test, testtarget) <br/><br/>OUTPUT<br/><strong> ## $loss</strong><br/><strong> ## [1] 31.14591 </strong><br/><strong> ##</strong><br/><strong> ## $mean_absolute_error</strong><br/><strong> ## [1] 3.614594</strong></pre>

<p>从前面的输出中，我们可以看到测试数据的损失和平均绝对误差分别为<kbd>31.15</kbd>和<kbd>3.61</kbd>。我们稍后将使用这些数字来比较和评估我们对当前模型所做的更改是否有助于提高预测性能。</p>





            



            

        

    






    

        <title>Prediction</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">预言；预测；预告</h1>

                

            

            

                

<p>让我们预测<kbd>test</kbd>数据的<kbd>medv</kbd>值，并使用以下代码将结果存储在<kbd>pred</kbd>中:</p>

<pre class="mce-root"># Prediction<br/>pred &lt;- model %&gt;%  predict(test)<br/>cbind(pred[1:10], testtarget[1:10])<br/><br/>OUTPUT<br/><strong>          [,1] [,2]</strong><br/><strong> [1,] 33.18942 36.2</strong><br/><strong> [2,] 18.17827 20.4</strong><br/><strong> [3,] 17.89587 19.9</strong><br/><strong> [4,] 13.07977 13.9</strong><br/><strong> [5,] 14.17268 14.8</strong><br/><strong> [6,] 19.09264 18.4</strong><br/><strong> [7,] 19.81316 18.9</strong><br/><strong> [8,] 21.00356 24.7</strong><br/><strong> [9,] 30.50263 30.8</strong><br/><strong>[10,] 19.75816 19.4</strong></pre>

<p class="mce-root"/>

<p class="mce-root"/>

<p>我们可以使用<kbd>cbind</kbd>函数查看前10个预测值和实际值。输出中的第一列显示基于模型的预测值，第二列显示实际值。我们可以从输出中观察到以下情况:</p>

<ul>

<li>测试数据中第一个样本的预测值约为<kbd>33.19</kbd>，实际值为<kbd>36.2</kbd>。该模型低估了响应大约<kbd>3</kbd>点。</li>

<li>对于第二个样本，模型低估了响应超过<kbd>2</kbd>点。</li>

<li>对于第十个样本，预测值和实际值非常接近。</li>

<li>对于第六个样本，模型高估了响应。</li>

</ul>

<p>为了全面了解预测性能，我们可以绘制预测值与实际值的散点图。我们将使用以下代码:</p>

<pre>plot(testtarget, pred,<br/>      xlab = 'Actual',<br/>      ylab = 'Prediction')<br/> abline(a=0,b=1)</pre>

<p class="mce-root">散点图显示了基于测试数据的预测响应值与实际响应值:</p>

<p class="CDPAlignCenter CDPAlign"><img class="details-image" src="img/16a25a48-a15a-4d4f-9ac8-ce7dd907adc3.png" style="width:26.50em;height:27.50em;"/></p>

<p>从上图中，我们可以看到预测模型的整体性能。实际值和预测值之间的关系是正的，近似线性。虽然我们可以看到该模型具有不错的性能，但显然还有进一步改进的余地，使数据点更接近截距为零、斜率为1的理想直线。我们将通过开发更深层次的神经网络模型来进一步探索对模型的改进。</p>





            



            

        

    






    

        <title>Improvements</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">丰富</h1>

                

            

            

                

<p>在修改后的新模型中，我们将通过添加更多层来建立更深的网络。额外的层被期望显示数据中的模式，这是我们先前使用的较小的网络所不能显示的。</p>





            



            

        

    






    

        <title>Deeper network architecture</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">更深层次的网络架构</h1>

                

            

            

                

<p>本实验使用的代码如下:</p>

<pre class="mce-root"># Model Architecture<br/>model &lt;- keras_model_sequential()<br/>model %&gt;%<br/> layer_dense(units = 100, activation = 'relu', input_shape = c(13)) %&gt;% <br/> layer_dropout(rate = 0.4) %&gt;%<br/> layer_dense(units = 50, activation = 'relu') %&gt;%<br/> layer_dropout(rate = 0.3) %&gt;%<br/> layer_dense(units = 20, activation = 'relu') %&gt;%<br/> layer_dropout(rate = 0.2) %&gt;%<br/> layer_dense(units = 1)  <br/>summary(model)<br/><br/>OUTPUT<br/> <strong>## ___________________________________________________________________________</strong><br/><strong> ## Layer (type)                     Output Shape                  Param #    </strong><br/><strong> ## ===========================================================================</strong><br/><strong> ## dense_4 (Dense)                  (None, 100)                   1400       </strong><br/><strong> ## ___________________________________________________________________________</strong><br/><strong> ## dropout_1 (Dropout)              (None, 100)                   0          </strong><br/><strong> ## ___________________________________________________________________________</strong><br/><strong> ## dense_5 (Dense)                  (None, 50)                    5050       </strong><br/><strong> ## ___________________________________________________________________________</strong><br/><strong> ## dropout_2 (Dropout)              (None, 50)                    0          </strong><br/><strong> ## ___________________________________________________________________________</strong><br/><strong> ## dense_6 (Dense)                  (None, 20)                    1020       </strong><br/><strong> ## ___________________________________________________________________________</strong><br/><strong> ## dropout_3 (Dropout)              (None, 20)                    0          </strong><br/><strong> ## ___________________________________________________________________________</strong><br/><strong> ## dense_7 (Dense)                  (None, 1)                     21         </strong><br/><strong> ## ===========================================================================</strong><br/><strong> ## Total params: 7,491</strong><br/><strong> ## Trainable params: 7,491</strong><br/><strong> ## Non-trainable params: 0</strong><br/><strong> ## _________________________________________________________________________</strong><br/><br/># Compile model<br/>model %&gt;% compile(loss = 'mse', <br/>                   optimizer = 'rmsprop', <br/>                   metrics = 'mae')<br/><br/># Fit model<br/>model_two &lt;- model %&gt;%  <br/>   fit(training,<br/>       trainingtarget,<br/>       epochs = 100,<br/>       batch_size = 32, <br/>       validation_split = 0.2)<br/>plot(model_two)</pre>

<p>从前面的代码中，我们可以看到我们现在有三个隐藏层，分别有<kbd>100</kbd>、<kbd>50</kbd>和<kbd>20</kbd>个单元。我们还在每个隐藏层后添加了一个丢弃层，速率分别为<kbd>0.4</kbd>、<kbd>0.3</kbd>和<kbd>0.2</kbd>。举例来说，舍弃层的比率意味着0.4的比率意味着在训练时第一个隐藏层中40%的单元被舍弃为零，这有助于避免过度拟合。这个模型的参数总数现在已经增加到<kbd>7,491</kbd>。请注意，在之前的模型中，参数的总数是<kbd>201</kbd>，显然我们正在寻求一个更大的神经网络。接下来，我们使用之前使用的相同设置编译模型，随后，我们将拟合模型并将结果存储在<kbd>model_two</kbd>中。</p>





            



            

        

    






    

        <title>Results</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">结果</h1>

                

            

            

                

<p>下图提供了100个时期内<kbd>model_two</kbd>的损失和平均绝对误差:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/b48f8055-750e-4560-9978-92c2fe0abfe3.png"/></p>

<p>从上图中，我们可以观察到以下情况:</p>

<ul>

<li>训练和验证数据的平均绝对误差和损失值非常快地下降到低值，并且在大约30个时期之后，我们没有看到任何大的改善。</li>

<li>没有过度拟合的证据，因为训练和验证误差似乎彼此更接近。</li>

</ul>

<p>我们可以使用以下代码获得测试数据的损失和平均绝对误差值:</p>

<pre class="mce-root"># Model evaluation<br/>model %&gt;%  evaluate(test, testtarget) <br/><br/>OUTPUT<br/> ## $loss<br/> ## [1] 24.70368 <br/> ##<br/> ## $mean_absolute_error<br/> ## [1] 3.02175 <br/><br/>pred &lt;- model %&gt;%  predict(test)<br/>plot(testtarget, pred,<br/>     xlab = 'Actual', <br/>     ylab = 'Prediction')<br/>abline(a=0,b=1)</pre>

<p>使用<kbd>test</kbd>数据和<kbd>model_two</kbd>得到的损耗和平均绝对误差值分别为<kbd>24.70</kbd>和<kbd>3.02</kbd>。与我们从<kbd>model_one</kbd>获得的结果相比，这是一个显著的进步。</p>

<p>使用下图中预测值与实际响应值的散点图，我们可以直观地看到这种改进:</p>

<p class="CDPAlignCenter CDPAlign"><img class="details-image" src="img/6cd957b8-3c86-4bc4-bdc7-ab0ae18ccb17.png" style="width:29.50em;height:30.67em;"/></p>

<p>从上图中，我们可以看到，实际值与预测值的散点图的分布明显小于之前的散点图。这表明与以前的模型相比，预测性能更好。虽然<kbd>model_two</kbd>的表现优于之前的模型，但在更高的值时，我们可以看到目标值出现了明显的低估。因此，尽管我们已经开发了一个更好的模型，我们还可以进一步探索进一步改进这个预测模型的潜力。</p>





            



            

        

    






    

        <title>Performance optimization tips and best practices</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">性能优化技巧和最佳实践</h1>

                

            

            

                

<p>提高模型性能可能涉及不同的策略。这里，我们将讨论两个主要策略。一种策略是对模型架构进行更改，并观察结果以获得任何有用的见解或改进的迹象。另一个策略可能涉及探索目标变量的转换。在本节中，我们将尝试这两种策略的组合。</p>





            



            

        

    






    

        <title>Log transformation on the output variable</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">输出变量的对数变换</h1>

                

            

            

                

<p>为了克服目标变量在较高值时被严重低估的问题，让我们尝试对目标变量进行对数变换，看看这是否有助于我们进一步改进模型。我们的下一个模型对架构也有一些小的改变。在<kbd>model_two</kbd>中，我们没有注意到任何与过度拟合相关的重大问题或证据，因此，我们可以稍微增加单位数量，也可以稍微降低辍学率。下面是这个实验的代码:</p>

<pre># log transformation and model architecture <br/>trainingtarget &lt;- log(trainingtarget)<br/> testtarget &lt;- log(testtarget)<br/> model &lt;- keras_model_sequential()<br/> model %&gt;%<br/>   layer_dense(units = 100, activation = 'relu', input_shape = c(13)) %&gt;%  <br/>   layer_dropout(rate = 0.4) %&gt;% <br/>   layer_dense(units = 50, activation = 'relu') %&gt;%<br/>   layer_dropout(rate = 0.2) %&gt;%<br/>   layer_dense(units = 25, activation = 'relu') %&gt;%<br/>   layer_dropout(rate = 0.1) %&gt;%<br/>   layer_dense(units = 1)<br/> summary(model)<br/><br/>OUTPUT<br/><strong>## ___________________________________________________________________________</strong><br/><strong> ## Layer (type)                     Output Shape                  Param #    </strong><br/><strong> ## ===========================================================================</strong><br/><strong> ## dense_8 (Dense)                  (None, 100)                   1400       </strong><br/><strong> ## ___________________________________________________________________________</strong><br/><strong> ## dropout_4 (Dropout)              (None, 100)                   0           </strong><br/><strong> ## ___________________________________________________________________________</strong><br/><strong> ## dense_9 (Dense)                  (None, 50)                    5050       </strong><br/><strong> ## ___________________________________________________________________________</strong><br/><strong> ## dropout_5 (Dropout)              (None, 50)                    0          </strong><br/><strong> ## ___________________________________________________________________________</strong><br/><strong> ## dense_10 (Dense)                 (None, 25)                    1275       </strong><br/><strong> ## ___________________________________________________________________________</strong><br/><strong> ## dropout_6 (Dropout)              (None, 25)                    0          </strong><br/><strong> ## ___________________________________________________________________________</strong><br/><strong> ## dense_11 (Dense)                 (None, 1)                     26         </strong><br/><strong> ## ===========================================================================</strong><br/><strong> ## Total params: 7,751</strong><br/><strong> ## Trainable params: 7,751</strong><br/><strong> ## Non-trainable params: 0</strong><br/><strong> ## ___________________________________________________________________________</strong></pre>

<p class="mce-root">我们将把第三个隐藏层的单位数从<kbd>20</kbd>增加到<kbd>25</kbd>。第二和第三隐藏层的辍学率也分别降低到<kbd>0.2</kbd>和<kbd>0.1</kbd>。请注意，参数的总数现在已经增加到<kbd>7751</kbd>。</p>

<p class="mce-root">我们接下来编译模型，然后拟合模型。模型结果存储在<kbd>model_three</kbd>中，我们用它来绘制图形，如下面的代码所示:</p>

<pre class="mce-root"># Compile model<br/>model %&gt;% compile(loss = 'mse', <br/>                   optimizer = optimizer_rmsprop(lr = 0.005),<br/>                   metrics = 'mae')<br/><br/># Fit model<br/> model_three &lt;- model %&gt;%  <br/>   fit(training,<br/>       trainingtarget,<br/>       epochs = 100,<br/>       batch_size = 32, <br/>       validation_split = 0.2)<br/>plot(model_three)</pre>

<p>以下显示了训练和验证数据的损失和平均绝对误差输出(<kbd>model_three</kbd>):</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/840b6abb-532f-41be-9f1d-880f25acd57d.png"/></p>

<div><p>从前面的图中我们可以看出，虽然图中的值由于对数变换而不能与之前的数字直接比较，但我们可以看到，对于平均绝对误差和损失，总误差在大约50个时期后下降并变得稳定。</p>





            



            

        

    






    

        <title>Model performance</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">模型性能</h1>

                

            

            

                

<p>我们还获得了这个新模型的<kbd>loss</kbd>和<kbd>mae</kbd>值，但同样，获得的数字不能与对数标度的前两个模型直接比较:</p>

<pre class="mce-root"># Model evaluation<br/>model %&gt;%  evaluate(test, testtarget) <br/><br/>OUTPUT<br/>## $loss<br/> ## [1] 0.02701566<br/> ##<br/> ## $mean_absolute_error<br/> ## [1] 0.1194756 <br/><br/>pred &lt;- model %&gt;%  predict(test)<br/> plot(testtarget, pred)</pre>

<p>我们获得了实际值(对数转换)与基于测试数据的预测值的散点图。我们还得到了原始标度下的实际值与预测值的散点图，以便与早期的图进行比较。预测响应值与实际响应值(<kbd>model_three</kbd>)的散点图如下图所示:</p>

<p class="CDPAlignCenter CDPAlign"><img class="details-image" src="img/70341185-4756-4a9d-a62c-46d2eaf4dafb.png"/></p>

<p class="mce-root"/>

<p class="mce-root"/>

<p>从上图中，我们可以看到，在早期模型中观察到的显著低估模式在对数标度和原始标度中都有所改善。在原始比例中，较高值处的数据点相对更接近对角线，这表明模型的预测性能有所提高。</p>





            



            

        

    






    

        <title>Summary</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:a4c88040-7c66-4c85-9d59-26726397fe76" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">摘要</h1>

                

            

            

                

<p>在本章中，我们介绍了当响应变量为数字类型时开发预测模型的步骤。我们从具有201个参数的神经网络模型开始，然后开发了具有超过7000个参数的深度神经网络模型。您可能已经注意到，与上一章相比，在本章中，我们使用了相对更深入和更复杂的神经网络模型，在上一章中，我们开发了一个具有分类性质的目标变量的分类模型。在<a href="c5c236d5-fc58-4d90-95b0-2b05b148b187.xhtml">第2章</a>、<em>用于多类分类的深度神经网络</em>和<a href="07c9aa4a-1c93-490a-bfcd-7c4bcde639d5.xhtml">第3章</a>、<em>用于回归的深度神经网络</em>中，我们基于结构化的数据开发了模型。在下一章，我们继续讨论数据类型是非结构化的问题。更具体地说，我们将处理数据的图像类型，并使用深度神经网络模型检查图像分类和识别的问题。</p>

<p>在下一章中，我们将介绍使用深度神经网络开发图像识别和预测模型所需的步骤。</p>





            



            

        

    



</div></body></html>