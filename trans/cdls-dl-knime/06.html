<html><head/><body>





	

		<title>B16391_09_Final_NM_ePUB</title>

		

	

	

		<div><h1 id="_idParaDest-158"><em class="italic"> <a id="_idTextAnchor316"/>第九章:</em>卷积神经网络用于图像分类</h1>

			<p>在前几章中，我们谈到了<strong class="bold">递归神经网络</strong> ( <strong class="bold"> RNNs </strong>)以及它们如何应用于不同类型的顺序数据和用例。在这一章中，我们要讲另一个神经网络家族，叫做<strong class="bold">卷积神经网络</strong>(<strong class="bold">CNN</strong>)。当用于具有网格状拓扑和空间依赖性的数据(如图像或视频)时，CNN尤其强大。</p>

			<p>我们将从CNN的一般介绍开始，解释卷积层背后的基本思想，并介绍一些相关的术语，如填充、池化、滤波器和步长。</p>

			<p>之后，我们将从头开始构建和训练一个用于图像分类的CNN。我们将涵盖所有需要的步骤:从图像的读取和预处理到CNN的定义、训练和应用。</p>

			<p>为了从头开始训练神经网络，通常需要大量的标记数据。对于一些特定的领域，如图像或视频，可能无法获得如此大量的数据，网络的训练可能变得不可能。迁移学习是解决这一问题的一种方法。迁移学习背后的想法包括使用为任务A训练的最先进的神经网络作为另一个相关任务b的起点。</p>

			<p>在本章中，我们将讨论以下主题:</p>

			<ul>

				<li>CNN简介</li>

				<li>用CNN对图像进行分类</li>

				<li>迁移学习简介</li>

				<li>应用迁移学习进行癌症类型预测</li>

			</ul>

			<h1 id="_idParaDest-159"><a id="_idTextAnchor317"/>CNN简介</h1>

			<p>CNN通常用于图像处理，并且是几个图像处理竞赛中的获奖模型。例如，它们经常用于图像分类、对象检测和语义分割。</p>

			<p>有时，CNN也用于与图像无关的任务，如推荐系统、视频或时间序列分析。事实上，CNN不仅应用于具有网格结构的二维数据，而且当应用于一维或三维数据时也可以工作。然而，在这一章中，我们关注最常见的<a id="_idIndexMarker809"/> CNN应用领域:<strong class="bold">图像处理</strong>。</p>

			<p>CNN是具有至少一个<strong class="bold">卷积层</strong>的神经<a id="_idIndexMarker810"/>网络。顾名思义，卷积图层对输入数据执行卷积数学变换。通过这样的数学变换，卷积层获得了从图像中检测和提取一些特征的能力，例如边缘、角和形状。这种提取的特征的组合用于分类图像或检测图像中的特定对象。</p>

			<p>卷积层通常与<a id="_idIndexMarker811"/>和<strong class="bold">合并层</strong>一起出现，也常用于图像处理的特征提取部分。</p>

			<p>因此，本节的目标是解释卷积层和池层如何单独和一起工作，并详细说明这两个层的不同设置选项。</p>

			<p>如前所述，在这一章中，我们将重点介绍用于图像分析的细胞神经网络。因此，在我们深入CNN的细节之前，让我们快速回顾一下图像是如何存储的。</p>

			<h2 id="_idParaDest-160"><a id="_idTextAnchor318"/>图像是如何存储的？</h2>

			<p>灰度图像<a id="_idIndexMarker812"/>可以存储为矩阵，其中每个单元代表图像<a id="_idIndexMarker813"/>的一个像素，单元值代表该像素的灰度级。例如，大小为<img src="img/Formula_B16391_09_001.png" alt=""/>像素的黑白图像可以表示为尺寸为<img src="img/Formula_B16391_09_002.png" alt=""/>的矩阵，其中矩阵的每个值在<img src="img/Formula_B16391_09_003.png" alt=""/>和<img src="img/Formula_B16391_09_004.png" alt=""/>之间。<img src="img/Formula_B16391_09_005.png" alt=""/>是黑色像素，<img src="img/Formula_B16391_09_006.png" alt=""/>是白色像素，两者之间的值对应于灰度中的灰度级。</p>

			<p><em class="italic">图9.1 </em>描述了一个例子:</p>

			<div><div><img src="img/B16391_09_001.jpg" alt="Figure 9.1 – Matrix representation of a grayscale 5 x 5 image"/>

				</div>

			</div>

			<p class="figure-caption">图<a id="_idTextAnchor319"/>9.1–灰度5 x 5图像的矩阵表示</p>

			<p>由于每个像素仅由一个灰度值表示，一个<strong class="bold">通道</strong>(矩阵)足以表示该图像。另一方面，对于彩色图像，需要不止一个值来定义每个像素的颜色。一种选择是使用指定红色、绿色和蓝色强度的三个值来定义像素颜色。在下面的截图中，为了表示彩色图像，使用了三个通道<a id="_idIndexMarker814"/>而不是一个:(<em class="italic">图9.2 </em>):</p>

			<div><div><img src="img/B16391_09_002.jpg" alt="Figure 9.2 – Representing a 28 x 28 color image using three channels for RGB"/>

				</div>

			</div>

			<p class="figure-caption">图<a id="_idTextAnchor320"/>9.2–使用三个RGB通道呈现28 x 28的彩色图像</p>

			<p>从灰度图像转移到<a id="_idIndexMarker815"/>一个<strong class="bold">红、绿、蓝</strong> ( <strong class="bold"> RGB </strong>)图像，更一般的概念<strong class="bold">张量</strong>——而不是简单矩阵的<a id="_idIndexMarker816"/>——变得必要。这样，灰度图像可以描述为<img src="img/Formula_B16391_09_007.png" alt=""/>的张量，而具有<img src="img/Formula_B16391_09_008.png" alt=""/>像素的彩色图像可以用<img src="img/Formula_B16391_09_009.png" alt=""/>张量表示。</p>

			<p>通常，表示具有<img src="img/Formula_B16391_09_010.png" alt=""/>像素高度、<img src="img/Formula_B16391_09_011.png" alt=""/>像素宽度和<img src="img/Formula_B16391_09_012.png" alt=""/>通道的图像的张量具有维度<img src="img/Formula_B16391_09_013.png" alt=""/> x <img src="img/Formula_B16391_09_014.png" alt=""/> x <img src="img/Formula_B16391_09_015.png" alt=""/>。</p>

			<p>但是为什么我们<a id="_idIndexMarker817"/>需要特殊的网络来分析图像呢？难道我们不能仅仅<strong class="bold">展平</strong>图像，将每个图像表示为一个长向量，并训练一个标准的全连接前馈神经网络吗？</p>

			<p class="callout-heading">重要说明</p>

			<p class="callout">将图像的<a id="_idIndexMarker818"/>矩阵表示转换为矢量的过程称为<strong class="bold">展平</strong>。</p>

			<h2 id="_idParaDest-161">我们为什么需要CNN？</h2>

			<p>对于基本的二进制图像，展平和完全连接的前馈网络可能会产生可接受的性能。然而，对于更复杂的图像，由于整个图像具有很强的像素依赖性，平坦化和前馈神经网络的组合通常会失败。</p>

			<p>事实上，当图像被展平成矢量时，空间依赖性就丧失了。因此，全连接前馈网络不是平移不变的。这意味着它们对同一图像的移位版本产生不同的结果。例如，网络可能学会识别图像左上角的猫，但同一网络无法检测同一图像右下角的猫。</p>

			<p>此外，图像的<a id="_idIndexMarker820"/>展平产生非常长的向量，因此它需要具有许多权重的非常大的全连接前馈网络。例如，对于具有三个通道的<img src="img/Formula_B16391_09_016.png" alt=""/>像素图像，网络需要<img src="img/Formula_B16391_09_017.png" alt=""/>输入。如果下一层有<img src="img/Formula_B16391_09_018.png" alt=""/>神经元，我们只需要在第一层训练<img src="img/Formula_B16391_09_019.png" alt=""/>权重。你会看到重量的数量会很快变得难以控制，很可能导致训练中的过度适应。</p>

			<p>卷积层是CNN的主要组成部分，它允许我们通过利用图像的空间属性来解决这个问题。那么，让我们来看看卷积层是如何工作的。</p>

			<h2 id="_idParaDest-162"><a id="_idTextAnchor322"/>卷积层是如何工作的？</h2>

			<p>CNN的想法是使用过滤器来检测图像不同部分的图案，也称为特征，如角落、垂直边缘和水平边缘。</p>

			<p>对于具有一个通道的图像，一个<strong class="bold">过滤器</strong>是一个<a id="_idIndexMarker822"/>小矩阵，通常大小为<img src="img/Formula_B16391_09_020.png" alt=""/>或<img src="img/Formula_B16391_09_021.png" alt=""/>，称为<strong class="bold">内核</strong>。不同的<a id="_idIndexMarker823"/>内核——即具有不同值的矩阵——过滤不同的模式。内核在图像上移动并执行卷积运算。该卷积运算为该层命名。这种卷积的输出是被称为<strong class="bold">特征图</strong>的<a id="_idIndexMarker824"/>。</p>

			<p class="callout-heading">重要说明</p>

			<p class="callout">对于具有三个通道的输入图像(例如，具有形状<img src="img/Formula_B16391_09_022.png" alt=""/>的输入张量)，具有核大小2的核具有形状<img src="img/Formula_B16391_09_023.png" alt=""/>。这意味着内核可以包含来自所有通道的信息，但只能包含在输入图像的一个小区域(在本例中为2×2)内。</p>

			<p><em class="italic">图9.3 </em>此处显示了<a id="_idIndexMarker825"/>一个如何为尺寸为<img src="img/Formula_B16391_09_024.png" alt=""/>的图像和尺寸为<img src="img/Formula_B16391_09_025.png" alt=""/>的内核计算卷积的示例:</p>

			<div><div><img src="img/B16391_09_003.jpg" alt="Figure 9.3 – Example of a convolution obtained by applying a 3 x 3 kernel to a 4 x 4 image"/>

				</div>

			</div>

			<p class="figure-caption">图9.3–通过将3 x 3内核应用于4 x 4图像获得的卷积示例</p>

			<p>在这个例子中，我们从<a id="_idIndexMarker826"/>将内核应用到图像的左上角<img src="img/Formula_B16391_09_026.png" alt=""/>区域开始。图像值按元素与内核值相乘，然后求和，如下所示:</p>

			<p class="figure"><img src="img/Formula_B16391_09_027.png" alt=""/></p>

			<p>此逐元素乘法和求和的结果是输出要素地图左上角的第一个值。然后，核在整个图像上移动，以计算输出特征图的所有其他值。</p>

			<p class="callout-heading">重要说明</p>

			<p class="callout">卷积运算用*表示，不同于矩阵乘法。即使该层被称为卷积，但大多数神经网络库实际上都实现了一个相关函数<a id="_idIndexMarker827"/>，称为<strong class="bold">互相关</strong>。为了执行正确的卷积，根据其数学定义，内核还必须翻转。对于CNN来说，这并没有什么不同，因为权重是学习来的。</p>

			<p>在<a id="_idIndexMarker828"/>卷积层中，大量过滤器(内核)在输入数据集上并行训练，用于所需任务。也就是说，内核中的权重不是手动设置的，而是在网络训练过程中作为权重自动调整的。在执行过程中，所有经过训练的内核都被用于计算特征图。</p>

			<p>特征图的维度是一个大小为<img src="img/Formula_B16391_09_028.png" alt=""/>的张量。在<em class="italic">图9.3 </em>的例子中，我们只应用了一个内核，特征图的维数是<img src="img/Formula_B16391_09_029.png" alt=""/>。</p>

			<p>历史上，内核是为选定的任务手工设计的。例如<em class="italic">图9.3 </em>中的内核检测垂直线。<em class="italic">图9.4 </em>这里向您展示了一些其他手工制作的内核的影响:</p>

			<div><div><img src="img/B16391_09_004.jpg" alt="Figure 9.4 – Impact of some hand-crafted kernels on the original image"/>

				</div>

			</div>

			<p class="figure-caption">图9.4–一些手工制作的<a id="_idTextAnchor324"/>内核对原始图像的影响</p>

			<p><a id="_idIndexMarker829"/>卷积操作只是卷积层的一部分。此后，将偏置和非线性激活函数应用于特征图中的每个条目。例如，我们可以为特征图中的每个值添加一个偏差值，然后<a id="_idIndexMarker830"/>应用<strong class="bold">整流线性单元</strong> ( <strong class="bold"> ReLU </strong>)作为激活函数，将所有低于偏差值的值设置为0。</p>

			<p class="callout-heading">重要说明</p>

			<p class="callout">在<a href="B16391_03_Final_PG_ePUB.xhtml#_idTextAnchor073"> <em class="italic">第三章</em> </a>、<em class="italic">神经网络入门</em>中，我们介绍了密集层。在密集层中，首先计算输入的加权和；然后，将偏差值加到总和上，并应用激活函数。在卷积层中，密集层的加权和被卷积代替。</p>

			<p>一个<a id="_idIndexMarker831"/>卷积层有多个设置选项。我们已经介绍了其中的三种，如下所示:</p>

			<ul>

				<li>内核大小，通常是<img src="img/Formula_B16391_09_030.png" alt=""/></li>

				<li>过滤器的数量</li>

				<li>激活函数，其中ReLU是最常用的函数</li>

			</ul>

			<p>还有三个设置选项:填充、步幅和扩张率。让我们继续填充。</p>

			<h2 id="_idParaDest-163"><a id="_idTextAnchor325"/>引入填充</h2>

			<p>当我们<a id="_idIndexMarker832"/>在<em class="italic">图9.3 </em>的示例中应用过滤器时，特征图的尺寸与输入图像的尺寸相比缩小了。输入图像的尺寸为<img src="img/Formula_B16391_09_031.png" alt=""/>，特征图的尺寸为<img src="img/Formula_B16391_09_032.png" alt=""/>。</p>

			<p>此外，通过查看特征图，我们可以看到输入图像内部的像素(值为f、g、j和k的像元)比拐角和边界处的像素更常被考虑在卷积中。这意味着内在价值将在进一步的分析中获得更高的权重。为了解决这个问题，可以通过在额外的外部单元格中添加零来对图像进行零填充(<em class="italic">图9.5 </em>)。这是一个叫做<strong class="bold">填充</strong>的过程<a id="_idIndexMarker833"/>。</p>

			<p><em class="italic">图9.5 </em>显示了一个<a id="_idIndexMarker834"/>零填充输入的例子:</p>

			<div><div><img src="img/B16391_09_005.jpg" alt="Figure 9.5 – Example of a zero-padded image"/>

				</div>

			</div>

			<p class="figure-caption">图9.5–零填充ima <a id="_idTextAnchor326"/> ge示例</p>

			<p>这里，在原始图像周围的每一行和每一列都添加了两个零值单元格。如果大小为<img src="img/Formula_B16391_09_033.png" alt=""/>的核现在被应用于该填充图像，则特征图的输出尺寸将与原始图像的尺寸相同。用于零填充的像元数是卷积层中的另一个可用设置。</p>

			<p>如果不使用填充，影响输出大小的另外两个设置称为<strong class="bold">步幅</strong>和<strong class="bold">扩张率</strong>。</p>

			<h2 id="_idParaDest-164"><a id="_idTextAnchor327"/>介绍步幅和扩张率</h2>

			<p>在<em class="italic">图9.3 </em>的例子中，我们将滤镜应用于每个像素。对于大尺寸的图像，并不总是需要对每个像素执行卷积。我们可以将内核移动不止一个水平或垂直像素，而不是总是移动一个像素。</p>

			<p>用于内核移位的像素数为<a id="_idIndexMarker835"/>称为<strong class="bold">步距</strong>。步幅通常由元组定义，指定水平和垂直方向上移动的单元数。没有填充的较高步幅值会导致输入图像的下采样。</p>

			<p><em class="italic">图9.6 </em>的顶部显示了大小为3 x 3的内核如何以步幅2，2在图像上移动。</p>

			<p>卷积<a id="_idIndexMarker836"/>层的另一个设置选项是<strong class="bold">膨胀率</strong>。膨胀率表示输入图像中的<img src="img/Formula_B16391_09_034.png" alt=""/>个连续单元中只有一个单元用于卷积运算。<img src="img/Formula_B16391_09_035.png" alt=""/>的放大率仅使用输入图像中每两个像素中的一个进行卷积。<img src="img/Formula_B16391_09_036.png" alt=""/>的放大率使用三个连续像素中的一个。至于步幅，膨胀率是水平和垂直方向的一组值。当使用高于<img src="img/Formula_B16391_09_037.png" alt=""/>的膨胀率时，内核在原始图像上被膨胀到更大的视野。因此，具有膨胀率的3×3内核<img src="img/Formula_B16391_09_038.png" alt=""/>在输入图像中探索大小为5×5的视场，同时仅使用9个卷积参数。</p>

			<p>对于一个<img src="img/Formula_B16391_09_039.png" alt=""/>内核和一个<img src="img/Formula_B16391_09_040.png" alt=""/>的膨胀率，内核仅使用其角值扫描输入图像上的一个<img src="img/Formula_B16391_09_041.png" alt=""/>区域(见<em class="italic">图9.6 </em>的下部)。这意味着对于<img src="img/Formula_B16391_09_042.png" alt=""/>的<a id="_idIndexMarker837"/>膨胀率，我们有一个大小为1的间隙。对于<img src="img/Formula_B16391_09_043.png" alt=""/>的膨胀率，我们的间隙大小为2，依此类推:</p>

			<div><div><img src="img/B16391_09_006.jpg" alt="Figure 9.6 – Impact of different stride and dilation rate values on the output feature map"/>

				</div>

			</div>

			<p class="figure-caption">图9.6-不同步幅和扩张率值<a id="_idTextAnchor328"/>对输出特征图的影响</p>

			<p>CNN中另一个常用的层是池层。</p>

			<h2 id="_idParaDest-165"><a id="_idTextAnchor329"/>引入池化</h2>

			<p><strong class="bold">汇集</strong>的想法是<a id="_idIndexMarker838"/>用汇总统计数据替换特征图的一个区域。例如，pooling可以用它的<a id="_idIndexMarker839"/>最大值，称为<strong class="bold">最大池</strong>，或它的<a id="_idIndexMarker840"/>平均值，称为<strong class="bold">平均池</strong> ( <em class="italic">图9.7 </em>):</p>

			<div><div><img src="img/B16391_09_007.jpg" alt="Figure 9.7 – Results of max and average pooling"/>

				</div>

			</div>

			<p class="figure-caption">图9.7–最大和平均池的结果</p>

			<p>合并图层以更有效的方式降低了输入影像的维度，并允许提取主要的、旋转的和位置不变的特征。</p>

			<p>与过滤器一样，在池化中，我们需要定义要计算汇总统计数据的浏览区域的大小。一个常用的设置是<img src="img/Formula_B16391_09_045.png" alt=""/>像素的池大小和每个方向两个像素的步幅。此设置将图像尺寸减半。</p>

			<p class="callout-heading">重要说明</p>

			<p class="callout">池化图层没有任何权重，所有设置都是在图层配置期间定义的。它们是静态层，并且它们的参数不像网络中的其他权重那样被训练。</p>

			<p>汇集层<a id="_idIndexMarker841"/>通常在一个卷积层或多个叠加卷积层之后使用。</p>

			<p>卷积图层可应用于输入影像和要素地图。事实上，在CNN中，多个卷积层经常一个叠一个地堆叠在一起。在这样的层级中，第一卷积层可以提取低级特征，例如边缘。下一层中的过滤器然后在提取的特征之上工作，并且可以学习检测形状，等等。</p>

			<p>最终提取的特征然后可以用于不同的任务。在图像分类的情况下，由多个卷积层叠加而成的特征图被展平，并在其上应用分类器网络。</p>

			<p>总而言之，用于图像分类的标准CNN首先使用一系列卷积和池化层，然后是平坦层，然后是一系列密集层，用于最终分类。</p>

			<p>现在我们已经熟悉了卷积层和池层，让我们看看如何将它们引入网络内部进行图像分类。</p>

			<h1 id="_idParaDest-166"><a id="_idTextAnchor330"/>用CNN对图像进行分类</h1>

			<p>在这一部分，我们将<a id="_idIndexMarker842"/>看到如何从零开始构建和训练一个用于图像分类的CNN。</p>

			<p>目标是用来自<strong class="bold"> MNIST数据库</strong>的数据对0到9之间的手写数字进行分类，这是一个<a id="_idIndexMarker843"/>大型手写数字数据库，通常用于训练各种图像处理应用。http://yann.lecun.com/exdb/mnist/的MNIST数据库包含60，000幅训练图像和10，000幅手写数字测试图像，可以从这个网站下载。</p>

			<p>为了读取和预处理图像，KNIME分析平台提供了一组专用的节点和组件，在安装了<strong class="bold"> KNIME图像处理扩展</strong>后即可使用。</p>

			<p class="callout-heading">小费</p>

			<p class="callout">KNIME Image <a id="_idIndexMarker844"/>处理扩展(<a href="https://www.knime.com/community/image-processing">https://www.knime.com/community/image-processing</a>)允许你读入超过140种不同格式类型的图像(感谢Bio-Formats <strong class="bold">应用处理接口</strong> ( <strong class="bold"> API </strong>))。此外，它还可以利用KNIME Analytics平台中的图形用户界面，应用众所周知的图像处理技术，如分割、特征提取、跟踪和分类。</p>

			<p class="callout">一般来说，节点通过内部库<code>ImgLib2-API</code>对多维图像数据(例如，视频、3D图像、多通道图像，甚至这些图像的组合)进行操作。几个节点计算分割图像(例如，单个细胞)的图像特征(例如，Zernike、纹理或直方图特征)。机器学习算法应用于最终分类的结果特征向量。</p>

			<p>为了在图像上应用和训练神经网络，我们需要一个进一步的扩展:KNIME图像处理-深度学习扩展。这个扩展引入了许多有用的图像操作——例如，图像数据需要进行一些转换，才能输入到<strong class="bold"> Keras网络学习器</strong>节点。</p>

			<p class="callout-heading">重要说明</p>

			<p class="callout">要在图像上训练和应用<a id="_idIndexMarker845"/>神经网络，需要安装以下扩展:</p>

			<p class="callout">KNIME图像处理(<a href="https://www.knime.com/community/image-processing">https://www.knime.com/community/image-processing</a>)</p>

			<p class="callout">KNIME图像处理-深度学习<a id="_idIndexMarker846"/>扩展(<a href="https://hub.knime.com/bioml-konstanz/extensions/org.knime.knip.dl.feature/latest">https://hub . KNIME . com/bioml-Konstanz/extensions/org . KNIME . knip . dl . feature/latest</a>)</p>

			<p>让我们从阅读和预处理手写数字开始。</p>

			<h2 id="_idParaDest-167"><a id="_idTextAnchor331"/>读取和预处理图像</h2>

			<p>对于这个<a id="_idIndexMarker847"/>案例研究，我们使用了<a id="_idIndexMarker848"/> MNIST数据集的一个子集:10，000个图像样本用于训练，1，500个用于测试。每个图像有<img src="img/Formula_B16391_09_046.png" alt=""/>个像素，只有一个通道。训练图像和测试图像保存在两个不同的文件夹中，文件名以数字表示。此外，我们有一个带有图像标签的表格，按照图像文件名的顺序排序。</p>

			<p>读取和预处理工作流的目标是读取图像并将其与标签进行匹配。因此，执行以下步骤(如图<em class="italic">图9.8 </em>所示):</p>

			<ol>

				<li>阅读并整理训练图像。</li>

				<li>导入训练图像的数字标签。</li>

				<li>将标签与图片配对。</li>

				<li>将像素类型从无符号字节转换为浮点。</li>

				<li>将标签转换为集合单元格。</li>

			</ol>

			<p>这些步骤由以下屏幕截图中所示的工作流执行:</p>

			<div><div><img src="img/B16391_09_008.jpg" alt="Figure 9.8 – This workflow reads a subset of the MNIST dataset, adds the corresponding labels, and transforms the pixel type from unsigned byte to float"/>

				</div>

			</div>

			<p class="figure-caption"><a id="_idTextAnchor332"/></p>

			<p class="figure-caption">图9.8-此工作流读取MNIST数据集的子集，添加相应的标签，并将像素类型从无符号字节转换为浮点型</p>

			<p>为了读取<a id="_idIndexMarker849"/>图像，我们使用<strong class="bold">图像读取器(表)</strong>节点<a id="_idIndexMarker850"/>。该节点需要一个带有图像文件的<strong class="bold">统一资源定位符</strong> ( <strong class="bold"> URL </strong>)路径<a id="_idIndexMarker851"/>的输入列。为了创建URL的排序列表，<strong class="bold">列表文件</strong>节点首先<a id="_idIndexMarker852"/>获取training文件夹中图像文件的所有路径。然后，使用<strong class="bold">排序图像</strong>元节点。<em class="italic">图9.9 </em>这里向您展示了元节点<a id="_idTextAnchor333"/>的内部:</p>

			<div><div><img src="img/B16391_09_009.jpg" alt="Figure 9.9 – Inside of the Sort images metanode"/>

				</div>

			</div>

			<p class="figure-caption">图9.9–排序图像元节点内部</p>

			<p>元节点用一个<strong class="bold">字符串操作</strong>节点从文件名中提取图像编号，并用一个<strong class="bold">排序器</strong>节点对它们进行排序。然后<strong class="bold">图像阅读器(表格)</strong>节点读取图像。</p>

			<p><strong class="bold">文件读取器</strong>节点位于<a id="_idIndexMarker853"/>下分支，读取带有图像标签的表格。</p>

			<p>在下一步中，<strong class="bold">列附加器</strong>节点<a id="_idIndexMarker854"/>将正确的标签附加到每个图像上。由于图像已经<a id="_idIndexMarker855"/>被分类以匹配它们相应的标签，简单的附加操作就足够了。<em class="italic">图9.10 </em>显示了<strong class="bold">列追加器</strong> no <a id="_idTextAnchor334"/> de的输出子集:</p>

			<div><div><img src="img/B16391_09_010.jpg" alt="Figure 9.10 – Output of the Column Appender node, with the digit image and the corresponding label"/>

				</div>

			</div>

			<p class="figure-caption">图9.10–列附加器节点的输出，带有数字图像和相应的标签</p>

			<p>接下来，<strong class="bold">图像计算器</strong>节点通过将每个像素值除以255，将像素类型从<em class="italic">无符号字节</em>改变为<em class="italic">浮点</em><a id="_idIndexMarker856"/>。</p>

			<p>最后，<strong class="bold">创建集合列</strong>节点为每个标签创建<a id="_idIndexMarker857"/>一个集合单元。需要使用<a id="_idIndexMarker858"/>集合单元来创建<a id="_idIndexMarker859"/>单热向量编码类，以便在训练期间使用。</p>

			<p>既然我们已经读取并预处理了训练图像，我们就可以设计网络结构了。</p>

			<h2 id="_idParaDest-168"><a id="_idTextAnchor335"/>设计网络</h2>

			<p>在本节中，你将学习如何定义一个经典的CNN用于图像分类。</p>

			<p>用于图像分类的经典CNN由两部分组成，它们以端到端的方式一起训练，如下所示:</p>

			<ul>

				<li><strong class="bold">特征提取</strong>:第一部分通过训练多个滤波器，对图像进行特征提取。</li>

				<li><strong class="bold">分类</strong>:第二部分在提取的特征上训练一个分类网络，可从特征提取部分产生的展平特征图中获得。</li>

			</ul>

			<p>我们从只有一个卷积层的简单网络结构开始，然后是用于特征提取部分的汇集层。然后将得到的特征图展平，并在其上训练一个简单的分类器网络，该网络只有一个具有ReLU激活功能的隐藏层。</p>

			<p>图9.11 中的工作流程显示了这个网络结构:</p>

			<div><div><img src="img/B16391_09_011.jpg" alt="Figure 9.11 – This workflow snippet builds a simple CNN for the classification of the MNIST dataset"/>

				</div>

			</div>

			<p class="figure-caption">图9.11–该工作流片段为MNIST数据集的分类构建了一个简单的CNN</p>

			<p>工作流程<a id="_idIndexMarker861"/>从<strong class="bold"> Keras输入层</strong>节点开始，到<a id="_idIndexMarker862"/>定义输入形状。MNIST数据集的图像有<img src="img/Formula_B16391_09_047.png" alt=""/>个像素，只有一个通道，因为它们是灰度图像。因此，输入是形状为<img src="img/Formula_B16391_09_048.png" alt=""/>的张量，因此输入形状被设置为<img src="img/Formula_B16391_09_049.png" alt=""/>。</p>

			<p>接下来，利用<strong class="bold"> Keras卷积2D层</strong>节点实现<a id="_idIndexMarker863"/>卷积层。<em class="italic">图9.12 </em>这里显示的是no <a id="_idTextAnchor337"/> de的配置窗口:</p>

			<div><div><img src="img/B16391_09_012.jpg" alt="Figure 9.12 – Keras Convolution 2D Layer node and its configuration window"/>

				</div>

			</div>

			<p class="figure-caption">图9.12–Keras卷积2D图层节点及其配置窗口</p>

			<p>名为<strong class="bold">滤镜</strong>的设置<a id="_idIndexMarker864"/>设置要应用的滤镜数量。这将是特征图的最后一个维度。在这个例子中，我们决定训练<em class="italic"> 32 </em>过滤器。</p>

			<p>接下来，您可以以像素为单位设置<strong class="bold">内核大小</strong>选项——即定义每个内核高度和宽度的整数元组。对于MNIST数据集，我们使用的核大小为<img src="img/Formula_B16391_09_050.png" alt=""/>。这意味着设置为<img src="img/Formula_B16391_09_051.png" alt=""/> .50。</p>

			<p>接下来，您可以将<code>dilation_rate</code>设置为大于1。</p>

			<p>接下来，您可以选择是否要使用零填充。<strong class="bold">填充</strong>选项允许您在<strong class="bold">有效</strong>和<strong class="bold">相同</strong>之间进行选择。<strong class="bold">有效</strong>表示不执行填充。<strong class="bold"> Same </strong>表示执行零填充，使得特征映射的输出维度与输入维度相同。由于图像边界上主要是黑色像素，我们决定不对图像进行零填充，并选择了有效的。</p>

			<p>接下来，你可以<a id="_idIndexMarker865"/>选择<strong class="bold">膨胀率</strong>选项，作为一个整数元组。目前，指定任何大于1的扩张率值都与指定任何大于1的步幅值不兼容。<img src="img/Formula_B16391_09_052.png" alt=""/>的膨胀率意味着没有像素被跳过。<img src="img/Formula_B16391_09_053.png" alt=""/>的膨胀率意味着每隔一秒钟就要用到一个像素。这意味着间隙大小为1。我们用<img src="img/Formula_B16391_09_054.png" alt=""/>来表示膨胀率。52。</p>

			<p>最后，必须选择<strong class="bold">激活功能</strong>选项。在本案例研究中，我们选择了卷积层最常用的激活函数:<strong class="bold"> ReLU </strong>。</p>

			<p>卷积层的输出张量(即我们的特征图)具有维度<img src="img/Formula_B16391_09_055.png" alt=""/>，因为我们有<img src="img/Formula_B16391_09_056.png" alt=""/>滤波器，并且我们不使用填充。</p>

			<p>接下来，使用一个<strong class="bold"> Keras Max Pooling 2D层</strong>节点<a id="_idIndexMarker866"/>在两个维度上应用Max Pooling。</p>

			<p><em class="italic">图9.13 </em>这里<a id="_idIndexMarker867"/>显示了节点的配置窗口:</p>

			<div><div><img src="img/B16391_09_013.jpg" alt="Figure 9.13 – Keras Max Pooling 2D Layer node and its configuration window"/>

				</div>

			</div>

			<p class="figure-caption">figure<a id="_idTextAnchor338"/>e 9.13–Keras Max池化2D图层节点及其配置窗口</p>

			<p>在<strong class="bold"> Keras Max Pooling 2D层</strong>节点的配置窗口中，可以定义<strong class="bold">池大小</strong>。同样，这是一个定义池窗口的整数元组。请记住，最大池的概念是用该区域中的最大值来表示池窗口大小的每个区域。</p>

			<p><strong class="bold">步距</strong>也是一个整数元组，设置步长来移动池窗口。</p>

			<p>最后，您可以通过选择<strong class="bold">有效</strong>来选择是否应用零填充，选择<strong class="bold">相同</strong>来应用填充。</p>

			<p>对于这个MNIST示例，我们将<strong class="bold">池大小</strong>设置为<img src="img/Formula_B16391_09_057.png" alt=""/>，将<strong class="bold">步距</strong>设置为<img src="img/Formula_B16391_09_058.png" alt=""/>，并且不应用填充。因此，汇集层的输出尺寸为<img src="img/Formula_B16391_09_059.png" alt=""/>。</p>

			<p>接下来，使用一个<strong class="bold"> Keras展平层</strong>节点<a id="_idIndexMarker868"/>将特征图转换成一个矢量，尺寸<a id="_idIndexMarker869"/>为<img src="img/Formula_B16391_09_060.png" alt=""/>。</p>

			<p>在<strong class="bold"> Keras展平层</strong>节点之后，我们建立一个简单的分类网络，有一个隐藏层和一个输出层。具有ReLU激活功能和100个单元的隐藏层由<em class="italic">图9.11 </em>中的第一个<strong class="bold"> Keras密集层</strong>节点实现，而输出层由<em class="italic">图9.11 </em>中的第二个(也是最后一个)<strong class="bold"> Keras密集层</strong>节点实现。由于这是一个具有10个不同类别的多类别分类问题，这里使用了具有10个单位的softmax激活函数。此外，使用<strong class="bold">名称前缀</strong> <em class="italic">输出</em>，以便我们在将网络应用于新数据时可以更容易地识别输出层。</p>

			<p>现在我们已经定义了网络结构，我们可以继续训练CNN。</p>

			<h2 id="_idParaDest-169"><a id="_idTextAnchor339"/>培训和应用网络</h2>

			<p>为了训练前一部分构建的<a id="_idIndexMarker870"/> CNN，我们再次使用<strong class="bold"> Keras网络学习器</strong>节点。在前面的章节中，我们<a id="_idIndexMarker871"/>已经看到这个节点为输入和目标数据提供了许多转换类型(例如，从数字(整数)集合到单键张量选项的<strong class="bold">)。安装<strong class="bold"> KNIME图像处理-深度学习扩展</strong>增加了一个转换选项:<strong class="bold">从图像(自动映射)</strong>。这个新的转换选项允许我们从输入表中选择一个图像列，并自动创建张量输入网络。</strong></p>

			<p><em class="italic">图9.14 </em>显示了<strong class="bold"> Keras网络学习器</strong>节点配置窗口的<strong class="bold">输入数据</strong>选项卡，包括该附加转换选项:</p>

			<div><div><img src="img/B16391_09_014.jpg" alt="Figure 9.14 – Input Data tab of the configuration window of the Keras Network Learner node with the additional conversion option, From Image (Auto-mapping)"/>

				</div>

			</div>

			<p class="figure-caption">图9.1<a id="_idTextAnchor340"/>4–带有附加转换选项的Keras网络学习器节点配置窗口的输入数据选项卡，来自图像(自动映射)</p>

			<p>在<strong class="bold">目标数据</strong>页签中，图像标签的集合单元格所在的列选择<strong class="bold">从数字(整数)集合到单热张量</strong>的转换选项。</p>

			<p>在底部的<a id="_idIndexMarker872"/>上，选择<em class="italic">分类交叉熵</em>激活函数，因为该问题是多类分类问题。</p>

			<p>在<strong class="bold">选项</strong>选项卡中，设置了<a id="_idIndexMarker873"/>以下训练参数:</p>

			<ul>

				<li><code>10</code></li>

				<li><code>200</code></li>

				<li><code>Adadelta with the default settings</code></li>

			</ul>

			<p><em class="italic">图9.15 </em>显示了节点执行后<strong class="bold"> Keras网络学习者</strong>节点的<strong class="bold">学习监视器</strong>视图中培训程序的进度:</p>

			<div><div><img src="img/B16391_09_015.jpg" alt="Figure 9.15 – The Learning Monitor view shows the training progress of the network"/>

				</div>

			</div>

			<p class="figure-caption">图9。<a id="_idTextAnchor341"/>15–学习监控视图显示网络的训练进度</p>

			<p><strong class="bold">学习监视器</strong>视图显示了网络在多个<a id="_idIndexMarker874"/>训练批次中的进度。在<a id="_idIndexMarker875"/>右侧，您可以看到最近几批的精确度。<strong class="bold">当前值</strong>显示上一批次的精度，在本例中为<strong class="bold"> 0.995 </strong>。</p>

			<p>既然我们已经有了一个在训练集上表现令人满意的经过训练的CNN，我们可以把它应用到测试集上。这里，与训练集相同的读取和预处理步骤也必须应用于测试集。</p>

			<p><strong class="bold"> Keras网络执行器</strong>节点<a id="_idIndexMarker876"/>将训练好的网络应用于测试集中的图像。在配置窗口中，产生不同数字的概率分布的最后一层被选择作为输出。</p>

			<p>此时，为了从网络输出中提取最终预测，需要<a id="_idIndexMarker878"/>位的后处理。</p>

			<h2 id="_idParaDest-170"><a id="_idTextAnchor342"/>预测提取和模型评估</h2>

			<p><strong class="bold"> Keras网络执行器</strong>节点<a id="_idIndexMarker880"/>的<a id="_idIndexMarker879"/>输出是一个12列的表格，包括以下内容:</p>

			<ul>

				<li>图像列</li>

				<li>真实类值，命名为<strong class="bold">实际值</strong></li>

				<li>10列，具有图像类别的概率值，具有列标题:<code>output/Softmax:0_x</code>，其中<code>x</code>是编码类别的0到9之间的数字</li>

			</ul>

			<p>后处理的目标是提取具有最高概率的类，然后评估网络性能。这由图9.16 中<em class="italic">所示的工作流片段实现:</em></p>

			<div><div><img src="img/B16391_09_016.jpg" alt="Figure 9.16 – This workflow snippet extracts the digit class with the highest probability and evaluates the network performance on the test set"/>

				</div>

			</div>

			<p class="figure-caption">图9.16–该工作流片段提取概率最高的数字类，并在测试集上评估网络性能</p>

			<p><strong class="bold">多对一</strong>节点提取每行中<a id="_idIndexMarker883"/>概率最高的列的<a id="_idIndexMarker881"/>列标题<a id="_idIndexMarker882"/>。</p>

			<p>然后，<strong class="bold">列表达式</strong>节点<a id="_idIndexMarker884"/>从列标题中提取类。</p>

			<p class="callout-heading">小费</p>

			<p class="callout"><strong class="bold">列表达式</strong>节点是一个非常强大的节点。它提供了使用表达式追加任意数量的新列或修改现有列的可能性。</p>

			<p class="callout">对于要追加或修改的每一列，可以定义一个单独的表达式。这些<a id="_idIndexMarker885"/>表达式可以使用预定义的<a id="_idIndexMarker886"/>函数简单创建，类似于<code>=</code>。</p>

			<p class="callout">输入表中可用的流变量和列可以通过提供的访问函数变量(“<code>variableName</code>”)和列(“<code>columnName</code>”)来访问。</p>

			<p><em class="italic">图9.17 </em>此处<a id="_idIndexMarker887"/>显示的是<strong class="bold">列表达式</strong>节点的<a id="_idIndexMarker888"/>配置窗口，用<em class="italic">图9.16 </em>中工作流片段中使用的表达式提取类信息。在这种情况下，表达式从名为<strong class="bold">的列中的字符串中提取最后一个字符，检测到的数字<a id="_idTextAnchor344"/> </strong>:</p>

			<div><div><img src="img/B16391_09_017.jpg" alt="Figure 9.17 – The Column Expression node and its configuration window"/>

				</div>

			</div>

			<p class="figure-caption">图9.17–列表达式节点及其配置窗口</p>

			<p>接下来，预测类的<a id="_idIndexMarker889"/>数据类型通过<strong class="bold">字符串从<code>String</code>转换为<code>Integer</code>到编号</strong>节点，并通过<strong class="bold">计分器</strong>节点在测试集上评估网络性能。</p>

			<p><em class="italic">图9.18 </em>所示为<strong class="bold">划线器</strong>点头<a id="_idTextAnchor345"/> e产生的视图；</p>

			<div><div><img src="img/B16391_09_018.jpg" alt="Figure 9.18 – View of the Scorer node, showing the performance of the network on the test set"/>

				</div>

			</div>

			<p class="figure-caption">图9.18-Scorer节点视图，显示了网络在测试集上的性能</p>

			<p>正如你所看到的，这个简单的CNN已经在测试集上达到了94%的准确率和0.934的Cohen's kappa。完整的工作流程可以在KNIME Hub上找到:<a href="https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/Chapter%209/">https://Hub . KNIME . com/kathrin/spaces/Codeless % 20 deep % 20 learning % 20 with % 20 KNIME/latest/Chapter % 209/</a>。</p>

			<p>在本节中，我们从头开始构建和训练了一个简单的CNN，对于这个相当简单的图像分类任务，达到了可接受的性能。当然，我们可以尝试通过以下方法来进一步提高该网络的性能:</p>

			<ul>

				<li>增加训练时期的数量</li>

				<li>添加第二卷积层和汇集层</li>

				<li>使用批量标准化进行训练</li>

				<li>使用增强</li>

				<li>使用辍学</li>

			</ul>

			<p>我们把这个留给你，继续用另一种网络学习方式，叫做迁移学习。</p>

			<h1 id="_idParaDest-171"><a id="_idTextAnchor346"/>迁移学习简介</h1>

			<p><strong class="bold">迁移学习</strong>的总体思路是将一个为任务<strong class="bold"> A </strong>训练的网络所获得的知识在<a id="_idIndexMarker893"/>另一个相关任务<strong class="bold"> B </strong>上重用。例如，如果我们训练一个网络来识别帆船(任务A)，我们可以使用这个网络作为起点来训练一个新的模型来识别摩托艇(任务B)。在这种情况下，任务A被称为<em class="italic">源任务</em>，任务B被称为<em class="italic">目标任务</em>。</p>

			<p>重用已训练的网络作为训练新网络的起点不同于训练网络的传统方式，在传统方式中，神经网络是针对特定数据集上的特定任务自行训练的。<em class="italic">图9.19 </em>显示了传统的网络训练方式，即针对不同的任务和领域训练不同的系统<a id="_idTextAnchor347"/> ins:</p>

			<div><div><img src="img/B16391_09_019.jpg" alt="Figure 9.19 – Traditional way of training machine learning models and neural networks"/>

				</div>

			</div>

			<p class="figure-caption">图9.19–训练机器学习模型和神经网络的传统方式</p>

			<p>但是为什么要用迁移学习来代替传统的、孤立的训练模式呢？</p>

			<h2 id="_idParaDest-172"><a id="_idTextAnchor348"/>为什么要使用迁移学习？</h2>

			<p>当前最先进的神经网络在处理特定的复杂任务时表现出惊人的性能。有时，这些模型甚至比人类更好，在棋盘游戏或检测图像中的物体方面击败了世界冠军。为了训练这些成功的网络，通常需要大量的标记数据，以及大量的计算资源和时间。</p>

			<p>要为一个新的领域获得一个全面的标记数据集，以便能够训练一个网络达到最先进的性能，可能是困难的，甚至是不可能的。例如，经常使用的<strong class="bold"> ImageNet数据库</strong>，用于训练最先进的模型，已经开发了多年。为新的图像域创建类似的新数据集需要时间。然而，当这些最先进的模型被应用到其他相关领域时，它们的性能通常会遭受相当大的损失，甚至更糟的是，它们会崩溃。这是因为模型偏向于训练数据和领域。</p>

			<p>迁移学习<a id="_idIndexMarker895"/>允许我们使用在任务和领域的训练中获得的知识作为起点，在没有足够的标记数据可用的领域中训练新模型。这种方法已经在许多计算机视觉和自然语言处理任务中显示出巨大的成果。</p>

			<p><em class="italic">图9.20 </em>这里形象地展示了迁移学习背后的思想:</p>

			<div><div><img src="img/B16391_09_020.jpg" alt="Figure 9.20 – Idea behind transfer learning"/>

				</div>

			</div>

			<p class="figure-caption">F <a id="_idTextAnchor349"/>图9.20–迁移学习背后的理念</p>

			<p>在我们讨论如何在训练神经网络时应用迁移学习之前，让我们快速看一下迁移学习的正式定义以及它可以应用的许多场景。</p>

			<h2 id="_idParaDest-173"><a id="_idTextAnchor350"/>迁移学习的正式定义</h2>

			<p>迁移学习和相关场景的正式定义<a id="_idIndexMarker896"/>可参见Sinno Jialin Pan和Qiang Yang的论文<em class="italic">迁移学习调查</em>，IEEE知识与数据工程汇刊，2009 <em class="italic"> </em> ( <a href="https://ieeexplore.ieee.org/abstract/document/5288526">和</a>)。</p>

			<p>该定义涉及一个<strong class="bold">域</strong>和一个<strong class="bold">任务</strong>的<a id="_idIndexMarker897"/>概念。</p>

			<p>在<a id="_idIndexMarker898"/>论文中，引入了一个<strong class="bold">域</strong> <img src="img/Formula_B16391_09_061.png" alt=""/>作为元组{ <img src="img/Formula_B16391_09_062.png" alt=""/>，其中<img src="img/Formula_B16391_09_063.png" alt=""/>是特征空间，<img src="img/Formula_B16391_09_064.png" alt=""/>是<img src="img/Formula_B16391_09_065.png" alt=""/>的边际概率分布。</p>

			<p>对于给定的域<img src="img/Formula_B16391_09_066.png" alt=""/>，任务<img src="img/Formula_B16391_09_067.png" alt=""/>也由以下两部分组成:</p>

			<ul>

				<li>一个标签空间<img src="img/Formula_B16391_09_068.png" alt=""/></li>

				<li>预测功能<img src="img/Formula_B16391_09_069.png" alt=""/></li>

			</ul>

			<p>这里，预测函数<img src="img/Formula_B16391_09_070.png" alt=""/>可以是条件概率分布<img src="img/Formula_B16391_09_071.png" alt=""/>，一般来说，预测函数是在带标签的训练数据上训练的函数，用于预测特征空间中任何样本<img src="img/Formula_B16391_09_073.png" alt=""/>的标签<img src="img/Formula_B16391_09_072.png" alt=""/>。</p>

			<p>使用这个<a id="_idIndexMarker899"/>术语，<strong class="bold">迁移学习</strong>由Sinno Jialin Pan和Qiang Yang定义如下:</p>

			<p class="author-quote"><em class="italic">给出一个源域</em> <img src="img/Formula_B16391_09_074.png" alt=""/> <em class="italic">和学习任务</em> <img src="img/Formula_B16391_09_075.png" alt=""/> <em class="italic">，一个目标域</em> <img src="img/Formula_B16391_09_076.png" alt=""/> <em class="italic">和学习任务</em> <img src="img/Formula_B16391_09_077.png" alt=""/> <em class="italic">，迁移学习旨在帮助提高学习目标预测函数</em><img src="img/Formula_B16391_09_078.png" alt=""/><img src="img/Formula_B16391_09_079.png" alt=""/><em class="italic">中的</em><img src="img/Formula_B16391_09_080.png" alt=""/><em class="italic"/><img src="img/Formula_B16391_09_081.png" alt=""/><em class="italic">，其中</em> <img src="img/Formula_B16391_09_082.png" alt=""/></p>

			<p>Sebastian Ruder <a id="_idIndexMarker900"/>在他的文章<em class="italic">迁移学习-机器学习的下一个前沿</em>，<em class="italic">2017</em>(<a href="https://ruder.io/transfer-learning/">https://ruder.io/transfer-learning/</a>)中使用了这个定义来描述下面<em class="italic">四种可以使用迁移学习的场景</em>:</p>

			<ol>

				<li value="1">Different feature spaces: <img src="img/Formula_B16391_09_084.png" alt=""/><p>论文中的一个例子是跨语言改编，我们有不同语言的文档。</p></li>

				<li>Different marginal probabilities: <img src="img/Formula_B16391_09_085.png" alt=""/><p>讨论不同主题的文档就是一个例子。这个场景被称为<em class="italic">域适配</em>。</p></li>

				<li>Different label spaces: <img src="img/Formula_B16391_09_086.png" alt=""/><p>(例如，如果我们有不同标签的文档)。</p></li>

				<li>不同的条件概率<img src="img/Formula_B16391_09_087.png" alt=""/>这通常与场景3一起出现。</li>

			</ol>

			<p>现在我们对迁移学习有了基本的了解，接下来让我们来看看迁移学习是如何应用到深度学习领域的。</p>

			<h2 id="_idParaDest-174"><a id="_idTextAnchor351"/>应用迁移学习</h2>

			<p>在神经网络中，训练期间获得的<a id="_idIndexMarker901"/>知识存储在层的权重中。例如，在CNN的情况下，许多过滤器被训练以提取许多特征。因此，如何从图像中提取这些特征的知识被存储在所实现的滤波器的核的权重中。</p>

			<p>在用于图像分类的堆叠CNN中，初始卷积层负责提取边缘等低级特征，而接下来的卷积层提取身体部位、动物或人脸等高级特征。基于提取的特征，训练最后的层来对图像进行分类。</p>

			<p>因此，如果我们想要训练CNN用于不同的图像分类任务，在不同的图像上和用不同的标签，我们一定不能从头开始训练新的过滤器，但是我们可以使用先前在最先进的网络中训练的卷积层作为起点。希望新的训练程序会更快，需要的数据更少。</p>

			<p>为了使用来自另一个网络的训练层作为训练起点，我们需要从原始网络中提取卷积层，然后在其上构建一些新层。为此，我们有以下两种选择:</p>

			<ul>

				<li>我们冻结已训练层的权重，并且仅基于冻结层的输出来训练添加的层。这种方法通常用于NLP应用程序，在这些应用程序中，经过训练的嵌入被重用。</li>

				<li>我们使用训练的权重来初始化网络中的新卷积层，然后在训练添加的层时对它们进行微调。在这种情况下，小的训练率用于不忘记从源任务学到的知识。</li>

			</ul>

			<p>对于本书的最后一个案例<a id="_idIndexMarker902"/>研究，我们希望训练一个神经网络来从组织病理学幻灯片图像中预测癌症类型。为了加快学习过程并考虑到我们拥有的相对较小的数据集，我们将从这里用作源网络的流行VGG16网络中的卷积层开始应用迁移学习。</p>

			<h1 id="_idParaDest-175"><a id="_idTextAnchor352"/>应用迁移学习进行癌症类型预测</h1>

			<p>我们<a id="_idIndexMarker903"/>将在这里介绍一个新的(也是最后的)案例研究。我们将从最先进的VGG16网络作为源网络开始，在描述淋巴瘤三种不同亚型的图像<a id="_idIndexMarker905"/>的<a id="_idIndexMarker904"/>数据集上训练新的目标网络，这些淋巴瘤<a id="_idIndexMarker906"/>是<strong class="bold">慢性淋巴细胞白血病</strong> ( <strong class="bold"> CLL </strong>)、<strong class="bold">滤泡性淋巴瘤</strong> ( <strong class="bold"> FL </strong>)和<strong class="bold">套细胞淋巴瘤</strong> ( <strong class="bold"> MCL </strong>)。</p>

			<p>医院病理学家的典型任务是查看组织病理学切片图像，并对淋巴瘤的类型做出决定。即使对于有经验的病理学家来说，这也是一项困难的任务，并且在许多情况下，需要后续测试来确认诊断。能够指导病理学家并加快他们工作速度的辅助技术将具有巨大的价值。</p>

			<p>VGG16 <a id="_idIndexMarker907"/>是2014年ImageNet挑战赛的冠军车型之一。这是一个堆叠的CNN网络，使用大小为<img src="img/Formula_B16391_09_026.png" alt=""/>的内核，深度不断增加——也就是说，过滤器数量不断增加。最初的网络是在ImageNet数据集上训练的，包含图像<img src="img/Formula_B16391_09_089.png" alt=""/>，涉及1000多个类。</p>

			<p><em class="italic">图9.21 </em>显示了VGG16模型的网络结构。</p>

			<p>它从两个卷积层开始，每个卷积层有64个滤波器。在最大池层之后，再次使用两个卷积层，这次每个卷积层有128个过滤器。然后，另一个最大池层后面是三个卷积层，每个卷积层有256个过滤器。在又一个最大汇集层之后，再次有三个卷积层，每个具有512个过滤器，接着是另一个汇集层和三个<a id="_idIndexMarker908"/>卷积层，每个具有512个过滤器。在最后一个汇集层之后，使用三个致密层:</p>

			<div><div><img src="img/B16391_09_021.jpg" alt="Figure 9.21 – Network structure of the VGG16 model"/>

				</div>

			</div>

			<p class="figure-caption">图9.21–vgg 16 mo<a id="_idTextAnchor353"/>del的网络结构</p>

			<p>在本案例研究中，我们希望重用VGG16模型的训练卷积层，并在癌细胞分类任务的顶部添加一些层。在训练过程中，卷积层将被冻结，仅训练添加的层。</p>

			<p>为此，我们构建了三个独立的子工作流:一个工作流下载数据，一个工作流预处理图像，第三个工作流使用迁移学习来训练神经网络。您可以从KNIME Hub下载包含三个子工作流的工作流:<a href="https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/Chapter%209/">https://Hub . KNIME . com/kathrin/spaces/Codeless % 20 deep % 20 learning % 20 with % 20 KNIME/latest/Chapter % 209/</a>。让我们从下载数据的工作流程开始。</p>

			<h2 id="_idParaDest-176"><a id="_idTextAnchor354"/>下载数据集</h2>

			<p>包含癌细胞图像的完整数据集<a id="_idIndexMarker909"/>可作为包含374张图像的单个<code>tar.gz</code>文件获得:<a href="https://ome.grc.nia.nih.gov/iicbu2008/lymphoma/index.html">https://ome.grc.nia.nih.gov/iicbu2008/lymphoma/index.html</a>。图9.22 中的<em class="italic">所示的工作流程下载文件，并为每个图像创建一个包含文件路径和类别信息的表格:</em></p>

			<div><div><img src="img/B16391_09_022.jpg" alt="Figure 9.22 – This workflow downloads the full labeled dataset of images of cancer cells"/>

				</div>

			</div>

			<p class="figure-caption">图9.22–该工作流程下载完整的<a id="_idTextAnchor355"/>标记的癌细胞图像数据集</p>

			<p>因此，<a id="_idIndexMarker910"/>工作流程首先使用<code>tar.gz</code>文件将下载的数据定义到<a id="_idIndexMarker912"/>创建的目录中。<code>.table</code>文件。</p>

			<p>下一步是预处理图像。</p>

			<h2 id="_idParaDest-177"><a id="_idTextAnchor356"/>读取并预处理图像</h2>

			<p>在下一个<a id="_idIndexMarker916"/>步骤中，读取由<em class="italic">图9.22 </em>中的工作流程创建的表格<a id="_idIndexMarker917"/>，并对图像进行预处理。每个图像的尺寸为1388像素、1040像素和三色通道；这意味着<img src="img/Formula_B16391_09_090.png" alt=""/>。为了降低计算的空间复杂度，我们使用了与论文<em class="italic">使用监督分类和多模态融合的组织学图像分类</em>(<a href="https://ieeexplore.ieee.org/document/5693834">https://ieeexplore.ieee.org/document/5693834</a>)中采用的方法类似的方法，其中每个图像被分割成25个块。对于这个用例，我们决定将每个图像分割成大小为<img src="img/Formula_B16391_09_091.png" alt=""/>的块。</p>

			<p>加载和预处理步骤由<em class="italic">图9.23 </em>所示的工作流程执行:</p>

			<div><div><img src="img/B16391_09_023.jpg" alt="Figure 9.23 – This workflow loads and preprocesses the image"/>

				</div>

			</div>

			<p class="figure-caption">图9.23–该工作流程加载并预处理图像</p>

			<p>第二个<a id="_idIndexMarker918"/>工作流从<a id="_idIndexMarker919"/>读取第一个工作流中创建的表格开始，包括图像路径和类别信息。接下来，在使用<strong class="bold">分区</strong>节点将数据集分成训练集和测试集之前，<strong class="bold">类别到编号</strong>节点用索引对不同的名义类值(FL、MCL和CLL)进行编码。对于本案例研究，我们决定使用60%的数据进行培训，40%的数据进行测试，对<strong class="bold">类</strong>列进行分层抽样。</p>

			<p>在<strong class="bold">加载并预处理图像(本地文件)</strong>组件中，图像被上传并预处理。</p>

			<p><em class="italic">图9.24 </em>显示了该组件的内部:</p>

			<div><div><img src="img/B16391_09_024.jpg" alt="Figure 9.24 – Inside of the Load and preprocess images (Local Files) component"/>

				</div>

			</div>

			<p class="figure-caption">图9.24–加载和预处理访问图像(本地文件)组件内部</p>

			<p><a id="_idIndexMarker920"/>组件使用一个<a id="_idIndexMarker921"/>循环一个接一个地加载和预处理图像。<strong class="bold">块循环开始</strong>节点，其中<a id="_idIndexMarker922"/>每个块一行，开始循环，而<a id="_idIndexMarker923"/>块循环结束节点，连接循环迭代的结果行，结束循环。</p>

			<p>在循环体中，一个图像总是加载有<strong class="bold">图像读取器(表)</strong>节点。然后使用<strong class="bold">图像计算器</strong>节点将图像归一化，将每个像素值除以255。</p>

			<p>接下来，<strong class="bold">图像裁剪器</strong>节点<a id="_idIndexMarker924"/>用于将图像裁剪至可除以64的尺寸。由于图像的原始大小为1388px 1040px，因此每个图像左侧的前44个像素和顶部的16个像素将被裁剪。</p>

			<p><em class="italic">图9.25 </em>这里显示了节点的配置窗口:</p>

			<div><div><img src="img/B16391_09_025.jpg" alt="Figure 9.25 – Image Cropper node and its configuration window"/>

				</div>

			</div>

			<p class="figure-caption">图9.25–图像裁剪器节点及其配置窗口</p>

			<p>接下来，<strong class="bold">分割器</strong>节点<a id="_idIndexMarker925"/>将每个图像分割成336个大小为64×64像素的图像，将每个新的<a id="_idIndexMarker927"/>子图像存储在一个新列中<a id="_idIndexMarker926"/>，总共约75，000个补丁。<em class="italic">图9.26 </em>显示了<strong class="bold">分割器</strong>节点配置窗口的<strong class="bold">高级</strong>选项卡，其中已经设置了结果图像每个维度的最大尺寸:</p>

			<div><div><img src="img/B16391_09_026.jpg" alt="Figure 9.26 – The Splitter node and its configuration window"/>

				</div>

			</div>

			<p class="figure-caption">图9.26–拆分器节点和i <a id="_idTextAnchor360"/> ts配置窗口</p>

			<p>接下来，在使用<strong class="bold">交叉连接器</strong>节点将类别信息添加到每个图像之前，将表格转置为一列并重命名。</p>

			<p>现在我们有了准备好的图像，我们可以继续最后的工作流程。</p>

			<h2 id="_idParaDest-178"><a id="_idTextAnchor361"/>训练网络</h2>

			<p>训练工作流程的第一步<a id="_idIndexMarker928"/>是使用<em class="italic"> VGG16的卷积层</em>作为起点来定义网络结构。</p>

			<p>VGG16模型最初被定型为预测ImageNet数据集中的类。尽管数据集中有1000个类，但没有一个与这项研究的三种癌症类型相匹配。因此，我们只回收VGG16网络的训练卷积层。然后，我们将在分类任务的基础上添加一些新的神经层，最后根据我们的任务对结果网络进行微调。</p>

			<p>为了训练最终的网络，我们将使用<strong class="bold"> Keras网络学习器</strong>节点和从<a id="_idIndexMarker929"/>训练集图像创建的大约75，000个补丁。这些步骤由<em class="italic">图9.27 </em>所示的工作流程执行:</p>

			<div><div><img src="img/B16391_09_027.jpg" alt="Figure 9.27 – Training workflow to train the new network to classify images of cancer cells"/>

				</div>

			</div>

			<p class="figure-caption">图9.27–训练工作流程来训练新网络对癌细胞图像进行分类</p>

			<p><a id="_idIndexMarker930"/>工作流程首先读取具有完整网络结构和权重的<code>.h5</code>文件的VGG16网络，或者网络保存在仅具有网络结构的<code>.json</code>或<code>.yaml</code>文件中。</p>

			<p>在这种情况下，我们读取经过训练的VGG16网络的<code>.h5</code>文件，因为我们的目标是使用嵌入网络内部的所有知识。</p>

			<p>VGG16网络的输出张量具有维度<img src="img/Formula_B16391_09_092.png" alt=""/>，这是最后一个max pooling层的输出的大小。在我们可以为分类任务添加一些密集层<a id="_idIndexMarker932"/>之前，我们使用<strong class="bold"> Keras展平层</strong>节点展平输出。</p>

			<p>现在，使用<strong class="bold"> Keras密集层</strong>节点添加了一个具有<strong class="bold"> ReLU </strong>激活和64个神经元的密集层。接下来，引入一个<strong class="bold">漏失层</strong>节点，漏失率为<img src="img/Formula_B16391_09_093.png" alt=""/>最后，最后一个<strong class="bold"> Keras密集层</strong>节点定义了网络的输出。由于我们正在处理具有三个不同类别的分类问题，因此采用了具有三个单元的<strong class="bold"> softmax </strong>激活函数。</p>

			<p>如果我们将最后一个<strong class="bold"> Keras密集层</strong>节点的输出连接到一个<strong class="bold"> Keras网络学习器</strong>节点，我们将微调所有层，包括来自VGG16模型的训练卷积层。我们不想失去所有的知识！因此，我们决定不对VGG16模型的层进行微调，而是只训练新添加的层。因此，VGG16模型的图层必须冻结。</p>

			<p>为了冻结网络的层，我们使用<a id="_idIndexMarker933"/><strong class="bold">Keras冻结层</strong>节点。<em class="italic">图9.28 </em>显示了该节点的配置窗口:</p>

			<div><div><img src="img/B16391_09_028.jpg" alt="Figure 9.28 – The Keras Freeze Layers node and its configuration window"/>

				</div>

			</div>

			<p class="figure-caption">图9.28–Keras冻结层<a id="_idTextAnchor363"/>节点及其配置窗口</p>

			<p>在<a id="_idIndexMarker934"/>配置窗口中，您可以选择要冻结的层。稍后，在训练网络时，所选层的权重将不会更新。所有其他层将被训练。我们冻结了每一层，除了我们在VGG16网络末端添加的层。</p>

			<p>在工作流的较低分支中，我们使用<strong class="bold">表读取器</strong>节点读取训练数据，并使用<strong class="bold">一对多</strong>节点对类进行一次性编码。</p>

			<p>现在我们有了训练数据和网络结构，我们可以用<strong class="bold"> Keras网络学习器</strong>节点对其进行微调。</p>

			<p>与本书中的所有其他案例研究一样，输入数据和目标数据的列在<strong class="bold"> Keras网络学习器</strong>节点的配置窗口中选择，以及所需的转换类型。在这种情况下，输入列的<strong class="bold"> From Image </strong>转换和目标列的from Number (double)已被选择。因为这是一个多类分类任务，所以采用了<strong class="bold">分类交叉熵</strong>损失函数。为了微调该网络，使用64的训练批次大小和RMSProp以及作为优化器的默认设置对其进行了5个时期的训练。</p>

			<p>一旦网络被微调，我们就在测试图像上评估它的性能。预处理后的测试图像作为64 x 64像素的小块，用<strong class="bold">读表器</strong>节点读取。为了预测图像的类别，我们使用<strong class="bold"> Keras网络执行器</strong>节点为每个64 x 64px的面片生成预测。然后，使用简单多数投票方案组合所有预测，在<strong class="bold">提取预测</strong>元节点中实现。</p>

			<p>最后，使用<strong class="bold">计分器</strong>节点评估<a id="_idIndexMarker935"/>网络。分类器已经达到了96%的准确率(再微调几个历元就能把准确率推到98%)。</p>

			<p class="callout-heading">小费</p>

			<p class="callout">在这个用例中，VGG16模型仅用于特征提取。因此，另一种方法是应用VGG16模型的卷积层来预先提取特征，并将它们作为输入馈送到经典前馈神经网络。这样做的好处是，每个映像只需向前传递VGG16一次，而不是在每次批量更新时都这样做。</p>

			<p>例如，我们现在可以保存网络并部署它，以允许病理学家通过网络浏览器访问这些预测。如何使用KNIME分析平台和KNIME服务器来实现这一点将在下一章中介绍。</p>

			<h1 id="_idParaDest-179"><a id="_idTextAnchor364"/>总结</h1>

			<p>在本章中，我们探讨了CNN，重点是图像数据。</p>

			<p>我们从卷积层的介绍开始，这是这个新的神经网络家族的名字的由来。在本简介中，我们解释了为什么CNN如此常用于图像数据，卷积网络如何工作，以及许多设置选项的影响。接下来，我们讨论了合并层，它通常在CNN中用于有效地缩减数据采样。</p>

			<p>最后，我们将所有这些知识付诸实践，从零开始构建和训练一个CNN，对MNIST数据集中0到9之间的数字图像进行分类。之后，我们讨论了迁移学习的概念，介绍了四种可以应用迁移学习的场景，并展示了如何在神经网络领域使用迁移学习。</p>

			<p>在最后一节中，我们应用迁移学习训练一个CNN来分类组织病理学幻灯片图像。这一次，我们没有从头开始训练它，而是重新使用经过训练的VGG16模型的卷积层来提取图像的特征。</p>

			<p>既然我们已经介绍了许多不同的用例，我们将继续下一步，即部署经过训练的神经网络。在下一章中，您将了解KNIME软件的不同部署选项。</p>

			<h1 id="_idParaDest-180"><a id="_idTextAnchor365"/>问题和练习</h1>

			<ol>

				<li value="1">What is the kernel size in a convolutional layer?<p>a)由统计值汇总的面积</p><p>b)在图像上移动的矩阵的大小</p><p>c)移动矩阵的像素数</p><p>d)层所用区域的大小</p></li>

				<li>What is a pooling layer?<p>A)池层是RNNs中常用的层</p><p>b)汇集层汇总具有统计值的区域</p><p>c)池层是前馈网络中常用的层</p><p>d)池层可用于对图像进行上采样</p></li>

				<li>When is transfer learning helpful?<p>a)将数据传输到另一个系统</p><p>b)如果没有可用的模型</p><p>c)如果没有足够的标记数据可用</p><p>d)比较不同的模型</p></li>

			</ol>

		</div>

	



</body></html>