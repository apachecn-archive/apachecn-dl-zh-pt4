<html><head/><body>





	

		<title>B16391_10_Final_VK_ePUB</title>

		

	

	

		<div><p><em class="italic"> <a id="_idTextAnchor367"/>第十章:</em>部署深度学习网络</p>

			<h1 id="_idParaDest-182">在本书的前几节中，我们讨论了针对许多不同用例的深度神经网络的训练，从用于欺诈检测的自动编码器开始，通过用于能耗预测和自由文本生成的<strong class="bold">长短期记忆</strong> ( <strong class="bold"> LSTM </strong>)网络，一直到癌细胞分类。但是训练网络并不是项目的唯一部分。一旦训练了深度学习网络，下一步就是部署它。</h1>

			<p>在探索一些用例的过程中，已经引入了第二个工作流，以部署网络来处理真实世界的数据。因此，您已经看到了一些部署示例。然而，在本书的最后一部分，我们将重点放在机器学习模型的许多部署选项上，特别是经过训练的深度学习网络。</p>

			<p>通常，会构建第二个工作流，专门用于部署。该工作流读取经过训练的模型和新的真实世界数据，它以与训练数据完全相同的方式预处理这些数据，然后将经过训练的深度学习网络应用于经过转换的数据，并根据项目的要求产生结果。</p>

			<p>本章重点介绍部署工作流中数据的读取、写入和预处理。</p>

			<p>本章首先回顾了保存、读取和转换训练好的网络的特性。接下来是两个例子，说明我们的情感分析用例的预处理也可以在部署工作流中实现。最后，本章展示了如何通过启用GPU支持来提高执行速度。</p>

			<p>本章由以下几节组成:</p>

			<p>网络结构的转换</p>

			<p>构建简单的部署工作流</p>

			<p>提高可扩展性–GPU执行</p>

			<p><a id="_idTextAnchor368"/>网络结构的转换</p>

			<h1 id="_idParaDest-183">部署工作流的目标是将一个训练有素的网络应用于新的真实世界数据。因此，训练工作流的最后一步必须是保存训练好的网络。</h1>

			<p><a id="_idTextAnchor369"/>拯救训练有素的网络</p>

			<h2 id="_idParaDest-184">本书中描述的所有网络都是使用Keras库训练的，依靠TensorFlow作为后端。因此，保存网络最自然的方法是继续使用Keras库，因此使用<code>.h5</code>文件。</h2>

			<p>然而，Keras格式的网络只能通过Keras库来解释和执行。这已经是TensorFlow库之上的一个级别了。直接在TensorFlow Java API上执行网络应用程序，而不是通过Keras Python API在Python内核上执行，这使得执行速度更快。好消息是，除了基于Keras库的节点之外，KNIME分析平台还有用于TensorFlow执行的节点。</p>

			<p>因此，如果需要更快的执行，Keras网络应该使用压缩的<code>zip</code>文件<code>SavedModel</code>转换成张量流网络<a id="_idIndexMarker939"/>。一个<code>SavedModel</code>文件包含一个完整的TensorFlow程序，包括权重和<a id="_idIndexMarker940"/>计算。它不需要运行原始的模型构建代码，这使得它对于共享或部署非常有用。</p>

			<p>部署网络的第一步是读取经过训练的网络。</p>

			<p><a id="_idTextAnchor370"/>阅读训练有素的网络</p>

			<h2 id="_idParaDest-185">KNIME Analytics <a id="_idIndexMarker941"/>平台提供了许多用于读取经过训练的神经网络的节点，如下:</h2>

			<p>Keras网络阅读器</p>

			<ul>

				<li>TensorFlow网络阅读器(和TensorFlow 2网络阅读器)</li>

				<li>DL Python网络创建器</li>

				<li>ONNX网络阅读器</li>

				<li>该<code>.h5</code>文件)或者只是一个没有权重的网络架构定义(一个<code>.json</code>或<code>.yaml</code>文件)。您可以使用该节点读取通过KNIME Analytics平台训练的网络或直接通过Keras训练的网络，如预训练的Keras网络。</li>

			</ul>

			<p><code>zip</code>文件。如果从一个目录读取，它必须是一个有效的<code>SavedModel</code>文件夹。如果从一个<code>zip</code>文件中读取，它必须包含一个有效的<code>SavedModel</code>文件夹。</p>

			<p>小费</p>

			<p class="callout-heading">TensorFlow网络阅读器节点允许我们在其配置窗口中选择标签和签名。标签用于标识要加载的元图定义。签名<code>SavedModel</code>可以有多个标签<a id="_idIndexMarker945"/>以及每个标签多个签名。用KNIME Analytics Platform保存的网络只有一个标签和一个签名。在配置窗口的<strong class="bold">高级</strong>选项卡中，您可以通过定义模型的输入和输出来定义您自己的签名，例如，通过选择一个隐藏层作为输出。</p>

			<p class="callout">另一个节点是<strong class="bold"> ONNX网络阅读器</strong>节点，它<a id="_idIndexMarker946"/>允许你不用写一行代码就能读取预训练的网络。<strong class="bold"> ONNX </strong>代表<strong class="bold">开放式神经网络交换</strong>，是由<a id="_idIndexMarker947"/>微软和脸书开发的神经网络标准格式。因为它是一种标准格式，所以它可以跨机器学习框架移植，如PyTorch、Caffe2、TensorFlow等。您可以从ONNX Model Zoo(<a href="https://github.com/onnx/models#vision">https://github.com/onnx/models#vision</a>)下载预训练的网络，并使用ONNX网络读取器节点读取它们。ONNX网络也可以使用<strong class="bold"> ONNX到TensorFlow网络转换器</strong>节点转换为TensorFlow网络，然后使用TensorFlow <a id="_idIndexMarker949"/>网络执行器节点<a id="_idIndexMarker948"/>执行。</p>

			<p>小费</p>

			<p class="callout-heading">要使用ONNX节点，您需要安装<strong class="bold"> KNIME深度学习–ONNX集成</strong>扩展。</p>

			<p class="callout">使用Python代码读取网络的另一个选项是<strong class="bold"> DL Python Network Creator </strong>节点，它可以<a id="_idIndexMarker950"/>用于使用几行Python代码读取预训练的神经网络。</p>

			<p>小费</p>

			<p class="callout-heading">DL Python Network Creator节点也可用于培训工作流，以使用Python代码而非图层节点来定义网络架构。</p>

			<p class="callout">到目前为止，我们使用基于Keras的节点，TensorFlow 1作为后端。也有使用TensorFlow 2作为后端实现类似操作的节点。</p>

			<p><a id="_idTextAnchor371"/>使用张量流2</p>

			<h2 id="_idParaDest-186">对于本书中的所有<a id="_idIndexMarker951"/>示例，我们都使用了基于Keras的节点，这些节点运行TensorFlow 1作为后端。自KNIME Analytics Platform 4.2发布以来，TensorFlow 2也受到支持。在KNIME Hub上，可以找到很多如何使用TensorFlow 2集成的例子。</h2>

			<p>TensorFlow 2集成<a id="_idIndexMarker952"/>带有三个节点:</p>

			<p><strong class="bold">tensor flow 2网络执行器</strong>节点</p>

			<ul>

				<li><strong class="bold">tensor flow 2网络阅读器</strong>节点</li>

				<li><strong class="bold">tensor flow 2网络作家</strong>节点</li>

				<li>要使用TensorFlow 2训练深度学习模型，您可以<a id="_idIndexMarker953"/>使用<strong class="bold"> DL Python网络学习器</strong>节点。</li>

			</ul>

			<p>既然我们已经查看了保存和读取神经网络的许多选项，那么让我们将重点放在构建一个简单的部署工作流上。</p>

			<p><a id="_idTextAnchor372"/>构建简单的部署工作流程</p>

			<h1 id="_idParaDest-187">到目前为止，在我们探索的所有<a id="_idIndexMarker954"/>案例研究中，我们总是对输入数据执行某种预处理，例如对分类特征编码、对文本编码或对数据进行规范化，这只是所采用的一些预处理步骤。在部署过程中，新输入的数据必须经过与训练数据完全相同的预处理，以便与任务和网络预期的输入保持一致。</h1>

			<p>在本节中，我们使用第七章 、<em class="italic">实现NLP应用</em>中所示的情感分析案例研究作为示例，并为其构建两个部署工作流。这两个工作流的目标都是从数据库中读取新的电影评论，预测情感，并将预测写入数据库。</p>

			<p>在第一个示例中，预处理步骤是在部署工作流中手工实现的。在第二个例子中，使用了<strong class="bold">集成部署</strong>特性。</p>

			<p><a id="_idTextAnchor373"/>手动构建部署工作流，没有集成部署</p>

			<h2 id="_idParaDest-188">部署工作流<a id="_idIndexMarker955"/>应该从数据库的一个表中访问新的评论，应用训练好的网络，将带有相应预测的评论写入数据库的另一个表中，并从第一个表中删除评论。</h2>

			<p>这些步骤由<em class="italic">图10.1 </em>中的工作流执行，您可以从KNIME Hub下载，网址为<a href="https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/Chapter_10/">https://Hub . KNIME . com/kathrin/spaces/Codeless % 20 deep % 20 learning % 20 with % 20 KNIME/latest/Chapter _ 10/</a>:</p>

			<p>图10.1–第7章 中<a href="B16391_07_Final_NM_ePUB.xhtml#_idTextAnchor230"> <em class="italic">情感分析案例研究的部署工作流程，实现NLP应用</em></a></p>

			<div><div><img src="img/B16391_10_001.jpg" alt="Figure 10.1 – Deployment workflow for the sentiment analysis case study from Chapter 7, Implementing NLP Applications"/>

				</div>

			</div>

			<p class="figure-caption">工作流首先<a id="_idIndexMarker956"/>连接到一个SQLite数据库，在那里<a id="_idIndexMarker957"/>使用<strong class="bold"> SQLite连接器</strong>节点存储新的电影评论。</p>

			<p>接下来，从名为<strong class="bold"> new_reviews </strong>的表中读取新评论的<strong class="bold"> SELECT </strong> SQL语句由<strong class="bold"> DB表选择器</strong>节点实现<a id="_idIndexMarker958"/>。</p>

			<p>然后，SQL语句通过<strong class="bold"> DB阅读器</strong>节点<a id="_idIndexMarker959"/>执行。结果，我们在节点输出端口的数据表中有了新的评论。</p>

			<p>小费</p>

			<p class="callout-heading">在<a href="B16391_02_Final_SK_ePUB.xhtml#_idTextAnchor051"> <em class="italic">第二章</em> </a>、<em class="italic">用KNIME Analytics平台进行数据访问和预处理</em>中，详细介绍了数据库扩展。请记住，数据库节点在其棕色方形输出端口创建一个SQL语句。</p>

			<p class="callout">在将网络应用到这些新的评审之前，我们需要执行与培训工作流中相同的转换。在<a href="B16391_07_Final_NM_ePUB.xhtml#_idTextAnchor230"> <em class="italic">第7章</em> </a>、<em class="italic">实现NLP应用</em>中报告的训练工作流中，有一个名为<strong class="bold">预处理测试集</strong>的元节点，所有需要的预处理步骤都应用于测试数据。我们使用这个元节点作为基础，为部署工作流中的传入数据创建预处理步骤。</p>

			<p><em class="italic">图10.2 </em>显示了这个<a id="_idIndexMarker960"/>元节点的内容，它专用于测试集的预处理:</p>

			<p>图10.2–第7章 中<a href="B16391_07_Final_NM_ePUB.xhtml#_idTextAnchor230"> <em class="italic">情感分析案例研究的训练工作流程中测试数据的预处理，实现NLP应用</em></a></p>

			<div><div><img src="img/B16391_10_002.jpg" alt="Figure 10.2 – Preprocessing of the test data in the training workflow of the sentiment analysis case study from Chapter 7, Implementing NLP Applications"/>

				</div>

			</div>

			<p class="figure-caption">在<em class="italic">图10.1 </em>的部署工作流程中，首先读取训练时创建的字典；然后在<strong class="bold">预处理</strong>元节点中实现预处理步骤。</p>

			<p><em class="italic">图10.3 </em>显示了该元节点<a id="_idTextAnchor376"/>端的工作流片段:</p>

			<p>图10.3–部署工作流的预处理元节点中的工作流片段</p>

			<div><div><img src="img/B16391_10_003.jpg" alt="Figure 10.3 – Workflow snippet inside the Preprocessing metanode of the deployment workflow"/>

				</div>

			</div>

			<p class="figure-caption">如果我们比较<em class="italic">图10.2 </em>和<em class="italic">图10.3 </em>中的<a id="_idIndexMarker961"/>工作流片段，您可以看到它们包含相同的预处理步骤，正如我们所料。</p>

			<p>既然与训练数据相同的预处理已经应用于部署数据，训练好的网络可以通过<strong class="bold"> Keras网络阅读器</strong>节点<em class="italic">图10.1 </em>引入<a id="_idIndexMarker962"/>。</p>

			<p>接下来，训练好的网络使用<strong class="bold"> Keras网络执行器</strong>节点在预处理的部署评审上运行。网络的<a id="_idIndexMarker963"/>输出是情绪等于1的概率，其中1编码一个积极的电影评论。通过<strong class="bold">规则引擎</strong>节点，这里也应用了与训练期间相同的阈值:阈值<img src="img/Formula_B16391_10_001.png" alt=""/>。</p>

			<p>最后一步，更新数据库中的表。首先，<strong class="bold"> DB Delete </strong>节点从<strong class="bold"> new_reviews </strong>表中删除我们刚刚分析的评论。然后，<strong class="bold"> DB Writer </strong>节点将新的电影评论及其预测附加到数据库中的另一个表，名为<strong class="bold">带感情评论</strong>。</p>

			<p>这是第一个使用KNIME分析平台部署神经网络的例子。应该定期执行此工作流，以预测所有新电影评论的情绪。</p>

			<p>小费</p>

			<p class="callout-heading">KNIME Server可以调度工作流的执行，因此您可以定期自动触发它们的执行。</p>

			<p class="callout">这种<a id="_idIndexMarker964"/>方法有一个缺点。如果根据更多数据或不同设置重新训练模型(例如，如果在训练期间考虑更多或更少的术语，或者规则引擎节点的阈值发生变化)，我们需要记住还要更新部署工作流中的预处理步骤。由于我们是健忘的人，我们可能会忘记或犯错误。</p>

			<p>克服这个问题的一个解决方案是<strong class="bold">集成部署</strong>的概念。</p>

			<p><a id="_idTextAnchor377"/>通过集成部署自动构建部署工作流</p>

			<h2 id="_idParaDest-189">在KNIME Analytics <a id="_idIndexMarker965"/> Platform 4.2以及其他工具之前，常见的方法是在部署工作流中手动实现数据混合、数据转换和网络执行。这意味着您需要将不同的预处理片段、参数和网络执行器节点从培训工作流复制到部署工作流，确保所有设置保持不变。</h2>

			<p>这种手动步骤会降低流程速度，并且很容易导致错误。自动化部分部署工作流的构造可能是一个更安全的选择，特别是如果模型经常改变，例如，每天甚至每小时。</p>

			<p>重要说明</p>

			<p class="callout-heading">培训过程的其他常见名称是数据科学创建或建模工作流。</p>

			<p class="callout">集成部署扩展中的节点缩小了创建和部署数据科学之间的差距。</p>

			<p>集成部署扩展</p>

			<h3>集成部署扩展允许数据科学家将模型培训<a id="_idIndexMarker966"/>和部署合并到一个工作流中。其思想是捕获部分培训工作流，并在培训工作流的执行过程中自动将它们写入部署工作流。</h3>

			<p>取代手动复制<a id="_idIndexMarker967"/>预处理部分，来自训练工作流的所需部分被<a id="_idIndexMarker968"/>在<strong class="bold">捕获工作流开始</strong>和<strong class="bold">捕获工作流结束</strong>节点之间捕获。中间被捕获的工作流部分可以被写入到一个新的工作流<a id="_idIndexMarker969"/>中，并带有一个<strong class="bold">工作流编写器</strong>节点。</p>

			<p>在培训工作流中使用集成部署扩展</p>

			<h3>让我们再次考虑<a id="_idIndexMarker970"/>在<a href="B16391_07_Final_NM_ePUB.xhtml#_idTextAnchor230"> <em class="italic">第7章</em> </a>、<em class="italic">实现NLP应用</em>中描述的情感分析案例研究的部署工作流。在培训工作流中，我们引入了<strong class="bold">捕获工作流开始</strong>节点和<strong class="bold">捕获工作流结束</strong>节点，以隔离我们希望在部署工作流中准确再现的工作流片段。</h3>

			<p>这包括以下内容:</p>

			<p>名为<strong class="bold">的元节点预处理测试集</strong>，包括所有需要的预处理步骤</p>

			<ul>

				<li><strong class="bold"> Keras网络执行器</strong>节点<a id="_idIndexMarker971"/>将训练好的网络应用于部署转换后的数据</li>

				<li><strong class="bold">规则引擎</strong>节点，其<a id="_idIndexMarker972"/>基于应用于输出类别概率的阈值来决定肯定或否定类别</li>

				<li>图10.4 中的工作流程向您展示了这个基于情感分析案例研究的示例。您可以从KNIME Hub的<a href="https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/Chapter_10/">https://Hub . KNIME . com/kathrin/spaces/Codeless % 20 deep % 20 learning % 20 with % 20 KNIME/latest/Chapter _ 10/</a>下载工作流程:</li>

			</ul>

			<p>图10.4–使用集成部署自动创建部署工作流的培训工作流</p>

			<div><div><img src="img/B16391_10_004.jpg" alt="Figure 10.4 – Training workflow that automatically creates a deployment workflow using Integrated Deployment"/>

				</div>

			</div>

			<p class="figure-caption"><a id="_idIndexMarker973"/>粗框中的部分是捕获的工作流片段。<strong class="bold">捕获工作流开始</strong>节点定义开始，而<strong class="bold">捕获工作流结束</strong>节点定义要捕获的工作流片段的结束。</p>

			<p>开始节点不需要任何配置。<em class="italic">图10.5 </em>显示了第<a id="_idTextAnchor379"/> e <strong class="bold">采集工作流结束</strong>节点的配置窗口:</p>

			<p>图10.5–捕获工作流结束节点的配置窗口</p>

			<div><div><img src="img/B16391_10_005.jpg" alt="Figure 10.5 – Configuration window of the Capture Workflow End node"/>

				</div>

			</div>

			<p class="figure-caption">在<a id="_idIndexMarker974"/>配置窗口中，您可以设置捕获的工作流片段的名称。您还可以设置捕获的代码片段是否应该与数据一起存储，如果是，还可以设置要包含的最大数据行数。我们将很快看到为什么在捕获的工作流片段中存储一些数据是有帮助的。</p>

			<p>然后通过<strong class="bold">捕获工作流结束</strong>节点的输出端口(黑色方块)导出捕获的工作流片段，无论有无数据。在<em class="italic">图10.4 </em>中的工作流中，工作流片段随后由<a id="_idIndexMarker975"/>的<strong class="bold">工作流编写器</strong>节点收集，并写入部署工作流中，不改变设置和配置。</p>

			<p><em class="italic">图10.6 </em>显示了<strong class="bold">工作流编写器</strong>节点的配置窗口<a id="_idTextAnchor380"/>:</p>

			<p>图10.6–工作流编写器节点及其配置窗口</p>

			<div><div><img src="img/B16391_10_006.jpg" alt="Figure 10.6 – The Workflow Writer node and its configuration window"/>

				</div>

			</div>

			<p class="figure-caption">在顶部，您可以<a id="_idIndexMarker976"/>设置目标工作流程的文件夹位置(<strong class="bold">输出位置</strong>)。</p>

			<p>接下来，您需要设置目标工作流的名称。节点会自动建议一个默认名称，您可以通过<strong class="bold">使用自定义工作流名称</strong>选项进行自定义。如果您选择的名称引用了已经存在的工作流，您可以让writer节点失败或覆盖。</p>

			<p>在底部，您可以为目标工作流选择部署选项:只需创建它，创建它并打开它，或者将其保存为一个<code>.knwf</code>文件以便导出。</p>

			<p>下图<em class="italic">图10.7 </em>，展示了由<strong class="bold">工作流编写器</strong>节点自动生成的部署工作流<a id="_idTextAnchor381"/>:</p>

			<p>图10.7–从通过集成部署捕获的工作流片段中自动创建的部署工作流</p>

			<div><div><img src="img/B16391_10_007.jpg" alt="Figure 10.7 – Automatically created deployment workflow from the workflow snippet captured via Integrated Deployment"/>

				</div>

			</div>

			<p class="figure-caption">在捕获的<a id="_idIndexMarker977"/>工作流中，您可以看到<strong class="bold">预处理测试集</strong>元节点，以及<strong class="bold"> Keras网络执行器</strong>、<strong class="bold">规则引擎</strong>和<strong class="bold">列过滤器</strong>节点。此外，整个集成部署流程增加了以下内容:</p>

			<p>两个<strong class="bold">参考阅读器</strong>节点。它们是一般的读取器节点，加载在捕获的工作流片段中找不到的静态参数的连接信息。</p>

			<ul>

				<li>一个<strong class="bold">容器输入(表)</strong>和一个<strong class="bold">容器输出(表)</strong>节点，以便接受输入数据和<a id="_idIndexMarker978"/>分别从和向其他应用发送输出数据<a id="_idIndexMarker979"/>。</li>

				<li>此部署工作流的执行可以由使用<strong class="bold">调用工作流(表)</strong>节点<a id="_idIndexMarker980"/>的另一个工作流触发，或者如果工作流已经部署在KNIMEs服务器上，则通过REST服务触发。在下一章中，我们将详细讨论REST调用和REST服务。</li>

			</ul>

			<p>在<em class="italic">图10.7 </em>中，示例部署工作流使用两个内部没有图标的阅读器节点读取工作流顶部的两个实体。左边的提供基于训练数据的字典表，右边的提供训练好的神经网络。</p>

			<p>此外，还可以看到两个新节点，分别是<strong class="bold">容器输入(表)</strong>和<strong class="bold">容器输出(表)</strong>节点。</p>

			<p><strong class="bold">容器输入(表格)</strong>节点从外部调用方(即<strong class="bold">调用工作流(基于表格)</strong>节点)接收数据表，并使其在输出端口可用。配置参数使外部调用程序能够向<strong class="bold">容器输入(表)</strong>节点发送数据表。</p>

			<p><strong class="bold">容器输入(表)</strong>节点也有一个可选的输入端口(由未填充的输入端口表示)。如果一个数据表连接到可选输入，节点将简单地把这个表转发到下一个节点；如果一个表是通过REST API提供的，那么提供的表<a id="_idIndexMarker981"/>将在输出端口上可用。</p>

			<p>如果没有输入，节点的输出将提供一个默认的模板表。这里，来自<strong class="bold">捕获工作流结束</strong>节点的<strong class="bold">存储输入表</strong>设置开始生效。如果选择存储一些数据行，它们将用于定义此默认模板表。</p>

			<p><strong class="bold">容器输出(表格)</strong>节点向外部调用者发送一个KNIME数据表。</p>

			<p>现在，让我们看看如何使用自动创建的工作流来预测部署期间新评论的情绪。</p>

			<p>使用自动创建的工作流</p>

			<h3>现在让我们看看如何使用部署工作流。</h3>

			<p><em class="italic">图10.8 </em>向您展示了如何使用自动创建的部署工作流<a id="_idIndexMarker982"/>来对新电影评论的情感进行分类，您可以从KNIME Hub下载并试用它，网址为<a href="https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/Chapter_10/">https://Hub . KNIME . com/kathrin/spaces/Codeless % 20 deep % 20 learning % 20 with % 20 KNIME/latest/Chapter _ 10/</a>:</p>

			<p>:<a id="_idTextAnchor382"/>图10.8-调用自动创建的部署工作流的工作流</p>

			<p class="figure-caption">工作流<a id="_idIndexMarker983"/>连接到数据库并读取传入的新电影评论。</p>

			<div><div><img src="img/B16391_10_008.jpg" alt="Figure 10.8 – Workflow calling the automatically created deployment workflow"/>

				</div>

			</div>

			<p>然后，<strong class="bold">调用工作流(基于表格)</strong>节点调用自动构建的部署工作流(<em class="italic">图10.7 </em>)。<strong class="bold">调用工作流(基于表格)</strong>节点实际上调用了驻留在您的本地工作区或已挂载的KNIME服务器上的其他工作流。被调用的工作流必须包含至少一个容器输入节点和一个容器输出节点，以定义两个工作流之间的接口:被调用的工作流和调用方工作流。</p>

			<p>通过<strong class="bold">调用工作流(基于表格)</strong>节点，我们将新的电影评论发送到部署工作流，以提供给<strong class="bold">容器输入(表格)</strong>节点。然后执行部署工作流，并将预测发送回调用方工作流，并通过<strong class="bold">调用工作流(基于表)</strong>节点的输出端口提供。</p>

			<p>这种策略的一大优点是确保了培训工作流中的数据操作和部署工作流中的数据操作之间的一致性。如果我们现在更改培训工作流中数据操作的任何设置，例如，<strong class="bold">规则引擎</strong>节点中阈值的值(<em class="italic">图10.4 </em>)，并且我们重新执行培训工作流，这些更改将自动导入到部署工作流的新版本(<em class="italic">图10.7 </em>)中，并由依赖它的任何工作流使用(<em class="italic">图10.8 </em>)。</p>

			<p>小费</p>

			<p class="callout-heading"><strong class="bold">集成部署</strong>扩展的另一个伟大节点是<strong class="bold">工作流组合器</strong>节点，它允许我们组合来自不同原始工作流的工作流片段。</p>

			<p class="callout">我们已经到了本章的最后一节，关于可扩展性和GPU执行。</p>

			<p><a id="_idTextAnchor383"/>提高可扩展性——GPU执行</p>

			<h1 id="_idParaDest-190">对于本书中描述的案例研究，我们使用了相对较小的数据集和小型网络。这使我们能够在几个小时内仅使用基于CPU的执行来训练网络。然而，在小数据集上需要几分钟或几小时的训练任务在大数据集上很容易需要几天或几周；小型网络架构的规模会快速增长，执行时间也会变得令人望而却步。一般来说，当使用深度神经网络时，训练阶段是资源最密集的任务。</h1>

			<p>GPU被设计用来同时处理多个计算。这种范式适合训练深度学习网络所需的密集计算。因此，GPU是在大型数据集上高效和有效地训练大型深度学习网络的替代选择。</p>

			<p>一些Keras库可以通过TensorFlow范例利用兼容NVIDIA的GPU的计算能力。因此，<strong class="bold"> KNIME Keras integration </strong>也可以利用GPU的计算能力更快地训练深度学习网络。</p>

			<p>在<a href="B16391_01_Final_NM_ePUB.xhtml#_idTextAnchor016"> <em class="italic">第一章</em> </a>、【KNIME Analytics平台深度学习介绍中，我们介绍了如何设置Python进行KNIME Keras集成和KNIME TensorFlow集成。为了在GPU上而不是在CPU上运行KNIME Keras集成，您不需要采取很多额外的步骤。</p>

			<p>当然，你需要一台支持GPU的电脑。TensorFlow 1.12需要CUDA计算能力为3.5或更高的NVIDIA GPU卡。</p>

			<p>除此之外，大部分需要的依赖项(即CUDA和cuDNN)都会在安装conda <code>tensorflow=1.12</code>和<code>keras-gpu=2.2.4</code>的时候被Anaconda自动安装。包装</p>

			<p>安装时唯一的额外步骤是手动安装最新版本的NVIDIA GPU驱动程序。</p>

			<p>在安装时，通过选择<code>keras-gpu=2.2.4</code>创建。</p>

			<p>使用TensorFlow集成时，还可以在GPU上执行<a id="_idIndexMarker986"/>来读取和执行<a id="_idIndexMarker987"/> TensorFlow的SavedModel。</p>

			<p>重要说明</p>

			<p class="callout-heading">对<strong class="bold"> KNIME TensorFlow集成</strong>(使用TensorFlow Java API)的GPU支持通常独立于对<strong class="bold"> KNIME Keras集成</strong>(使用Python)的GPU支持。因此，必须单独设置两个GPU支持。由于TensorFlow的限制，GPU对KNIME TensorFlow集成的支持只能在Windows和Linux上运行，而不能在Mac上运行。</p>

			<p class="callout">在撰写本文时，KNIME推荐了以下GPU配置。</p>

			<p>KNIME TensorFlow集成使用TensorFlow版本1.13.1，这需要在您的系统上安装以下NVIDIA软件:</p>

			<p>NVIDIA GPU驱动:CUDA 10.0要求410.x以上。</p>

			<ul>

				<li>CUDA工具包:TensorFlow (≥ 1.13.0)支持CUDA 10.0。</li>

				<li>cuDNN(版本≥7 . 4 . 1):CUDA 10.0选择cud nn v 7 . 6 . 0(2019 . 5 . 20)。</li>

				<li>详细说明和最新更新请查看KNIME文档(<a href="https://docs.knime.com/2019-06/deep_learning_installation_guide/index.html#tensorflow-integration">https://docs . KNIME . com/2019-06/deep _ learning _ installation _ guide/index . html # tensor flow-integration</a>)。</li>

			</ul>

			<p><a id="_idTextAnchor384"/>总结</p>

			<h1 id="_idParaDest-191">在这一章中，我们讨论了三个不同的主题。我们首先总结了读取、转换和编写神经网络的许多选项。</h1>

			<p>然后，我们使用第七章 、<em class="italic">实现NLP应用</em>中的情感分析案例研究，继续讨论神经网络的部署。这里的目标是建立一个工作流，该工作流使用经过训练的神经网络来预测存储在数据库中的新评论的情绪。我们已经展示了一个部署工作流可以通过两种方式进行组装:手动或通过集成部署自动组装。</p>

			<p>本章的最后一节讨论了网络培训和执行的可扩展性。特别是，它展示了如何在训练神经网络时利用GPU的计算能力。</p>

			<p>在本书的下一章也是最后一章中，我们将探讨在使用深度学习时的进一步部署选项和最佳实践。</p>

			<p><a id="_idTextAnchor385"/>问题和练习</p>

			<h1 id="_idParaDest-192">a) Keras到张量流网络转换</h1>

			<ol>

				<li>Which network conversions are available in KNIME Analytics Platform?<p>b) TensorFlow到Keras网络转换</p><p>c) ONNX到Keras网络转换</p><p>d) Keras到ONNX网络转换</p><p>a)集成部署允许我们在执行过程中重新训练模型。</p></li>

				<li>Which statements regarding Integrated Deployment are true (two statements are correct)?<p>b)自动生成的工作流的执行可以由另一个工作流触发。</p><p>c)培训工作流的执行由部署工作流触发。</p><p>d)综合部署缩小了培训和部署之间的差距。</p><p>d) Integrated Deployment closes the gap between training and deployment.</p></li>

			</ol>

		</div>

	



</body></html>