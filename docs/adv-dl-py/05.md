<title>Advanced Convolutional Networks</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# 高级卷积网络

在[第二章](d94e220f-820e-40da-8bb5-9593e0790b21.xhtml)、*了解卷积网络*中，我们讨论了**卷积神经网络**(**CNN**)的构建模块以及它们的一些性质。在这一章中，我们将更进一步，讨论一些最流行的 CNN 架构。这些网络通常将多个原始卷积和/或汇集操作组合在一个新颖的构建块中，作为复杂架构的基础。这使我们能够建立非常深(有时是宽)的网络，具有很高的表示能力，能够很好地执行复杂的任务，如图像网络分类、图像分割、语音识别等。这些模型中有许多是作为 ImageNet 挑战赛的参与者首次发布的，他们通常都会获胜。为了简化我们的任务，我们将在图像分类的背景下讨论所有架构。我们仍将讨论更复杂的任务，但我们将在第四章、*对象检测和图像分割*中讨论。

本章将涵盖以下主题:

*   AlexNet 简介
*   视觉几何组导论
*   了解剩余网络
*   理解初始网络
*   引入异常
*   MobileNet 简介
*   DenseNets 简介
*   神经结构搜索的工作原理
*   胶囊网络简介

<title>Introducing AlexNet</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# AlexNet 简介

我们将讨论的第一个模型是 2012 年 **ImageNet 大规模视觉识别挑战赛** ( **ILSVRC** ，或简称 ImageNet)的获胜者。它的昵称是 Alex net(*ImageNet class ification with Deep convolutionary Neural Networks*，[https://papers . nips . cc/paper/4824-ImageNet-class ification-with-Deep-convolutionary-Neural-Networks . pdf](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf))，以其作者之一 Alex Krizhevsky 的名字命名。虽然这个模型现在很少使用，但它是当代深度学习的一个重要里程碑。

下图显示了网络架构:

![](assets/ec08175c-5282-4be2-b6e7-6f2d99272166.png)

AlexNet 架构。最初的模型被一分为二，因此它可以放在两个 GPU 的内存中

该模型具有五个互相关卷积层、三个重叠最大池层、三个全连接层和 ReLU 激活。输出是 1，000 路 softmax(每个 ImageNet 类一个)。第一个和第二个卷积层使用局部响应归一化，这是一种归一化，有点类似于批量归一化。完全连接的层的辍学率为 0.5。为了防止过度拟合，使用 256×256 输入图像的随机 227×227 裁剪来训练网络。该网络实现了 37.5%和 17.0%的前 1 和前 5 测试集错误率。

在下一节中，我们将讨论一种由牛津视觉几何小组在 2014 年推出的神经网络架构，当时它在当年的 ImageNet 挑战赛中获得了亚军。

<title>An introduction to Visual Geometry Group </title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# 视觉几何组导论

接下来我们要讨论的架构是**视觉几何组** ( **VGG** )(来自牛津视觉几何组，*大规模 Ima 的极深卷积网络*g*e*识别，[https://arxiv.org/abs/1409.1556](https://arxiv.org/abs/1409.1556)[)](https://arxiv.org/abs/1409.1556)。VGG 网络家族今天仍然很受欢迎，并且经常被用作新架构的基准。在 VGG(例如 LeNet-5:[http://yann.lecun.com/exdb/lenet/](http://yann.lecun.com/exdb/lenet/)和 AlexNet)之前，网络的初始卷积层使用具有大感受野的滤波器，例如 11×11。此外，网络通常具有交替的单一卷积层和汇集层。该论文的作者观察到，具有大滤波器大小的卷积层可以用具有较小滤波器的两个或更多卷积层的堆叠来代替(分解卷积)。例如，我们可以用两个 3×3 层的叠层替换一个 5×5 层，或者用三个 3×3 层的叠层替换一个 7×7 层。

这种结构有如下几个优点:

*   堆叠层的最后一层的神经元具有相当于具有大过滤器的单层的感受野大小。
*   与具有大过滤器尺寸的单个层相比，堆叠层的权重和操作的数量更少。假设我们想要用两个 3×3 层替换一个 5×5 层。我们还假设所有层都有相同数量的输入和输出通道(切片)， *M* 。5×5 层的总权重数(不包括偏差)为*5 * 5 * M * M = 25 * M²。另一方面，单个 3×3 层的总重量是*3 * 3 * M * M = 9 * M²，对于两层来说，简单地说就是*2 *(3 * 3 * M * M)= 18 * M²，这使得这种排列的效率提高了 28%(18/25 = 0.72)。使用更大的过滤器，效率将进一步提高。***
*   堆叠多个层使得决策函数更具区分性。

VGG 网络由两层、三层或四层堆叠卷积层与最大池层组合而成的多个模块组成。我们可以在下表中看到两种最流行的变体， **VGG16** 和 **VGG19** :

![](assets/ab51fa0e-ccbf-4a89-b3c7-f76561637925.png)Architecture of the VGG16 and VGG19 networks, named after the number of weighted layers in each network

随着 VGG 网络深度的增加，卷积层的宽度(滤波器的数量)也在增加。我们有多对体积深度为 128/256/512 的交叉通道回旋连接到具有相同深度的其它层。此外，我们还有两个 4，096 单元的全连接层，随后是一个 1000 单元的全连接层和一个 softmax(每个 ImageNet 类一个)。正因为如此，VGG 网络有大量的参数(权重)，这使得它们的内存效率低，并且计算量大。尽管如此，这仍然是一个流行且简单的网络架构，通过添加批处理规范化，它得到了进一步的改进。

在下一节中，我们将以 VGG 为例，说明如何使用 TensorFlow 和 PyTorch 加载预训练的网络模型。

<title>VGG with PyTorch and TensorFlow</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# VGG 与 PyTorch 和 TensorFlow

PyTorch 和 TensorFlow 都对 VGG 模型进行了预训练。让我们看看如何使用它们。

Keras 是 TensorFlow 2 的官方部分，因此，我们将使用它来加载模型:

```
import tensorflow as tf

# VGG16
vgg16 = tf.keras.applications.vgg16.VGG16(include_top=True,
                                          weights='imagenet',
                                          input_tensor=None,
                                          input_shape=None,
                                          pooling=None,
                                          classes=1000)

# VGG19 
vgg19 = tf.keras.applications.vgg19.VGG19(include_top=True,
                                          weights='imagenet',
                                          input_tensor=None,
                                          input_shape=None,
                                          pooling=None,
                                          classes=1000)
```

通过设置`weights='imagenet'`参数，网络将加载预训练的 ImageNet 权重(它们将自动下载)。您可以将`include_top`设置为`False`，这将为迁移学习场景排除完全连接的层。在这种情况下，您也可以通过将元组值设置为`input_shape`来使用任意输入大小——卷积层将自动缩放以匹配所需的输入形状。这是可能的，因为卷积滤波器在整个特征图上是共享的。因此，我们可以在不同大小的特征图上使用相同的过滤器。

我们将继续 PyTorch，在这里您可以选择是否要使用预训练模型(同样，自动下载):

```
import torchvision.models as models
model = models.vgg16(pretrained=True)
```

您可以尝试其他预训练模型，使用我们描述的相同程序。为了避免重复，我们不会在本节中包含其他架构的相同代码示例。

在下一节中，我们将讨论最流行的 CNN 架构之一，它是在 VGG 之后发布的。

<title>Understanding residual networks</title>

<link rel="stylesheet" href="css/style.css" type="text/css">

# 了解剩余网络

残差网络(**resnet**、*用于图像识别的深度残差学习*、[https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385))于 2015 年发布，当时他们赢得了当年 ImageNet 挑战赛的所有五个类别。在[第 1 章](b94f711b-daab-4de7-97b7-b7efccd0b392.xhtml)、*神经* *网络的具体细节*中，我们提到了神经网络的层不限于顺序，而是形成一个图。这是我们将要学习的第一个架构，它利用了这种灵活性。这也是第一个成功训练出深度超过 100 层网络的网络架构。

由于更好的权重初始化、新的激活函数以及标准化层，现在可以训练深度网络。但是，该论文的作者进行了一些实验，并观察到具有 56 层的网络比具有 20 层的网络具有更高的训练和测试误差。他们认为情况不应该如此。理论上，我们可以采用一个浅层网络，并在其上堆叠身份层(这些层的输出只是重复输入)，以产生一个更深的网络，其行为与浅层网络完全相同。然而，他们的实验无法与浅层网络的性能相匹配。

为了解决这个问题，他们提出了一种由剩余块构成的网络。一个残差块由两个或三个顺序卷积层和一个单独的并行标识(中继器)快捷连接组成，它连接第一层的输入和最后一层的输出。我们可以在下面的截图中看到三种类型的残留块:

![](assets/9629b25c-e912-469b-83c7-9d1f4058a249.png)

从左至右:原始残差块；原始瓶颈剩余块；预激活剩余块；预激活瓶颈剩余块

每个块有两条平行的路径。左边的路径类似于我们见过的其他网络，由顺序卷积层+批量归一化组成。右侧路径包含标识快捷连接(也称为跳过连接)。这两条路径通过逐元素求和来合并。也就是说，左右张量具有相同的形状，并且第一张量的元素被添加到第二张量中相同位置的元素。输出是与输入形状相同的单个张量。实际上，我们向前传播该模块学习的特征，但也传播原始的未修改的信号。通过这种方式，我们可以更接近作者描述的原始场景。由于跳过连接，网络可以决定跳过一些卷积层，实际上减少了它自己的深度。残余块以块的输入和输出具有相同尺寸的方式使用填充。由于这一点，我们可以将任意数量的块堆叠成任意深度的网络。

现在，让我们看看图中的模块有何不同:

*   第一块包含两个 3×3 卷积层。这是原始的残差块，但是如果层很宽，堆叠多个块在计算上变得昂贵。
*   第二个块相当于第一个，但是它使用了所谓的瓶颈层。首先，我们使用 1×1 卷积对输入体积深度进行下采样(我们在[第 2 章](d94e220f-820e-40da-8bb5-9593e0790b21.xhtml)、*了解卷积网络*中讨论了这一点)。然后，我们对减少的输入应用 3×3(瓶颈)卷积。最后，我们用另一个 1×1 卷积将输出扩展回所需深度。这一层比第一层计算量少。
*   第三块是该想法的最新修订版，由相同的作者于 2016 年发表(*深度剩余网络中的身份映射*、【https://arxiv.org/abs/1603.05027】)。它使用预激活，批量归一化和激活函数在卷积层之前。这乍一看似乎很奇怪，但是由于这种设计，跳过连接路径可以在整个网络中不间断地运行。这与其它剩余块相反，在其它剩余块中，至少一个激活功能在跳过连接的路径上。堆叠的剩余块的组合仍然具有正确顺序的层。
*   第四个块是第三层的瓶颈版本。它遵循与瓶颈剩余层 v1 相同的原理。

在下表中，我们可以看到该论文作者提出的网络家族:

![](assets/3bf80ec8-ffb0-4f87-964a-3db43e6b09d0.png)

最受欢迎的剩余网络家族。残余块由圆角矩形表示

它们的一些属性如下:

*   它们从跨度为 2 的 7×7 卷积层开始，然后是 3×3 最大池。该层也用作缩减采样步骤-网络的其余部分从 56×56 的小得多的切片开始，而不是从 224×224 的输入开始。
*   网络其余部分的下采样是用步长为 2 的修改后的残差块来实现的。
*   平均池在所有残差块之后和 1，000 单位完全连接的 softmax 图层之前对输出进行缩减采样。

ResNet 系列网络之所以受欢迎，不仅因为它们的精确性，还因为它们的相对简单性和残差块的多功能性。正如我们提到的，由于填充，残差块的输入和输出形状可以是相同的。我们可以以不同的配置堆叠残差块，以解决具有大范围训练集大小和输入维数的各种问题。由于这种普遍性，我们将在下一节实现一个 ResNet 示例。

<title>Implementing residual blocks</title>

<link rel="stylesheet" href="css/style.css" type="text/css">

# 实现残差块

在本节中，我们将使用 PyTorch 1.3.1 和`torchvision` 0.4.2 实现一个预激活 ResNet 来对 CIFAR-10 图像进行分类。让我们开始:

1.  像往常一样，我们将从进口开始。注意，我们将使用 PyTorch 功能模块的简写`F`([https://pytorch.org/docs/stable/nn.html#torch-nn-functional](https://pytorch.org/docs/stable/nn.html#torch-nn-functional)):

```
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
from torchvision import transforms
```

2.  接下来，让我们定义预激活常规(非瓶颈)剩余块。我们将把它实现为`nn.Module`——所有神经网络模块的基类。让我们从类定义和`__init__`方法开始:

```
class PreActivationBlock(nn.Module):
    expansion = 1
    def __init__(self, in_slices, slices, stride=1):
        super(PreActivationBlock, self).__init__()

        self.bn_1 = nn.BatchNorm2d(in_slices)

                                out_channels=slices,kernel_size=3, 
                                stride=stride, padding=1,
                                bias=False)

        self.bn_2 = nn.BatchNorm2d(slices)
        self.conv_2 = nn.Conv2d(in_channels=slices, 
                                out_channels=slices,kernel_size=3, 
                                stride=1, padding=1,
                                bias=False)

        # if the input/output dimensions differ use convolution for 
        the shortcut
        if stride != 1 or in_slices != self.expansion * slices:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels=in_slices,
                          out_channels=self.expansion * slices,
                          kernel_size=1,
                          stride=stride,
                          bias=False)
            )
```

我们将在`__init__`方法中只定义可学习的块组件——包括卷积和批量标准化操作。另外，请注意我们实现`shortcut`连接的方式。如果输入维数与输出维数相同，我们可以直接用输入张量作为捷径。然而，如果维度不同，我们必须借助 1×1 卷积来转换输入，其步长和输出通道与主路径中的通道相同。尺寸可能因高度/宽度(`stride != 1`)或深度(`in_slices != self.expansion * slices`)而不同。`self.expansion`是一个超参数，包含在最初的 ResNet 实现中。它允许我们扩展残差块的输出深度。

3.  实际的数据传播是在`forward`方法中实现的(请注意缩进，因为它是`PreActivationBlock`的成员):

```
def forward(self, x):
    out = F.relu(self.bn_1(x))

    # reuse bn+relu in downsampling layers
    shortcut = self.shortcut(out) if hasattr(self, 'shortcut')
    else x

    out = self.conv_1(out)

    out = F.relu(self.bn_2(out))
    out = self.conv_2(out)

    out += shortcut

    return out
```

我们使用函数`F.relu`作为激活函数，因为它没有可学习的参数。然后，如果快捷连接是一个卷积而不是一个恒等式(也就是说，块的输入/输出维度不同)，我们将重用`F.relu(self.bn_1(x))`为快捷连接添加非线性和批量标准化。否则，我们就重复输入。

4.  然后，让我们实现剩余块的瓶颈版本。我们将使用与非瓶颈实现中相同的蓝图。我们将从类定义和`__init__`方法开始:

```
class PreActivationBottleneckBlock(nn.Module):
    expansion = 4
    def __init__(self, in_slices, slices, stride=1):
        super(PreActivationBottleneckBlock, self).__init__()

        self.bn_1 = nn.BatchNorm2d(in_slices)
        self.conv_1 = nn.Conv2d(in_channels=in_slices, 
                                out_channels=slices, kernel_size=1,
                                bias=False)

        self.bn_2 = nn.BatchNorm2d(slices)
        self.conv_2 = nn.Conv2d(in_channels=slices, 
                                out_channels=slices, kernel_size=3, 
                                stride=stride, padding=1,
                                bias=False)

        self.bn_3 = nn.BatchNorm2d(slices)
        self.conv_3 = nn.Conv2d(in_channels=slices,
                                out_channels=self.expansion * 
                                slices,
                                kernel_size=1,
                                bias=False)

        # if the input/output dimensions differ use convolution for the shortcut
        if stride != 1 or in_slices != self.expansion * slices:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels=in_slices,
                          out_channels=self.expansion * slices,
                          kernel_size=1, stride=stride,
                          bias=False)
            )
```

`expansion`参数是最初实现后的`4`。`self.conv_1`卷积运算代表 1×1 下采样瓶颈连接，`self.conv_2`是实际卷积，`self.conv_3`是上采样 1×1 卷积。快捷机制遵循与`PreActivationBlock`相同的逻辑。

5.  接下来，让我们实现`PreActivationBottleneckBlock.forward`方法。同样，它遵循与`PreActivationBlock`中相同的逻辑:

```
def forward(self, x):
    out = F.relu(self.bn_1(x))

    #  reuse bn+relu in downsampling layers
    shortcut = self.shortcut(out) if hasattr(self, 'shortcut') 
    else x

    out = self.conv_1(out)

    out = F.relu(self.bn_2(out))
    out = self.conv_2(out)

    out = F.relu(self.bn_3(out))
    out = self.conv_3(out)

    out += shortcut

    return out
```

6.  接下来，我们来实现残网本身。我们将从类定义(它继承了`nn.Module`)和`__init__`方法开始:

```
class PreActivationResNet(nn.Module):
    def __init__(self, block, num_blocks, num_classes=10):
        """
        :param block: type of residual block (regular or 
        bottleneck)
        :param num_blocks: a list with 4 integer values.
            Each value reflects the number of residual blocks in 
            the group
        :param num_classes: number of output classes
        """

        super(PreActivationResNet, self).__init__()

        self.in_slices = 64

        self.conv_1 = nn.Conv2d(in_channels=3, out_channels=64,
                                kernel_size=3, stride=1, padding=1,
                                bias=False)

        self.layer_1 = self._make_group(block, 64, num_blocks[0], 
        stride=1)
        self.layer_2 = self._make_group(block, 128, num_blocks[1], 
        stride=2)
        self.layer_3 = self._make_group(block, 256, num_blocks[2], 
        stride=2)
        self.layer_4 = self._make_group(block, 512, num_blocks[3], 
        stride=2)
        self.linear = nn.Linear(512 * block.expansion, num_classes)
```

该网络包含四组残差块，就像原始实现一样。每组的块数由`num_blocks`参数指定。初始卷积使用步长为 1 的 3×3 滤波器，而不是最初实现中步长为 2 的 7×7 滤波器。这是因为 32×32 CIFAR-10 图像比 224×224 ImageNet 图像小得多，并且不需要向下采样。

7.  然后，我们将实现`PreActivationResNet._make_group`方法，创建一个剩余块组。该组中的所有模块的步幅为 1，除了第一个模块，其中`stride`作为参数提供:

```
def _make_group(self, block, slices, num_blocks, stride):
    """Create one residual group"""

    strides = [stride] + [1] * (num_blocks - 1)
    layers = []
    for stride in strides:
        layers.append(block(self.in_slices, slices, stride))
        self.in_slices = slices * block.expansion

    return nn.Sequential(*layers)
```

8.  接下来，我们将实现`PreActivationResNet.forward`方法，该方法通过网络传播数据。在完全连接的最终图层之前，我们可以看到缩减采样平均池:

```
def forward(self, x):
    out = self.conv_1(x)
    out = self.layer_1(out)
    out = self.layer_2(out)
    out = self.layer_3(out)
    out = self.layer_4(out)
    out = F.avg_pool2d(out, 4)
    out = out.view(out.size(0), -1)
    out = self.linear(out)

    return out
```

9.  一旦我们完成了网络，我们可以实现几个 ResNet 配置。以下是具有 34 个卷积层的`ResNet34`，分组在`[3, 4, 6, 3]`个非瓶颈剩余块中:

```
def PreActivationResNet34():
    return PreActivationResNet(block=PreActivationBlock,
                               num_blocks=[3, 4, 6, 3])
```

10.  最后，我们可以训练网络。我们将从定义训练和测试数据集开始。我们不会深入讨论实施细节，因为我们已经在[第 2 章](d94e220f-820e-40da-8bb5-9593e0790b21.xhtml)、*了解卷积网络*中讨论过类似的场景。我们将通过用四个像素填充样本来扩充训练集，然后我们将从中随机抽取 32×32 的裁剪。以下是实现:

```
# training data transformation
transform_train = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4821, 0.4465), (0.2470, 0.2435, 
    0.2616))
])

# training data loader
train_set = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, 
                                        transform=transform_train)

train_loader = torch.utils.data.DataLoader(dataset=train_set, 
                                        batch_size=100,
                                        shuffle=True, 
                                        num_workers=2)

# test data transformation
transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4821, 0.4465), (0.2470, 0.2435, 
    0.2616))
])

# test data loader
testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                        download=True, 
                                        transform=transform_test)

test_loader = torch.utils.data.DataLoader(dataset=testset, 
                                        batch_size=100,
                                        shuffle=False,
                                        num_workers=2)
```

11.  然后，我们将实例化网络模型和训练参数—交叉熵损失和 Adam 优化器:

```
# load the pretrained model
model = PreActivationResNet34()

# select gpu 0, if available
# otherwise fallback to cpu
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# transfer the model to the GPU
model = model.to(device)

# loss function
loss_function = nn.CrossEntropyLoss()

# We'll optimize all parameters
optimizer = optim.Adam(model.parameters())
```

12.  我们现在可以为`EPOCHS`时代训练网络。`train_model`、`test_model`和`plot_accuracy`函数与我们在[第二章](d94e220f-820e-40da-8bb5-9593e0790b21.xhtml)、*理解卷积网络*的*用 PyTorch 实现迁移学习*一节中定义的函数相同，在此不再赘述。以下是代码:

```
# train
EPOCHS = 15

test_acc = list()  # collect accuracy for plotting
for epoch in range(EPOCHS):
    print('Epoch {}/{}'.format(epoch + 1, EPOCHS))

    train_model(model, loss_function, optimizer, train_loader)
    _, acc = test_model(model, loss_function, test_loader)
    test_acc.append(acc)

plot_accuracy(test_acc)
```

并且，在下图中，我们可以看到 15 次迭代中的测试准确性(训练可能需要一段时间):

![](assets/ace8fd47-9786-401b-87fc-75cc65bba7e9.png)

15 个时期内的 ResNet34 CIFAR 精度

The code in this section is partially based on the pre-activation ResNet implementation in [https://github.com/kuangliu/pytorch-cifar](https://github.com/kuangliu/pytorch-cifar).

在本节中，我们讨论了各种类型的 ResNets，然后用 PyTorch 实现了一个。在下一节中，我们将讨论盗梦网络——又一个网络家族，它将并行连接的使用提升到了一个新的水平。

<title>Understanding Inception networks</title>

<link rel="stylesheet" href="css/style.css" type="text/css">

# 理解初始网络

Inception networks ( *用卷积更深入*，[https://arxiv.org/abs/1409.4842](https://arxiv.org/abs/1409.4842))于 2014 年推出，当时他们赢得了当年的 ImageNet 挑战赛(这里似乎有一个模式)。从那以后，作者发布了该架构的多个改进(版本)。

有趣的事实:盗梦空间这个名字部分来自于**我们需要更深入的**互联网迷因，与电影*盗梦空间*有关。

Inception networks 背后的想法始于一个基本前提，即图像中的对象具有不同的比例。远处的物体可能会占据图像的一小部分，但同样的物体一旦靠近，可能会占据图像的大部分。这给标准的 CNN 带来了困难，在标准的 CNN 中，不同层中的神经元具有施加在输入图像上的固定感受野大小。一个规则的网络可能是一个很好的特定尺度的物体探测器，但在其他情况下可能会错过它们。为了解决这个问题，论文的作者提出了一种新的体系结构:由初始块组成的体系结构。一个先启块从一个公共输入开始，然后将它分成不同的并行路径(或者塔)。每条路径要么包含具有不同大小过滤器的卷积层，要么包含汇集层。这样，我们对相同的输入数据应用不同的感受野。在初始块的末尾，不同路径的输出被连接起来。在接下来的几节中，我们将讨论初始网络的不同变体。

<title>Inception v1</title>

<link rel="stylesheet" href="css/style.css" type="text/css">

# 盗梦空间 v1

下图显示了 Inception block 的第一个版本，它是 GoogLeNet 网络架构的一部分([https://arxiv.org/abs/1409.4842](https://arxiv.org/abs/1409.4842))。GoogLeNet 包含九个这样的初始模块:

![](assets/532d7c33-b7ba-4743-a7f2-c44ef6b9c4e5.png)

《盗梦空间》v1 区块，灵感来自 https://arxiv.org/abs/1409.4842

v1 模块有四条路径:

*   1×1 卷积，相当于输入的中继器
*   1×1 卷积，然后是 3×3 卷积
*   1×1 卷积，然后是 5×5 卷积
*   步幅为 1 的 3×3 最大池

块中的层使用填充，使得输入和输出具有相同的形状(但深度不同)。填充也是必要的，因为每个路径会产生不同形状的输出，这取决于过滤器的大小。这对于所有版本的初始块都是有效的。

该初始模块的另一项主要创新是使用 1×1 下采样卷积。它们是必需的，因为所有路径的输出被连接起来以产生块的最终输出。连接的结果是具有四倍深度的输出。如果另一个 Inception 块跟随当前块，其输出深度将再次增加四倍。为了避免这种指数增长，该模块使用 1×1 卷积来减少每个路径的深度，从而减少模块的输出深度。这使得在不耗尽资源的情况下创建更深层次的网络成为可能。

GoogLeNet 还利用辅助分类器——也就是说，它在不同的中间层有两个额外的分类输出(具有相同的基本事实标签)。在训练期间，损失的总值是辅助损失和真实损失的加权和。

<title>Inception v2 and v3</title>

<link rel="stylesheet" href="css/style.css" type="text/css">

# Inception v2 和 v3

Inception v2 和 v3 一起发布，并提出了对原始 Inception 块的几项改进(*重新思考计算机视觉的 Inception 架构*、【https://arxiv.org/abs/1512.00567】和)。第一个是将 5×5 卷积分解成两个堆叠的 3×3 卷积。我们在*视觉几何组简介*部分讨论了这种方法的优势。

我们可以在下图中看到新的先启块:

![](assets/26826db8-c95e-41ee-a113-970221a8668e.png)

受 https://arxiv.org/abs/1512.00567 启发的《盗梦空间 A》

下一个改进是将一个 *n* × *n* 卷积分解成两个堆叠的非对称 1× *n* 和 *n* ×1 卷积。例如，我们可以将一个 3×3 卷积分成两个 1×3 和 3×1 卷积，其中 3×1 卷积应用于 1×3 卷积的输出。在第一种情况下，滤波器大小为 3*3 = 9，而在第二种情况下，我们的组合大小为(3*1) + (1*3) = 3 + 3 = 6，效率为 33%，如下图所示:

![](assets/023a33c1-b7ee-4535-ab68-18ab39d21038.png)

3×3 卷积在 1×3 和 3×1 卷积中的因式分解。受 https://arxiv.org/abs/1512.00567 的启发

作者介绍了两种新的利用因子分解卷积的模块。这些块中的第一个(总共是第二个)相当于初始块 A:

![](assets/43e66db9-3ccb-4855-b1df-0890467a8f60.png)

盗梦空间 b .当 n=3 时，相当于 a .灵感来自 https://arxiv.org/abs/1512.00567

第二个(总共第三个)块类似，但不对称卷积是平行的，导致更高的输出深度(更多的级联路径)。这里的假设是，网络的特征(不同的过滤器)越多，它学习的速度就越快(我们也在第二章、*了解卷积网络*中讨论了对更多过滤器的需求)。另一方面，较宽的层需要更多的内存和计算时间。作为一种折衷，此块仅用于网络的深层部分，位于其他块之后:

![](assets/e74a4669-e728-4122-ad8d-a5607c4ba63e.png)

受 https://arxiv.org/abs/1512.00567 启发的盗梦空间 C 座

使用这些新的模块，作者提出了两个新的初始网络:v2 和 v3。这个版本的另一个主要改进是使用了批处理规范化，它是由相同的作者引入的。

<title>Inception v4 and Inception-ResNet</title>

<link rel="stylesheet" href="css/style.css" type="text/css">

# 盗梦空间 v4 和盗梦空间 ResNet

在 Inception networks 的最新版本中，作者介绍了三个新的精简的 Inception blocks，它们建立在以前版本的想法之上( *Inception-v4，Inception-ResNet 和剩余连接对学习的影响*，【https://arxiv.org/abs/1602.07261】)。他们引入了 7×7 非对称因子分解卷积，以及平均池而不是最大池。更重要的是，他们创建了一个称为 Inception-ResNet 的剩余/初始混合网络，其中的初始块也包括剩余连接。我们可以在下图中看到这样一个模块的示意图:

![](assets/c073e89b-8b95-4fb6-b486-aaa22c26193b.png)

具有剩余跳过连接的启始块

在这一部分中，我们讨论了不同类型的初始网络以及在不同的初始块中使用的不同原则。接下来，我们将讨论一个更新的 CNN 架构，它将 Inception 概念带到了一个新的深度(或者宽度，就像它应该的那样)。

<title>Introducing Xception</title>

<link rel="stylesheet" href="css/style.css" type="text/css">

# 引入异常

到目前为止，所有的 Inception 块都是从将输入分成几个并行的路径开始的。每条路径继续进行降维 1×1 跨通道卷积，然后是常规跨通道卷积。一方面，1×1 连接映射跨通道相关性，而不是空间相关性(因为 1×1 滤波器大小)。另一方面，随后的跨通道卷积映射两种类型的相关性。让我们回忆一下，在[第二章](d94e220f-820e-40da-8bb5-9593e0790b21.xhtml)、*理解卷积网络*中，我们介绍了**深度可分卷积** ( **DSC** )，它结合了以下两种运算:

*   **深度方向卷积**:在深度方向卷积中，单个输入切片产生单个输出切片，因此它只映射空间(而不是跨通道)相关性。
*   **1×1 跨通道卷积**:对于 1×1 卷积，我们有相反的情况，即它们只映射跨通道相关。

Xception(*Xception:Deep Learning with depth wise Separable Convolutions*，【https://arxiv.org/abs/1610.02357】)的作者认为，事实上，我们可以将 DSC 视为一个 Inception 块的极端(因此得名)版本，其中每个深度方向的输入/输出片对代表一个并行路径。我们有和输入切片一样多的并行路径。下图显示了一个简化的先启块及其到异常块的转换:

![](assets/41ef8798-793d-4b06-8b80-d4fd09bf4d0c.png)

左图:简化的初始模块。右:异常块。受 https://arxiv.org/abs/1610.02357 的启发

异常模块和 DSC 有两个不同之处:

*   除此之外，1×1 卷积优先进行，而不是像 DSC 那样最后进行。但是，这些操作无论如何都是要堆叠在一起的，我们可以假设顺序并不重要。
*   Xception 模块在每次卷积后使用 ReLU 激活，而 DSC 在跨通道卷积后不使用非线性。根据作者的实验，没有非线性深度方向卷积的网络收敛更快且更准确。

下图描述了例外网络的架构:

![](assets/c75638b5-9f2a-4871-874c-c3013d8f80ee.png)

从左至右:入口流；中流，重复八次；退出流程。资料来源:https://arxiv.org/abs/1610.02357

它由线性堆叠的 DSC 构成，其一些特性如下:

*   该网络包含 36 个卷积层，构造成 14 个模块，除了第一个和最后一个模块之外，所有模块周围都有线性剩余连接。这些模块分为三个连续的虚拟流—入口、中间和出口。
*   在入口和出口流中使用 3×3 最大池的下采样；中间流没有下采样；完全连接层之前的全局平均池。
*   所有卷积和 DSC 之后都是批处理规范化。
*   所有 DSC 的深度乘数都为 1(无深度扩展)。

这一部分总结了一系列基于先启的模型。在下一节中，我们将关注一个特殊的模型，它优先考虑小的内存占用和计算效率。

<title>Introducing MobileNet</title>

<link rel="stylesheet" href="css/style.css" type="text/css">

# MobileNet 简介

在本节中，我们将讨论一个名为 MobileNet 的轻量级 CNN 模型( *MobileNetV2:反向残差和线性瓶颈*、【https://arxiv.org/abs/1801.04381】和)。我们将重点关注这个想法的第二个版本(MobileNetV1 是在 *MobileNets:用于移动视觉应用的高效卷积神经网络*、[https://arxiv.org/abs/1704.04861](https://arxiv.org/abs/1704.04861)中介绍的)。

MobileNet 的目标是内存和计算能力有限的设备，比如移动电话(这个名字有点暴露了这一点)。为了减少足迹，网络使用 DSC、线性瓶颈和反向残差。

我们已经熟悉了 DSC，所以让我们讨论另外两个:

*   **线性瓶颈**:为了理解这个概念，我们引用这篇论文:

“考虑由 *n* 层*L[I]组成的深度神经网络，其中每一层都具有维度为 [![](assets/684623c0-9307-4ec3-9630-699e64599285.png)] 的激活张量。在本节中，我们将讨论这些激活张量的基本属性，我们将把它们视为尺寸为*d[I]的 [![](assets/d2c0077c-fecb-48f2-9e46-06527c760674.png)] 【像素】的容器。非正式地，对于真实图像的输入集合，我们说层激活集合(对于任何层*L[I])形成了“*感兴趣流形”*。长期以来，人们一直认为神经网络中感兴趣的流形可以嵌入到低维子空间中。换句话说，当我们查看深度卷积层的所有单个 *d* 通道像素时，这些值中编码的信息实际上位于某个流形中，可以嵌入到低维子空间中。”***

一种方法是使用 1×1 瓶颈卷积。但是，该论文的作者认为，如果这个卷积之后是 ReLU 这样的非线性，这可能会导致多种信息的丢失。如果 ReLU 输入大于 0，那么这个单元的输出就相当于输入的线性变换。但是，如果输入较小，则 ReLU 会折叠，并且该单元的信息会丢失。因此，MobileNet 使用 1×1 瓶颈卷积，无需非线性激活。

*   **反向残差**:在*残差网络*部分，我们引入了瓶颈残差块，其中非捷径路径的数据流为**输入- > 1×1 瓶颈 conv - > 3×3 conv - > 1×1 非抽样 conv** 。换句话说，它遵循一个**宽- >窄- >宽**的数据表示。作者认为*瓶颈实际上包含了所有必要的信息，而扩展层仅仅作为伴随张量的非线性变换的实现细节*。正因为如此，他们建议在瓶颈连接之间建立捷径连接。

基于这些属性，MobileNet 模型由以下构建块组成:

![](assets/f84ccba9-bb59-4d84-bcd9-3701fd3b9e62.png)

上图:步长为 1 的反向剩余块。下图:步幅 2 街区

该模型使用 ReLU6 非线性:ReLU6 = min(max(input，0)，6)。最大激活值限制为 6，这样，在低精度浮点计算中，非线性更加稳定。那是因为 6 最多可以取 3 位，剩下的留给数的浮点部分。

除了步幅之外，块由扩展因子 *t* 描述，该扩展因子确定瓶颈卷积的扩展比率。

下表显示了块的输入和输出尺寸之间的关系:

![](assets/deac5fcf-f98e-40f8-b066-5e2f656d142a.png)

输入和输出维度关系。来源:https://arxiv.org/abs/1801.04381

上表中， **h** 和 **w** 为输入高度和宽度， **s** 为步幅， **k** 和**k’**为通道的输入和输出数量。

最后，这是完整的模型架构:

![](assets/f4f0756c-e7fb-4b20-a32a-683e628747be.png)

MobileNetV2 架构。资料来源:https://arxiv.org/abs/1801.04381

每行描述一组一个或多个相同的块，重复 *n* 次。同一组中的所有层具有相同数量的输出通道 **c** 。每个序列的第一层都有一个步幅， **s** ，其他的都用步幅 1。所有空间卷积都使用 3 × 3 核。如上表所述，扩展因子 **t** 始终应用于输入尺寸。

我们将讨论的下一个模型是具有新型构造块的网络模型，其中所有层都是互连的。

<title>An introduction to DenseNets</title>

<link rel="stylesheet" href="css/style.css" type="text/css">

# DenseNets 简介

DenseNet ( *密集连接的卷积网络*，【https://arxiv.org/abs/1608.06993】)试图缓解消失梯度问题，改善特征传播，同时减少网络参数的数量。我们已经看到 ResNets 如何引入带有跳过连接的剩余块来解决这个问题。DenseNets 从这一想法中获得了一些灵感，并通过引入密集块而更进一步。密集块由连续的卷积层组成，其中任何一层都与所有后续层直接相连。换句话说，网络层 *l* 将从所有前面的网络层接收输入 **x** *[l]* :

![](assets/6c100639-f0e1-4f6e-8fd0-f7df5a9cacad.png)

这里，![](assets/72b34058-eb37-45f3-b58e-6714361f0560.png)是前面网络层的**连接的**输出特征图。这与 ResNets 不同，在 ResNets 中，我们使用元素式求和来组合不同的层。 *H [ l]*

![](assets/e47bdbbc-aaad-41b4-9371-2498f5bbe3c8.png)

密集块:降维层(虚线)是 DenseNet-B 架构的一部分，而 DenseNet-A 没有。不显示 DenseNet-C

让我们来定义它们:

*   **DenseNet-A** :这是基块，其中*H[l]由批量归一化、激活、3×3 卷积组成:*

![](assets/2934a1ea-ee3a-404e-8913-e08533fd1c18.png)

*   **DenseNet-B** :作者还介绍了第二种类型的密集块 DenseNet-B，它在每次连接后应用降维 1×1 卷积:

*![](assets/7f2113f2-433e-409a-bca9-51c15c338392.png)*

*   **DenseNet-C** :进一步修改，在每个密集块后增加一个下采样 1×1 卷积。B 和 C 的组合称为 DenseNet-BC。

一个密集的块由它的卷积层数和每层的输出体深度来指定，在这个上下文中称为**增长率**。假设密集块的输入有*k[0]的体深度，每个卷积层的输出体深度为 *k* 。然后，由于拼接，第 *l* 层的输入音量深度将是*k[0]+k[x](L1)*。尽管密集块的后面的层具有较大的输入体积深度(由于许多连接)，但是 DenseNets 可以使用低至 12 的增长率值，这减少了参数的总数。为了理解为什么会这样，让我们把特征图想象成网络的集体知识。每一层都将其自己的 *k* 特征图添加到该状态，增长率决定了该层贡献给它的信息量。由于这种密集的结构，全局状态可以从网络内的任何地方访问(因此有术语“全局”)。换句话说，不需要像在传统网络架构中那样从一层复制到下一层，这允许我们从较少数量的特征地图开始。*

为了使拼接成为可能，密集块使用填充，使得整个块中所有输出切片的高度和宽度都相同。但正因为如此，在密集块中不可能进行下采样。因此，密集网络由多个连续的密集块组成，由缩减采样池操作分隔。

该论文的作者提出了一个 DenseNets 系列，其整体架构类似于 ResNet:

![](assets/8eed3144-e67e-4370-ac24-9c13d1bdbcd1.png)

DenseNet 网络家族。资料来源:https://arxiv.org/abs/1608.06993

它们具有以下属性:

*   从 7×7 步长 2 下采样卷积开始。
*   步长为 2 的进一步下采样 3×3 最大池。
*   四组 DenseNet-B 嵌段。网络系列的不同之处在于每组中密集块的数量。
*   缩减采样由密集组之间跨度为 2 的 2×2 池化操作的过渡层处理。
*   过渡层进一步包含 1×1 瓶颈卷积，以减少特征图的数量。这个卷积的压缩比由一个超参数指定， *θ* ，其中*0*<*θ*≤*1*。如果输入特征图的数量是 *m* ，那么输出特征图的数量是 *θm.*
*   密集数据块最终形成一个 7×7 的全局平均池，后面是一个 1000 单元的完全连接的 softmax 层。

DenseNet 的作者还发布了一个改进的 DenseNet 模型，称为 MSDNet ( *多尺度密集网络用于资源高效的图像分类*、【https://arxiv.org/abs/1703.09844】)，它(顾名思义)使用多尺度密集块。

通过 DenseNet，我们结束了关于传统 CNN 架构的讨论。在下一节中，我们将讨论是否有可能将寻找最佳神经网络结构的过程自动化。

<title>The workings of neural architecture search</title>

<link rel="stylesheet" href="css/style.css" type="text/css">

# 神经结构搜索的工作原理

到目前为止，我们讨论的神经网络模型是由它们的作者设计的。但是，如果我们能让计算机自己设计神经网络呢？进入**神经架构搜索**(**NAS**)——一种自动设计神经网络的技术。

在我们继续之前，让我们看看网络体系结构由哪些部分组成:

*   代表网络的操作图。正如我们在[第一章](b94f711b-daab-4de7-97b7-b7efccd0b392.xhtml)、*神经网络的基本要素*中所讨论的，操作包括(但不限于)卷积、激活函数、全连接层、规范化等等。
*   每个操作的参数。例如，卷积参数包括:类型(跨通道、深度等)、输入维度、输入和输出切片数、跨距和填充。

在本节中，我们将讨论具有强化学习的基于梯度的 NAS(*具有强化学习的神经架构搜索*、【https://arxiv.org/abs/1611.01578】)。此时，我们将不讨论强化学习，而是将重点放在算法上。首先，我们可以将网络定义表示为一个字符串(一个令牌序列)。让我们假设我们将生成一个连续的 CNN，它只由卷积组成。

然后，字符串定义的一部分将如下所示:

![](assets/dd4ee96f-aa67-4c50-b853-a98045890dbd.png)

我们不必指定图层类型，因为我们只使用卷积。为了简单起见，我们排除了填充。为了清楚起见，第一行的下标文本被包含在内，但不会包含在算法版本中。

我们可以在下图中看到算法概述:

![](assets/9c0eb578-01b6-4814-881f-79cb79301681.png)

NAS 概述。资料来源:https://arxiv.org/abs/1611.01578

先说控制器。这是一个 RNN，其任务是生成新的网络架构。尽管我们还没有讨论 RNNs(这一荣誉要到第七章、*了解递归网络*才会到来)，我们还是会尝试解释它是如何工作的。在[第一章](b94f711b-daab-4de7-97b7-b7efccd0b392.xhtml)、*神经网络的基本要素*中，我们提到 RNN 维持一个内部状态——它之前所有输入的总结。基于该内部状态和最新的输入样本，网络生成新的输出，更新其内部状态，并等待下一个输入。

这里，控制器将生成描述网络架构的字符串序列。控制器输出是序列的单个令牌。这可能是过滤器高度/宽度、步幅宽度/高度或输出过滤器的数量。令牌的类型取决于当前生成的架构的长度。一旦我们有了这个令牌，我们就把它作为输入反馈给 RNN 控制器。然后，网络生成序列的下一个令牌。

下图描述了这一过程:

![](assets/36bb6544-b95c-41a3-879b-78160ed1fd28.png)

用 RNN 控制器生成网络架构。输出令牌作为输入反馈给控制器，以生成下一个令牌。资料来源:https://arxiv.org/abs/1611.01578

图中白色的垂直方块代表 RNN 控制器，由两层**长短期记忆** ( **LSTM** )细胞组成(沿*y*-轴)。尽管该图显示了 RNN 的多个实例(沿着 *x* 轴)，但它实际上是同一个网络；只是**在时间上展开**，来表示序列生成的过程。也就是说，沿着 *x* 轴的每一步代表网络定义的单个令牌。在步骤 *t* 的令牌预测由 softmax 分类器执行，然后在步骤 *t+1* 作为控制器输入。我们继续这个过程，直到生成的网络的长度达到某个值。最初，这个值很小(一个短网络)，但是随着训练的进行，它逐渐增加(一个更长的网络)。

为了更好地理解 NAS，让我们看一下算法的分步执行:

1.  控制器生成一个新的架构， *A* 。
2.  它建立并**训练**具有所述架构的新网络，直到它收敛。
3.  它在训练集的保留部分上测试新网络，并测量误差 *R* 。
4.  它利用这个误差来更新控制器参数，*θ[c]。由于我们的控制器是 RNN，这意味着训练网络和调整其权重。模型参数以减少未来架构的误差 *R* 的方式被更新。这是通过一种叫做强化的强化学习算法实现的，这超出了本节的范围。*
5.  它重复这些步骤，直到生成的网络的误差 *R* 低于某个阈值。

控制器可以生成带有一些限制的网络架构。正如我们在本节前面提到的，最严重的情况是生成的网络仅由卷积层组成。为了简化事情，每个卷积层自动包括批量归一化和 ReLU 激活。但是从理论上讲，控制器可以生成更复杂的体系结构和其他层，比如池化或规范化。我们可以通过在层类型的架构序列中添加额外的控制器步骤来实现这一点。

该论文的作者实现了一种技术，允许我们向生成的架构添加剩余的跳过连接。它与称为锚点的特殊类型的控制器步骤一起工作。层 *N* 的锚点具有基于内容的 sigmoids。一个 sigmoid *的输出 j (j = 1，2，3，...N-1)* 表示当前层具有到层 *j* 的剩余连接的概率。

修改后的控制器如下图所示:

![](assets/6365b957-b098-48ef-b4fc-95a9c8460a5c.png)

具有用于剩余连接的锚点的 RNN 控制器。资料来源:https://arxiv.org/abs/1611.01578

如果一个图层有多个输入图层，则所有输入将沿通道(深度)维度连接。跳过连接可能会给网络设计带来一些问题:

*   网络的第一个隐藏层(即未与任何其他输入层连接的层)使用输入图像作为输入层。
*   在网络的末端，所有没有被连接的层输出以最终的隐藏状态被连接，该隐藏状态被发送到分类器。
*   可能发生要连接的输出具有不同大小的情况。在这种情况下，较小的要素地图用零填充，以匹配较大的要素地图的大小。

在他们的实验中，作者使用了一个具有两层 LSTM 单元的控制器，每层有 35 个单元。对于每个卷积，控制器必须从值{1，3，5，7}中选择一个滤波器高度和宽度，以及{24，36，48，64}中的一个滤波器数量。此外，他们还进行了两组实验——一组实验允许控制者在{1，2，3}中选择步幅，另一组实验的步幅固定为 1。

一旦控制器生成架构，新的网络就在 CIFAR-10 数据集的 45，000 个图像上被训练 50 个时期。剩余的 5000 幅图像用于验证。在训练期间，控制器从 6 层的架构深度开始，然后每 1600 次迭代增加 2 层。表现最好的模型的验证精度为 3.65%。是用 800 个 12,800 个架构后发现的(哇！).计算要求如此之高的原因是，每一个新的网络都是从零开始训练的，只是为了产生一个精度值，然后可以用这个精度值来训练控制器。最近，新的 ENAS 算法(*通过参数共享*、[https://arxiv.org/abs/1802.03268](https://arxiv.org/abs/1802.03268)进行有效的神经架构搜索)使得通过在生成的模型之间共享权重来显著减少 NAS 的计算资源成为可能。

在下一节中，我们将讨论一种新型的神经网络，它试图克服我们到目前为止讨论过的 CNN 的一些局限性。

<title>Introducing capsule networks</title>

<link rel="stylesheet" href="css/style.css" type="text/css">

# 胶囊网络简介

胶囊网络(*胶囊之间的动态路由*、【https://arxiv.org/abs/1710.09829】和)被引入作为克服标准 CNN 的一些限制的方法。为了理解胶囊网络背后的思想，我们需要首先理解它们的局限性，这将在下一节中看到。

<title>The limitations of convolutional networks</title>

<link rel="stylesheet" href="css/style.css" type="text/css">

# 卷积网络的局限性

让我们从辛顿教授自己的一句话开始:

“卷积神经网络中使用的池操作是一个巨大的错误，它如此有效的事实是一场灾难。”

正如我们在[第二章](d94e220f-820e-40da-8bb5-9593e0790b21.xhtml)、*了解卷积网络*中提到的，CNN 是**平移不变**。让我们想象一张有脸的图片，位于图片的右半部分。平移不变性是指一个 CNN 非常擅长告诉我们图片中包含了人脸，但是它无法告诉我们人脸是在图像的左边还是右边。这种行为的罪魁祸首是池层。每个池层都引入了一点翻译不变性。例如，最大池路由仅转发一个输入神经元的激活，但后续层不知道路由哪个神经元。

通过堆叠多个汇集层，我们逐渐增加感受野的大小。但是，被检测的对象可能在新感受野的任何地方，因为没有一个汇集层传递这样的信息。因此，我们也增加了平移不变性。起初，这似乎是一件好事，因为最终的标签必须是平移不变的。但是，这带来了一个问题，因为 CNN 不能识别一个物体相对于另一个物体的位置。CNN 会将以下两个图像识别为一张脸，因为它们都包含脸的组成部分(鼻子、嘴和眼睛),而不管它们彼此的相对位置。

这也被称为**毕加索问题**，如下图所示:

![](assets/2b264a39-059f-4898-8bbc-b3d5b423b1ff.png)

卷积网络会将这两幅图像识别为一张脸

但是，这还不是全部。即使这张脸有不同的方向，CNN 也会感到困惑，例如，如果它被颠倒过来。克服这一点的一种方法是在训练期间增加数据(旋转)。但是，这只能说明网络的局限性。我们必须明确地显示不同方向的物体，并告诉 CNN，这实际上是同一个物体。

到目前为止，我们已经看到 CNN 丢弃了翻译信息(过渡不变性)，并且不理解对象的方向。在计算机视觉中，平移和定向的结合被称为**姿态**。姿势足以在坐标系中唯一地识别对象的属性。让我们用计算机图形来说明这一点。一个三维物体，比如一个立方体，完全由它的姿态和边长定义。将 3D 对象的表示转换为屏幕上的图像的过程称为渲染。只要知道它的姿势和立方体的边长，我们就可以从我们喜欢的任何角度渲染它。

因此，如果我们能够以某种方式训练网络来理解这些属性，我们就不必向它提供同一对象的多个增强版本。CNN 做不到这一点，因为它的内部数据表示不包含关于物体姿态的信息(只包含其类型)。相比之下，胶囊网络**保存了物体类型和姿态的信息**。因此，它们可以检测到可以相互转化的物体，这就是所谓的**等方差**。我们也可以把这想象成**反转图形**，也就是根据物体的渲染图像来重建物体的属性。

为了解决这些问题，论文的作者提出了一种新型的网络构建模块，称为**胶囊**，代替神经元。让我们在下一节讨论它。

<title>Capsules</title>

<link rel="stylesheet" href="css/style.css" type="text/css">

# 胶囊

胶囊的输出是矢量，而神经元的输出是标量值。胶囊输出向量具有以下含义:

*   向量的元素表示对象的姿态和其他属性。
*   向量的长度在(0，1)范围内，表示在该位置检测到特征的概率。提醒一下，向量的长度是 [![](assets/0164c9bd-513d-44ac-a282-cf9fc9a2293c.png)] ，其中 *v [ i ]* 是向量元素。

让我们考虑一个检测人脸的胶囊。如果我们开始在图像上移动一张脸，胶囊向量的值将会改变，以反映位置的变化。但是，它的长度会一直保持不变，因为脸的概率不随位置而变。

胶囊被组织在相互连接的层中，就像一个规则的网络。一层中的胶囊充当下一层中胶囊的输入。像 CNN 一样，浅层探测基本特征，深层将它们组合成更抽象和复杂的特征。但是现在，胶囊也传递位置信息，而不仅仅是探测到的物体。这允许更深层次的胶囊不仅分析特征的存在，而且分析它们的关系。例如，胶囊层可以检测嘴、脸、鼻子和眼睛。随后的胶囊层将不仅能够验证这些特征的存在，而且能够验证它们是否具有正确的空间关系。只有当这两个条件都为真时，后续层才能验证人脸是否存在。这是胶囊网络的高级概述。现在，让我们看看胶囊到底是如何工作的。

我们可以在下面的截图中看到一个胶囊的示意图:

![](assets/17593e60-cd8e-4ffd-8916-b875625f79c7.png)

胶囊

我们按以下步骤来分析一下:

1.  胶囊输入为输出向量， **u** *[1] ，* **u** *[2] ，...***u***[n]*，来自上一层的胶囊。
2.  我们将每个向量**u***I乘以其对应的权重矩阵 *W [ij]* ，产生**pred****fiction 向量**， [![](assets/af47eced-a6b2-4d2c-9b72-529fc22462c1.png)] 。权重矩阵 **W** 对来自前一层的胶囊的低级特征和当前层中的高级特征之间的空间和其他关系进行编码。例如，假设当前图层中的胶囊检测人脸，前一图层中的胶囊检测嘴( **u** *[ 1 ]* )、眼睛( **u** *[ 2 ]* )和鼻子( **u** *[ 3 ]* )。然后， [![](assets/b4c26187-9be6-4b8e-8eb0-bc91e7ad1715.png)] 就是脸部的预测位置，给定嘴的位置在哪里。同样， [![](assets/dcaec96e-5891-4d32-9a83-430790d1ff04.png)] 基于检测到的眼睛位置预测面部位置，而 [![](assets/309fb5d1-833a-4b43-b136-62fdd584760a.png)] 基于鼻子位置预测面部位置。如果所有三个较低级别的胶囊向量在同一位置上一致，则当前胶囊可以确信人脸确实存在。在这个例子中，我们只使用了位置，但是向量可以对特征之间的其他类型的关系进行编码，例如比例和方向。通过反向传播学习权重 **W** 。*

3.  接下来，我们将 [![](assets/2970c647-8b48-4b8e-960d-c8616516740c.png)] 向量乘以标量耦合系数 *c [ ij ]* 。除了权重矩阵之外，这些系数是一组独立的参数。它们存在于任何两个胶囊之间，并且指示哪个高级胶囊将从较低级胶囊接收输入。但是，与通过反向传播调整的权重矩阵不同，耦合系数是通过一个称为**动态路由**的过程在正向传递过程中动态计算的。我们将在下一节描述它。
4.  然后，我们对加权输入向量求和。该步骤类似于神经元中的加权和，但使用向量:

![](assets/ba2e77a3-d557-4965-a7cd-c66f0513762e.png)

5.  最后，我们将计算胶囊的输出， **v** *[j]* ，通过挤压矢量， **s** *[j]* 。在这种情况下，挤压意味着变换向量，使其长度在(0，1)范围内，而不改变其方向。如上所述，胶囊向量的长度表示检测到的特征的概率，并且在(0，1)范围内挤压它反映了这一点。为此，作者提出了一个新颖的公式:

![](assets/45aaa75e-ef3c-4427-8b4f-6ad373e78a0c.png)

现在我们知道了胶囊的结构，在下一节中，我们将描述计算不同层的胶囊之间的耦合系数的算法。也就是说，它们之间传递信号的机制。

<title>Dynamic routing</title>

<link rel="stylesheet" href="css/style.css" type="text/css">

# 动态路由

让我们描述计算耦合系数的动态路由过程，*c[ij]，如下图所示:*

![](assets/3433e46b-78fc-42f1-a1f8-d187d0824843.png)

动态路由示例。成组的点表示彼此一致的低级胶囊

我们有一个较低级别的胶囊， *I* ，它必须决定是否将其输出发送到两个较高级别的胶囊之一， *J* 和 *K* 。深色点和浅色点表示预测向量![](assets/52b505fd-dae9-4348-8af6-c50be798ceab.png)和![](assets/d8f4d069-59c4-418d-8641-0644a4c1a5c5.png)，这些预测向量 *J* 和 *K* 已经从其他较低级别的胶囊接收到。从 *I* 胶囊到 *J* 和 *K* 胶囊的箭头指向从 *I* 到 *J* 和 *K* 的![](assets/18952087-30c0-49a3-a1de-6641307e87f4.png)和![](assets/017be278-853c-4f1b-936c-0dfcbc6e49b3.png)预测向量。聚集的预测向量(较亮的点)表示在高级特征方面彼此一致的低级胶囊。例如，如果 *K* 胶囊描述了一张脸，那么聚类预测将指示较低级别的特征，例如嘴、鼻子和眼睛。相反，分散的(较暗的)点表示不同意。如果 *I* 胶囊预测车辆轮胎，它将与 *K* 中的群集预测不一致。

然而，如果 *J* 中的聚类预测表示诸如前灯、挡风玻璃或挡泥板之类的特征，那么 *I* 的预测将与它们一致。较低级别的胶囊有办法确定它们属于每个较高级别的胶囊的聚集组还是分散组。如果它们属于群集组，它们将增加与该胶囊的相应耦合系数，并将在该方向上发送它们的矢量。反之，如果他们落入分散群，系数会降低。

让我们用作者介绍的一步一步的算法将这些知识形式化:

1.  对于 *l* 层中的所有 *i* 胶囊和 *(l + 1)* 层中的 *j* 胶囊，我们将初始化 [![](assets/d0af0750-02cf-491b-9bcd-1965a7670f14.png)] ，其中 *b [ ij ]* 是一个临时变量，相当于 *c [ ij ]* 。所有*b[ij]的向量表示为**b**I*。在算法开始时， *i* 胶囊有均等的机会将其输出路由到 *(l + 1)* 层的任何胶囊。

2.  重复 *r* 次迭代，其中 *r* 为参数:
    1.  对于所有在 *l* 层的 *i* 胶囊: [![](assets/ac9bd249-5a93-4e77-9f99-f9583cef4ac8.png)] 。胶囊的所有输出耦合系数的总和*c[I]等于 1(它们具有概率性质)，因此是 softmax。*
    2.  对于 *(l + 1)* 层中的所有 *j* 胶囊: [![](assets/5c2be571-0a64-4f10-be1c-3c7574a40c67.png)] 。也就是说，我们将计算 *(l + 1)* 层的所有非挤压输出向量。
    3.  对于 *(l + 1)* 层中的所有 *j* 胶囊，我们将计算挤压矢量: [![](assets/c045dd46-4691-40a5-b186-a2ad864ccd04.png)] 。
    4.  对于 *l* 层的所有 *i* 胶囊， *(l + 1)* 层的 *j* 胶囊: [![](assets/022f06a1-e7e3-446a-bbf5-8c55e5f72cfa.png)] 。这里， [![](assets/3768d012-866d-44cb-8efd-bb6d3210fa24.png)] 是低级 *i* 胶囊的预测矢量和高级 *j* 胶囊矢量的输出矢量的点积。如果点积较高，则 *i* 胶囊与其他低级胶囊一致，后者将其输出路由至 *j* 胶囊，耦合系数增加。

作者最近发布了一个更新的动态路由算法，它使用了一种叫做期望最大化的聚类技术。可以在原论文中了解更多，*带 EM 路由的矩阵胶囊*(【https://ai.google/research/pubs/pub46653】[)。](https://ai.google/research/pubs/pub46653)

<title>The structure of the capsule network</title>

<link rel="stylesheet" href="css/style.css" type="text/css">

# 胶囊网络的结构

在本节中，我们将描述胶囊网络的结构，作者使用该网络对 MNIST 数据集进行分类。网络的输入是 28×28 MNIST 灰度图像，步骤如下:

1.  我们将从具有 256 个 9×9 滤波器、步距 1 和 ReLU 激活的单个卷积层开始。输出体积的形状为(256，20，20)。
2.  我们有另一个卷积层，具有 256 个 9×9 滤波器和步长 2。输出体积的形状为(256，6，6)。
3.  使用该层的输出作为第一个胶囊层的基础，称为`PrimaryCaps`。取(256，6，6)输出体积，并将其分成 32 个独立的(8，6，6)块。也就是说，32 个块中的每一个都包含八个 6×6 的切片。从每个切片中取一个具有相同坐标的激活值，并将这些值组合成一个向量。例如，我们可以获取片 1 的 activation (3，7)，片 2 的 activation(3，7)，等等，并将它们组合成长度为 8 的向量。我们会有 36 个这样的向量。然后，我们将**将每个矢量**转换成一个胶囊，总共 36 个胶囊。`PrimaryCaps`层输出体积的形状为(32，8，6，6)。

4.  第二个胶囊层叫做`DigitCaps`。它包含 10 个胶囊(每个数字一个)，其输出是长度为 16 的向量。`DigitCaps`层输出体积的形状为(10，16)。在推断过程中，我们计算每个`DigitCaps`胶囊向量的长度。然后，我们将具有最长向量的胶囊作为网络的预测结果。
5.  在训练期间，网络在`DigitCaps`之后包括三个额外的全连接层，最后一层有 784 个神经元(28×28)。在前向训练过程中，最长的胶囊向量用作这些层的输入。他们试图从这个向量开始重建原始图像。然后，将重建的图像与原始图像进行比较，其差异用作反向传递的附加正则化损失。

胶囊网络是计算机视觉的一种新的有前途的方法。然而，它们还没有被广泛采用，在本书讨论的任何深度学习库中都没有正式的实现，但你可以找到多个第三方实现。

<title>Summary</title>

<link rel="stylesheet" href="css/style.css" type="text/css">

# 摘要

在这一章中，我们讨论了一些流行的 CNN 架构:我们从经典的，AlexNet 和 VGG 开始。然后，我们特别关注 ResNets，它是最著名的网络架构之一。我们还讨论了初始网络的各种体现以及与之相关的 Xception 和 MobileNetV2 模型。我们还谈到了令人兴奋的神经结构搜索的新领域。最后，我们讨论了胶囊网络——一种新型的 CV 网络，它试图克服 CNN 的一些固有限制。

我们已经在[第 2 章](d94e220f-820e-40da-8bb5-9593e0790b21.xhtml)、*了解卷积网络*中看到了如何应用这些模型，其中我们在分类任务的迁移学习场景中使用了 ResNet 和 MobileNet。在下一章，我们将会看到如何将它们应用到更复杂的任务中，比如物体检测和图像分割。