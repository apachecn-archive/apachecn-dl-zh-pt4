<title>Emerging Neural Network Designs</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# 新兴神经网络设计

在这一章中，我们将看看一些新兴的**神经网络** ( **NN** )设计。它们还没有达到成熟，但对未来有潜力，因为它们试图解决现有 DL 算法中的基本限制。如果有一天，这些技术中的任何一项被证明是成功的，并对实际应用有用，我们可能会向人工智能更近一步。

我们需要记住的一件事是结构化数据的本质。到目前为止，在本书中，我们一直关注于处理图像或文本——换句话说，非结构化数据。这不是巧合，因为神经网络擅长于在像素或文本序列的组合中寻找结构这一看似复杂的任务。另一方面，当涉及结构化数据(如社交网络图或大脑连接)时，ML 算法(如梯度增强树或随机森林)的性能似乎与 NNs 不相上下，甚至更好。在这一章中，我们将介绍图形神经网络来处理任意结构的图形。

另一个神经网络的局限性表现在**递归网络** ( **RNNs** )。理论上，这些是最强大的神经网络模型之一，因为它们是图灵完全的，这意味着 RNN 理论上可以解决任何计算问题。实际情况往往不是这样。RNNs(甚至是 T4 的长期短期记忆系统 T5，LSTM 的 T7)也很难在更长的时间内携带信息。一种可能的解决方案是用外部可寻址存储器来扩展 RNN。我们将在本章中探讨如何做到这一点。

本章的主题并没有脱离本书的其他主题。事实上，我们将会看到，我们要研究的新网络架构基于我们已经介绍过的许多算法。这些包括卷积、rnn 和注意力模型，以及其他模型。

本章将涵盖以下主题:

*   图形神经网络简介
*   介绍内存增强的神经网络

<title>Introducing Graph NNs</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# 图形神经网络简介

在了解**图 NNs** ( **GNNs** 之前，我们先来看看为什么我们需要图网络。我们首先定义一个图，它是一组对象(也称为**节点**或**顶点**)，其中一些对象对之间有连接(或**边**)。

In this section, we'll use several survey papers as resources, most notably *A* *Comprehensive Survey on Graph Neural Networks* ([https://arxiv.org/abs/1901.00596](https://arxiv.org/abs/1901.00596)), which contains some quotes and images.

图形具有以下属性:

*   我们将把图表示为![](assets/40da6b62-68d7-4d59-9247-d8e142246f89.png)，其中 *V* 是节点的集合， *E* 是边的集合。
*   表达式![](assets/88ec490a-336a-4f32-b501-138e471e5801.png)描述了两个节点![](assets/46829fd0-f93c-4710-909c-612208907d50.png)之间的边。
*   邻接矩阵![](assets/2bd7df0f-0b56-4b25-aef4-9c8855ffcc90.png)，其中 *n* 是图节点的数量。如果边缘![](assets/96f0fb9d-25e2-4d01-bdcc-8bb2f14baa86.png)存在，则写为![](assets/f3dd7e83-f3cd-4074-9873-d75fac7463d8.png)，如果不存在，则写为![](assets/d6be8b1c-c944-47bc-9051-aab6d6c44840.png)。
*   当边有方向时，图可以是**有向的**，当边没有方向时，图可以是**无向的**。无向图的邻接矩阵是对称的——这就是![](assets/8a2dc410-555b-4395-a48d-6034f07430d0.png)。有向图的邻接矩阵是不对称的——也就是![](assets/0e4b2a68-8374-496e-b3ef-90c570166d30.png)。
*   图可以是**循环的**或**非循环的**。顾名思义，循环图包含至少一个循环，它是一个非空的节点路径，其中只有第一个和最后一个节点是相同的。非循环图不包含循环。
*   图的边和节点都可以有相关的属性，称为特征向量。我们将用![](assets/0f8228cc-225b-44df-bd68-1449db642346.png)来表示节点 *v* 的 *d* 维特征向量。如果一个图有 *n* 个节点，我们可以把它们表示成一个矩阵![](assets/1c5fd1ea-48cd-43c1-854d-e7b081d2ea18.png)。同理，每个边属性都是一个 *c* 维特征向量，表示为![](assets/500c1356-80bc-4683-8bc8-afb9b4cd5109.png)，其中 *v* 和 *u* 为节点。我们可以将一个图的边属性集合表示为一个矩阵![](assets/f22c4803-7135-40dc-ae0e-d6ab74e68ee5.png)。

下图显示了一个有五个节点的有向图及其相应的邻接矩阵:

![](assets/4859621a-c3d2-4895-a357-11a006dfefe6.png)

Directed graph with five nodes and its corresponding ![](assets/e6a20be5-c2c0-46cf-82ef-5b766a62dc65.png) adjacency matrix

图是一种通用的数据结构，非常适合在许多现实世界场景中组织数据的方式。以下是示例的非穷尽列表:

*   我们可以用图来表示社交网络中的用户(节点)和他们的朋友群(边)。事实上，这就是脸书对他们的社交图所做的(*剖析脸书社交图，*【https://arxiv.org/abs/1111.4503】)。
*   我们可以把一个分子表示成一个图形，其中节点是原子，边是它们之间的化学键。
*   我们可以将街道网络(一个经典的例子)表示为图形，其中街道是边，它们的交叉点是节点。
*   在在线商务中，我们可以将用户和商品表示为节点，将它们之间的关系表示为边。

接下来，让我们讨论可以用图解决的任务类型。它们大致分为三类:

*   **节点聚焦**:单个节点的分类和回归。例如，在著名的扎卡里空手道俱乐部问题(【https://en.wikipedia.org/wiki/Zachary%27s_karate_club】)中，我们有许多空手道俱乐部成员(节点)和他们之间的友谊(边)。最初，俱乐部只有一名教练，所有成员在该教练的指导下集体训练。后来，俱乐部分成两个小组，有两个不同的教练。假设除了一个俱乐部成员之外的所有成员都选择加入两个组中的一个，目标是确定哪个组将选择最后一个未决定的成员(分类)，给定其与其他成员的友谊集。
*   **边缘聚焦**:图的单个边缘的分类和回归。例如，我们可以预测社交网络中的两个人互相认识的可能性有多大。换句话说，任务是确定两个图节点之间是否存在边。
*   **图聚焦**:全图分类回归。例如，给定一个用图形表示的分子，我们可以预测该分子是否有毒。

接下来，让我们概述一下 GNNs 的主要训练框架:

*   **监督**:所有训练数据都有标签。我们可以在节点、边和图形级别应用监督学习。
*   **无监督**:这里的目标是学习某种形式的图形嵌入——例如，使用自动编码器(我们将在本章后面讨论这个场景)。我们可以在节点、边和图形级别应用无监督学习。
*   **半监督**:这通常应用于节点级别，其中一些图节点被标记，而一些没有。半监督学习特别适合图形，因为我们可以做出简单(但通常是正确的)的假设，即相邻节点可能具有相同的标签。例如，假设我们有两个相邻的连接节点。其中一个包含汽车图像，另一个包含卡车图像。让我们假设卡车节点被标记为车辆，而汽车节点未被标记。我们可以安全地假设汽车节点也是一辆汽车，因为它靠近另一辆汽车节点(卡车)。在 GNNs 中，我们可以通过多种方式利用这个图形属性。我们将概述其中的两种(它们并不相互排斥):
    *   通过将图的邻接矩阵作为网络的输入来隐式地使用该属性。网络将施展魔法，并有希望推断出相邻节点可能具有相同的标签，从而由于附加信息而增加了预测的准确性。我们将在本章讨论的大多数 gnn 都使用这种机制。
    *   **标签传播**，我们可以使用带标签的节点作为种子，根据它们与带标签节点的接近程度，将标签分配给未带标签的节点。我们可以通过以下步骤以迭代的方式达到收敛:
        1.  从种子标签开始。
        2.  对于所有图形节点(种子节点除外)，根据其相邻节点的标签分配标签。该步骤为整个图创建新的标签配置，其中一些节点可能需要基于修改后的邻居标签的新标签。
        3.  如果满足收敛标准，则停止标签传播；否则，重复步骤 2。

我们将使用这个简短的图介绍作为下几节的基础，在下几节中，我们将讨论各种类型的图为中心的神经网络模型。GNN 竞技场相对较新，在计算机视觉领域，还没有类似于**卷积网络**(**CNN**)的完美模型。相反，我们有不同的模型和不同的属性。它们中的大多数都属于几个通用的类别，并且有人试图创建一个足够通用的框架来组合它们。这本书的目的不是发明新的模型或模型分类法，而是；相反，我们将向您介绍一些现有的。

<title>Recurrent GNNs</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# 复发性 GNNs

我们将从查看**图形神经网络** ( **图形神经网络**开始这一部分；参见【https://ieeexplore.ieee.org/document/4700287】**[)的图形神经网络模型。虽然论文的作者将模型缩写为 GNN，但我们将使用 GraphNN 缩写来指代它，以避免与 GNN 缩写相冲突，后者是为一般的图形网络类保留的。这是最早提出的 GNN 模型之一。它扩展了现有的神经网络来处理图形结构的数据。与我们使用单词的上下文(即其周围的单词)来创建嵌入向量的方式相同(](https://ieeexplore.ieee.org/document/4700287)[第 6 章](fe6a42c9-f18e-4c2b-9a82-99ec53e727ca.xhtml) *，语言建模*，我们可以使用节点的相邻图节点来做同样的事情。GraphNNs 旨在基于节点 *v* 的邻域创建该节点的 *s* 维向量状态![](assets/e1c524a1-4bb1-4438-966b-00993d86d5af.png)。与语言建模类似，向量状态可以作为其他任务的输入，比如节点分类。**

通过循环交换邻居信息来更新节点的状态，直到达到稳定的平衡。让我们用![](assets/3bd465a0-a7b2-44d0-9ca6-f316a4c15867.png)来表示一组邻居节点 *v* ，用 *u* 来表示该邻居的单个节点。使用以下公式循环更新节点的隐藏状态:

![](assets/bc73d220-66ee-4229-9e08-46567127e7c9.png)

这里， *f* 是一个参数函数(例如一个**前馈 NN** ( **FFNN** ))，每个状态![](assets/e1889615-9da0-42d8-96b9-833d85ff49c1.png)被随机初始化。参数函数 *f* 将 *v* 的特征向量 *![](assets/8e00e0c7-e952-4459-9bda-debeb4a0f2bd.png)* 、其邻居 *u* 的特征向量![](assets/dda100a7-6d39-42b9-b482-ebfc6882f7e5.png)、连接 *u* 和 *v* 的边的特征向量![](assets/2123d1d9-f3ac-4968-b4fd-c8a1b4633c9e.png)以及在步骤 *t-1* 的 *u* 的状态向量![](assets/b40c18b0-cbc8-4505-9cf3-b9db3e3e3a66.png)作为输入。换句话说， *f* 使用关于 *v* 的邻域的所有已知信息。表达式![](assets/161bd9cc-1ccb-4477-972e-908460c7624b.png)是应用于所有邻居节点的 *f* 的总和，这使得 GraphNN 独立于邻居的数量及其排序。函数 *f* 对于过程的所有步骤都是相同的(即具有相同的权重)。

注意，我们有一个迭代(或循环)过程，其中步骤 *t* 的状态基于直到 *t-1* 的步骤数，如下所示:

![](assets/9e7c34c0-c84f-4979-b13c-02c9e6d344f3.png)

更新特征向量状态的循环过程；对于所有步骤， **Grec** 递归层是相同的(即，具有相同的权重);资料来源:https://arxiv.org/abs/1901.00596

这个过程一直持续到达到稳定的平衡。为此，函数 *f* 必须是收缩映射。我们来澄清一下:当应用于任意两点(或值)A 和 B 时，一个收缩映射函数 *f* 满足条件![](assets/6a9b9e1e-bd66-4509-9081-1d2371d51fb5.png)，其中γ为标量值![](assets/20f023c9-77a0-42d0-b88d-6a2f2359c604.png)。换句话说，收缩映射缩小了映射后两点之间的距离。这确保了对于任何初始值![](assets/3601a48a-7d0c-4dd3-98f6-112e93dd8b86.png)，系统将收敛(指数快速)到平衡状态向量![](assets/b0bb88a6-0596-4699-a87a-446972438586.png)。我们可以将 NN 修改成收缩函数，但这超出了本书的范围。

现在我们有了隐藏状态，我们可以用它来完成诸如节点分类之类的任务。我们可以用下面的公式来表示:

![](assets/db4574c8-41af-44da-9fb4-7e90b7721985.png)

在该等式中，![](assets/b0bb88a6-0596-4699-a87a-446972438586.png)是达到平衡时的状态， *g* 是参数函数，例如，针对分类任务激活 softmax 的全连接图层。

接下来，让我们看看如何训练 GraphNN，给定一些或所有图节点的一组训练标签*t[I]和一个小批量的大小 *m* 。要训练 GraphNN，请完成以下步骤:*

1.  按照我们刚刚描述的循环过程，计算所有 *m* 节点的![](assets/b0bb88a6-0596-4699-a87a-446972438586.png)和 *o [ v ]* 。
2.  计算代价函数(*t[I]是节点 *i* 的标号):*

![](assets/bd326435-7a13-4c36-b3ac-25821841be2e.png)

3.  向后传播成本。注意，将步骤 1 的节点状态更新与当前步骤的梯度传播交替进行允许 GraphNN 处理循环图。
4.  更新组合网络的权重 *g(f)* 。

GraphNN 有几个限制，其中之一是计算平衡状态向量![](assets/b0bb88a6-0596-4699-a87a-446972438586.png)效率不高。此外，正如我们在本节前面提到的，GraphNN 使用相同的参数(权重)在所有步骤 *t* 中更新![](assets/b0bb88a6-0596-4699-a87a-446972438586.png)。相比之下，其他神经网络模型可以使用具有不同权重集的多个堆叠层，这使得我们可以捕捉数据的层次结构。它还允许我们在一次向前传递中计算![](assets/b0bb88a6-0596-4699-a87a-446972438586.png)。最后，值得一提的是，尽管计算![](assets/b0bb88a6-0596-4699-a87a-446972438586.png)是一个循环过程，但 GraphNN 不是一个循环网络。

**门控图 NN** 模型( **GGNN** 、[https://arxiv.org/abs/1511.05493](https://arxiv.org/abs/1511.05493))试图借助**门控递归单元**细胞(或 **GRU** )来克服这些限制；更多信息，参见第 7 章、*了解递归网络*)作为递归函数。我们可以将 GGNN 定义如下:

![](assets/c6865cb0-0fab-4627-b4b6-02ff5cb78f3d.png)

在前面的公式中，![](assets/e46f22e8-6d32-4c56-8d73-4470554a49de.png)。为了澄清，GGNN 基于其同一步骤的相邻状态![](assets/d3c1e172-c9e8-4106-a5b6-54d77730e785.png)*t*和其先前的隐藏状态![](assets/75ceb0fc-8945-42a1-b824-4096c1bb42a0.png)来更新状态。

从历史的角度来看，GraphNNs 是第一批 GNN 模型之一。但是正如我们提到的，它们有一些局限性。在下一节中，我们将讨论卷积图网络，这是最近的发展。

<title>Convolutional Graph Networks</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# 卷积图网络

**卷积图网络** ( **ConvGNN** )在更新状态向量时，使用一堆特殊的图卷积层(Gconv*)对图的节点执行卷积。与 GraphNNs 类似，图形卷积采用节点的邻居，并产生其矢量表示![](assets/6f08cd10-d31e-4f38-ac59-8cabc213aad4.png)。但是 GraphNN 在计算![](assets/bf2fd2ce-b2d5-48fa-8702-dbbeeea83486.png)的所有步骤 *t* 中使用相同的层(即相同的权重集)，而 ConvGNN 在每一步都使用不同的层。下图说明了这两种方法之间的区别:

![](assets/75832ae4-bfe8-484e-a504-9eefdee3a8bb.png)

顶部:GraphNN 在所有步骤 t 上使用相同的 Grec 递归层；下图:GCN 每一步都使用不同的 Gconv [*] 层；资料来源:https://arxiv.org/abs/1901.00596

对于 ConvGNN，步数 *t* 由网络的深度定义。虽然我们将从稍微不同的角度讨论这个问题，但 ConvGNN 的行为与常规 FFNN 一样，只是具有图形卷积。通过堆叠多个层，每个节点的最终隐藏表示从更远的邻域接收消息，如下图所示:

![](assets/90f9c2fd-c6b9-4b89-a3af-73dd9243052f.png)

Top:节点级分类图 cn；下图:图级分类图。资料来源:https://arxiv.org/abs/1901.00596

该图显示了两种情况:

*   节点级(顶层)，其中每个卷积层(包括最后一层)的输出是图中每个节点的向量。我们可以对这些向量执行节点级操作。

*   图形级(底部)，交替图形卷积和池化操作，以一个读出层结束，随后是几个完全连接的层，这些层汇总整个图形以产生单个输出。

现在我们已经对 ConvGNN 有了一个高层次的概述，在下一节中，我们将讨论图形卷积(之后，我们将讨论读出层和池层)。

<title>Spectral-based convolutions</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# 基于频谱的卷积

有各种类型的图卷积(查看*对图神经网络*的全面调查)，但在这一节中，我们将讨论来自*的带有图卷积网络的半监督分类*(【https://arxiv.org/abs/1609.02907】)的算法。我们将用 GCN 来表示这种卷积，以避免与一般的 ConvGNN 符号混淆，ConvGNN 符号通常指的是图形卷积网络。GCN 是所谓的**基于光谱的**类 ConvGNNs 的代表。这些算法通过从图形信号处理的角度引入滤波器来定义图形卷积，其中图形卷积操作被解释为从图形信号中去除噪声。

在*图神经网络*部分*、*中，我们定义了隐藏节点状态![](assets/b1e6e909-4469-4c99-8193-9c922b7114c7.png)，并注意到![](assets/f907d77e-60b9-436e-a154-6b69b18be076.png)在 GGNN 的情况下。让我们通过在矩阵![](assets/b2332c0f-094d-4ecb-94e0-a1d354281c7d.png)中堆叠图中所有节点的隐藏向量状态来扩展这种表示法，其中 *n* 是图中节点的总数， *d* 是特征向量的大小。矩阵的每一行代表单个节点的隐藏状态。然后，我们可以在步骤 *l+1* 为单个 GCN 层定义通用公式如下:

![](assets/145d7088-3fdd-4fae-ae22-91ca8ce6b26c.png)

这里， **A** 是邻接矩阵， *f* 是非线性激活，比如 ReLU，![](assets/49f58e0e-95c2-4168-b77d-3e0cfa0058e4.png)(特征向量矩阵)。由于![](assets/7562814c-e3e6-4725-83d2-ce4ee25ae57c.png)和![](assets/8630b436-b3bc-4ec0-89fe-8bc4fb72235b.png)具有相同的大小，![](assets/95d3840b-a76f-4f57-b8bb-69b70ff60f2f.png)与节点特征矩阵 **X** 具有相同的维数(参见*图形神经网络*部分)。然而，![](assets/05b65ee5-1076-4b17-a762-c2bd6b74bf16.png)，其中 *z* 是隐藏状态向量![](assets/150965c7-c90c-4a99-99be-972af915b99d.png)的大小，并且不一定与初始的 *d* 相同。

让我们继续一个简化但具体的 GCN 版本:

![](assets/181962b9-f896-49b5-9978-75461955b3af.png)

这里，![](assets/b3c301c4-c317-4e82-8ab4-3e9b17d1d5b5.png)是权重矩阵，σ是 sigmoid 函数。由于邻接矩阵 **A** 以矩阵形式表示图形，我们可以在一次操作中计算出该层的输出。![](assets/fa44df2d-508c-42aa-a875-20de6c4de0f9.png)操作允许每个节点从它的邻居节点接收输入(它也允许 GCN 处理有向和无向图)。让我们通过一个例子来看看这是如何工作的。我们将使用我们在*图神经网络*部分*中介绍的五节点图。*为了可读性，我们将为每个节点分配一个一维向量隐藏状态![](assets/712b0558-85ca-42f7-9e12-f4c66e78f352.png)，其值等于节点号![](assets/ac37c382-7f41-405e-bd39-1cf4acf16e4d.png)。然后我们可以用下面的公式计算这个例子:

![](assets/f1d830f5-de0c-4fcd-94f8-5876ec5da8cc.png)

我们可以看到![](assets/2a88e6d6-53ea-4b02-977e-90196ff09f68.png)是如何工作的，因为它从节点 2、3 和 5 接收输入。如果![](assets/712b0558-85ca-42f7-9e12-f4c66e78f352.png)有更多的维度，那么输出向量的每个单元将是输入节点的状态向量的相应单元的总和:

![](assets/72198d96-67d3-4f33-bf65-0a078dfcf0fd.png)

这里，![](assets/a64b3256-e78f-4152-b6ae-e3ef4f263258.png)是邻接矩阵的单元。

尽管这种解决方案很好，但它有两个限制:

*   并非所有节点都从它们自己的先前状态接收输入。在前面的示例中，只有节点 2 从自身获取输入，因为它有一条循环边(这是将节点连接到自身的边)。这个问题的解决方案是通过将邻接矩阵主对角线上的所有值都设置为 1 来人为地为所有节点创建循环边:![](assets/7ba61638-6168-435c-8cff-ba793c77c713.png)。在这个等式中， **I** 是单位矩阵，它在主对角线上有 1，在所有其他单元中有 0。
*   由于 **A** 没有被归一化，与具有较少数量邻居的节点相比，具有大量邻居的节点的状态向量将以不同的方式改变它们的尺度。我们可以在前面的例子中看到这一点，其中![](assets/82a870e8-c31a-4587-a0b3-572fa5aa1099.png)与其他节点相比更大，因为节点 4 在其邻域中有 3 个节点。解决这个问题的方法是将邻接矩阵归一化，使得一行中所有元素之和等于 1: ![](assets/d2340045-f977-47fe-98c8-f1f2c167e1f6.png)。我们可以通过将 **A** 乘以逆度矩阵 **D** ^(-1) 来实现。度矩阵 **D** 是一个对角线矩阵(即除了主对角线之外的所有其他元素都为零)，它包含了关于每个节点的度的信息。我们将一个节点的邻居数量称为该节点的度数。例如，我们的示例图的度矩阵如下:

![](assets/d6e2c432-11b2-4ea4-ade3-a9b3e6a13ff0.png)

因此， **D** ^(-1) **A** 就变成了如下:

![](assets/441e83ce-02c3-40d5-bfac-0b6e443512a6.png)

这种机制为每个相邻节点分配相同的权重。在实践中，论文作者发现使用对称归一化![](assets/9f5251dd-2d80-411a-b3ed-76f750f333c8.png)效果更好。

在我们合并了这两个改进之后，GCN 公式的最终形式可以写成如下:

![](assets/3baa1355-11c2-4958-9f68-0ce56e796f8c.png)

请注意，我们刚刚描述的 GCN 只包括节点的近邻作为上下文。每个堆叠层有效地将节点的感受野增加超过其紧邻节点 1。ConvGNN 的第二层的感受野包括紧邻的邻居，第二层的感受野包括距离当前节点两跳的节点，等等。

在下一节中，我们将研究图形卷积运算的第二个主要类别，称为基于空间的卷积。

<title>Spatial-based convolutions with attention</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# 基于空间的注意力卷积

第二个 ConvGNN 类别是基于空间的方法，它从计算机视觉卷积中获得灵感([第 2 章](d94e220f-820e-40da-8bb5-9593e0790b21.xhtml)、*理解卷积网络*)。我们可以将图像视为一个图形，其中每个像素都是一个节点，直接连接到其相邻的像素(下图左侧的图像)。比如我们用 3 × 3 做滤镜，每个像素的邻域由 8 个像素组成。在图像卷积中，这个 3 × 3 加权滤波器应用于 3 × 3 片，结果是所有九个像素的亮度的加权和。同样，基于空间的图形卷积将中心结点的表示与其相邻结点的表示进行卷积，以获得中心结点的更新表示，如下图右侧图像所示:

![](assets/ff69efd8-2240-4c09-91b1-0dc56b8601e9.png)

左图:像素网格上的 2D 卷积；右图:空间图形卷积。资料来源:https://arxiv.org/abs/1901.00596

一般的基于空间的卷积有点类似于 GCN，因为两种运算都依赖于图邻居。GCN 使用逆序矩阵为每个邻居分配权重。空间卷积将卷积滤波器用于同样的目的。两者之间的主要区别在于，在 GCNs 的情况下，权重是固定的并且是归一化的，而空间卷积的滤波器权重是可学习的并且不是归一化的。在某种意义上，我们可以认为 GCN 也是一种基于空间的方法。

我们将通过一种特定类型的基于空间的模型来继续这一部分，这种模型被称为**图形注意力网络** ( **盖特**)(有关更多信息，请访问【https://arxiv.org/abs/1710.10903】T4)，它通过一个特殊的图形自我注意力层来实现图形卷积。GAT 不是学习卷积滤波器或使用平均邻接矩阵作为 GCN，而是使用自关注机制的关注分数来为每个相邻节点分配权重。GAT 层是图注意网络的主要构件，图注意网络由多个堆叠的 GAT 层组成。和 GCN 一样，每增加一层都会增加目标节点的感受野。

与 GCN 类似，GAT 层将一组节点特征向量![](assets/c8d92091-850b-429b-9887-f9951f2b976f.png)作为输入，并输出一组不同的特征向量![](assets/94b3890d-c654-4568-a6e0-7b28defceaa8.png)，不必具有相同的基数。按照我们在[第 8 章](0a021de6-b007-49bf-80e9-b7f6a72cbba7.xhtml)、*序列对序列模型和注意*中概述的程序，操作从计算每两个邻域节点的特征向量![](assets/22e50d7b-c169-4fe9-9244-60ca93fa9882.png)和![](assets/25e3efe7-32af-43ac-8b81-e7d78773b0fd.png)之间的比对分数开始:

![](assets/e6e85a94-9570-4d47-9407-50a8683c25e8.png)

这里，![](assets/dda45c47-d17b-4ed9-a7ed-3d28f1e198fb.png)是一个权重矩阵，它将输入向量转换为输出向量的基数，并提供必要的可学习参数。 *f [ a]*

![](assets/c7f67757-7c1b-422f-9386-391ea231573b.png)

这里，![](assets/cfa05b0f-6474-45b1-9e53-9721753eb371.png)表示拼接。如果我们不施加任何限制，每个节点将能够关注图中的所有其他节点，而不管它们与目标节点的接近程度；然而，我们只对邻近的节点感兴趣。GAT 的作者提出通过使用掩蔽注意力来解决这一问题，其中掩蔽覆盖不是目标节点的直接邻居的所有节点。我们将用![](assets/aff2d979-9d86-46ce-a910-60474eb51ada.png)来表示节点 *i* 的直接邻居。

接下来，我们使用 softmax 计算注意力分数。以下是通用公式和带*f[a]的公式(仅适用于直接邻居):*

![](assets/d88cf72d-7ec5-4a14-a934-b8d252571566.png)

一旦我们有了注意力分数，我们可以使用它们来计算每个节点的最终输出特征向量(我们在第 8 章、*序列到序列模型和注意力*中将其称为上下文向量)，这是所有邻居的输入特征向量的加权组合:

![](assets/78546e42-dca7-43b1-9697-59eab1457c33.png)

这里，σ是 sigmoid 函数。该论文的作者还发现多头注意力有利于模型的性能:

![](assets/88571404-92dd-4633-b741-4b6ee1978dcc.png)

这里， *k* 是每个头部的指数(总共有 *K* 个头部)，![](assets/8969baab-d817-478e-b2fe-06e80d6affc7.png)是每个关注头部的关注分数，![](assets/152f315b-ca65-41dc-a5b5-2d1e1a86a10b.png)是每个关注头部的权重矩阵。由于![](assets/2ce5f52e-452e-46cb-8bf7-2bdd2ed5d3a8.png)是串联的结果，所以它的基数会是 *k × z [ l+1 ]* 。因此，在网络的最终关注层中，级联是不可能的。为了解决这个问题，该论文的作者建议您应该对最后一层中注意力头的输出进行平均(用索引 *L* 表示):

![](assets/07cb2578-7a7a-48e3-ad4c-2f725c517613.png)

下图显示了 GAT 环境下常规注意力和多头注意力的比较。在左图中，我们可以看到应用在两个节点和 *i* 和 *j* 之间的常规注意力机制。在右图中，我们可以看到节点 *1* 及其邻域的 *k = 3* 头的多头注意力。聚集的特征或者被连接(对于所有隐藏的 GAT 层)或者被平均(对于最终的 GAT 层):

![](assets/7ec5f308-a34d-4a98-9ad7-2afb2b22536f.png)

左:两个节点上的常规注意；右图:节点 1 及其邻域的多头注意力。资料来源:https://arxiv.org/abs/1710.10903

一旦我们有了最终 GAT 层的输出，我们就可以使用它作为下一个特定任务层的输入。例如，这可能是一个完全连接的图层，具有用于节点分类的 softmax 激活。

在结束专门讨论 ConvGNNs 的这一部分之前，让我们讨论一下我们还没有涉及的最后两个组件。第一个是我们在*卷积* *图* *网络*部分开头的图级分类示例中介绍的读出层。它将最后一个图卷积层**H**(*L*)的所有节点状态作为输入，并输出概括整个图的单个向量。我们可以将其正式定义如下:

![](assets/02793365-ff3a-479e-bef6-59c93a6c6798.png)

这里， *G* 表示图形节点的集合， *R* 是读出函数。有多种方法可以实现它，但最简单的方法是对所有节点状态进行元素求和或平均。

我们要看的下一个(也是最后一个)ConvGNN 组件是池操作。同样，有各种方法可以使用它，但最简单的方法之一是使用与我们在计算机视觉卷积中使用的相同的最大/平均池操作:

![](assets/20c1fb51-9f9a-46b6-a295-1e57bf879451.png)

这里， *p* 表示统筹窗口的大小。如果汇集窗口包含整个图形，汇集将变得类似于读数。

我们对 ConvGNNs 的讨论到此结束。在下一节中，我们将讨论图形自动编码器，它提供了一种生成新图形的方法。

<title>Graph autoencoders</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# 图形自动编码器

让我们快速回顾一下自动编码器，我们在第五章、*、*、*生成模型*中首次介绍了它。一个**自动编码器**是一个试图复制其输入的 FFN(更准确地说，它试图学习一个恒等函数![](assets/9b1a90cb-7d76-4d0a-b2ac-ab69e9a8f07e.png))。我们可以将自动编码器视为两个组件的虚拟组合——编码器**编码器**，它将输入数据映射到网络的内部潜在特征空间(表示为向量 *z* ) *、*和解码器**，它试图从网络的内部数据表示中重建输入。我们可以通过最小化损失函数(称为**重构误差)**来以无监督的方式训练自动编码器，该损失函数测量原始输入与其重构之间的距离。**

 ****图形自动编码器** ( **GAE** )类似于自动编码器，区别在于编码器将图形节点映射到自动编码器潜在特征空间，然后解码器试图从中重建特定的图形特征。在这一节，我们将讨论一个 GAE 变体，在*变分图自动编码器*([https://arxiv.org/abs/1611.07308](https://arxiv.org/abs/1611.07308))中介绍，它也概述了 GAE 的变分版本( **VGAE** )。下图显示了一个 GAE 示例:

![](assets/ad20131f-4b1e-4cd7-b137-7c2e4b24725b.png)

图形自动编码器的一个例子。资料来源:https://arxiv.org/abs/1901.00596

编码器是我们在*基于频谱的卷积*部分定义的 GCN 模型，用于计算图节点的网络嵌入![](assets/e799be66-a517-4c9e-b202-62de22c1ae57.png)，其中 *n* 个节点中的每个节点的嵌入是一个 *d* 维向量 **z** 。它将邻接矩阵 **A** 和一组节点特征向量 **X** 作为输入(就像我们在本章中讨论的其他 GNN 模型一样)。编码器由以下公式表示:

![](assets/d0753995-166a-4769-8d36-7d50faced583.png)

这里， **W [1]** 和 **W [2]** 是两个 GCN 图卷积的可学习参数(权重)，而 *f* 是一个非线性激活函数，类似 ReLU。该论文的作者使用了两个图卷积层，尽管所提出的算法可以用于任何数量的层。

解码器试图重建图邻接矩阵![](assets/3f98fb9c-d5e9-454b-9459-6b3c28bfe9c7.png):

![](assets/2ccf67b6-cb38-47a2-b535-a03c5c14aa87.png)

这里，σ是 sigmoid 函数。它首先计算 **Z** 和它的转置:![](assets/c60a2b16-86cd-4a4a-b5ec-5a9ced360624.png)之间的点(或内)积。为了清楚起见，该操作计算图中每个节点 *i* 的向量嵌入*z[I]和每个其他节点 *j* 的向量嵌入*z[j]的点积，如下例所示:**

![](assets/8f72a2b2-988f-4043-a076-8ad4bc89f926.png)

正如我们在[第一章](b94f711b-daab-4de7-97b7-b7efccd0b392.xhtml)、*神经网络的基本要素*中提到的，我们可以把点积看作向量之间的相似性度量。因此，![](assets/2921f759-7c77-4965-95a0-a5832062c067.png)测量每一对可能的节点之间的距离。这些距离是重建工作的基础。此后，解码器应用非线性激活函数，并继续重构图邻接矩阵。我们可以通过最小化真实重构邻接矩阵之间的差异来训练 GAE。

接下来，让我们来关注一下**变分图自动编码器** ( **VGAE** )。很像我们在第五章、*生成模型*中讨论的**变分自动编码器** ( **VAE** )，VGAE 是一个生成模型，可以生成新的图(更具体地说，新的邻接矩阵)。为了理解这一点，让我们先简单回顾一下 VAEs。与常规的自动编码器不同，VAE 瓶颈层不会直接输出潜在状态向量。而是输出两个向量，描述潜在向量 **z** 分布的**均值** μ和**方差** σ。我们将使用它们从高斯分布中采样一个与 **z** 维数相同的随机向量ε。更具体地说，我们将ε移动潜在分布的平均值μ，并按潜在分布的方差σ对其进行缩放:

![](assets/b8e54537-e06d-4f5f-aa11-7fccb06056bc.png)

这种技术被称为**重新参数化**技巧，它允许随机向量具有与原始数据集相同的均值和方差。

我们可以将 VGAE 视为 GAE 和 VAE 的结合，因为它处理图形输入(如 GAE)，并遵循相同的原则生成新数据(如 VAE)。首先，让我们关注编码器，它分为两条路径:

![](assets/79b471f1-7bc7-43e7-ae07-ea9e44021ce1.png)

这里，权重 **W [0]** 在路径之间共享， *![](assets/37a71eea-c7d9-44c7-9af8-f0b2cc2217cc.png)* 为对称归一化邻接矩阵， *** μ *** 为均值向量矩阵***[I]*****， *** σ *** 为方差矩阵***[I]*****然后，完整图的编码器推断步骤被定义为所有图节点 *i* 的潜在表示的内积:****

 ****![](assets/4b4675d4-526e-406a-9f32-a24fb0b4444b.png)

在这个公式中， *n* 是图中的节点数，![](assets/bf7e4027-8056-49cc-ba8d-d2bdc0e9618e.png)代表真实概率分布![](assets/9451f080-cacc-4328-a19d-760505c64b27.png)的编码器近似值，其中 *φ* 是网络参数(这里我们保留了[第五章](319c18b2-c733-402e-937c-ace912ff87ca.xhtml)、*生成模型*的标注)。近似是具有特定节点平均值*μ[I]和对角协方差值![](assets/2f51c5e2-c99d-47ca-bb62-40c4b90271e7.png)的高斯分布:*

![](assets/0778279e-d32e-46ba-8829-8147a91ed5ae.png)

接下来，我们定义生成步骤，它创建新的邻接矩阵。它是随机潜在向量的内积:

![](assets/033b088c-576d-467d-b720-253c5476b649.png)

这里，![](assets/9ca6cbb0-7521-41d1-a4d5-7c34c4c78dd7.png)表示两个节点 *i* 和 *j* 之间是否存在边，![](assets/154fcf49-1337-4f63-982d-b95af38be050.png)表示真实概率的解码器近似值![](assets/7daf605e-a4ff-4848-85e4-4628a726bec9.png)。我们可以使用已经熟悉的 VAE 成本来训练 VGAE:

![](assets/98b1075f-740f-4e14-bae3-2ef89538d3d8.png)

这里，第一项是 kull back-lei bler 散度，第二项是重建成本。

这就结束了我们对 GAE 和 VGAE 的描述。在下一节中，我们将讨论另一种图形学习范式，它使得混合结构化和非结构化数据作为网络输入成为可能。

<title>Neural graph learning</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# 神经图形学习

在本节中，我们将描述**神经图学习**范例( **NGL** )(有关更多信息，请参见*神经图学习:使用图训练神经网络*(位于[)https://storage . Google APIs . com/pub-tools-public-publication-data/pdf/bbd 774 a3 c 6 f 13 f 05 BF 754 e 09 aa 45 e 7 aa 6 fa a08 a 8 . pdf](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/bbd774a3c6f13f05bf754e09aa45e7aa6faa08a8.pdf))，这使得基于结构化的非结构化数据增加训练成为可能更具体地说，我们将讨论**神经结构化学习**框架( **NSL** )(更多信息，请访问[https://www.tensorflow.org/neural_structured_learning/](https://www.tensorflow.org/neural_structured_learning/))，它基于 TensorFlow 2.0 并实现了这些原则。

为了理解 NGL 是如何工作的，我们将使用 CORA 数据集([https://relational.fit.cvut.cz/dataset/CORA](https://relational.fit.cvut.cz/dataset/CORA))，该数据集由 2708 篇科学出版物组成，分为 7 类中的 1 类(这是数据集的非结构化部分)。数据集中所有出版物(即词汇表)中的唯一单词数为 1，433。每个出版物被描述为一个单一的**多孔**编码向量。这是一个大小为 1，433(与词汇表相同)的向量，其中单元值为 0 或 1。如果出版物包含词汇表的第 *i-* 个单词，那么该出版物的独热编码向量的第 *i* 个单元被设置为 1。如果出版物中没有该单词，则该单元格设置为 0。这种机制保留了文章中出现的单词的信息，但不保留它们的顺序信息。数据集还包含 5429 篇引用的有向图，其中节点是出版物，它们之间的边指示出版物 *v* 是否引用出版物 *u* (这是数据集的结构化部分)。

接下来，让我们关注 NGL 本身，从下图开始:

![](assets/3465ccd4-42ab-4e41-9ebb-38a0638e7460.png)

NGL 框架:绿色实线表示非结构化输入数据流；黄色虚线显示结构化信号数据流；灵感来源:https://www . tensor flow . org/neural _ structured _ learning/framework

它作为常规 NN 训练框架的一种包装器，可以应用于任何类型的网络，包括 FFN 和 r NN。例如，我们可以有一个常规的 FFN，它将多宿主编码的发布向量作为输入，并尝试使用 softmax 输出将其分类到 7 个类别中的一个，如前图中绿色不间断线所示。NGL 允许我们用引用文献提供的结构化数据来扩展这个网络，如黄色虚线所示。

让我们看看这是如何工作的。我们首先假设图中的相邻节点有些相似。我们可以把这个假设转移到 NN 域，假设样本 *i* 的 NN 产生的嵌入向量(嵌入是最后一个隐藏层的输出)应该有点类似于样本 *j* 的嵌入，假设两个样本在关联图中是邻居。在我们的例子中，我们可以假设出版物 *i* 的嵌入向量应该类似于出版物 *j* 的嵌入向量，前提是其中一个引用了另一个(也就是说，它们在引用图中是邻居)。在实践中，我们可以通过以下步骤实现这一点:

1.  从包含非结构化数据(多宿主编码的出版物)和结构化数据(引用图表)的数据集开始。
2.  构建特殊类型的复合训练样本(分批组织)，其中每个复合样本由单个常规输入样本(一个多跳编码的发布)和其相邻样本的 *K* (引用初始样本或被初始样本引用的多跳编码的发布)组成。
3.  将复合样本馈送到神经网络，并为初始样本及其相邻样本生成嵌入。虽然上图显示两条路径并行运行，但事实并非如此。该图旨在说明网络处理中心样本及其邻居，但实际的神经网络并不参与这种安排——它只是将所有多跳编码的输入作为单个批处理的一部分，并对它们进行处理。相反，常规 NN 顶部的 NSL 部分区分了这两个组件。
4.  计算由两部分组成的特殊类型的复合损失函数:正则监督损失和正则化邻居损失，其使用度量来测量初始样本嵌入与其邻居的嵌入之间的距离。邻居损失是允许我们用结构化信号来扩充非结构化训练数据的机制。综合损失定义如下:

![](assets/e4f50ba5-e319-41ab-8440-81d100e27716.png)

这个公式有以下特点:

*   *n* 是小批量中复合样品的数量。
*   ![](assets/7ea30bdb-fb32-4c9b-9c37-4ebfca7b74f5.png)是监督损失函数。
*   *f[θ]是带权值 *θ的 NN 函数。**
*   *α* 是确定两个损失分量之间相对权重的标量参数。
*   ![](assets/e380c730-c4df-4fa8-b86d-afe275fc6ed0.png)是样本 *x [ i ]* 的图邻居的集合。注意，邻居损失在图的所有节点的所有邻居上迭代(两个和)。
*   ![](assets/8dae52a2-49ba-4628-8a68-369127f9643c.png)是样本 *i* 和 *j* 之间的图边的权重。如果任务没有权重的概念，我们可以假设所有的权重都是 1。
*   ![](assets/9820c380-205c-4127-8628-991725805d52.png)是样本 *i* 和 *j* 的嵌入向量之间的距离度量。

由于邻居损失的正则化性质，NGL 也被称为**图正则化**。

5.  向后传播误差并更新网络权重 *θ* 。

现在我们已经有了图正则化的概述，让我们来实现它。

<title>Implementing graph regularization</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# 实现图形正则化

在本节中，我们将借助 NSL 框架在 Cora 数据集上实现图形正则化。本例基于[https://www . tensor flow . org/neural _ structured _ learning/tutorials/graph _ keras _ MLP _ Cora](https://www.tensorflow.org/neural_structured_learning/tutorials/graph_keras_mlp_cora)上的教程。在我们继续实现之前，我们必须满足一些先决条件。首先，我们需要 TensorFlow 2.0 和`neural-structured-learning` 1.1.0 包(可通过`pip`获得)。

一旦我们满足了这些要求，我们就可以继续实施了:

1.  我们将从包导入开始:

```py
import neural_structured_learning as nsl
import tensorflow as tf
```

2.  我们将继续使用程序的一些常量参数(希望常量名称和注释能说明问题):

```py
# Cora dataset path
TRAIN_DATA_PATH = 'data/train_merged_examples.tfr'
TEST_DATA_PATH = 'data/test_examples.tfr'
# Constants used to identify neighbor features in the input.
NBR_FEATURE_PREFIX = 'NL_nbr_'
NBR_WEIGHT_SUFFIX = '_weight'
# Dataset parameters
NUM_CLASSES = 7
MAX_SEQ_LENGTH = 1433
# Number of neighbors to consider in the composite loss function
NUM_NEIGHBORS = 1
# Training parameters
BATCH_SIZE = 128

```

`TRAIN_DATA_PATH`和`TEST_DATA_PATH`下的文件包含 Cora 数据集和标签，以 TensorFlow 友好的格式进行预处理。

3.  接下来，让我们加载数据集。这个过程通过使用两个函数来实现:`make_dataset`构建整个数据集，以及`parse_example`解析单个复合样本(`make_dataset`在内部使用`parse_example`)。我们从`make_dataset`开始:

```py
def make_dataset(file_path: str, training=False) -> tf.data.TFRecordDataset:
    dataset = tf.data.TFRecordDataset([file_path])
    if training:
        dataset = dataset.shuffle(10000)
    dataset = dataset.map(parse_example).batch(BATCH_SIZE)

    return dataset
```

请注意，`dataset.map(parse_example)`在内部将`parse_example`应用于数据集的所有样本。让我们继续讨论`parse_example`的定义，从声明开始:

```py
def parse_example(example_proto: tf.train.Example) -> tuple:
```

该函数创建了代表单个复合样本的一种模板的`feature_spec`字典，稍后将使用来自数据集的实际数据填充该字典。首先，我们用代表多宿主编码出版物的`'words'`和代表出版物类别的`'label'`的占位符实例`tf.io.FixedLenFeature`填充`feature_spec`(请记住缩进，因为该代码仍然是`parse_example`的一部分):

```py
    feature_spec = {
        'words':
            tf.io.FixedLenFeature(shape=[MAX_SEQ_LENGTH],
                                  dtype=tf.int64,
                                  default_value=tf.constant(
                                      value=0,
                                      dtype=tf.int64,
                                      shape=[MAX_SEQ_LENGTH])),
        'label':
            tf.io.FixedLenFeature((), tf.int64, default_value=-1),
    }
```

然后，我们迭代第一个`NUM_NEIGHBORS`邻居，并将它们的多跳向量和边权重分别添加到`nbr_feature_key`和`nbr_weight_key`关键字下的`feature_spec`:

```py
    for i in range(NUM_NEIGHBORS):
        nbr_feature_key = '{}{}_{}'.format(NBR_FEATURE_PREFIX, i, 'words')
        nbr_weight_key = '{}{}{}'.format(NBR_FEATURE_PREFIX, i, NBR_WEIGHT_SUFFIX)
        feature_spec[nbr_feature_key] = tf.io.FixedLenFeature(
            shape=[MAX_SEQ_LENGTH],
            dtype=tf.int64,
            default_value=tf.constant(
                value=0, dtype=tf.int64, shape=[MAX_SEQ_LENGTH]))

        feature_spec[nbr_weight_key] = tf.io.FixedLenFeature(
            shape=[1], dtype=tf.float32, default_value=tf.constant([0.0]))

    features = tf.io.parse_single_example(example_proto, feature_spec)

    labels = features.pop('label')
    return features, labels
```

请注意，我们使用来自数据集的真实样本填充模板，代码片段如下:

```py
    features = tf.io.parse_single_example(example_proto, feature_spec)
```

4.  现在，我们可以实例化训练和测试数据集:

```py
train_dataset = make_dataset(TRAIN_DATA_PATH, training=True)
test_dataset = make_dataset(TEST_DATA_PATH)
```

5.  接下来，让我们实现模型，这是一个简单的 FFN，有两个隐藏层和 softmax 作为输出。该模型以多宿主编码的发布向量作为输入，输出发布类。它独立于 NSL，并且可以以简单的监督方式被训练为一个分类:

```py
def build_model(dropout_rate):
    """Creates a sequential multi-layer perceptron model."""
    return tf.keras.Sequential([
        # one-hot encoded input.
        tf.keras.layers.InputLayer(
            input_shape=(MAX_SEQ_LENGTH,), name='words'),

        # 2 fully connected layers + dropout
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dropout(dropout_rate),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dropout(dropout_rate),

        # Softmax output
        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')
    ])
```

6.  接下来，让我们实例化模型:

```py
model = build_model(dropout_rate=0.5)
```

7.  我们拥有使用图正则化所需的所有要素。我们将从用 NSL 包装纸包装`model`开始:

```py
graph_reg_config = nsl.configs.make_graph_reg_config(
    max_neighbors=NUM_NEIGHBORS,
    multiplier=0.1,
    distance_type=nsl.configs.DistanceType.L2,
    sum_over_axis=-1)
graph_reg_model = nsl.keras.GraphRegularization(model,
                                                graph_reg_config)
```

我们用图正则化参数实例化`graph_reg_config`对象(一个`nsl.configs.GraphRegConfig`的实例):`max_neighbors=NUM_NEIGHBORS`是要使用的邻居的数量，`multiplier=0.1`相当于我们在*神经结构化学习*部分介绍的复合损失的参数α，`distance_type=nsl.configs.DistanceType.L2`是相邻节点嵌入之间的距离度量。

8.  接下来，我们可以建立一个训练框架并启动 100 个时期的训练:

```py
graph_reg_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy'])

# run eagerly to prevent epoch warnings
graph_reg_model.run_eagerly = True

graph_reg_model.fit(train_dataset, epochs=100, verbose=1)
```

9.  训练完成后，我们可以在测试数据集上运行训练好的模型:

```py
eval_results = dict(
    zip(graph_reg_model.metrics_names,
        graph_reg_model.evaluate(test_dataset)))
print('Evaluation accuracy: {}'.format(eval_results['accuracy']))
print('Evaluation loss: {}'.format(eval_results['loss']))
```

如果一切顺利，程序的输出应该是:

```py
Evaluation accuracy: 0.8137432336807251
Evaluation loss: 1.1235489577054978
```

我们关于 GNN 的讨论到此结束。正如我们提到的，有各种类型的 gnn，我们在这里只包括一小部分。如果你有兴趣了解更多，我建议你参考我们在本节开始时介绍的调查论文，或者在 https://github.com/thunlp/GNNPapers 查看以下与 GNN 相关的论文精选列表。

在下一节中，我们将讨论一种使用外部存储器存储信息的新型神经网络。

<title>Introducing memory-augmented NNs</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# 介绍内存增强的神经网络

我们已经在神经网络中看到了记忆的概念(尽管形式很奇怪)——例如，LSTM 细胞可以在输入门和遗忘门的帮助下添加或删除其隐藏细胞状态的信息。另一个例子是注意机制，其中表示编码的源序列的向量集可以被视为由编码器写入和由解码器读取的外部存储器。但是这种能力有一些限制。首先，编码器只能写入单个内存位置，即序列的当前元素。它也不能更新先前写入的向量。另一方面，解码器只能从数据库中读取，但不能写入数据库。

在这一节中，我们将进一步介绍内存的概念，看看解决这些限制的**内存增强 NNs** ( **MANNs** )。这是一种新的算法类别，仍处于早期阶段，不像更主流的神经网络类型，如卷积和 RNNs，它们已经存在了几十年。我们要讨论的第一个曼网络是神经图灵机。

<title>Neural Turing machines</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# 神经图灵机

曼恩斯的概念最初是随着**神经图灵机** ( **NTM** )的概念引入的(更多信息，请访问【https://arxiv.org/abs/1410.5401】T4)。NTM 有两个组成部分:

*   神经网络控制器。
*   外部存储器，表示为矩阵![](assets/3a804a65-9cd9-4d40-ba70-790164f5d22b.png)。矩阵包含 *n* 行 *d* 维向量。

下图提供了 NTM 架构的概述:

![](assets/63d5e3d7-f148-42f6-b002-0023aba080ea.png)

资料来源:https://arxiv.org/abs/1410.5401 NTM

NTM 以顺序的方式工作(像 RNN 一样)，控制器接受输入向量并产生输出向量作为响应。它还可以在多个并行读/写磁头的帮助下读写内存。

让我们把注意力集中在阅读操作上，这与我们在[第八章](0a021de6-b007-49bf-80e9-b7f6a72cbba7.xhtml)、*序列对序列模型和注意力*中研究的注意机制非常相似。读取头总是读取整个存储矩阵，但它是通过关注具有不同强度的不同存储向量来完成的。为此，读取头发出具有以下约束的 *n* 维向量![](assets/6daa56ae-2570-4259-8817-ab17c4c9ce79.png)(在步骤 *t* ):

![](assets/1814d2d9-a6b2-452d-9a6d-b3bcc602ba3e.png)

![](assets/6d2eb2e7-c39d-4d13-b8bb-caa46bb4c330.png)实现了一种注意机制，其中向量的每个单元 *i* 表示第 *i* 个内存向量(即矩阵 **M** 的第 *i* 行)在形成输出时的权重。在步骤 *t* 的读操作的输出是一个 *d* 维向量**r**t，定义为所有存储器向量的加权和:

![](assets/b280f69c-ef47-48e3-b01b-3aab5fc3bbf2.png)

这种操作类似于我们在[第八章](0a021de6-b007-49bf-80e9-b7f6a72cbba7.xhtml)、*、*、*中讨论的软注意机制的序列对序列模型和注意。*软注意(不同于硬注意)是可微分的，这个操作也是如此。这样，整个 NTM(控制器和存储器)就是一个单可微系统，这使得用梯度下降和反向传播来训练它成为可能。

接下来，让我们关注写操作，它由两个步骤组成:**擦除**之后是**添加**。写磁头发出与读磁头相同类型的注意力矢量![](assets/3f322f02-bf5f-4755-bf19-2a8c6a629a17.png)。它还发出另一个**擦除**向量![](assets/16e529ef-8102-4f10-bd67-49b4debee77d.png)，其值都在(0，1)范围内。我们可以将在步骤 *t* 对存储器的单个行 *i* 的擦除操作定义为这两个向量以及在步骤 *t-1* 、 *![](assets/1615bdc5-cb7e-4add-9413-819093aa8950.png)* 的存储器状态的函数:

![](assets/9ac76018-5dec-4d02-a939-af1502e59eab.png)

这里， **1** 是一个一的 *d* 维向量，并且![](assets/0a454eb0-2060-4036-8808-ec22c05940af.png)和擦除组件之间的乘法是基于元素的。根据这个公式，只有当权重![](assets/b683581b-9d4f-4dbb-a5e9-c31f603969ac.png)和 **e** [* t *] 都不为零时，存储单元才能被擦除。这种机制可以与以任意顺序书写的多个注意头一起工作，因为乘法是可交换的。

擦除操作之后是添加操作。写磁头产生一个**相加**向量![](assets/0e7b6af0-ab80-48ed-ad62-7615fc08410f.png)，该向量在擦除之后被加到存储器，以在步骤 *t* 产生最终的存储器状态:

![](assets/f5634fb9-b32d-4620-9f0c-f6d4fb9ca6dd.png)

我们现在熟悉了读写操作，但我们仍然不知道如何产生注意力向量![](assets/b68175cd-78ce-4ada-844c-77285e9aa0e9.png)(我们将省略上标索引，因为以下描述适用于读写头)。NTM 使用两种互补的寻址机制来做到这一点:基于内容和基于位置。

我们将从基于内容的寻址开始，其中每个磁头(读和写)发出一个键向量![](assets/199a165e-f567-4c4c-8c71-d4ffd10f4489.png)。使用相似性度量![](assets/ccf35344-a461-4be5-8eb0-4adf5effc5ba.png)将该向量与每个内存向量![](assets/1a7e81ac-d914-400e-98d8-a4e4705d0dc9.png)进行比较。NTM 的作者建议使用余弦相似度，定义如下:

![](assets/ff8af2ff-641e-4ad7-a7d7-1e4a2dee9576.png)

然后，我们将基于内容的寻址向量的单个单元定义为所有存储器向量的相似性结果的软最大值:

![](assets/45358260-1d54-47a0-8550-50668fbc10a8.png)

这里，![](assets/25c1dc3b-42fa-4009-8b71-1ce5a3b112d2.png)是标量值键强度，它扩大或缩小焦点的范围。对于小的![](assets/68d864a1-6d82-4cb8-b3e8-8e99f90b6eab.png)值，注意力将分散到所有的记忆向量上，而对于大的![](assets/fd2b11cb-dc95-4bf1-85f3-26254d747cc3.png)，注意力将只集中在最相似的记忆向量上。

《NTM》的作者认为，在一些问题中，基于内容的关注是不够的，因为变量的内容可以是任意的，但它的地址必须是可识别的。他们引用算术问题作为这样一个问题:两个变量， *x* 和 *y，*可以取任意两个值，但是过程 *f(x，y) = x × y* 仍然应该被定义。该任务的控制器可以获取变量 *x* 和 *y* 的值，将它们存储在不同的地址，然后检索它们并执行乘法算法。在这种情况下，变量是按位置寻址的，而不是按内容寻址的，这就引出了基于位置的寻址机制。它适用于随机存取内存跳转和跨位置的简单迭代。它通过将注意力重心向前或向后移动一步来做到这一点。

例如，如果当前权重完全集中在一个位置，旋转 1 会将焦点转移到下一个位置。负偏移会使权重向相反方向移动。

内容和位置寻址结合使用，如下图所示:

![](assets/85a0d3f5-3abe-477a-ad36-8d35cf7cf6d4.png)

寻址机制的流程图。资料来源:https://arxiv.org/abs/1410.5401

让我们一步一步来看看它是如何工作的:

1.  内容寻址基于存储器![](assets/0ca2bba2-b305-4317-be6d-f6fb3f8f4706.png)、密钥向量![](assets/9f276f5b-544b-4fcc-901c-381034e1ce43.png)和密钥强度![](assets/05075069-9a60-4db0-a319-edb925e1bee5.png)产生内容寻址向量![](assets/24698595-cba6-4e49-a5cc-eaa5b7e39db7.png)。
2.  **插值**是位置寻址机制中三个步骤的第一步，它发生在实际的权重移动之前。每个磁头(读或写)在(0，1)范围内发射一个标量**插值门** *g [t]* 。 *g [t]*

![](assets/1b1a66be-56db-4c99-8fbe-eba8c9f4d51a.png)

如果 *g [t] = 0* ，那么我们将完全保留之前的寻址向量。或者，如果 *g [t] = 1* ，我们将只使用基于内容的寻址向量。

3.  下一步是**卷积移位**，它引起插值注意![](assets/2695b5b4-f6e0-4ea2-ad94-4206e85b7c04.png)，并确定如何移位。让我们假设头部注意力可以向前(+1)，向后(-1)，或者保持不变(0)。每个头发出一个偏移加权值*s[t]T6 】,它定义了允许偏移的归一化分布。在这种情况下， *s [ t ]* 将具有三个元素，它们指示执行-1、0 和 1 移位的程度。如果我们假设内存向量索引是从 0 开始的(从 0 到 *n-1* ，那么我们可以将![](assets/f90f0bf5-bcad-43ac-a5d5-907197941f39.png)旋转 *s [ t ]* 定义为循环卷积:*

![](assets/575ed1d9-39a1-487c-83c0-ec259ba0c411.png)

注意，尽管我们迭代了所有的内存索引，但是*s[t]只在允许的位置上有非零值。*

4.  最后的寻址步骤是**锐化**步骤。一方面，在多个方向上以不同程度同时移动的能力的影响是注意力可能会模糊。比如说，我们以 0.6 的概率向前移位(+1)，以 0.2 的概率向后移位(-1)，以 0.2 的概率不移位(0)。当我们应用转移时，最初集中的注意力将在三个位置之间变得模糊。为了解决这个问题，NTM 的作者建议您修改每个头部以发射另一个标量![](assets/d3f6fbce-c18b-4f0e-9827-0f14088edf05.png)，这将使用以下公式锐化最终结果:

![](assets/65574cfa-18eb-4cbe-94c2-3d48206dded0.png)

现在我们知道了寻址是如何工作的，让我们把注意力集中在控制器上，我们可以使用 RNN(例如 LSTM)或 FFN。NTM 的作者认为，LSTM 控制器有内部存储器，这是外部存储器的补充，也允许控制器混合来自多个时间步骤的信息。然而，在 NTM 的情况下，FFN 控制器可以模仿 RNN 控制器，在每一步都在相同的内存位置读写。此外，FFN 更加透明，因为其读/写模式比内部 RNN 状态更容易解释。

该论文的作者说明了 NTM 如何处理几项任务，其中之一是复制操作，其中 NTM 必须复制输入序列作为输出。该任务说明了模型长期存储和访问信息的能力。输入序列具有 1 到 20 之间的随机长度。序列中的每个元素都是一个包含八个二进制元素的向量(代表一个字节)。首先，模型一步一步地处理输入序列，直到到达一个特殊的分隔符。然后，它开始生成输出序列。在生成阶段没有额外的输入，以确保模型可以在没有中间辅助的情况下生成整个序列。作者比较了 NTM 和 LSTM 模型的性能，并指出 NTM 在训练中收敛更快，与 LSTM 相比可以复制更长的序列。基于这些结果，在检查了控制器和记忆的相互作用后，他们得出结论，NTM 不仅仅是记住了输入序列；相反，它学习一种复制算法。我们可以用下面的伪代码来描述算法的操作序列:

![](assets/1caca29c-2202-4f57-b9d7-fe759aca2b8d.png)

https://arxiv.org/abs/1410.5401 的 NTM 模型学习了一种复制算法

接下来，让我们从控制器和内存之间交互的角度来关注复制算法，如下图所示:

![](assets/6ca3e380-8db5-43da-9134-41804d670ece.png)

复制算法期间的控制器/存储器交互；来源:https://arxiv.org/abs/1410.5401

左栏显示输入阶段。左上角的图像表示 8 位二进制向量的输入序列，中间的图像表示添加到内存的向量，左下角的图像表示每一步的内存写注意权重。右栏显示输出相位。右上方的图像表示生成的 8 位二进制向量的输出序列，右中间的图像表示从存储器读取的向量，右下方的图像表示每一步的存储器读取注意权重。底部图像示出了读写操作期间磁头位置的增量偏移。请注意，注意力权重显然集中在一个单一的记忆位置。同时，输入和输出序列在每个时间步长从相同的位置读取，并且读取向量等同于写入向量。这表示输入序列的每个元素都存储在单个存储单元中。

在我们结束本节之前，让我们提一下 NTM 的作者发布了一种改进的内存网络架构，称为**差分神经计算机** ( **DNC** )(更多信息，请参见【https://www.nature.com/articles/nature20101】的*使用具有动态外部内存的神经网络的混合计算*)。与 NTM 相比，DNC 引入了几项改进:

*   该模型仅使用基于内容的寻址(与 NTM 中的内容和位置相反)。
*   该模型使用动态内存分配，通过在链表中添加和删除位置来维护可用内存位置的列表(这仍然是可区分的)。该机制允许模型仅在标记为空闲的位置写入新数据。
*   该模型通过维护关于控制器写入的存储器位置顺序的信息来使用临时存储器链接，这允许它在不同的存储器位置存储顺序数据。

这就结束了我们对 NTM 建筑的描述。在下一节中，我们将讨论在*用记忆增强神经网络进行一次性学习*的论文中介绍的对 NTM 的改进(【https://arxiv.org/abs/1605.06065】T2)。我们将用 MANN*来表示改进的体系结构，以避免与首字母缩写 MANN 混淆，后者指的是一般类型的内存网络。

<title>MANN*</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# 曼*

曼恩*读操作与 NTM 读操作非常相似，除了它不包括密钥强度参数![](assets/8c0a80bc-2768-4808-8e72-f461746e5822.png)。另一方面，MANN*引入了一种新的基于内容的写寻址机制，称为**最近最少使用的访问** ( **LRUA** )，作为组合内容/位置 NTM 寻址机制的替代。LRUA 写操作写入最少使用的内存位置或最近使用的内存位置。实现这一点有两个原因:通过向最少使用的位置写入新存储器来保存最近存储的信息，以及通过向最后使用的位置写入新数据，新信息充当对先前写入状态的一种更新。但是模型如何知道使用两个选项中的哪一个呢？MANN*寻址机制通过引入使用权重向量![](assets/942f9145-7af4-4021-91b2-b8273dc3dbc9.png)在两个选项之间进行插值。通过在步骤 *t-1* 将使用权重![](assets/c3d2a1a3-ef5d-4dbe-a8b7-730b11c08666.png)与当前读写注意权重相加，在每个时间步更新这些权重:

![](assets/2cbd95cb-891b-4356-8f4d-3d5e2c75332b.png)

这里，标量γ是一个衰变参数，它决定了方程的两个分量之间的平衡。MANN*还引入了最近最少使用的权重向量![](assets/d164f3e8-dc60-4160-a78e-948c3fa5e6d3.png)，其中向量的每个元素定义如下:

![](assets/56e10e46-4b66-48f6-b857-36a016d72d29.png)

这里，![](assets/fd4e3e1b-12e6-4f16-b340-f7cce5feb910.png)是向量![](assets/069a6770-86b9-4e68-b663-c171e9c6bf2a.png)的第 *n* 个最小元素， *n* 等于内存读取次数。此时，我们可以计算写入权重，这是读取权重和步骤 *t-1* 中最近最少使用的权重之间的插值:

![](assets/0e93623e-c9b1-448f-a4ef-dc45cd8afea3.png)

这里，σ是 sigmoid 函数，α是可学习的标量参数，指示如何在两个输入权重之间进行平衡。现在，我们可以将新数据写入内存，这分两步完成:第一步是使用权重![](assets/c3d2a1a3-ef5d-4dbe-a8b7-730b11c08666.png)计算最近最少使用的位置。第二步是实际的写作:

![](assets/96e22cde-65e1-45cc-92c2-bde6ce8ebecc.png)

这里，![](assets/a9d608c2-aecf-41f2-9de9-0bdffed8b1aa.png)是我们在讨论 NTM 时定义的关键向量。

MANN*的论文对控制器与输入数据和读/写磁头的交互方式进行了更详细的描述(与 NTM 的原始论文相比)。该论文的作者指出，他们的最佳性能模型使用 LSTM(见[第 7 章](379a4f7b-48da-40f2-99d6-ee57a7a5dcca.xhtml)、*了解递归*、*网络*)控制器。以下是 LSTM 控制器插入曼恩*系统的方式:

*   在步骤 *t* 的控制器输入是连接的向量![](assets/70297af4-5d9d-42f7-978d-154a789d8906.png)，其中![](assets/29facb26-b5e5-4791-b7d2-f46ea48f2edc.png)是输入数据，![](assets/00d06425-4270-48fc-a1f8-38ad093018f3.png)是系统在步骤 *t-1* 的输出。在分类任务中，输出![](assets/45e28d30-ccfd-4c93-9b00-134ae9ad11e1.png)是独热编码的类表示。
*   在步骤 *t* 的控制器输出是级联的![](assets/0d1c22f1-5e92-42ed-a861-30e93b59c749.png)，其中![](assets/da198e0a-707e-4d3a-9631-8823a3723322.png)是 LSTM 单元隐藏状态，![](assets/109f037d-5344-433d-a0b5-8e60125ed09c.png)是读取操作的结果。对于分类任务，我们可以使用![](assets/2672393f-2e20-4718-8c23-0fb701375f61.png)作为具有 softmax 输出的全连接层的输入，从而得到表达式![](assets/bc440539-668c-4312-b516-773202d903cc.png)，其中![](assets/0518e846-b423-4882-9564-61c3c2dca8c8.png)是全连接层权重。
*   用作读/写操作的注意力权重的基础的关键向量![](assets/36e80a51-1d5c-4419-b724-02754ea8fd03.png)是 LSTM 单元状态![](assets/71582670-adc7-4831-a821-11d6edc829bd.png)。

这结束了我们对曼恩斯的讨论，事实上，这一章。

<title>Summary</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# 摘要

在这一章中，我们讨论了两类新兴的神经网络模型——GNNs 和 MANNs。我们从简单介绍图开始，然后我们看了几种不同类型的 GNN，包括 GraphNN、图卷积网络、图注意网络和图自动编码器。我们通过查看 NGL 结束了图表部分，并使用基于 TensorFlow 的 NSL 框架实现了一个 NGL 示例。然后，我们将重点放在内存增强网络上，其中我们研究了 NTM 和曼*架构。

在下一章中，我们将着眼于新兴的元学习领域，它包括让 ML 算法学会学习。******