<link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style00.css" rel="stylesheet" type="text/css"> 

# *第十二章* : PyTorch 和 AutoML

**自动机器学习** ( **AutoML** )为给定的神经网络提供了寻找最佳神经架构和最佳超参数设置的方法。在讨论第五章*混合高级模型*中的`RandWireNN`模型时，我们已经详细介绍了神经架构搜索。

在这一章中，我们将更广泛地了解 PyTorch 的 AutoML 工具—**Auto-py torch**—它执行神经结构搜索和超参数搜索。我们还将看看另一个名为 **Optuna** 的 AutoML 工具，它为 PyTorch 模型执行超参数搜索。

在本章结束时，非专家将能够设计几乎没有领域经验的机器学习模型，专家将大大加快他们的模型选择过程。

本章分为以下几个主题:

*   用 AutoML 寻找最佳神经结构
*   使用 Optuna 进行超参数搜索

# 技术要求

我们将在所有练习中使用 Jupyter 笔记本。下面是本章将要安装的 Python 库的列表，使用`pip`(例如，通过在命令行运行`pip install torch==1.7.0`):

```py
jupyter==1.0.0
```

```py
torch==1.7.0
```

```py
torchvision==0.8.1
```

```py
torchviz==0.0.1
```

```py
autoPyTorch==0.0.2
```

```py
configspace==0.4.12
```

```py
git+https://github.com/shukon/HpBandSter.git
```

```py
optuna==2.2.0
```

注意

在撰写本文时，Auto-PyTorch 在 Linux 和 macOS 中完全受支持。但是，Windows 用户在安装库时可能会遇到问题。因此，建议使用 macOS 或 Linux 来处理 Auto-PyTorch。

与本章相关的所有代码文件可在以下 GitHub 页面获得:[https://GitHub . com/packt publishing/Mastering-py torch/tree/master/chapter 12](https://github.com/PacktPublishing/Mastering-PyTorch/tree/master/Chapter12)。

# 使用 AutoML 寻找最佳神经架构

一种思考机器学习算法的方式是,它们自动化了学习给定输入和输出之间关系的过程。在传统的软件工程中，我们必须以函数的形式明确地编写/编码这些关系，这些函数接受输入并返回输出。在机器学习的世界里，机器学习模型为我们找到了这样的功能。虽然我们在一定程度上实现了自动化，但还有很多事情要做。除了挖掘和清理数据之外，为了获得这些功能，还需要执行一些常规任务:

*   选择机器学习模型(或模型系列，然后是模型)
*   决定模型架构(特别是在深度学习的情况下)
*   选择超参数
*   基于验证集性能调整超参数
*   尝试不同的模型(或模型系列)

这些任务证明了人类机器学习专家的要求。这些步骤中的大多数都是手动的，要么花费大量时间，要么需要大量专业知识来减少所需的时间，并且我们的机器学习专家远远少于创建和部署机器学习模型所需的数量，这些模型在行业和学术界越来越受欢迎，越来越有价值，越来越有用。

这就是 AutoML 出手相救的地方。AutoML 已经成为机器学习领域的一门学科，旨在自动化之前列出的步骤以及其他步骤。

在这一节中，我们将看一下 Auto-PyTorch——一个为使用 py torch 而创建的 AutoML 工具。以练习的形式，我们将找到一个最佳的神经网络以及超参数来执行手写数字分类——这是我们在第一章 、*使用 PyTorch 进行深度学习概述*的 [*中完成的任务。*](B12158_01_Final_ASB_ePUB.xhtml#_idTextAnchor017)

与第一章的不同之处在于，这一次，我们不决定架构或超参数，而是让 Auto-PyTorch 为我们解决这个问题。我们将首先加载数据集，然后定义一个 Auto-PyTorch 模型搜索实例，最后运行模型搜索例程，这将为我们提供一个性能最佳的模型。

工具引用

Auto-py torch([https://github.com/automl/Auto-PyTorch](https://github.com/automl/Auto-PyTorch))*Auto-py torch 表格:高效健壮的多保真元学习 AutoDL* 、*卢卡斯·齐默*、*马里尤斯·林道尔*和*弗兰克·赫特*[https://arxiv.org/abs/2006.13799](https://arxiv.org/abs/2006.13799)

## 使用 Auto-PyTorch 进行最优 MNIST 模型搜索

我们将以 Jupyter 笔记本的形式执行模型搜索。在正文中，我们只展示了代码的重要部分。完整的代码可以在这里找到:

[https://github . com/packt publishing/Mastering-py torch/blob/master/chapter 12/automl-py torch . ipynb](https://github.com/PacktPublishing/Mastering-PyTorch/blob/master/Chapter12/automl-pytorch.ipynb)

### 加载 MNIST 数据集

我们现在将讨论用于逐步加载数据集的代码，如下所示:

1.  First, we import the relevant libraries, like this:

    ```py
    import torch
    from autoPyTorch import AutoNetClassification
    ```

    最后一行非常重要，因为我们在这里导入了相关的 Auto-PyTorch 模块。这将帮助我们设置和执行模型搜索会话。

2.  接下来，我们使用 Torch **应用编程接口**(**API**)加载训练和测试数据集，如下:

    ```py
    train_ds = datasets.MNIST(...)
    test_ds = datasets.MNIST(...)
    ```

3.  然后，我们将这些数据集张量转换成训练和测试输入(`X`)和输出(`y`)数组，就像这样:

    ```py
    X_train, X_test, y_train, y_test = train_ds.data.numpy().reshape(-1, 28*28), test_ds.data.numpy().reshape(-1, 28*28) ,train_ds.targets.numpy(), test_ds.targets.numpy()
    ```

请注意，我们正在将图像整形为大小为 784 的扁平向量。在下一节中，我们将定义一个 Auto-PyTorch 模型搜索器，它期望一个扁平化的特征向量作为输入，因此我们进行整形。

Auto-PyTorch 目前(在撰写本文时)仅分别以`AutoNetClassification`和`AutoNetImageClassification`的形式提供对特征化和图像数据的支持。虽然我们在这个练习中使用特征化的数据，但我们将它作为一个练习留给读者使用图像数据来代替，使用这里的教程:[https://github . com/automl/Auto-py torch/blob/master/examples/basics/Auto-py torch % 20 tutorial . ipynb](https://github.com/automl/Auto-PyTorch/blob/master/examples/basics/Auto-PyTorch%20Tutorial.ipynb)。

### 用自动 PyTorch 运行神经结构搜索

在前面的部分加载了数据集，我们现在将使用 Auto-PyTorch 定义一个模型搜索实例，并使用它来执行神经结构搜索和超参数搜索的任务。我们将如下进行:

1.  This is the most important step of the exercise, where we define an `autoPyTorch` model search instance, like this:

    ```py
    autoPyTorch = AutoNetClassification("tiny_cs",  # config preset
                 log_level='info', max_runtime=2000, min_budget=100, max_budget=1500)
    ```

    这里的配置来自位于[https://github.com/automl/Auto-PyTorch](https://github.com/automl/Auto-PyTorch)的 Auto-PyTorch 库中提供的示例。但一般来说，`tiny_cs`用于更快的搜索，对硬件要求更少。

    预算的争论都是关于对自动 PyTorch 进程的资源消耗设置约束。默认情况下，预算的单位是时间——也就是说，多少**中央处理单元** / **图形处理单元** ( **CPU** / **GPU** )的时间是我们在模型搜索上放心花费的。

2.  After instantiating an Auto-PyTorch model search instance, we execute the search by trying to fit the instance on the training dataset, as follows:

    ```py
    autoPyTorch.fit(X_train, y_train, validation_split=0.1)
    ```

    在内部，Auto-PyTorch 将基于原始论文中提到的方法运行几个不同的模型架构和超参数设置的`trials`，可以在[https://arxiv.org/abs/2006.13799](https://arxiv.org/abs/2006.13799)找到。

    不同的`trials`将针对 10%验证数据集进行基准测试，表现最佳的`trial`将作为输出返回。上述代码片段中的命令应输出以下内容:

    ![Figure 12.1 – Auto-PyTorch model accuracy](Images/B12158_12_01.jpg)

    图 12.1-自动 PyTorch 模型精确度

    *图 12.1* 基本显示了 Auto-PyTorch 为给定任务找到最优的超参数设置——例如，学习率为`0.068`，动量为`0.934`，等等。前面的屏幕截图还显示了所选最佳模型配置的训练和验证集的准确性。

3.  Having converged to an optimal trained model, we can now make predictions on our test set using that model, as follows:

    ```py
    y_pred = autoPyTorch.predict(X_test)print("Accuracy score", np.mean(y_pred.reshape(-1) == y_test))
    ```

    它应该输出类似这样的内容:

![Figure 12.2 – Auto-PyTorch model accuracy](Images/B12158_12_02.jpg)

图 12.2-自动 PyTorch 模型精确度

正如我们所看到的，我们已经获得了一个模型，其测试集性能相当不错，为 96.4%。对于上下文，在这个任务上的随机选择将导致 10%的执行率。我们在没有定义模型架构或超参数的情况下获得了这种良好的性能。在设置较高的预算时，更广泛的搜索可能会导致更好的性能。

此外，性能会因执行搜索的硬件(机器)而异。拥有更多计算能力和内存的硬件可以在相同的时间预算内运行更多的搜索，因此可以带来更好的性能。

### 可视化最佳 AutoML 模型

在这一节中，我们将查看通过运行上一节中的模型搜索例程获得的性能最佳的模型。我们将如下进行:

1.  Having already looked at the hyperparameters in the preceding section, let's look at the optimal model architecture that Auto-PyTorch has devised for us, as follows:

    ```py
    pytorch_model = autoPyTorch.get_pytorch_model()
    print(pytorch_model)
    ```

    它应该输出类似这样的内容:

    ![Figure 12.3 – Auto-PyTorch model architecture](Images/B12158_12_03.jpg)

    图 12.3–自动 PyTorch 模型架构

    模型由一些包含全连接层、批量标准化层和 ReLU 激活的结构化残差块组成。最后，我们看到一个最终的全连接层，有 10 个输出，从 0 到 9 的每个数字一个输出。

2.  We can also visualize the actual model graph using `torchviz`, as shown in the next code snippet:

    ```py
    x = torch.randn(1, pytorch_model[0].in_features)
    y = pytorch_model(x)
    arch = make_dot(y.mean(), params=dict(pytorch_model.named_parameters()))
    arch.format="pdf"
    arch.filename = "convnet_arch"
    arch.render(view=False)
    ```

    这将在当前工作目录中保存一个`convnet_arch.pdf`文件，打开后应该是这样的:

    ![Figure 12.4 – Auto-PyTorch model diagram](Images/B12158_12_04.jpg)

    图 12.4–自动 PyTorch 模型图

3.  To peek into how the model converged to this solution, we can look at the search space that was used during the model-finding process with the following code:

    ```py
    autoPyTorch.get_hyperparameter_search_space()
    ```

    这将输出以下内容:

![Figure 12.5 – Auto-PyTorch model search space](Images/B12158_12_05.jpg)

图 12.5–自动 PyTorch 模型搜索空间

它基本上列出了构建模型所需的各种成分，以及每种成分的分配范围。例如，学习率被分配到从 **0.0001** 到 **0.1** 的范围内，并且该空间以对数标度被采样——这不是线性采样而是对数采样。

在*图 12.1* 中，我们已经看到 Auto-PyTorch 从这些范围中采样的精确超参数值是给定任务的最佳值。我们也可以手动改变这些超参数范围，甚至使用 Auto-PyTorch 模块下的`HyperparameterSearchSpaceUpdates`子模块添加更多超参数。你可以在 https://github.com/automl/Auto-PyTorch#configuration 的 Auto-PyTorch GitHub 文档中找到更多细节。

这就结束了我们对 Auto-py torch——py torch 的一个自动化工具——的探索。我们使用 Auto-PyTorch 成功地建立了一个 MNIST 数字分类模型，无需指定模型结构或超参数。这个练习将帮助你开始使用这个和其他 AutoML 工具，以自动化的方式构建 PyTorch 模型。一些其他类似的工具在此列出:

*   hyperopt:https://github . com/hyperopt/hyperopt
*   曲调:[https://docs.ray.io/en/latest/tune/index.html](https://docs.ray.io/en/latest/tune/index.html)
*   超级搜索:[https://github.com/kevinzakka/hypersearch](https://github.com/kevinzakka/hypersearch)
*   斯科奇:[https://github.com/skorch-dev/skorch](https://github.com/skorch-dev/skorch)
*   https://botorch.org/
*   -= the last fantasy =-荣誉出品本字幕仅供学习交流，严禁用于商业途径

虽然我们无法在本章中涵盖所有这些工具，但在下一节中，我们将讨论 Optuna，这是一个专门致力于寻找一组最佳超参数的工具，它与 PyTorch 配合得很好。

# 使用 Optuna 进行超参数搜索

Optuna 是支持 PyTorch 的超参数搜索工具之一。你可以详细阅读该工具使用的搜索策略，如 *Optuna* 论文中的 **TPE** ( **树形 Parzen 估计**)和 **CMA-ES** ( **协方差矩阵自适应进化策略**)，在[https://arxiv.org/pdf/1907.10902.pdf](https://arxiv.org/pdf/1907.10902.pdf)。除了高级超参数搜索方法之外，该工具还提供了一个简洁的 API，我们稍后将对此进行探讨。

工具引用

Optuna:下一代超参数优化框架。

*秋叶拓哉*、*佐野正太郎*、*柳濑俊彦*、*太田赳*、*小山正典* (2019，在 KDD)。

在本节中，我们将再次构建和训练`MNIST`模型，这一次使用 Optuna 来计算最佳的超参数设置。我们将以练习的形式一步步讨论代码的重要部分。完整的代码可以在这里找到:

[https://github . com/packt publishing/Mastering-py torch/blob/master/chapter 12/optuna _ py torch . ipynb](https://github.com/PacktPublishing/Mastering-PyTorch/blob/master/Chapter12/optuna_pytorch.ipynb)

# 定义模型架构并加载数据集

首先，我们将定义一个符合 Optuna 的模型对象。所谓符合 Optuna，我们是指在 Optuna 提供的模型定义代码中添加 API，以实现模型超参数的参数化。为此，我们将如下进行:

1.  First, we import the necessary libraries, as follows:

    ```py
    import torch
    import optuna
    ```

    在整个练习过程中,`optuna`库将为我们管理超参数搜索。

2.  接下来，我们定义模型架构。因为我们想要灵活地使用一些超参数——比如层数和每层中的单元数——我们需要在模型定义代码中包含一些逻辑。因此，首先，我们已经声明我们需要在`1`到`4`卷积层和`1`到`2`全连接层之间的任何地方，如下面的代码片段所示:

    ```py
    class ConvNet(nn.Module):
        def __init__(self, trial):
            super(ConvNet, self).__init__()
            num_conv_layers =  trial.suggest_int("num_conv_layers", 1, 4)
            num_fc_layers = trial.suggest_int("num_fc_layers", 1, 2)
    ```

3.  We then successively append the convolutional layers, one by one. Each convolutional layer is instantly followed by a `ReLU` activation layer, and for each convolutional layer, we declare the depth of that layer to be between `16` and `64`.

    步幅和填充分别固定为`3`和`True`，然后整个卷积块是，接着是`MaxPool`层，然后是`Dropout`层，丢失概率范围在`0.1`到`0.4`(另一个超参数)之间，如下面的代码片段所示:

    ```py
            self.layers = []
            input_depth = 1 # grayscale image
            for i in range(num_conv_layers):
                output_depth = trial.suggest_int(f"conv_depth_{i}", 16, 64)
                self.layers.append(nn.Conv2d(input_depth, output_depth, 3, 1))
                self.layers.append(nn.ReLU())
                input_depth = output_depth
            self.layers.append(nn.MaxPool2d(2))
            p = trial.suggest_float(f"conv_dropout_{i}", 0.1, 0.4)
            self.layers.append(nn.Dropout(p))
            self.layers.append(nn.Flatten())
    ```

4.  Next, we add a flattening layer so that fully connected layers can follow. We have to define a `_get_flatten_shape` function to derive the shape of the flattening layer output. We then successively add fully connected layers, where the number of units is declared to be between `16` and `64`. A `Dropout` layer follows each fully connected layer, again with the probability range of `0.1` to `0.4`.

    最后，我们添加了一个固定的全连接层，它输出`10`个数字(每个类/数字一个)，后面是一个`LogSoftmax`层。定义了所有的层之后，我们实例化我们的模型对象，如下所示:

    ```py
            input_feat = self._get_flatten_shape()
            for i in range(num_fc_layers):
                output_feat = trial.suggest_int(f"fc_output_feat_{i}", 16, 64)
                self.layers.append(nn.Linear(input_feat, output_feat))
                self.layers.append(nn.ReLU())
                p = trial.suggest_float(f"fc_dropout_{i}", 0.1, 0.4)
                self.layers.append(nn.Dropout(p))
                input_feat = output_feat
            self.layers.append(nn.Linear(input_feat, 10))
            self.layers.append(nn.LogSoftmax(dim=1))
            self.model = nn.Sequential(*self.layers)
        def _get_flatten_shape(self):
            conv_model = nn.Sequential(*self.layers)
            op_feat = conv_model(torch.rand(1, 1, 28, 28))
            n_size = op_feat.data.view(1, -1).size(1)
            return n_size
    ```

    该模型初始化功能以`trial`对象为条件，该对象由 Optuna 提供便利，并将决定我们模型的超参数设置。最后，`forward`方法非常简单，如下面的代码片段所示:

    ```py
        def forward(self, x):
            return self.model(x)
    ```

    因此，我们已经定义了模型对象，现在可以继续加载数据集了。

5.  数据集加载的代码与 [*第 1 章*](B12158_01_Final_ASB_ePUB.xhtml#_idTextAnchor017) 、*使用 PyTorch 进行深度学习概述*中的代码相同，并在下面的代码片段中再次显示:

    ```py
    train_dataloader = torch.utils.data.DataLoader(...)
    test_dataloader = ...
    ```

在这一节中，我们已经成功地定义了参数化的模型对象，并加载了数据集。我们现在将定义模型训练和测试例程，以及优化时间表。

## 定义模型训练程序和优化时间表

模型训练本身涉及到优化器、学习率等超参数。在练习的这一部分，我们将利用 Optuna 的参数化功能定义模型训练程序。我们将如下进行:

1.  首先，我们定义训练程序。同样，代码与我们在 [*第 1 章*](B12158_01_Final_ASB_ePUB.xhtml#_idTextAnchor017) 、*使用 PyTorch 进行深度学习概述*中找到的练习中针对该模型的训练例程代码相同，这里再次显示:

    ```py
    def train(model, device, train_dataloader, optim, epoch):
        for b_i, (X, y) in enumerate(train_dataloader):
            … 
    ```

2.  模型测试程序需要稍微增加。为了按照 Optuna API 的要求进行操作，测试例程需要返回一个模型性能度量——在本例中是精度——以便 Optuna 可以根据这个度量比较不同的超参数设置，如下面的代码片段所示:

    ```py
    def test(model, device, test_dataloader):
        with torch.no_grad():
            for X, y in test_dataloader:
                … 
        accuracy = 100\. * success/ len(test_dataloader.dataset)
        return accuracy
    ```

3.  Previously, we would instantiate the model and the optimization function with the learning rate, and start the training loop outside of any function. But to follow the Optuna API requirements, we do all that under an `objective` function, which takes in the same `trial` object that was fed as an argument to the `__init__` method of our model object.

    这里也需要`trial`对象,因为存在与决定学习率值和选择优化器相关联的超参数，如以下代码片段所示:

    ```py
    def objective(trial):
        model = ConvNet(trial)
        opt_name = trial.suggest_categorical("optimizer", ["Adam", "Adadelta", "RMSprop", "SGD"])
        lr = trial.suggest_float("lr", 1e-1, 5e-1, log=True)
        optimizer = getattr(optim,opt_name)(model.parameters(), lr=lr)    
        for epoch in range(1, 3):
            train(model, device, train_dataloader, optimizer, epoch)
            accuracy = test(model, device,test_dataloader)
            trial.report(accuracy, epoch)
            if trial.should_prune():
                raise optuna.exceptions.TrialPruned()
        return accuracy
    ```

对于每个时期，我们记录由模型测试程序返回的精确度。此外，在每个时期，我们检查我们是否将修剪-也就是说，如果我们将跳过-当前时期。这是 Optuna 提供的另一个功能，用于加快超参数搜索过程，这样我们就不会在糟糕的超参数设置上浪费时间。

## 运行 Optuna 的超参数搜索

在练习的最后部分，我们将实例化一个被称为的 **Optuna 研究**，使用模型定义和训练例程，我们将为给定的模型和给定的数据集执行 Optuna 的超参数搜索过程。我们将如下进行:

1.  Having prepared all the necessary components in the preceding sections, we are ready to start the hyperparameter search process—something that is called a `study` in Optuna terminology. A `trial` is one hyperparameter-search iteration in a `study`. The code can be seen in the following snippet:

    ```py
    study = optuna.create_study(study_name="mastering_pytorch", direction="maximize")
    study.optimize(objective, n_trials=10, timeout=2000)
    ```

    `direction`参数帮助 Optuna 比较不同的超参数设置。因为我们的衡量标准是准确性，所以我们需要`maximize`这个衡量标准。我们允许`study`最多有`2000`秒，或者最多有`10`个不同的搜索——以先完成的为准。前面的命令应该输出以下内容:

    ![Figure 12.6 – Optuna logs](Images/B12158_12_06.jpg)

    图 12.6–Optuna 日志

    正如我们所见，的第三个`trial`是最优的试验，产生了 98.77%的测试集准确率，最后三个`trials`被删减。在日志中，我们还可以看到每个未修剪的`trial`的超参数。对于最优的`trial`，比如有三个卷积层分别有 27、28、46 个特征图，然后有两个全连接层分别有 57、54 个单元/神经元，以此类推。

2.  每个`trial`被赋予一个完成或删减的状态。我们可以用下面的代码来区分它们:

    ```py
    pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]
    ```

3.  And finally, we can specifically look at all the hyperparameters of the most successful `trial` with the following code:

    ```py
    print("results: ")
    trial = study.best_trial
    for key, value in trial.params.items():
        print("{}: {}".format(key, value))
    ```

    您将看到以下输出:

![Figure 12.7 – Optuna optimal hyperparameters](Images/B12158_12_07.jpg)

图 12.7–Optuna 最佳超参数

正如我们所看到的，输出显示了总的`trials`数和成功执行的`trials`数。它进一步向我们展示了最成功的`trial`的模型超参数，如层数、层中神经元的数量、学习速率、优化时间表等等。

这使我们结束了练习。我们已经成功地使用 Optuna 为手写数字分类模型的不同种类的超参数定义了一系列超参数值。使用 Optuna 的超参数搜索算法，我们运行了 10 个不同的`trials`，并设法在其中一个`trials`中获得了 98.77%的最高准确率。来自最成功的`trial`的模型(架构和超参数)可用于大型数据集的训练，从而服务于生产系统。

使用本节中的课程，您可以使用 Optuna 为用 PyTorch 编写的任何神经网络模型找到最佳超参数。如果模型非常大和/或有太多的超参数需要优化，Optuna 也可以以分布式方式使用。你可以在这里阅读更多关于分布式调优的:[https://optuna . readthe docs . io/en/stable/tutorial/004 _ distributed . html # distributed](https://optuna.readthedocs.io/en/stable/tutorial/004_distributed.html#distributed)。

最后，Optuna 不仅支持 PyTorch，还支持其他流行的机器学习库，比如`TensorFlow`、`Sklearn`、`MXNet`等等。

# 总结

在本章中，我们讨论了 AutoML，它旨在提供模型选择和超参数优化的方法。AutoML 对于新手来说很有用，他们不太擅长做出决策，比如在一个模型中放置多少层，使用哪个优化器，等等。AutoML 对于专家来说也是有用的，既可以加速模型训练过程，也可以为给定的任务发现优秀的模型体系结构，这几乎是不可能手工完成的。

我们看了两个可以和 PyTorch 一起使用的不同的 AutoML 工具。首先，我们讨论了 Auto-PyTorch，它既能找到最佳的神经结构，又能找到最佳的超参数设置。我们使用了来自 [*第一章*](B12158_01_Final_ASB_ePUB.xhtml#_idTextAnchor017) 、*使用 PyTorch 进行深度学习概述*的 MNIST 手写数字分类任务，使用 Auto-PyTorch 找到了该任务的最佳模型。我们获得了 96.4%的最高准确率。

接下来，我们探索了 Optuna，这是另一个自动化超参数搜索的 AutoML 工具。我们用这个工具来完成同样的任务。与 Auto-PyTorch 的不同之处在于，我们需要在高层次(层的类型)上手动定义架构；然而，低层细节(层数和单元数)被超参数化。Optuna 给了我们一个表现最好的模型，准确率为 98.77%。

这两个练习都证明了我们可以发现、训练和部署高性能 PyTorch 模型，而无需定义模型架构或超参数值。这打开了许多可能性，我鼓励你在你的一个机器学习项目中尝试 AutoML，让 AutoML 为你找到模型，而不是手动定义它。例如，这可以为您节省几天的时间，这些时间通常花费在不同模型架构的实验上。

在下一章，我们将研究机器学习的另一个越来越重要和关键的方面，尤其是深度学习。我们将仔细研究如何解释 PyTorch 模型产生的输出——这个领域通常被称为模型可解释性或可解释性。