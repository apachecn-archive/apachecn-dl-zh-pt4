<link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style00.css" rel="stylesheet" type="text/css"> 

# *第十三章* : PyTorch 和可交代的 AI

在本书中，我们建立了几个深度学习模型，可以为我们执行不同类型的任务。例如，手写数字分类器、图像字幕生成器、情感分类器等等。虽然我们已经掌握了如何使用 PyTorch 训练和评估这些模型，但我们不知道在这些模型进行预测时，它们内部究竟发生了什么。模型可解释性或可解释性是机器学习领域，我们的目标是回答这样一个问题，为什么模型会做出这样的预测？更详细地说，模型在输入数据中看到了什么来做出特定的预测？

在本章中，我们将使用第一章 *【使用 PyTorch 的深度学习概述】中的 [*手写数字分类模型，来理解其内部工作原理，并由此解释为什么该模型对给定的输入做出某种预测。我们将首先只使用 PyTorch 代码来剖析这个模型。然后，我们将使用一个专门的模型可解释性工具包，称为 **Captum** ，来进一步研究模型内部发生了什么。Captum 是 PyTorch 的专用第三方库，为深度学习模型提供模型可解释性工具，包括基于图像和文本的模型。*](B12158_01_Final_ASB_ePUB.xhtml#_idTextAnchor017)*

本章应该为你提供揭示深度学习模型内部的必要技能。以这种方式查看模型内部可以帮助您推断模型的预测行为。在本章结束时，你将能够利用实际操作经验，开始使用 PyTorch(和 Captum)解释你自己的深度学习模型。

本章分为以下几个主题:

*   PyTorch 中的模型可解释性
*   使用 Captum 解释模型

# 技术要求

我们将在所有练习中使用 Jupyter 笔记本。下面是使用`pip`应该为本章安装的 Python 库的列表。例如，在命令行上运行`pip install torch==1.4.0`:

```
jupyter==1.0.0
```

```
torch==1.4.0
```

```
torchvision==0.5.0 matplotlib==3.1.2
```

```
captum==0.2.0
```

与本章相关的所有代码文件均可在[https://github . com/packt publishing/Mastering-py torch/tree/master/chapter 13](https://github.com/PacktPublishing/Mastering-PyTorch/tree/master/Chapter13)处获得。

# PyTorch 中的模型可解释性

在本节中，我们将以练习的形式使用 PyTorch 剖析一个经过训练的手写数字分类模型。更准确地说，我们将查看经过训练的手写数字分类模型的卷积层的细节，以了解该模型正在从手写数字图像中学习什么视觉特征。我们将看看卷积滤波器/内核以及这些滤波器产生的特征图。

这些细节将有助于我们理解模型如何处理输入图像，从而做出预测。练习的完整代码可以在[https://github . com/packt publishing/Mastering-py torch/blob/master/chapter 13/py torch _ interpretatibility . ipynb](https://github.com/PacktPublishing/Mastering-PyTorch/blob/master/Chapter13/pytorch_interpretability.ipynb)找到。

## 训练手写数字分类器——概述

我们将快速地回顾一下在训练手写数字分类模型中涉及的步骤，如下所示:

1.  首先，我们导入相关的库，然后设置随机种子，以便能够重现本练习的结果:

    ```
    import torch
    np.random.seed(123)
    torch.manual_seed(123)
    ```

2.  接下来，我们将定义模型架构:

    ```
    class ConvNet(nn.Module):
        def __init__(self):
        def forward(self, x):
    ```

3.  接下来，我们将定义模型训练和测试例程:

    ```
    def train(model, device, train_dataloader, optim,  epoch):
    def test(model, device, test_dataloader):
    ```

4.  然后我们定义训练和测试数据集加载器:

    ```
    train_dataloader = torch.utils.data.DataLoader(...)
    test_dataloader = torch.utils.data.DataLoader(...)
    ```

5.  接下来，我们实例化我们的模型并定义优化时间表:

    ```
    device = torch.device("cpu")
    model = ConvNet()
    optimizer = optim.Adadelta(model.parameters(), lr=0.5)
    ```

6.  Finally, we start the model training loop where we train our model for 20 epochs:

    ```
    for epoch in range(1, 20):
        train(model, device, train_dataloader, optimizer, epoch)
        test(model, device, test_dataloader)
    ```

    这将输出以下内容:

    ![Figure 13.1 – Model training logs
    ](Images/Figure_13.1_B12158.jpg)

    图 13.1–模型培训日志

7.  Finally, we can test the trained model on a sample test image. The sample test image is loaded as follows:

    ```
    test_samples = enumerate(test_dataloader)
    b_i, (sample_data, sample_targets) = next(test_samples)
    plt.imshow(sample_data[0][0], cmap='gray', interpolation='none')
    plt.show()
    ```

    这将输出以下内容:

    ![Figure 13.2 – An example of a handwritten image
    ](Images/Figure_13.2_B12158.jpg)

    图 13.2–手写图像示例

8.  Then, we use this sample test image to make a model prediction, as follows:

    ```
    print(f"Model prediction is : {model(sample_data).data.max(1)[1][0]}")
    print(f"Ground truth is : {sample_targets[0]}")
    ```

    这将输出以下内容:

![Figure 13.3 – Model prediction
](Images/Figure_13.3_B12158.jpg)

图 13.3–模型预测

因此，我们训练了一个手写数字分类模型，并使用它对样本图像进行推理。我们现在将看看训练模型的内部。我们还将研究这个模型学习了哪些卷积滤波器。

## 可视化模型的卷积滤波器

在这一部分中，我们将通过训练模型的卷积层查看，并查看模型在训练期间学习的过滤器。这将告诉我们卷积层是如何对输入图像进行操作的，提取了哪些类型的特征，等等:

1.  First, we need to obtain a list of all the layers in the model, as follows:

    ```
    model_children_list = list(model.children())
    convolutional_layers = []
    model_parameters = []
    model_children_list
    ```

    这将输出以下内容:

    ![Figure 13.4 – Model layers
    ](Images/Figure_13.4_B12158.jpg)

    图 13.4–模型层

    可以看到，有两个卷积层都有 3×3 大小的滤波器。第一卷积层使用 **16** 这样的滤波器，而第二卷积层使用 **32** 。在本练习中，我们将重点放在可视化卷积层上，因为它们在视觉上更直观。但是，您也可以通过可视化其他图层(如线性图层)的已知权重来探索这些图层。

2.  Next, we select only the convolutional layers from the model and store them in a separate list:

    ```
    for i in range(len(model_children_list)):
        if type(model_children_list[i]) == nn.Conv2d:
            model_parameters.append(model_children_list[i].w      eight)
            convolutional_layers.append(model_children_list[i])
    ```

    在这个过程中，我们还确保存储每个卷积层中学习到的参数或权重。

3.  We are now ready to visualize the learned filters of the convolutional layers. We begin with the first layer, which has 16 filters of size 3x3 each. The following code visualizes those filters for us:

    ```
    plt.figure(figsize=(5, 4))
    for i, flt in enumerate(model_parameters[0]):
        plt.subplot(4, 4, i+1)
        plt.imshow(flt[0, :, :].detach(), cmap='gray')
        plt.axis('off')
    plt.show()
    ```

    这将输出以下内容:

    ![Figure 13.5 – The first convolutional layer's filters
    ](Images/Figure_13.5_B12158.jpg)

    图 13.5–第一个卷积层的过滤器

    首先，我们可以看到所有学习过的过滤器彼此略有不同，这是一个好迹象。这些过滤器内部通常有对比值，这样当在图像周围卷积时，它们可以提取一些类型的梯度。在模型推断过程中，这 16 个过滤器中的每一个都独立地对输入灰度图像进行操作，并产生 16 个不同的特征图，我们将在下一节中对其进行可视化。

4.  Similarly, we can visualize the 32 filters learned in the second convolutional layer using the same code, as in the preceding step, but with the following change:

    ```
    plt.figure(figsize=(5, 8))
    for i, flt in enumerate(model_parameters[1]):
    plt.show()
    ```

    这将输出以下内容:

![Figure 13.6 – The second convolutional layer's filters
](Images/Figure_13.6_B12158.jpg)

图 13.6–第二个卷积层的过滤器

同样，我们有 32 个不同的过滤器/内核，它们具有旨在从图像中提取梯度的对比值。这些滤波器已经应用于第一个卷积层的输出，因此产生了更高级别的输出特征图。具有多个卷积层的 CNN 模型的通常目标是不断产生越来越复杂或更高级别的特征，这些特征可以表示复杂的视觉元素，例如脸上的鼻子、路上的交通灯等等。

接下来，我们将看看这些滤波器对给定输入进行运算/卷积时，卷积层会产生什么结果。

## 可视化模型的特征图

在本节中，我们将通过卷积层运行一个样本手写图像，并可视化这些层的输出:

1.  First, we need to gather the results of every convolutional layer output in the form of a list, which is achieved using the following code:

    ```
    per_layer_results = [convolutional_layers[0](sample_data)]
    for i in range(1, len(convolutional_layers)):
        per_layer_results.append(convolutional_layers[i](per_layer_results[-1]))
    ```

    注意，我们分别调用每个卷积层的前向传递，同时确保第 *n* 个卷积层接收第( *n-1* 个卷积层的输出作为输入。

2.  We can now visualize the feature maps produced by the two convolutional layers. We will begin with the first layer by running the following code:

    ```
    plt.figure(figsize=(5, 4))
    layer_visualisation = per_layer_results[0][0, :, :, :]
    layer_visualisation = layer_visualisation.data
    print(layer_visualisation.size())
    for i, flt in enumerate(layer_visualisation):
        plt.subplot(4, 4, i + 1)
        plt.imshow(flt, cmap='gray')
        plt.axis("off")
    plt.show()
    ```

    这将输出以下内容:

    ![Figure 13.7 – The first convolutional layer's feature maps
    ](Images/Figure_13.7_B12158.jpg)

    图 13.7-第一个卷积层的特征图

    数字 **(16，26，26)** 表示第一卷积层的输出尺寸。本质上，样本图像大小是(28，28)，滤波器大小是(3，3)，并且没有填充。因此，得到的特征映射大小将是(26，26)。因为16 个滤镜产生的这样的特征图有 16 个(请参考*图 13.5* )，所以整体输出维数为(16，26，26)。

    如您所见，每个过滤器从输入图像中产生一个特征图。此外，每个特征图表示图像中不同的视觉特征。例如，左上角的特征图实质上反转了图像中的像素值(请参考*图 13.2* )，而右下角的特征图代表某种形式的边缘检测。

    然后，这 16 个特征映射被传递到第二卷积层，在第二卷积层，另外 32 个滤波器分别对这 16 个特征映射进行卷积，以产生 32 个新的特征映射。我们接下来会看看这些。

3.  We can use the same code as the preceding one with minor changes (as highlighted in the following code) to visualize the 32 feature maps produced by the next convolutional layer:

    ```
    plt.figure(figsize=(5, 8))
    layer_visualisation = per_layer_results[1][0, :, :, :]
        plt.subplot(8, 4, i + 1)
    plt.show()
    ```

    这应该输出以下:

![Figure 13.8 – The second convolutional layer's feature maps
](Images/Figure_13.8_B12158.jpg)

图 13.8–第二个卷积层的特征图

与早期的 16 个特征地图相比，这 32 个特征地图显然更加复杂。他们似乎不仅仅做边缘检测，这是因为他们已经在第一个卷积层的输出上操作，而不是原始输入图像。

在该模型中，2 个卷积层之后是 2 个线性层，分别具有(4，608x64)和(64x10)个参数。虽然线性层权重也有助于可视化，但从视觉上来看，参数的数量(4，608x64)太多了。因此，在本节中，我们将只对卷积权重进行直观分析。

令人欣慰的是，我们有更多复杂的方法来解释模型预测，而不必查看如此大量的参数。在下一节中，我们将探索 Captum，这是一个机器学习模型可解释性工具包，它与 PyTorch 一起工作，并帮助我们在几行代码内解释模型决策。

# 使用 Captum 解释模型

Captum([https://captum.ai/](https://captum.ai/))是一个由脸书在 PyTorch 之上构建的开源模型可解释性库，它目前(在撰写本文时)正在积极开发中。在本节中，我们将使用我们在上一节中训练的手写数字分类模型。我们还将使用 Captum 提供的一些模型可解释性工具来解释该模型做出的预测。以下练习的完整代码可以在这里找到:[https://github . com/packt publishing/Mastering-py torch/blob/master/chapter 13/captum _ interpretatibility . ipynb](https://github.com/PacktPublishing/Mastering-PyTorch/blob/master/Chapter13/captum_interpretability.ipynb)。

## 设置 Captum

模型训练代码类似于*训练手写数字分类器——概述*部分中显示的代码。在下面的步骤中，我们将使用训练好的模型和样本图像来了解模型内部发生的情况，同时对给定的图像进行预测:

1.  为了使用 Captum 的内置模型可解释性函数，我们需要执行一些与 Captum 相关的额外导入:

    ```
    from captum.attr import IntegratedGradients	
    from captum.attr import Saliency
    from captum.attr import DeepLift
    from captum.attr import visualization as viz
    ```

2.  In order to do a model forward pass with the input image, we reshape the input image to match the model input size:

    ```
    captum_input = sample_data[0].unsqueeze(0)
    captum_input.requires_grad = True
    ```

    根据 Captum 的要求，输入张量(图像)需要参与梯度计算。因此，我们将`requires_grad`标志设置为`True`的输入。

3.  Next, we prepare the sample image to be processed by the model interpretability methods using the following code:

    ```
    orig_image = np.tile(np.transpose((sample_data[0].cpu().detach().numpy() / 2) + 0.5, (1, 2, 0)), (1,1,3))
    _ = viz.visualize_image_attr(None, orig_image, cmap='gray', method="original_image", title="Original Image")
    ```

    这将输出以下内容:

![Figure 13.9 – The original image
](Images/Figure_13.09_B12158.jpg)

图 13.9–原始图像

我们已经在深度维度上平铺了灰度图像，以便它可以被 Captum 方法使用，该方法需要一个 3 通道图像。

接下来，我们将通过预训练的手写数字分类模型，将 Captum 的一些可解释性方法实际应用于准备好的灰度图像的正向传递。

## 探索 Captum 的可解释性工具

在这一部分，我们将看看 Captum 提供的一些模型可解释性方法。

解释模型结果的最基本方法之一是查看显著性，显著性表示输出(本例中为 0 类)相对于输入(即输入图像像素)的梯度。特定输入的梯度越大，该输入就越重要。你可以在[https://arxiv.org/pdf/1312.6034.pdf](https://arxiv.org/pdf/1312.6034.pdf)的原始显著性论文中读到更多关于这些梯度是如何精确计算的。Captum 提供了显著性方法的实现:

1.  In the following code, we use Captum's `Saliency` module to compute the gradients:

    ```
    saliency = Saliency(model)
    gradients = saliency.attribute(captum_input, target=sample_targets[0].item())
    gradients = np.reshape(gradients.squeeze().cpu().detach().numpy(), (28, 28, 1))
    _ = viz.visualize_image_attr(gradients, orig_image, method="blended_heat_map", sign="absolute_value",
    show_colorbar=True, title="Overlayed Gradients")
    ```

    这应该输出以下内容:

    ![Figure 13.10 – Overlayed gradients
    ](Images/Figure_13.10_B12158.jpg)

    图 13.10–重叠渐变

    在前面的代码中，我们将获得的渐变调整为大小`(28,28,1)`，以便将它们覆盖在原始图像上，如前面的图表所示。Captum 的`viz`模块为我们处理可视化。我们可以使用下面的代码，在没有原始图像的情况下，只进一步可视化渐变:

    ```
    plt.imshow(np.tile(gradients/(np.max(gradients)), (1,1,3)));
    ```

    我们将获得以下输出:

    ![Figure 13.11 – Gradients
    ](Images/Figure_13.11_B12158.jpg)

    图 13.11–梯度

    正如您所看到的，渐变遍布图像中可能包含数字`0`的像素区域。

2.  Next, using a similar code fashion, we will look at another interpretability method – integrated gradients. With this method, we will look for **feature attribution** or **feature importance**. That is, we'll look for what pixels are important to use when making predictions. Under the integrated gradients technique, apart from the input image, we also need to specify a baseline image, which is usually set to an image with all of the pixel values set to zero.

    然后相对于输入图像沿着从基线图像到输入图像的路径计算梯度积分。集成梯度技术的实现细节可以在 https://arxiv.org/abs/1703.01365 的[原始论文中找到。以下代码使用 Captum 的`IntegratedGradients`模块得出每个输入图像像素的重要性:](https://arxiv.org/abs/1703.01365)

    ```
    integ_grads = IntegratedGradients(model)
    attributed_ig, delta=integ_grads.attribute(captum_input, target=sample_targets[0], baselines=captum_input * 0, return_convergence_delta=True)
    ```

    attributed _ ig = NP . shape(attributed _ ig . squeeze()。cpu()。分离()。numpy()，(28，28，1))

    ```
    _ = viz.visualize_image_attr(attributed_ig, orig_image, method="blended_heat_map",sign="all",show_colorbar=True, title="Overlayed Integrated Gradients")
    ```

    此应输出以下内容:

    ![Figure 13.12 – Overlayed integrated gradients
    ](Images/Figure_13.12_B12158.jpg)

    图 13.12–叠加的综合梯度

    正如所料，包含数字`0`的像素区域中的梯度很高。

3.  Finally, we will look at yet another gradient-based attribution technique, called **deeplift**. Deeplift also requires a baseline image besides the input image. Once again for the baseline, we use an image with all the pixel values set to zero. Deeplift computes the change in non-linear activation outputs with respect to the change in input from the baseline image to the input image (*Figure 13.9*). The following code uses the `DeepLift` module provided by Captum to compute the gradients and displays these gradients overlayed on the original input image:

    ```
    deep_lift = DeepLift(model)
    attributed_dl = deep_lift.attribute(captum_input, target=sample_targets[0], baselines=captum_input * 0, return_convergence_delta=False)
    ```

    attributed _ dl = NP . shape(attributed _ dl . squeeze(0))。cpu()。分离()。numpy()，(28，28，1))

    ```
    _ = viz.visualize_image_attr(attributed_dl, orig_image, method="blended_heat_map",sign="all",show_colorbar=True, title="Overlayed DeepLift")
    ```

    您应该会看到以下输出:

![Figure 13.13 – Overlayed deeplift
](Images/Figure_13.13_B12158.jpg)

图 13.13–重叠的深度提升

同样，包含数字`0`的像素周围的梯度值是极端的。

这就把我们带到了本练习和本部分的结尾。Captum 提供的模型可解释性技术更多，比如*层导*、 *GradCAM* 、 *SHAP* 。你可以在 https://captum.ai/docs/algorithms 阅读更多关于这些技术的内容。模型可解释性是一个活跃的研究领域，因此像 Captum 这样的库可能会迅速发展。在不久的将来，可能会开发更多这样的库，这将使我们能够将模型可解释性作为机器学习生命周期的标准组件。

# 总结

在这一章中，我们简要探讨了如何使用 PyTorch 解释或解读深度学习模型做出的决策。以手写数字分类模型为例，我们首先揭示了 CNN 模型卷积层的内部工作原理。我们演示了如何可视化卷积层产生的卷积滤波器和特征图。

然后，我们使用了基于 PyTorch 的专用第三方模型可解释性库，名为 Captum。我们使用 Captum 提供的现成实现来实现特征属性技术，如显著性、集成渐变和深度提升。使用这些技术，我们演示了模型如何使用输入进行预测，以及输入的哪些部分对模型进行预测更重要。

在本书的下一章，也是最后一章，我们将学习如何在 PyTorch 上快速训练和测试机器学习模型——这是一种用于快速迭代各种机器学习想法的技能。我们还将讨论一些深度学习库和框架，它们支持使用 PyTorch 进行快速原型开发。