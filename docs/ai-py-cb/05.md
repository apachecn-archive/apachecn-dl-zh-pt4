<title>Heuristic Search Techniques and Logical Inference</title> <link rel="stylesheet" href="css/style.css" type="text/css">  Heuristic Search Techniques and Logical Inference

在这一章中，我们将介绍一系列解决问题的工具。我们将从本体和基于知识的推理开始，然后在**布尔可满足性** ( **SAT** )和组合优化的背景下继续优化，在这里我们将模拟社会中个人行为和协调的结果。最后，我们将实现蒙特卡罗树搜索来寻找象棋中的最佳走法。

我们将在本章中讨论各种技术，包括逻辑解算器、图嵌入、**遗传算法** ( **GA** )、**粒子群优化** ( **PSO** )、SAT 解算器、**模拟退火** ( **SA** )、蚁群优化、多代理系统和蒙特卡罗树搜索。

在本章中，我们将介绍以下配方:

*   基于知识做出决策
*   解决 n 皇后问题
*   寻找最短的公交路线
*   模拟疾病的传播
*   用蒙特卡罗树搜索编写象棋引擎

我们开始吧！

# 基于知识做出决策

当关于一个话题有很多背景知识时，为什么不在做决定时使用它呢？这被称为基于知识的系统。专家系统中的推理机和逻辑解算器中的统一就是这样的例子。

另一种在决策时检索知识的方法是基于在图形中表示知识。图中的每个节点代表一个概念，而每条边代表一种关系。两者都可以嵌入并表示为数字特征，表示它们相对于图形其他元素的位置。

在这个食谱中，我们将通过两个例子来说明每种可能性。

From Aristotle to Linnaeus to today's mathematicians and physicists, people have tried to put order into the world by categorizing objects into a systematic order, called taxonomy. Mathematically, taxonomies are expressed as graphs, which represent information as tuples *(s, o),* in that subject s which is connected to object o; or triplets *(s, p, o)*, in that *a* is related to (a predicate of) *p* to *o*. A frequently used type of taxonomy is the ISA taxonomy, where relationships are of the type is*-a*. For example, a car is a vehicle, and a plane is also a vehicle.

## 做好准备

在这个菜谱中，我们将使用从 Python 的`nltk` ( **自然语言工具包**)库接口的逻辑解算器，然后使用称为`networkx`和`karateclub`的图形库。

下载这些库需要使用的`pip`命令如下:

```py
pip install nltk karateclub networkx
```

对于这个食谱的第二部分，我们还需要从 Kaggle 下载动物园数据集，可以在[https://www.kaggle.com/uciml/zoo-animal-classification](https://www.kaggle.com/uciml/zoo-animal-classification)获得。

## 怎么做...

正如我们在这个食谱的介绍中所解释的，我们将从两种不同的方法来看两个不同的问题。

我们将从使用逻辑解算器的逻辑推理开始。

### 逻辑推理

在这个菜谱的这一部分，我们将看一个使用与`nltk`库捆绑在一起的库进行逻辑推理的简单例子。还有许多其他方法来实现逻辑推理，其中一些我们将在*中看到...*本食谱末尾一节。

我们将使用一个非常简单的玩具问题，你可以在任何一本*101-逻辑介绍*书中找到，尽管可以采用更复杂的方法来解决这类问题。

我们的问题是众所周知的:如果所有的人都会死，苏格拉底是人，那么苏格拉底也会死吗？

我们可以在`nltk`中非常自然地表达这一点，如下所示:

```py
from nltk import *
from nltk.sem import Expression

p1 = Expression.fromstring('man(socrates)')
p2 = Expression.fromstring('all x.(man(x) -> mortal(x))')
c = Expression.fromstring('mortal(socrates)')
ResolutionProver().prove(c, [p1, p2], verbose=True)
```

前面的代码给出了以下输出:

```py
[1] {-mortal(socrates)}     A 
[2] {man(socrates)}         A 
[3] {-man(z2), mortal(z2)}  A 
[4] {-man(socrates)}        (1, 3) 
[5] {mortal(socrates)}      (2, 3) 
[6] {}                      (1, 5) 
True
```

求解器提供的推理也可以自然读出，这里就不解释这个了。我们将在*工作原理中了解它的内部工作原理...*一节。

接下来，我们将看看知识嵌入。

### 知识嵌入

在这个食谱的这一部分，我们将通过把信息嵌入到一个多维空间来尝试利用信息是如何相互关联的，这个多维空间可以作为特征化的一部分。

在这里，我们将加载数据，预处理数据，嵌入数据，然后根据物种的新特性，通过对物种进行分类来测试我们的嵌入。让我们开始吧:

1.  **数据集加载和预处理**:首先，我们将动物园数据集加载到熊猫中，就像我们已经做了很多次的那样。然后，我们将确保二进制列被表示为`bool`而不是`int`:

```py
import pandas as pd
zoo = pd.read_csv('zoo.csv')
binary_cols = zoo.columns[zoo.nunique() == 2]
for col in binary_cols:
    zoo[col] = zoo[col].astype(bool)
labels = [
    'Mammal', 'Bird', 'Reptile',
    'Fish', 'Amphibian', 'Bug',
    'Invertebrate'
]
training_size = int(len(zoo) * 0.8)
```

动物园数据集包含 101 种动物，每种动物都有描述其是否有毛发或产奶的特征。这里，目标类是动物的生物类。

2.  **图形嵌入**:`get_triplet()`函数返回格式为( *s* ， *p* ， *o* )的二进制和整数元素的三元组。注意，我们从完整的数据集创建三元组，而不仅仅是训练数据集。然而，为了避免目标泄漏，我们不从目标为训练集之外的数据点创建三元组:

```py
all_labels = { i+1: c for i, c in enumerate(labels) }
cols = list(zoo.columns)

triplets = []
def get_triplet(row, col):
    if col == 'class_type':
        return (
            all_labels[row[col]],
            'is_a',
            row['animal_name'],
        )
    # int properties:
    if col in ['legs']:
        #if row[col] > 0:
        return (
            row['animal_name'],
            'has' + col,
            str(row[col]) + '_legs'
        )
        #else:
        # return ()
    # binary properties:
    if row[col]:
        return (
            row['animal_name'],
            'has',
            str(col)
        )
    else:
        return ()

for i, row in zoo.iterrows():
    for col in cols:
        if col == 'animal_name':
            continue
        if col == 'class_type' and i > training_size:
                continue
        triplet = get_triplet(row, col)
        if triplet:
            triplets.append(triplet)
```

前面的代码将创建我们的三胞胎。让我们来看看其中的一些，了解一下它们的样子。以下是我们得到的前 20 个条目；我们使用`triplets[:20]`来获得它们:

```py
[('aardvark', 'has', 'hair'),
 ('aardvark', 'has', 'milk'),
 ('aardvark', 'has', 'predator'),
 ('aardvark', 'has', 'toothed'),
 ('aardvark', 'has', 'backbone'),
 ('aardvark', 'has', 'breathes'),
 ('aardvark', 'haslegs', '4_legs'),
 ('aardvark', 'has', 'catsize'),
 ('Mammal', 'is_a', 'aardvark'),
 ('antelope', 'has', 'hair'),
 ('antelope', 'has', 'milk'),
 ('antelope', 'has', 'toothed'),
 ('antelope', 'has', 'backbone'),
 ('antelope', 'has', 'breathes'),
 ('antelope', 'haslegs', '4_legs'),
 ('antelope', 'has', 'tail'),
 ('antelope', 'has', 'catsize'),
 ('Mammal', 'is_a', 'antelope'),
 ('bass', 'has', 'eggs'),
 ('bass', 'has', 'aquatic')]
```

前面的代码块显示了几个结果三元组的例子。总共，我们得到了 101 行中的 842 个三元组。

现在，我们可以使用`networkx` API 将这个数据集加载到一个图表中:

```py
import networkx as nx

class Vocabulary:
    label2id = {}
    id2label = {}
    def lookup(self, word):
        """get word id; if not present, insert"""
        if word in self.label2id:
            return self.label2id[word]
        ind = len(self.label2id)
        self.label2id[word] = ind
        return ind

    def inverse_lookup(self, index):
        if len(self.id2label) == 0:
            self.id2label = {
                ind: label
                for label, ind in self.label2id.items()
            }
        return self.id2label.get(index, None)

vocab = Vocabulary()
nx_graph = nx.Graph()
for (a, p, b) in triplets:
    id1, id2 = vocab.lookup(a), vocab.lookup(b)
    nx_graph.add_edge(id1, id2)
```

`Vocabulary`类是`label2id`和`id2label`字典的包装器。我们需要这样做，因为一些图形嵌入算法不接受节点或关系的字符串名称。在这里，我们将概念标签转换成 id，然后将它们存储在图中。

现在，我们可以用不同的算法在数字上嵌入图形。我们将在这里使用`Walklets`:

```py
from karateclub.node_embedding.neighbourhood import Walklets

model_w = Walklets(dimensions=5)
model_w.fit(nx_graph)
embedding = model_w.get_embedding()
```

前面的代码显示，图中的每个概念都将由一个 5 维向量表示。

现在，我们可以测试这些特征对于预测目标(`the animal`)是否有用:

```py
trainamals = [
    vocab.label2id[animal]
    for animal in zoo.animal_name.values[:training_size]
]
testimals = [
    vocab.label2id[animal]
    for animal in zoo.animal_name.values[training_size:]
]
clf = SVC(random_state=42)
clf.fit(embedding[trainamals, :], zoo.class_type[:training_size])

test_labels = zoo.class_type[training_size:]
test_embeddings = embedding[testimals, :]
print(end='Support Vector Machine: Accuracy: ')
print('{:.3f}'.format(
  accuracy_score(test_labels, clf.predict(test_embeddings)
))
print(confusion_matrix(test_labels, clf.predict(test_embeddings)))
```

输出如下所示:

```py
Support Vector Machine: Accuracy = 0.809
[[5 0 0 0 0 0 0]
 [0 4 0 0 0 0 0]
 [2 0 0 1 0 0 0]
 [0 0 0 3 0 0 0]
 [1 0 0 0 0 0 0]
 [0 0 0 0 0 2 0]
 [0 0 0 0 0 0 3]]
```

这看起来很好，尽管只有当我们有一个超出我们训练范围的知识库时，这项技术才变得真正有趣。如果不加载数百万个三元组或巨大的图，很难显示图嵌入。我们将在下一节提到几个大型知识库。

## 它是如何工作的...

在这一节中，我们将看看这个食谱背后的基本概念，以及它相应的方法。首先，我们将讨论逻辑推理和逻辑证明，然后再看 Walklets 中的知识嵌入和图形嵌入。

### 逻辑推理

逻辑推理是一个连接逻辑推理技术的术语，如演绎、归纳和溯因推理。**溯因推理**，常用于专家系统，是检查可获得的观察值并从中得出可能的结论(T2 最佳解释)的过程。

An expert system is a reasoning system that emulates the decision-making abilities of human experts. Expert systems are designed to solve complex problems by reasoning through bodies of knowledge, represented mainly as if-then-else rules (this is called a **knowledge base**).

**归纳推理**是关于在遵循初始前提和规则的情况下确定结论。在**演绎推理**中，我们从观察中推断出一条规则。

为了应用逻辑推理，语言陈述必须被编码为格式良好的逻辑公式，以便我们可以应用逻辑演算。格式良好的公式可以包含以下实体:

*   谓词符号如 *P*
*   ![](assets/545096dd-fa85-4d9d-a871-cdefbe354cef.png)等号
*   否定，![](assets/53c24013-9588-4000-a136-097c75269a05.png)
*   二元连接词，如![](assets/98e2563b-94db-4ae8-afc4-4f8657c8ae33.png)
*   量词如![](assets/75440140-643f-4d1a-a844-d114521c3111.png)(表示全部)![](assets/0bf2d4e5-1c93-4fdb-8686-ab6e6004fc8d.png)(存在)。

例如，苏格拉底是男人的推理。人终有一死。因此，苏格拉底是凡人，可以用命题逻辑表达为一个逻辑陈述，如下:

![](assets/d8ac40e5-3dcc-4ed0-b84b-bcdf306724c8.png)

接下来，我们将看看逻辑证明。

### 逻辑证明者

自动定理证明是一个广泛的领域，包括基于逻辑定理和数学公式的工作。我们已经看了证明由逻辑方程组成的一阶逻辑方程的问题。搜索算法与逻辑方程相结合，从而可以决定命题公式的可满足性(参见本章中的*解决 n 皇后问题*方法)，以及给定一组公理的句子的有效性。`nltk`中的*归结定理证明器*提供了其他功能，如统一、包含、**问答**(**QA**):[http://www.nltk.org/howto/resolution.html](http://www.nltk.org/howto/resolution.html)。

在下一小节中，我们将看看知识嵌入。

### 知识嵌入

一个**知识嵌入** ( **可**)指的是从它们的关系中导出的概念的分布式表示。这些通常用一个**知识图** ( **KG** )来表示。

一个众所周知的 KG 的例子是 **WordNet** (G.A. Miller 等人， *WordNet:一个在线词汇数据库*；1990)，它提供了同义词、上位词和其他词的扩展，类似于同义词词典，并可用于所有主要操作系统的不同 GUI 和适当的命令行。WordNet 可用于 200 多种语言，每个单词(同义词集)通过直接语义关系与其他单词相关，如上位词或下位词、部分词或全词等。

kg 可以用在自然语言处理应用程序中，以支持决策，它们可以有效地用作查找引擎或推理。

知识嵌入是概念关系的低维表示，可以使用嵌入或更通用的降维方法来提取。在下一小节中，我们将看看 Walklet 嵌入方法。

### 用钱包嵌入图形

Walklet 算法基本上是将 Word2Vec skipgram 算法应用于图中的顶点，因此我们将基于概念的连接来获得概念的嵌入，而不是单词的嵌入(Word2Vec 的原始应用)。Walklet 算法对图的顶点上的短随机行走进行子采样，作为路径，然后将其传递给浅层神经网络(见下图)进行 skipgram 训练。

skipgram 算法(Mikolov 等人 2013；[https://arxiv.org/abs/1301.3781](https://arxiv.org/abs/1301.3781)根据单词本身预测单词的上下文(即顶点)。每个单词被特征化为一个连续的单词向量包(实际上，每个单词都在我们使用的字典中被索引)，并且我们基于隐藏层投影来预测周围单词(概念)的索引。该隐藏层投影的维数和上下文的窗口大小是该算法的主要参数。经过训练后，我们使用隐藏层作为嵌入。

下图说明了 skipgram 网络体系结构，它包含单词预测的输入层、隐藏层和输出层:

![](assets/7fed0371-75d1-4335-9469-b7c20c468b6d.png)

*w(t)* 指当前词(或概念)，而 *w(t-2)* 、 *w(t-1)* 、 *w(t+1)* 、 *w(t+2)* 分别指前后两个词。我们根据当前单词预测单词上下文。正如我们已经提到的，上下文的大小(窗口大小)是 skipgram 算法的一个超参数。

一个相关的算法是**连续词袋算法** ( **CBOW** )，其中架构是颠倒的——我们基于上下文预测单个单词。两者都基于这样的假设，即同现的词有相关的意义，或者它们有分布上的相似性，这意味着它们在意义上是相似的。这被称为**分布假设**(哈里斯，1954 年，*分布结构*)。

Walklet 算法在大型图形上表现良好，并且——因为它是一个神经网络——可以在线训练。你可以在布莱恩·佩罗齐等人的 2017 年论文中找到更多关于随身听的信息，*不要走，跳过！在线学习多尺度* *网络嵌入**([https://arxiv.org/abs/1605.02115](https://arxiv.org/abs/1605.02115))。*

 *## 请参见

以下是 Python 中可用于逻辑推理的库:

*   症状:[https://docs.sympy.org/latest/modules/logic.html](https://docs.sympy.org/latest/modules/logic.html)
*   https://github.com/logpy/logpy[任侃逻辑编程:](https://github.com/logpy/logpy)
*   py datalog:[https://sites.google.com/site/pydatalog/](https://sites.google.com/site/pydatalog/)

我们一直按照`nltk`中的推理指南来做这道菜。你可以在官方`nltk`网站找到更多工具:【http://www.nltk.org/howto/inference.html】T2。

其他一些用于图形嵌入的库如下:

*   https://karateclub.readthedocs.io/en/latest/index.html
*   pykg 2 vec:[https://github.com/Sujit-O/pykg2vec](https://github.com/Sujit-O/pykg2vec)
*   PyTorch BigGraph(由脸书研究):[https://github.com/facebookresearch/PyTorch-BigGraph](https://github.com/facebookresearch/PyTorch-BigGraph)
*   GraphVite: [https://graphvite.io/](https://graphvite.io/)
*   AmpliGraph(埃森哲公司):[https://docs.ampligraph.org/](https://docs.ampligraph.org/)
*   pydf 2vec:[https://github . com/ibcnservices/pydf 2vec](https://github.com/IBCNServices/pyRDF2Vec)

由爱丁堡大学的博士生 Benedek Rozemberczki 维护的 KarateClub 包含许多无监督图嵌入算法的实现。

一些图形库也提供链接预测。这意味着，对于给定的一组节点，您可以推断是否存在与其他节点的关系。关于链接预测的综述可以在安德雷·罗西等人的*链接预测的知识图嵌入:比较分析*中找到。(2020;https://arxiv.org/abs/2002.00819。

一些关于现实世界和/或常识的推理资源如下:

*   动作核心:[http://www.actioncores.org/apidoc.html#pracinference](http://www.actioncores.org/apidoc.html#pracinference)
*   https://github.com/INK-USC/KagNet
*   艾伦 AI 常识知识图:[https://mosaic . allenai . org/projects/common sense-Knowledge-Graphs](https://mosaic.allenai.org/projects/commonsense-knowledge-graphs)
*   *常识推理题页面*http://commonsensereasoning.org/problem_page.html[NYU CS:](http://commonsensereasoning.org/problem_page.html)

*关于图的学习:开放图基准:关于图的机器学习的数据集，胡等人，2020*(【https://arxiv.org/pdf/2005.00687.pdf】)是用机器学习进行图嵌入的又一参考。

有几个大型的真实世界知识数据库，如下所示:

*   维基数据:[https://www . wiki data . org/](https://www.wikidata.org/)
*   概念 5:[https://github.com/commonsense/conceptnet5](https://github.com/commonsense/conceptnet5)
*   开放的多语言 Wordnet:[http://compling.hss.ntu.edu.sg/omw/](http://compling.hss.ntu.edu.sg/omw/)
*   雅戈:[https://github.com/yago-naga/yago3](https://github.com/yago-naga/yago3)

# 解决 n 皇后问题

在数理逻辑中，可满足性是关于一个公式在某种解释(参数)下是否可以成立。如果一个公式在任何解释下都不成立，我们说它是不可满足的。一个**布尔可满足性问题**，或 **SAT** ，是关于一个布尔公式在其参数的任何值下是否有效(可满足)。由于许多问题都可以归结为 SAT 问题，并且存在求解器和优化器，所以它是一类重要的问题。

SAT 问题已经被证明是 NP 完全的。NP 完全性(简称**非确定性多项式时间**)是指一个问题的解可以在多项式时间内被验证。注意，这并不是说可以快速找到解决方案，只是说解决方案可以快速验证。NP 完全问题通常用搜索试探法和算法来解决。

在这份食谱中，我们将通过各种方式解决 SAT 问题。我们将举一个相对简单且研究充分的例子，称为 n 皇后问题，我们试图将皇后放在一个由 *n* 乘 *n* 个正方形组成的棋盘上，这样任何列、行和对角线最多只能有一个皇后。

首先，我们将应用遗传算法，然后粒子群算法，然后一个专门的 SAT 求解器。

## 做好准备

我们将使用`dd`求解器来解决这个食谱中的一个方法。要安装它，我们还需要`omega`库。我们可以通过使用`pip`命令得到这两者，如下所示:

```py
pip install dd omega
```

我们稍后将使用 dd SAT 求解器库，但首先，我们将看看其他一些算法方法。

## 怎么做...

我们将从 GA 开始。

### 遗传算法

首先，我们将定义染色体是如何表示的，以及它是如何变异的。然后，我们将定义一个反馈循环来测试这些染色体并改变它们。我们将在*中解释算法本身是如何工作的...*一节，在本食谱的末尾。让我们开始吧:

1.  **表示一个解决方案**(一条染色体):面向对象的风格有助于定义染色体。让我们看看我们的实现。首先，我们需要知道什么是染色体，它有什么作用:

```py
import random
from typing import Optional, List, Tuple

class Chromosome:
    def __init__(self, configuration: Optional[List]=None, nq: Optional[int]=None):
        if configuration is None:
            self.nq = nq
            self.max_fitness = np.sum(np.arange(nq))
            self.configuration = [
                random.randint(1, nq) for _ in range(nq)
            ]
        else:
            self.configuration = configuration
            self.nq = len(configuration)
            self.max_fitness = np.sum(np.arange(self.nq))

    def fitness(self):
        return cost_function(self.configuration) / self.max_fitness

    def mutate(self):
        ind = random.randint(0, self.nq-1)
        val = random.randint(1, self.nq)
        self.configuration[ind] = val
```

前面的代码创建了我们的基本数据结构，其中包含一个可以复制和变异的候选解决方案。此代码指的是成本函数。

我们需要一个成本函数，这样我们就知道如何适应我们的基因:

```py
def cost_function(props):
    res = 0
    for i1, q1 in enumerate(props[:-1]):
        for i2, q2 in enumerate(props[i1+1:], i1+1):
            if (q1 != q2) and (abs(i1 - i2) != abs(q1 - q2)):
                res += 1
    return res
```

我们可以根据这个成本函数来选择基因(见`fitness()`方法)。

2.  **编写主算法**:n 皇后问题的 GA 如下(这里我们省略了可视化):

```py
class GeneticQueen:
    def __init__(self, nq, population_size=20, mutation_prob=0.5):
        self.nq = nq
        self.population_size = population_size
        self.mutation_prob = mutation_prob
        self.population = [Chromosome(nq=nq) for _ in range(population_size)]
        self.solution = None
        self.best_fitness = None

    def iterate(self):
        new_population = []
        best_fitness = -1
        for i in range(len(self.population)):
            p1, p2 = self.get_parents()
            child = Chromosome(self.cross_over(p1, p2))
            if random.random() < self.mutation_prob:
                child.mutate()
            new_population.append(child)
            fit = child.fitness()
            if fit > best_fitness:
                best_fitness = fit
            if fit == 1:
                self.solution = child
                break                
        self.best_fitness = best_fitness
        self.population = new_population

    def cross_over(self, p1, p2):
        return [
            yi
            if random.random() > 0
            else xi
            for xi, yi in zip(
                p1.configuration,
                p2.configuration
            )
        ]

    def get_parents(self) -> Tuple[Chromosome, Chromosome]:
        weights = [chrom.fitness() for chrom in self.population]
        return tuple(
            random.choices(
                self.population, 
                weights=weights,
                k=2
            )
        )
```

这个类包含染色体的群体，并且可以有应用于它的方法(群体控制，如果你喜欢的话)，例如使用什么样的双亲(`get_parents()`)和他们的交配(`cross_over()`)。注意`iterate()`方法，这是实现主要逻辑的地方。我们将对我们在*中做出的主要决定进行评论...*一节。

3.  **运行算法**:我们通过简单地实例化一个`GeneticQueen`并调用`iterate()`来执行算法。我们还可以添加一些额外的行来获得定期更新，并随着时间的推移收集健身数据。然后，我们运行算法，如下所示:

```py
def ga_solver(nq):
    fitness_trace = []
    gq = GeneticQueen(nq=nq)
    generation = 0
    while not gq.solution:
        gq.iterate()
        if (generation % 100) == 0:
            print('Generation {}'.format(generation))
            print('Maximum Fitness: {:.3f}'.format(gq.best_fitness))
        fitness_trace.append(gq.best_fitness)
        generation += 1

    gq.visualize_solution()
    return fitness_trace
```

最后，我们可以将解决方案可视化。

如果我们运行前面的代码，我们将得到如下所示的单次运行(您的可能看起来不同):

```py
Generation 0
Maximum Fitness: 0.857
Generation 100
Maximum Fitness: 0.821
Generation 200
Maximum Fitness: 0.892
Generation 300
Maximum Fitness: 0.892
Generation 400
Maximum Fitness: 0.892
```

前面的代码给出了以下输出:

![](assets/ac966a3c-1d5d-4a9a-9d61-b5f3c6051cc9.png)

这花了将近 8 秒的时间来完成。

下图显示了算法每次迭代中最佳染色体的适应度:

![](assets/58a57946-e6ab-4001-a30c-753e83544296.png)

在这里，我们可以看到算法的适应度并不总是提高；也可以往下走。我们可以选择保留这里最好的染色体。在这种情况下，我们不会看到任何下降(但潜在的负面影响是，我们可能会以局部最小值告终)。

现在，让我们继续粒子群优化！

### 粒子群优化

在食谱的这一部分，我们将从头开始为 n 皇后问题实现一个 PSO 算法。让我们开始吧:

1.  **表示一个解决方案**:类似于 g a，我们需要定义一个解决方案看起来像什么。在 PSO 中，这意味着我们定义一个粒子:

```py
class Particle:
    best_fitness: int = 0

    def __init__(
        self, N=None, props=None,
        velocities=None
    ):
        if props is None:
            self.current_particle = np.random.randint(0, N-1, N)
            self.best_state = np.random.randint(0, N-1, N)
            self.velocities = np.random.uniform(-(N-1), N-1, N)
        else:
            self.current_particle = props
            self.best_state = props
            self.velocities = velocities

        self.best_fitness = cost_function(self.best_state)

    def set_new_best(self, props: List[int], new_fitness: int): 
        self.best_state = props
        self.best_fitness = new_fitness

    def __repr__(self):
        return f'{self.__class__.__name__}(\n' +\
            f'\tcurrent_particle={self.current_particle}\n' +\
            f'\best_state={self.best_state}\n' +\
            f'\tvelocities={self.velocities}\n' +\
            f'\best_fitness={self.best_fitness}\n' +\
            ')'
```

这是我们将要使用的主要数据结构。它包含一个候选解决方案。应用粒子群优化算法将涉及改变这些粒子群。我们将在*如何工作中更详细地解释`Particle`如何工作...*一节。

我们将使用为 GA 定义的相同的成本函数。这个成本函数告诉我们我们的粒子有多适合给定的问题——换句话说，属性向量有多好。

我们将把初始化和主算法打包成一个类:

```py
class ParticleSwarm:
  def __init__(self, N: int, n_particles: int,
    omega: float, phip: float, phig: float
  ):
    self.particles = [Particle(N=N) for i in range(n_particles)]
    self.omega = omega
    self.phip = phip
    self.phig = phig

  def get_best_particle(self):
    best_particle = 0
    best_score = -1
    score = -1
    for i, particle in enumerate(self.particles):
        score = cost_function(particle.current_particle)
        if score > best_score:
            best_score = score
            best_ind = i
    return self.particles[best_ind].current_particle, best_score

  def iterate(self):
    for particle in self.particles:
      rg = np.random.rand((N))
      rp = np.random.rand((N))
      delta_p = particle.best_state - particle.current_particle
      delta_g = best_particle - particle.current_particle
      update = (rp * self.phip * delta_p +
        \ rg * self.phig * delta_g)  # local vs global
      particle.velocities = self.omega * particle.velocities + update
      particle.current_particle = (np.abs(
        particle.current_particle + particle.velocities
      ) % N ).astype(int)  # update the particle best
      current_fitness = cost_function(particle.current_particle)
      if current_fitness > particle.best_fitness:
        particle.set_new_best(
          particle.current_particle, current_fitness
        )
        particle_candidate, score_candidate = get_best_particle(particles)
        if best_score_cand > best_score:
          best_particle = particle_candidate
          best_score = score_candidate
    return best_particle, best_score
```

`get_best_particle()`方法返回最佳配置和最佳分数。注意`iterate()`方法，它更新我们的粒子并返回最佳粒子及其分数。关于此更新的详细信息在*中提供...*一节。优化过程本身是使用一些相对简单的公式来完成的。

我们还想展示我们的解决方案。显示板位置的代码如下:

```py
import chess
import chess.svg
from IPython.display import display

def show_board(queens):
    fen = '/'.join([queen_to_str(q) for q in queens])
    display(chess.svg.board(board=chess.Board(fen), size=300))
```

下面是 PSO 的主要算法:

```py
def particle_swarm_optimization(
    N: int, omega: float, phip: float, phig: float,
    n_particles: int, visualize=False, max_iteration=999999
) -> List[int]:
  def print_best():
    print(f'iteration {iteration} - best particle: {best_particle}, score: {best_score}')
  solved_cost = np.sum(np.arange(N))
  pso = ParticleSwarm(N, n_particles, omega, phip, phig)
  iteration = 0
  best_particle, best_score = get_best_particle(particles)
  scores = [best_score]
  if visualize:
    print('iteration:', iteration)
    show_board(best_particle)
  while best_score < solved_cost and iteration < max_iteration:
    if (iteration % 500) == 0 or iteration == 0:
      print_best()
      best_particle, best_score = pso.iterate()
    if iteration > 0 and visualize:
      print('iteration:', iteration)
      show_board(best_particle)
    scores.append(best_score)
    iteration += 1
  print_best()
  return best_particle, scores
```

类似于我们在 GA 中所做的，我们跟踪我们的解决方案在迭代过程中的表现(通过我们的成本函数)。main 函数返回以下内容:

*   `best_particle`:最佳解决方案
*   我们迭代的最好成绩

正如我们之前提到的，我们将在*工作原理中解释所有这些是如何工作的...*一节。

你可以在[https://github . com/packt publishing/Artificial-Intelligence-with-Python-Cookbook/blob/master/chapter 05/solving-n-queens . MD](https://github.com/PacktPublishing/Artificial-Intelligence-with-Python-Cookbook/blob/master/chapter05/solving-n-queens.md)查看用 *n = 8* 运行的算法的输出。

我们在这里使用象棋库进行可视化。

在下图中，您可以看到我们迭代过程中的解决方案质量:

![](assets/1882e481-9689-40e1-bc00-9e98ff95a298.png)

由于所有粒子都保持自己的最佳解记录，所以分数永远不会下降。在第 1323 次迭代时，我们得到了一个解，算法停止了。

### SAT 求解器

这在很大程度上基于可以在加州理工学院版权所有的`dd`库中找到的示例，该示例位于[https://github . com/tulip-control/DD/blob/0f 6d 16483 cc 13078 edebac 9 e 89 D1 d 4b 99d 22991 e/examples/queens . py](https://github.com/tulip-control/dd/blob/0f6d16483cc13078edebac9e89d1d4b99d22991e/examples/queens.py)。

在 Python 的现代 SAT 求解器中，我们可以将约束定义为简单的函数。

基本上，有一个公式包含了所有的约束。一旦满足了所有约束条件(或所有约束条件的结合)，就找到了解决方案:

```py
def queens_formula(n):
    present = at_least_one_queen_per_row(n)
    rows = at_most_one_queen_per_line(True, n)
    cols = at_most_one_queen_per_line(False, n)
    slash = at_most_one_queen_per_diagonal(True, n)
    backslash = at_most_one_queen_per_diagonal(False, n)
    s = conj([present, rows, cols, slash, backslash])
    return s
```

下面是对`at_least_one_queen_per_row`的约束:

```py
def at_least_one_queen_per_row(n):
    c = list()
    for i in range(n):
        xijs = [_var_str(i, j) for j in range(n)]
        s = disj(xijs)
        c.append(s)
    return conj(c)
```

这里，我们对每一行的皇后取析取。

主要运行如下所示:

```py
def benchmark(n):
    t0 = time.time()
    u, bdd = solve_queens(n)
    t1 = time.time()
    dt = t1 - t0

    for i, d in enumerate(bdd.pick_iter(u)):
        if len(d) > 0:
            visualize_solution(d)
            break
    n_solutions = bdd.count(u)

    s = (
        '------\n'
        'queens: {n}\n'
        'time: {dt} (sec)\n'
        'node: {u}\n'
        'total nodes: {k}\n'
        'number solutions: {n_solutions}\n'
        '------\n'
    ).format(
        n=n, dt=dt, u=u, k=len(bdd),
        n_solutions=n_solutions,
    )
    print(s)
    return dt
```

当我们运行它时，我们应该会看到一个示例解决方案。我们还应该得到一些关于找到了多少解决方案以及找到它们需要多长时间的统计数据。

以下是我们对八皇后问题的示例解决方案:

![](assets/adf9eaae-ec96-44ba-aa1f-6f99090ae6a4.png)

文本输出如下所示:

```py
queens: 8
time: 4.775595426559448 (sec)
node: -250797
total nodes: 250797
number solutions: 92
```

这个求解器不仅得到了所有的解(我们只可视化了其中的一个)，而且比遗传算法快了一倍！

## 它是如何工作的...

在这一节中，我们将从遗传算法开始，解释我们在这个食谱中采用的不同方法。

### 遗传算法

GA 本质上非常简单:我们维护一组候选解(称为染色体),我们有两个操作可以用来改变它们:

*   两条染色体有孩子(这意味着它们混合在一起)
*   `mutation:`一条染色体随机变化

一条染色体有一个存储在`configuration`中的候选解。当初始化一个染色体时，我们必须给出它的皇后数或初始配置。我们在本章前面已经讨论过什么是染色体。如果没有给出配置，那么我们需要创建一个具有列表理解的配置，比如`[random.randint(1, nq) for _ in range(nq)]`。

一个染色体可以计算出自己的适合度；这里，我们使用了与之前相同的成本函数，但这一次，我们将其缩放到 0 到 1 之间，其中 1 表示我们找到了一个解决方案，任何介于两者之间的值都表示我们离找到解决方案有多近。一条染色体也可以自身变异；也就是说，它可以随机更改其中一个值。

在算法的每次迭代中，我们通过使用这两种操作来创建新一代染色体。算法本身很简单:

1.  首先，我们用代表解的不同参数的不同值初始化我们的第一代染色体。
2.  然后，我们计算染色体的适应度。这可以通过与环境的互动来实现，也可以是解决方案的内在因素，就像我们的九皇后组合问题一样。
3.  接下来，我们创建新一代染色体，如下所示:
    *   选择父母时要考虑他们的健康状况
    *   按照一定的概率突变几个染色体
4.  最后，我们从*步骤 2* 开始重复，直到适应度足够高或者我们已经迭代了很多次。

我们在这里非常宽松地表达了最后一步。基本上，我们可以决定什么时候适应度足够高，要迭代多少次。这些是我们的停止标准。

这在我们的`GeneticQueen.iterate()`实现中非常清晰，所以让我们为了可视化的目的再看一看(只是稍微简化了):

```py
def iterate(self):
  new_population = []
  for i in range(len(self.population)):
    p1, p2 = self.get_parents()
    child = Chromosome(self.cross_over(p1, p2))
    if random.random() < self.mutation_prob:
      child.mutate()
    new_population.append(child)
```

关于遗传算法，我们必须做出的一个主要决定是，我们是保持最佳解决方案，还是所有染色体(即使是最好的)都必须死亡(可能在生育后代之后)。在这里，每一次迭代都创造了全新的一代。

我们随机选择父母，通过他们的适应度加权，最适合的更有可能被选择。我们实现中的`cross-over`函数在每个参数的两个父参数之间随机决定。

GA 必须做出的主要超参数和主要决策如下:

*   人口规模(我们有多少条染色体？)
*   突变率(染色体突变时变化有多大？)
*   多少(哪些)染色体产生后代？通常，这些是最适合的。
*   我们的停止标准是什么？通常，算法的适应性有一个阈值和一组迭代次数。

正如我们所看到的，GA 非常灵活，非常直观。在下一节，我们将看看粒子群算法。

### 粒子群优化

我们从`Particle`数据结构开始实现。为了初始化一个粒子，我们传递皇后数(`N`)或者速度和参数的向量。基本上，一个粒子有一个配置，或者一组参数——在这种情况下是一个向量——在一定程度上适合一个问题(`current_particle`)和一个速度(类似于学习率)。粒子的每个属性向量代表女王的位置。

然后，PSO 以一种特殊的方式将变化应用于粒子。PSO 是局部搜索和全局搜索的结合；也就是说，在每个粒子上，我们试图将我们的搜索指向全局最佳的粒子以及该粒子过去的最佳状态。粒子维护其最佳实例化的记录；即其最佳参数的向量和相应的分数。我们也保持参数的相应速度。根据使用的公式，这些速度可以减慢、增加或改变方向。

PSO 有几个参数，如下所示(大部分在我们的实现中被命名；这里，我们省略了与九皇后问题相关的问题):

*   `omega`:衰减参数
*   `phip`:控制本地搜索的贡献
*   `phig`:控制全局搜索的贡献
*   `n_particles`:粒子数
*   `max_iterations`:用于无解决方案的提前停止

在我们的 PSO 问题中，有两个增量，`delta_p`和`delta_g`，其中 *p* 和 *g* 分别代表粒子和全局。这是因为其中一个是相对于粒子的历史最佳值计算的，而另一个是相对于粒子的全局最佳值计算的。

根据以下代码计算更新:

```py
delta_p = particle.best_state - particle.current_particle
delta_g = best_particle - particle.current_particle
update = (rp * phip * delta_p +\
 rg * phig * delta_g) # local vs global
```

这里，`rp`和`rg`是随机数，`phip`和`phig`分别是局部和全局因子。它们指的要么是一个独特的粒子，要么是所有的粒子，如`delta_p`和`delta_g`变量所示。

还有另一个参数`omega`，它控制着水流速度的衰减。在每次迭代中，根据以下公式计算新的速度:

```py
particle.velocities = omega * particle.velocities + update
```

反过来，粒子参数根据它们的速度递增。

注意，该算法对为`phip`、`phig`和`omega`选择的内容很敏感。

我们的成本函数(或优度函数)根据给定的皇后配置计算粒子的分数。该配置被表示为范围]0，N-1[*中的索引列表。*对于每对皇后，该函数检查它们是否在对角线、垂直或水平方向上重叠。每一个没有冲突的检查都得一分，所以最高分是![](assets/f0965a57-dba1-4252-a522-06eced1f26c9.png)。这是 8 皇后问题的 28。

### SAT 求解器

专业可满足性解算器有很多不同的工作方式。龚薇薇和徐舟(2017)的一项调查提供了不同方法的广泛概述:【https://aip.scitation.org/doi/abs/10.1063/1.4981999】。

我们在菜谱中使用的`dd`解算器使用的是**二元决策图** ( **BDD** )，由 Randal Bryant ( *布尔函数操作的基于图形的算法*，1986 年)引入。二元决策图(有时称为**分支程序**)是表示为布尔函数的约束，与其他编码相反，例如否定正常。

在 BDD 中，一个算法或一组约束被表示为一个布尔维域上的布尔函数， *n* ，其值为真或假:

![](assets/a0c150ba-9740-4023-a19f-3ea43deae487.png)

这意味着我们可以将问题表示为二叉树，或者等价地，表示为真值表。

为了说明这一点，让我们看一个例子。我们可以枚举二元变量( *x1* 、 *x2* 和 *x3* )的所有状态，然后得出一个最终状态，这是 *f* 的结果。下面的真值表总结了我们的变量的状态，以及我们的函数评估:

| *x1* | *x2* | *x3* | *f* |
| 错误的 | 错误的 | 错误的 | 错误的 |
| 错误的 | 错误的 | 真实的 | 错误的 |
| 错误的 | 真实的 | 错误的 | 错误的 |
| 错误的 | 真实的 | 真实的 | 错误的 |
| 真实的 | 错误的 | 错误的 | 真实的 |
| 真实的 | 错误的 | 真实的 | 错误的 |
| 真实的 | 真实的 | 错误的 | 真实的 |
| 真实的 | 真实的 | 真实的 | 真实的 |

这对应于下面的二叉树:

![](assets/ea715312-19c9-45ce-a2ae-bcc9a3124140.png)

二叉树和真值表有高度优化的库实现，这意味着它们可以运行得非常快。这解释了我们为什么这么快就得到结果。

## 请参见

Python 中还有许多其他 SAT 求解器，其中一些如下:

*   微软的 PDP 解决方案:[https://github.com/microsoft/PDP-Solver](https://github.com/microsoft/PDP-Solver)
*   Z3，由微软研究:[https://github.com/Z3Prover/z3](https://github.com/Z3Prover/z3)
*   Python 绑定到 picosat，由 Continuum 开发:[https://github.com/ContinuumIO/pycosat](https://github.com/ContinuumIO/pycosat)

关于 SAT 求解器的讨论，当应用于数独时，可以在这里找到:[https://coding nest . com/modern-SAT-solvers-fast-neat-under-used-part-1-of-n/](https://codingnest.com/modern-sat-solvers-fast-neat-underused-part-1-of-n/)。

关于骑士和流民问题的 Z3 的例子可以在这里找到:[https://Jamie collinson . com/blog/solving-Knights-and-jackets-with-Z3/](https://jamiecollinson.com/blog/solving-knights-and-knaves-with-z3/)。

# 寻找最短的公交路线

寻找最短的公交路线意味着在地图上找到一条连接各点(公交车站)的路径。这是旅行推销员问题的一个例子。在这份食谱中，我们将用不同的算法来解决寻找最短公交路线的问题，包括模拟退火和蚁群优化。

## 做好准备

除了我们一直依赖的标准依赖项，如`scipy`和`numpy`，我们将使用`scikit-opt`库，它为群体智能实现了许多不同的算法。

群体智能是分散的、自组织系统的集体行为，导致观察者眼中出现明显的智能。这个概念用在基于人工智能的工作中。自然系统，如蚁群、鸟群、鹰狩猎、动物放牧和细菌生长，在全球范围内表现出一定程度的智能，尽管蚂蚁、鸟和鹰通常表现出相对简单的行为。受生物学启发的群算法包括遗传算法、粒子群优化、模拟退火和蚁群优化。

我们可以如下安装`scikit-opt`和`pip`:

```py
pip install scikit-opt
```

现在，我们准备解决旅行推销员问题。

## 怎么做...

正如我们前面提到的，我们将用两种不同的方法来解决最短公交路线问题。

首先，我们需要为公交车站创建一个坐标(经度，纬度)列表。问题的难度取决于停的次数(`N`)。这里，我们将`N`设置为`15`:

```py
import numpy as np
N = 15
stops = np.random.randint(0, 100, (N, 2))
```

我们还可以预先计算站点之间的距离矩阵，如下所示:

```py
from scipy import spatial

distance_matrix = spatial.distance.cdist(stops, stops, metric='euclidean')
```

我们可以将这个距离矩阵输入到两个算法中以节省时间。

我们将从模拟退火开始。

### 模拟退火

在这一小节中，我们将编写寻找最短公交路线的算法。这是基于 Luke Mile 对模拟退火的 Python 实现，应用于旅行商问题时:[https://gist . github . com/qpwo/a 46274751 C5 db 2 ab 1d 936980072 a 134](https://gist.github.com/qpwo/a46274751cc5db2ab1d936980072a134)。让我们开始吧:

1.  实现本身简短明了:

```py
def find_tour(stops, distance_matrix, iterations=10**5):
    def calc_distance(i, j):
        """sum of distance to and from i and j in tour
        """
        return sum(
            distance_matrix[tour[k], tour[k+1]]
            for k in [j - 1, j, i - 1, i]
        )

    n = len(stops)
    tour = np.random.permutation(n)
    lengths = []
    for temperature in np.logspace(4, 0, num=iterations):
        i = np.random.randint(n - 1) # city 1
        j = np.random.randint(i + 1, n) # city 2
        old_length = calc_distance(i, j)
        # swap i and j:
        tour[[i, j]] = tour[[j, i]]
        new_length = calc_distance(i, j)
        if np.exp((old_length - new_length) / temperature) < np.random.random():  # bad swap
            tour[[i, j]] = tour[[j, i]]  # undo swap
            lengths.append(old_length)
        else:
            lengths.append(new_length) 
    return tour, lengths
```

2.  接下来，我们需要调用算法，如下所示:

```py
from scipy.spatial.distance import euclidean
tour, lengths = find_tour(
    stops, distance_matrix, iterations=1000000
)
```

这是最终解决方案，路径如下:

![](assets/b06783a1-cd08-427f-8393-fa053648e368.png)

我们还可以绘制算法的内部距离度量。请注意这个内部成本函数如何一直下降，直到大约 800，000 次迭代:

![](assets/0ed8b401-9405-4b86-a9ca-6bfbc670008e.png)

现在，让我们尝试一下蚁群优化。

### 蚁群优化

这里，我们从库中加载实现。我们将在*中解释它是如何工作的细节...*章节:

```py
from sko.ACA import ACA_TSP

def cal_total_distance(tour):
    return sum([
        distance_matrix[tour[i % N], tour[(i + 1) % N]]
        for i in range(N)
    ])

aca = ACA_TSP(
    func=cal_total_distance,
    n_dim=N,
    size_pop=N,
    max_iter=200,
    distance_matrix=distance_matrix
)
best_x, best_y = aca.run()
```

我们正在使用基于我们先前检索的点距离(`distance_matrix`)的距离计算。

同样，我们可以通过迭代绘制最佳路径和路径距离，如下所示:

![](assets/2836f8ea-47e2-447a-b4d6-8e60b7fef4b7.png)

我们可以再次看到最终的路径，这是我们优化的结果(左边的子图)，以及它在算法迭代过程中的距离(右边的子图)。

## 它是如何工作的...

最短公共汽车路线问题是旅行商问题的一个例子，而旅行商问题又是组合优化的一个著名例子。

Combinatorial optimization refers to using combinatorial techniques to solve discrete optimization problems. In other words, it is the act of finding a solution among a combination of objects. Discrete, in this case, means that there are a finite number of options. The intelligence part of combinatorial optimization goes into either reducing the search space or accelerating the search. The traveling salesman problem, the minimum spanning tree problem, the marriage problem, and the knapsack problem are all applications of combinatorial optimization.

TSP 可以表述如下:给定一个要访问的城镇列表，穿过所有城镇并返回起点的最短路径是什么？TSP 应用于规划、物流和微芯片设计等领域。

现在，让我们更详细地看看模拟退火和蚁群优化。

### 模拟退火

模拟退火是一种概率优化技术。这个名字来自冶金学，在冶金学中，加热和冷却被用来减少材料中的缺陷。简而言之，在每一次迭代中，都会发生一次状态转换(变更)。如果改变成功，系统将降低其温度。这可以重复进行，直到状态足够好，或者直到我们达到一定的迭代次数。

在这个食谱中，我们随机初始化我们的城市之旅，然后迭代模拟退火。SA 的主要思想是变化率取决于一定的温度。在我们的实现中，我们从逻辑上将温度从 4 降低到 0。在每次迭代中，我们尝试交换(我们可以尝试其他操作)两个随机的公共汽车站，在我们的路径(旅游)中索引 *i* 和 *j* ，其中 *i < j* ，然后我们计算从 *i-1* 到 *i* ，从 *i* 到 *i+1* ，从 *j 我们还需要对`calc_distance`进行距离测量。我们在这里选择了欧几里德距离，但我们也可以选择其他距离。*

当我们需要决定是否接受交换时，温度会被考虑在内。我们计算交换前后路径长度差异的指数:

![](assets/a27925b2-5ca8-464f-a966-f4cd0733f1e1.png)

然后，我们抽取一个随机数。如果这个随机数低于我们的表达式，我们接受改变；否则，我们撤销它。

### 蚁群优化

顾名思义，**蚁群优化**的灵感来源于蚁群。让我们用信息素来打个比方，信息素是蚂蚁在沿着一条路径行进时分泌的:在这里，代理人有候选解，它们越接近该解就越有吸引力。

一般来说，蚂蚁数量 *k* 以如下概率从状态 *x* 移动到状态 *y* :

![](assets/cca21206-5116-4d0a-b6bb-b7d3d9bae156.png)

*Tau* 是存放在 *x* 和 *y* 之间的信息素踪迹。 *eta* 参数控制信息素的影响，其中 *eta* 的 *beta* 的幂是状态转换(例如，转换成本的一倍)。信息素轨迹根据包含状态转换的整体解决方案的好坏进行更新。

`scikit-opt`函数在这里完成了繁重的工作。我们只需要传递几个参数，比如距离函数，点数，种群中蚂蚁的数量，迭代次数，距离矩阵，就可以调用`run()`。

## 请参见

你也可以把这个问题作为一个混合整数问题来解决。Python-MIP 库解决混合整数问题，你可以在[https://python-mip.readthedocs.io/en/latest/examples.html](https://python-mip.readthedocs.io/en/latest/examples.html)找到 TSP 的例子。

TSP 也可以用 Hopfield 网络来解决，如本教程所述:[https://www . tutorialspoint . com/artificial _ neural _ Network/artificial _ neural _ Network _ optimization _ using _ Hopfield . htm](https://www.tutorialspoint.com/artificial_neural_network/artificial_neural_network_optimization_using_hopfield.htm)。这里讨论一种布谷鸟搜索方法:【https://github.com/Ashwin-Surana/cuckoo-search】T2。

`scikit-opt`是一个强大的启发式算法库。它包括以下算法:

*   差异进化
*   遗传算法
*   粒子群优化
*   模拟退火
*   蚁群算法
*   免疫算法
*   人工鱼群算法

文档包含了更多解决 TSP 的例子:[https://scikit-opt.github.io/scikit-opt/#/en/README?id = _ 22-遗传算法求解旅行商问题](https://scikit-opt.github.io/scikit-opt/#/en/README?id=_22-genetic-algorithm-for-tsptravelling-salesman-problem)。另一个类似于`scikit-opt`的图书馆是`pyswarms`，可以在[https://pyswarms.readthedocs.io/en/latest/index.html](https://pyswarms.readthedocs.io/en/latest/index.html)找到。

正如我们在这个配方的介绍中提到的，运输物流在 TSP 中有它自己的应用，即使是最纯粹的形式。https://thelivinglib.org/mapaton-cdmx/提供了墨西哥 30，000 辆公共汽车、小型公共汽车和货车的数据集。

# 模拟疾病的传播

历史上，天花、肺结核和黑死病等流行病对人类产生了重大影响。截至 2020 年，新冠肺炎正在世界各地的人群中传播，在几乎没有伤亡的情况下控制病毒的政治和经济问题已被广泛讨论。

关于新冠肺炎，对自由主义者来说，瑞典在一段时间内是不需要封锁的典范，尽管次要因素如高比例的单身家庭和社会距离的文化倾向没有被考虑在内。最近，瑞典的死亡人数一直在上升，其人均死亡率是最高的记录之一([https://www.worldometers.info/coronavirus/](https://www.worldometers.info/coronavirus/))。

在英国，最初的反应是依靠群体免疫，而封锁是在其他国家已经实施后几周才宣布的。因为没有能力应付，国家医疗服务体系(T2 国民医疗服务体系(T3))在商业医院使用临时的床位和租用的床位。

A **multi-agent system** (**MAS**) is a computer simulation consisting of participants known as agents. The individual agents can respond heuristically or based on reinforcement learning. Conjunctively, the system behavior of these agents responding to each other and to the environment can be applied to study topics, including the following:

*   合作与协调
*   分布式约束优化
*   沟通和谈判
*   分布式问题求解，尤其是分布式约束优化

在这份食谱中，一个相对简单的多主体模拟将向您展示不同的反应如何导致疫情死亡人数和传播的差异。

## 做好准备

我们将使用`mesa`多智能体建模库来实现我们的多智能体模拟。

用于此的`pip`命令如下:

```py
pip install mesa
```

现在，我们准备好了！

## 怎么做...

此模拟基于枫雨研究有限公司的工作。对于此配方，我们在引入医院床位和封锁政策等因素方面做了一些更改，并且我们还更改了感染和活动病例的计算方式。你可以在 https://github.com/benman1/covid19-sim-mesa 找到完整的代码。

声明:这个食谱的目的不是提供医疗建议，我们也不是合格的医疗从业者或专家。

首先，我们将通过`Person`类来定义我们的代理:

```py
class Person(Agent):
    def __init__(self, unique_id, model):
        super().__init__(unique_id, model)
        self.alive = True
        self.infected = False
        self.hospitalized = False
        self.immune = False
        self.in_quarantine = False  # self-quarantine
        self.time_infected = 0
```

这将代理定义为具有健康和隔离状态的人员。

我们仍然需要一些方法来改变其他属性的变化。我们不会一一介绍，只介绍那些足以让你理解所有东西是如何组合在一起的。我们需要了解的核心问题是，当代理人被感染时，他们做了什么。基本上，在被感染时，我们需要了解病原体是否会感染其他人、死于感染或康复:

```py
    def while_infected(self):
        self.time_infected += 1
        if self.hospitalized:
            # stay in bed, do nothing; maybe die
            if self.random.random() < (
                    self.model.critical_rate *
                    self.model.hospital_factor
            ):
                # die
                self.alive = False
                self.hospitalized = False
                self.infected = False
                return
            self.hospitalized -= 1
            return
        if self.random.random() < (
            self.model.quarantine_rate /
            self.model.recovery_period
        ):
            self.set_quarantine()
        if not self.in_quarantine:
            self.infect_others()  # infect others in same cell
        if self.time_infected < self.model.recovery_period:
            if self.random.random() < self.model.critical_rate:
                if self.model.hospital_takeup:
                    self.hospitalized = self.model.hospital_period
                    self.set_quarantine()
                else:
                    self.alive = False # person died from infection
                    self.infected = False
        else:  # person has passed the recovery period so no longer infected
            self.infected = False
            self.quarantine = False
            if self.random.random() < self.model.immunity_chance:
                self.immune = True
```

在这里，我们可以看到相当多的变量是在模型级别定义的，比如`self.model.critical_rate`、`self.model.hospital_factor`和`self.model.recovery_period`。稍后我们将更详细地研究这些模型变量。

现在，我们需要一种方法让我们的代理记录他们的位置，这在`mesa`中被称为`MultiGrid`:

```py
    def move_to_next(self):
        possible_steps = self.model.grid.get_neighborhood(
            self.pos,
            moore=True,
            include_center=False
        )
        new_position = self.random.choice(possible_steps)
        self.model.grid.move_agent(self, new_position)
```

这相对简单。如果代理移动，他们在他们的邻居内移动；即下一个相邻小区。

在每个周期(迭代)调用的入口方法是`step()`方法:

```py
    def step(self):
        if self.alive:
            self.move()
```

如果代理人活着，他们每走一步都会移动。它们移动时会发生以下情况:

```py
    def move(self):
        if self.in_quarantine or self.model.lockdown:
            pass
        else:
            self.move_to_next()
        if self.infected:
            self.while_infected()
```

这就是我们特工的主要逻辑；即`Person`。现在，让我们看看在模型级别上，所有东西是如何结合在一起的。这可以在`model.py`里面的`Simulation`类中找到。

让我们看看代理是如何创建的:

```py
    def create_agents(self):
        for i in range(self.num_agents):
            a = Person(i, self)
            if self.random.random() < self.start_infected:
                a.set_infected()
            self.schedule.add(a)
            x = self.random.randrange(self.grid.width)
            y = self.random.randrange(self.grid.height)
            self.grid.place_agent(a, (x, y))
```

前面的代码创建了我们需要的任意多个代理。根据`start_infected`参数，部分会被感染。我们还将代理添加到网格中组织的细胞图中。

我们还需要定义一些数据收集器，如下所示:

```py
        def set_reporters(self):
            self.datacollector = DataCollector(
                model_reporters={
                    'Active Cases': active_cases,
                    'Deaths': total_deaths,
                    'Immune': total_immune,
                    'Hospitalized': total_hospitalized,
                    'Lockdown': get_lockdown,
                })
```

这个列表字典中的变量在每个循环中都会被追加，这样我们就可以绘制它们或者对它们进行统计评估。作为一个例子，让我们看看`active_cases`函数是如何定义的:

```py
def active_cases(model):
    return sum([
        1
        for agent in model.schedule.agents
        if agent.infected
    ])
```

当被调用时，该函数遍历模型中的代理，并对状态为`infected`的代理进行计数。

同样，就像对于`Person`，`Simulation`的主要逻辑在`step()`方法中，该方法将模型提前一个周期:

```py
    def step(self):
        self.datacollector.collect(self)
        self.hospital_takeup = self.datacollector.model_vars[
            'Hospitalized'
        ][-1] < self.free_beds
        self.schedule.step()
        if self.lockdown:
            self.lockdown -= 1
        else:
            if self.lockdown_policy(
                self.datacollector.model_vars['Active Cases'],
                self.datacollector.model_vars['Deaths'],
                self.num_agents
            ):
                self.lockdown = self.lockdown_period
        self.current_cycle += 1
```

让我们看看随着时间的推移，不同的封锁政策如何影响死亡和疾病的传播。

我们将使用之前在这些模拟中使用的同一组变量。我们对它们进行了设置，使它们按照 1/1000 的因子大致对应于英国:

```py
scale_factor = 0.001
area = 242495  # km2 uk
side = int(math.sqrt(area)) # 492

sim_params = {
    'grid_x': side,
    'grid_y': side,
    'density': 259 * scale_factor, # population density uk,
    'initial_infected': 0.05,
    'infect_rate': 0.1,
    'recovery_period': 14 * 12,
    'critical_rate': 0.05,
    'hospital_capacity_rate': .02,
    'active_ratio': 8 / 24.0,
    'immunity_chance': 1.0,
    'quarantine_rate': 0.6,
    'lockdown_policy': lockdown_policy,
    'cycles': 200 * 12,
    'hospital_period': 21 * 12,
}
```

我们将在*如何工作中解释网格的动机...*一节。

锁定由`lockdown_policy`方法声明，该方法被传递给`Simulation`的构造函数。

首先，让我们看看没有引入锁定时的数据。如果我们的`policy`函数总是返回`False`，我们可以创建这个策略:

```py
def lockdown_policy(infected, deaths, population_size):
    return 0
```

结果图显示了我们随时间收集的五个变量:

![](assets/dadc7951-0559-418e-8da7-a54ec51e1248.png)

总的来说，我们有 8774 人死亡。

在这里，我们可以看到随着根据此策略提前解除封锁，出现了几波感染:

```py
def lockdown_policy(infected, deaths, population_size):
  if (
    (max(infected[-5 * 10:]) / population_size) > 0.6
    and 
    (len(deaths) > 2 and deaths[-1] > deaths[-2])
 ):
 return 7 * 12
 return 0
```

当我们运行此模拟时，我们得到了完全不同的结果，如下所示:

![](assets/bb631cd4-91dc-4621-bfaa-b39786d40cec.png)

250 次迭代周围的矩形显示了何时宣布锁定(忽略比例或形状)。总的来说，我们可以看到这导致了 20，663 人死亡。这个极高的死亡率——远高于`critical_rate`参数——由于免疫前的再感染，被设定为 5%。

让我们将这与一项非常谨慎的政策进行比较，即每当死亡率上升或如果人口感染率在(大约)3 周内上升超过 20%，就宣布封锁:

```py
def lockdown_policy(infected, deaths, population_size):
    if infected[-1] / population_size > 0.2:
        return 21 * 12
    return 0
```

通过一次锁定，我们得到了下面的图表，它显示了总共约 600 例死亡:

![](assets/e0201d7c-7781-4da1-8408-76ad16e461d5.png)

您可以更改这些参数或玩弄逻辑来创建更复杂和/或更真实的模拟。

更多围绕原著的细节可以在网上找到([https://Teck 78 . blogspot . com/2020/04/using-mesa-framework-to-simulate-spread . html](https://teck78.blogspot.com/2020/04/using-mesa-framework-to-simulate-spread.html))。

## 它是如何工作的...

模拟非常简单:它由代理组成，并在迭代中进行(称为循环)。每个代理都代表了群体的一部分。

在这里，一定的人群感染了这种疾病。在每个周期(相当于 1 小时)，感染者可以去医院(如果有能力的话)，死亡，或走向康复。他们也可以被隔离。当它们活着、没有康复、没有被隔离时，它们可以感染空间上靠近它们的其他人。当恢复时，病原体会变得免疫。

在每个周期中，代理可以四处移动。如果他们没有被隔离或者国家封锁已经宣布，他们会转移到一个新的位置；否则，它们会留在原地。如果一个人被感染，他们可能会死亡，去医院，康复，感染他人，或被隔离。

根据死亡率和感染率，可以根据不同的政策宣布全国封锁。这是我们模拟的主要焦点:全国封锁的引入如何影响死亡人数？

我们需要考虑不同的变量。一是人口密度。我们可以通过在地图或网格上放置我们的代理来引入人口密度，其中网格大小由`grid_x`和`grid_y`定义。`infect_rate`参数必须根据网格大小和人口密度进行调整。

这里我们要考虑更多的参数，例如:

*   `initial_infected`是人群最初被感染的比率。
*   `recovery_period`表示感染后恢复所需的周期数(大约以小时为单位),`0`表示从不。
*   `critical_rate`是指在整个恢复期内，患者可能会病危的比率，这意味着他们可能会去医院，或者死亡。
*   `hospital_capacity_rate`是总人口中人均医院床位数。我们通过在线搜索([https://www . hsj . co . uk/acute-care/NHS-hospitals-have-four-times-than-normal/7027392 . article](https://www.hsj.co.uk/acute-care/nhs-hospitals-have-four-times-more-empty-beds-than-normal/7027392.article)，[https://www . kings fund . org . uk/publications/NHS-hospital-bed-numbers](https://www.kingsfund.org.uk/publications/nhs-hospital-bed-numbers))发现了这一点。
*   还有`active_ratio`，定义一个人的活跃程度；`quarantine_rate`，决定某人进入自我隔离的可能性有多大(如果不是医院)；和`immunity_chance`，这是相关的恢复后。
*   模拟将运行一段设定的时间`cycles`，我们的锁定策略在`lockdown_policy`函数中声明。

在`Simulation`的`step()`方法中，我们进行了数据收集。然后，我们根据`free_beds`变量检查医院是否可以接收更多的病人。然后，我们用`self.schedule.step()`运行代理。如果我们在一级防范禁闭中，我们会倒数。一旦宣布了锁定，就将锁定从`False`设置为`lockdown_period`变量(通过使用 Python 的鸭子类型)。

鉴于一段时间内有多少特工被感染和死亡(列表),函数决定国家封锁应该持续多久。在这里，0 表示我们不宣布封锁。

## 还有更多...

由于模拟可能需要很长时间来运行，因此尝试参数可能会非常慢。我们可以使用`matplotlib.`的实时绘图功能，而不必进行一次完整的运行，然后再看我们是否得到了想要的效果

为了获得更快的反馈，让我们实时绘制模拟循环，如下所示:

```py
%matplotlib inline
from collections import defaultdict
from matplotlib import pyplot as plt
from IPython.display import clear_output

def live_plot(data_dict, figsize=(7,5), title=''):
    clear_output(wait=True)
    plt.figure(figsize=figsize)
    for label,data in data_dict.items():
        plt.plot(data, label=label)
    plt.title(title)
    plt.grid(True)
    plt.xlabel('iteration')
    plt.legend(loc='best')
    plt.show()

model = Simulation(sim_params)
cycles_to_run = sim_params.get('cycles')
print(sim_params)
for current_cycle in range(cycles_to_run):
    model.step()
    if (current_cycle % 10) == 0:
        live_plot(model.datacollector.model_vars)

print('Total deaths: {}'.format(
    model.datacollector.model_vars['Deaths'][-1]
))
```

这将持续(每 10 个周期)更新我们的模拟参数图。如果不成功，我们可以中止它，而不必等待完整的模拟。

## 请参见

你可以在[https://mesa.readthedocs.io/en/master/](https://mesa.readthedocs.io/en/master/)找到更多关于 mesa 的基于多代理的 Python 建模。其他一些多代理库如下:

*   MAgent 专门研究 2D 环境，有大量的代理通过强化学习进行学习:[https://github.com/PettingZoo-Team/MAgent](https://github.com/PettingZoo-Team/MAgent)。
*   osBrain 和 PADE 是通用的多代理系统库。它们分别位于 https://osbrain.readthedocs.io/en/stable/的和 https://pade.readthedocs.io/en/latest/的。
*   SimPy 是一个离散事件模拟器，可以用于更广泛的模拟:[https://simpy.readthedocs.io/en/latest/](https://simpy.readthedocs.io/en/latest/)。

其他模拟器也已经发布，最突出的是 CovidSim 微观模拟模型([https://github.com/mrc-ide/covid-sim](https://github.com/mrc-ide/covid-sim))，它是由伦敦帝国理工学院主持的 MRC 全球传染病分析中心开发的。

# 用蒙特卡罗树搜索编写象棋引擎

国际象棋是一种双人棋盘游戏，自 15 世纪以来一直是一种流行的智力游戏。在 1997 年一台计算机击败人类世界冠军之前，一台计算机在 20 世纪 50 年代击败了第一位人类玩家(一个完全的新手)。从那以后，他们已经发展到拥有超人的智慧。编写国际象棋引擎(一个下国际象棋的计算机程序)的主要困难之一是在众多的变化和组合中搜索并挑选出最好的一个。

在这个菜谱中，我们将使用蒙特卡罗树搜索来创建一个基本的象棋引擎。

## 做好准备

我们将使用`python-chess`库进行可视化，以获得有效的移动，并知道一个状态是否结束。我们可以用`pip`命令安装它，如下所示:

```py
pip install python-chess
```

我们将使用这个库进行可视化，在每个位置生成有效的移动，并检查我们是否到达了最终位置。

## 怎么做...

这个食谱是基于 Luke Miles 在[https://gist . github . com/qpwo/c 538 c6f 73727 e 254 FDC 7 fab 81024 F6 e 1](https://gist.github.com/qpwo/c538c6f73727e254fdc7fab81024f6e1)的蒙特卡罗树搜索的最小实现。

首先，我们将查看用于定义树搜索类的代码，然后查看搜索是如何工作的。之后，我们将学习如何将它应用于国际象棋。

### 树形搜索

树搜索是采用搜索树作为数据结构的搜索。一般来说，在搜索树中，节点(或树叶)代表一个概念或一种情况，然后这些节点通过边(分支)连接起来。树搜索遍历树以得出最佳解决方案。

让我们从实现树搜索类开始:

```py
import random

class MCTS:
    def __init__(self, exploration_weight=1):
        self.Q = defaultdict(int)
        self.N = defaultdict(int)
        self.children = dict()
        self.exploration_weight = exploration_weight
```

我们将在*中更详细地了解这些变量的工作原理...*一节。我们很快会给这个类添加更多的方法。

我们的树搜索中的不同步骤在我们的`do_rollout`方法中执行:

```py
    def do_rollout(self, node):
        path = self._select(node)
        leaf = path[-1]
        self._expand(leaf)
        reward = self._simulate(leaf)
        self._backpropagate(path, reward)
```

每个`rollout()`调用都给我们的树增加了一层。

让我们依次完成四个主要步骤:

1.  `select`步骤找到一个还没有开始模拟的叶节点:

```py
    def _select(self, node):
        path = []
        while True:
            path.append(node)
            if node not in self.children or not self.children[node]:
                return path
            unexplored = self.children[node] - self.children.keys()
            if unexplored:
                n = unexplored.pop()
                path.append(n)
                return path
            node = self._select(random.choice(self.children[node]))
```

这是递归定义的，所以如果我们没有找到一个未浏览的节点，我们将浏览当前节点的子节点。

2.  扩展步骤添加子节点，即在给定电路板位置的情况下，可以通过有效移动到达的节点:

```py
    def _expand(self, node):
        if node in self.children:
            return
        self.children[node] = node.find_children()
```

这个函数用节点的后代(或子节点)更新`children`字典。这些节点是任何有效的板位置，可以在一次移动中从该节点到达。

3.  模拟步骤运行一系列移动，直到游戏结束:

```py
    def _simulate(self, node):
        invert_reward = True
        while True:
            if node.is_terminal():
                reward = node.reward()
                return 1 - reward if invert_reward else reward
            node = node.find_random_child()
            invert_reward = not invert_reward
```

该功能将模拟播放到游戏结束。

4.  反向传播步骤将奖励与路径的每一步相关联:

```py
    def _backpropagate(self, path, reward):
        for node in reversed(path):
            self.N[node] += 1
            self.Q[node] += reward
            reward = 1 - reward
```

最后，我们需要一种方法来选择最好的移动，这可以简单到浏览`Q`和`N`字典并选择具有最大效用(奖励)的后代:

```py
    def choose(self, node):
        if node not in self.children:
            return node.find_random_child()

        def score(n):
            if self.N[n] == 0:
                return float('-inf')
            return self.Q[n] / self.N[n]

        return max(self.children[node], key=score)
```

我们将任何看不见的节点的分数设置为`-infinity`，以避免选择看不见的移动。

### 实现节点

现在，让我们学习如何为我们的象棋实现使用一个节点。

因为这是基于`python-chess`库的，所以相对容易实现:

```py
import hashlib
import copy

class ChessGame:
    def find_children(self):
        if self.is_terminal():
            return set()
        return {
            self.make_move(m) for m in self.board.legal_moves
        }

    def find_random_child(self):
        if self.is_terminal():
            return None
        moves = list(self.board.legal_moves)
        m = choice(moves)
        return self.make_move(m)

    def player_win(self, turn):
        if self.board.result() == '1-0' and turn:
            return True
        if self.board.result() == '0-1' and not turn:
            return True
        return False

    def reward(self):
        if self.board.result() == '1/2-1/2':
            return 0.5
        if self.player_win(not self.board.turn):
            return 0.0

    def make_move(self, move):
        child = self.board.copy()
        child.push(move)
        return ChessGame(child)

    def is_terminal(self):
        return self.board.is_game_over()
```

我们在这里省略了一些方法，但是不要担心——我们将在*它是如何工作的章节中介绍它们...*一节。

现在一切都准备好了，我们终于可以下棋了。

### 下棋

让我们下象棋吧！

下面是一个简单的循环，带有图形提示，说明电路板的位置:

```py
from IPython.display import display
import chess
import chess.svg

def play_chess():
    tree = MCTS()
    game = ChessGame(chess.Board())
    display(chess.svg.board(board=game.board, size=300))
    while True:
        move_str = input('enter move: ')
        move = chess.Move.from_uci(move_str)
        if move not in list(game.board.legal_moves):
            raise RuntimeError('Invalid move')
        game = game.make_move(move)
        display(chess.svg.board(board=game.board, size=300))
        if game.is_terminal():
            break
        for _ in range(50):
            tree.do_rollout(game)
        game = tree.choose(game)
        print(game)
        if game.is_terminal():
            break
```

然后，你应该被要求进入一个移动到棋盘上的某个位置。每走一步后，会出现一个棋盘，显示棋子的当前位置。这可以从下面的截图中看出:

![](assets/b028c2ce-c138-4008-bf02-ab37d0372fa8.png)

请注意，移动必须输入 UCI 符号。如果你以正方形到正方形的格式输入移动，例如 a2a4，它应该总是有效的。

这里使用的播放强度不是很高，但是仍然可以很容易地看到一些改进。注意，这个实现不是并行的。

## 它是如何工作的...

在**蒙特卡洛树搜索** ( **MCTS** )中，我们应用了蒙特卡洛方法——基本上是随机抽样——以获得玩家所做的移动强度的概念。对于每一步棋，我们随机移动直到游戏结束。如果我们经常这样做，我们会得到一个好的估计。

树形搜索维护不同的变量:

*   `Q`是每个节点的总奖励。
*   `N`是每个节点的总访问次数。
*   `children`保存每个节点的子节点——从电路板位置可以到达的节点。
*   在我们的例子中，节点是一个板状态。

这些字典很重要，因为我们将节点(董事会状态)的效用与回报进行平均，并且我们根据节点被访问的频率(或者更确切地说，被访问的次数)对节点进行采样。

搜索的每次迭代包括四个步骤:

1.  选择
2.  膨胀
3.  模拟
4.  反向传播

最基本的选择步骤是寻找一个还没有探索过的节点(比如一个棋盘位置)。

扩展步骤用所选节点的子节点更新`children`字典。

模拟步骤很简单:我们玩出一连串的随机移动，直到到达终点位置并返回奖励。由于这是一个两人零和棋盘游戏，当轮到对手时，我们必须反转奖励。

反向传播步骤沿着反向路径将奖励与探索路径中的所有节点相关联。`_backpropagate()`方法沿着一系列移动(一条路径)回溯所有节点，给它们赋予奖励，并更新访问次数。

至于实现节点，节点必须是可散列的和可比较的，因为我们将把它们存储在前面提到的字典中。所以，在这里，我们需要实现`__hash__`和`__eq__`方法。我们之前省略了它们，因为我们不需要它们来理解算法本身，所以为了完整起见，我们在这里添加了它们:

```py
    def __hash__(self):
        return int(
            hashlib.md5(
                self.board.fen().encode('utf-8')
            ).hexdigest()[:8],
            16
        )

    def __eq__(self, other):
        return self.__hash__() == other.__hash__()

    def __repr__(self):
        return '\n' + str(self.board)
```

在调试时，`__repr__()`方法会非常有用。

对于`ChessGame`类的主要功能，我们还需要以下方法:

*   `find_children()`:从当前节点查找所有可能的后继节点
*   `find_random_child()`:从当前节点中寻找一个随机的后继节点
*   `is_terminal()`:确定一个节点是否是终端
*   `reward()`:为当前节点提供奖励

请再看一下`ChessGame`的实现，看看它是如何工作的。

## 还有更多...

MCTS 的一个主要扩展是**上置信树** ( **UCTs** )，用于平衡勘探和开采。第一个在 9x9 棋盘上达到丹水平的围棋程序是 MCTS 和 UCT。

为了实现`UCT`扩展，我们必须返回到我们的`MCTS`类并做一些修改:

```py
    def _uct_select(self, node):
        log_N_vertex = math.log(self.N[node])

        def uct(n):
            return self.Q[n] / self.N[n] + self.exploration_weight * math.sqrt(
                log_N_vertex / self.N[n]
            )

        return max(self.children[node], key=uct)
```

`uct()`函数应用**置信上限** ( **UCB** )公式，该公式提供了一个带有分数的移动。节点 *n* 的分数是从节点 *n* 开始的所有模拟中获胜的模拟数量的总和，加上一个置信项:

![](assets/3cd15c9a-842a-4e93-9c8b-6866bed8a6e0.png)

这里， *c* 是常数。

接下来，我们需要替换最后一行代码，以便它使用`_uct_select()`而不是 `_select()`进行递归。在这里，我们将替换`_select()`的最后一行，使其表述如下:

```py
            node = self._uct_select(node)
```

做这个改动应该会进一步增加代理的发挥实力。

## 请参见

想了解更多关于 UCTs 的内容，可以看看下面这篇关于 MoGO 的文章，关于第一个在 9x9 的棋盘上达到 dan 级别的计算机围棋程序:[https://Hal . inria . fr/file/index/docid/369786/filename/TCI AIG-2008-0010 _ Accepted _。pdf](https://hal.inria.fr/file/index/docid/369786/filename/TCIAIG-2008-0010_Accepted_.pdf) 。它还提供了伪代码的 MCTS 描述。

easyAI 库包含了很多不同的搜索算法:[https://zulko.github.io/easyAI/index.html](https://zulko.github.io/easyAI/index.html)。*