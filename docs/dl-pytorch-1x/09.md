<title>Implementing Autoencoders</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# å®ç°è‡ªåŠ¨ç¼–ç å™¨

æœ¬ç« é€šè¿‡å¼•å…¥è‡ªåŠ¨ç¼–ç å™¨æ¥é˜è¿°åŠç›‘ç£å­¦ä¹ ç®—æ³•çš„æ¦‚å¿µï¼Œç„¶åç»§ç»­è®¨è®º**å—é™ç»å°”å…¹æ›¼æœºå™¨** ( **RBMs** )å’Œ**æ·±åº¦ä¿¡å¿µç½‘ç»œ** ( **DBNs** )ï¼Œä»¥ä¾¿ç†è§£æ•°æ®çš„æ¦‚ç‡åˆ†å¸ƒã€‚è¿™ä¸€ç« å°†å‘ä½ æ¦‚è¿°è¿™äº›ç®—æ³•æ˜¯å¦‚ä½•åº”ç”¨äºä¸€äº›ç°å®ä¸–ç•Œçš„é—®é¢˜çš„ã€‚è¿˜å°†æä¾›ç”¨ PyTorch å®ç°çš„ç¼–ç ç¤ºä¾‹ã€‚

è‡ªåŠ¨ç¼–ç å™¨æ˜¯ä¸€ç§æ— ç›‘ç£çš„å­¦ä¹ æŠ€æœ¯ã€‚ä»–ä»¬å¯ä»¥è·å–ä¸€ä¸ªæœªæ ‡è®°çš„æ•°æ®é›†ï¼Œå¹¶é€šè¿‡ä½¿ç”¨éç›‘ç£å­¦ä¹ é—®é¢˜(ä¸ç›‘ç£å­¦ä¹ é—®é¢˜ç›¸å)å¯¹å…¶è¿›è¡Œå»ºæ¨¡æ¥é‡å»ºåŸå§‹è¾“å…¥ã€‚è‡ªåŠ¨ç¼–ç å™¨çš„ç›®æ ‡æ˜¯ä½¿è¾“å…¥å°½å¯èƒ½ä¸è¾“å‡ºç›¸ä¼¼ã€‚

å…·ä½“æ¥è¯´ï¼Œæœ¬ç« å°†æ¶µç›–ä»¥ä¸‹ä¸»é¢˜:

*   è‡ªåŠ¨ç¼–ç å™¨åŠå…¶åº”ç”¨ç»¼è¿°
*   ç“¶é¢ˆå’ŒæŸå¤±å‡½æ•°
*   ä¸åŒç±»å‹çš„è‡ªåŠ¨ç¼–ç å™¨
*   å—é™ç»å°”å…¹æ›¼æœºå™¨
*   æ·±åº¦ä¿¡å¿µç½‘ç»œ

<title>Applications of autoencoders</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# è‡ªåŠ¨ç¼–ç å™¨çš„åº”ç”¨

è‡ªåŠ¨ç¼–ç å™¨å±äºä»£è¡¨æ€§å­¦ä¹ ï¼Œç”¨äºå¯»æ‰¾è¾“å…¥çš„å‹ç¼©è¡¨ç¤ºã€‚å®ƒä»¬ç”±ä¸€ä¸ªç¼–ç å™¨å’Œä¸€ä¸ªè§£ç å™¨ç»„æˆã€‚ä¸‹å›¾æ˜¾ç¤ºäº†è‡ªåŠ¨ç¼–ç å™¨çš„ç»“æ„:

![](assets/693d5531-ef4e-45a0-aa19-a9c0854da1ec.png)

è‡ªåŠ¨ç¼–ç å™¨çš„åº”ç”¨ç¤ºä¾‹åŒ…æ‹¬:

*   æ•°æ®å»å™ª
*   æ•°æ®å¯è§†åŒ–çš„é™ç»´
*   å›¾è±¡ç”Ÿæˆ
*   æ’å…¥æ–‡æœ¬

<title>Bottleneck and loss functions</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# ç“¶é¢ˆå’ŒæŸå¤±å‡½æ•°

è‡ªåŠ¨ç¼–ç å™¨åœ¨ç½‘ç»œä¸Šå¼ºåŠ äº†ä¸€ä¸ªç“¶é¢ˆï¼Œå¼ºåˆ¶æ‰§è¡ŒåŸå§‹è¾“å…¥çš„å‹ç¼©çŸ¥è¯†è¡¨ç¤ºã€‚å¦‚æœç“¶é¢ˆä¸å­˜åœ¨ï¼Œç½‘ç»œå°†ç®€å•åœ°å­¦ä¹ è®°å¿†è¾“å…¥å€¼ã€‚å› æ­¤ï¼Œè¿™æ„å‘³ç€æ¨¡å‹ä¸èƒ½å¾ˆå¥½åœ°æ¦‚æ‹¬çœ‹ä¸è§çš„æ•°æ®:

![](assets/a862aa43-423e-4616-b93e-6c317b509ee9.png)

ä¸ºäº†è®©æ¨¡å‹æ£€æµ‹åˆ°ä¿¡å·ï¼Œæˆ‘ä»¬éœ€è¦å®ƒå¯¹è¾“å…¥æ•æ„Ÿï¼Œä½†ä¸è¦å¤ªæ•æ„Ÿï¼Œä»¥è‡³äºå®ƒåªæ˜¯è®°ä½å®ƒä»¬ï¼Œè€Œä¸èƒ½å¾ˆå¥½åœ°é¢„æµ‹çœ‹ä¸è§çš„æ•°æ®ã€‚ä¸ºäº†ç¡®å®šæœ€ä½³æƒè¡¡ï¼Œæˆ‘ä»¬éœ€è¦æ„å»ºä¸€ä¸ªæŸå¤±/æˆæœ¬å‡½æ•°:

![](assets/8e2bfc83-5110-405d-9e0a-74b6c8312912.png)

æœ‰ä¸€äº›å¸¸ç”¨çš„è‡ªåŠ¨ç¼–ç å™¨æ¶æ„æ¥æ–½åŠ è¿™ä¸¤ä¸ªçº¦æŸï¼Œå¹¶ç¡®ä¿è¿™ä¸¤è€…ä¹‹é—´æœ‰ä¸€ä¸ªæœ€ä½³çš„å¹³è¡¡ã€‚

<title>Coded example â€“ standard autoencoder</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# ç¼–ç ç¤ºä¾‹â€“æ ‡å‡†è‡ªåŠ¨ç¼–ç å™¨

åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•åœ¨ PyTorch ä¸­ç¼–è¯‘è‡ªåŠ¨ç¼–ç å™¨æ¨¡å‹:

1.  é¦–å…ˆï¼Œå¯¼å…¥ç›¸å…³çš„åº“:

```py
import os
from torch import nn
from torch.autograd import Variable
from torch.utils.data import DataLoader
from torchvision import transforms
from torchvision.datasets import MNIST
from torchvision.utils import save_image
```

2.  ç°åœ¨ï¼Œå®šä¹‰æ¨¡å‹å‚æ•°:

```py
number_epochs = 10
batch_size = 128
learning_rate = 1e-4
```

3.  ç„¶åï¼Œå¯åŠ¨ä¸€ä¸ªå‡½æ•°æ¥å˜æ¢ MNIST æ•°æ®é›†ä¸­çš„å›¾åƒ:

```py
transform_image = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

dataset = MNIST('./data', transform=transform_image)
data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
```

4.  å®šä¹‰è‡ªåŠ¨ç¼–ç å™¨ç±»ï¼Œåœ¨å…¶ä¸­è¾“å…¥æ•°æ®å¹¶åˆå§‹åŒ–æ¨¡å‹:

```py
class autoencoder_model(nn.Module):
    def __init__(self):
        super(autoencoder_model, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(28 * 28, 128),
            nn.ReLU(True),
            nn.Linear(128, 64),
            nn.ReLU(True), nn.Linear(64, 12), nn.ReLU(True), nn.Linear(12, 3))
        self.decoder = nn.Sequential(
            nn.Linear(3, 12),
           nn.ReLU(True),
            nn.Linear(12, 64),
            nn.ReLU(True),
            nn.Linear(64, 128),
            nn.ReLU(True), nn.Linear(128, 28 * 28), nn.Tanh())

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

model = autoencoder_model()
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(
model.parameters(), lr=learning_rate, weight_decay=1e-5)
```

5.  å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œè¯¥å‡½æ•°å°†åœ¨æ¯ä¸ªå†å…ƒåè¾“å‡ºæ¨¡å‹ä¸­çš„å›¾åƒ:

```py
def to_image(x):
    x = 0.5 * (x + 1)
    x = x.clamp(0, 1)
    x = x.view(x.size(0), 1, 28, 28)
    return x
```

6.  ç°åœ¨ï¼Œåœ¨æ¯ä¸ªæ—¶æœŸè¿è¡Œæ¨¡å‹ï¼Œå¹¶æŸ¥çœ‹é‡å»ºå›¾åƒçš„ç»“æœ:

```py
for epoch in range(number_epochs):
    for data in data_loader:
        image, i = data
        image = image.view(image.size(0), -1)
        image = Variable(image)

        # Forward pass
        output = model(image)
        loss = criterion(output, image)

        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print('Epoch [{}/{}], Loss:{:.4f}'.format(epoch + 1, number_epochs, loss.data[0]))
    if epoch % 10 == 0:
        pic = to_image(output.cpu().data)
        save_image(pic, './mlp_img/image_{}.png'.format(epoch))

torch.save(model.state_dict(), './sim_autoencoder.pth')
```

è¿™å°†äº§ç”Ÿä»¥ä¸‹è¾“å‡º:

![](assets/b9ecb6f8-ef83-48aa-8e49-e29b3a0f6bca.png)

ä¸‹å›¾æ˜¾ç¤ºäº†è‡ªåŠ¨ç¼–ç å™¨åœ¨æ¯ä¸ªæ—¶æœŸçš„è¾“å‡º:

![](assets/ab6c7350-99d9-4cb1-bde0-602292f98856.png)

éšç€æ¨¡å‹ç»§ç»­å­¦ä¹ ï¼Œç»è¿‡çš„æ—¶æœŸè¶Šå¤šï¼Œå›¾åƒå°±å˜å¾—è¶Šæ¸…æ™°ã€‚

<title>Convolutional autoencoders</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# å·ç§¯è‡ªåŠ¨ç¼–ç å™¨

è‡ªåŠ¨ç¼–ç å™¨å¯ä»¥ç”¨äºå·ç§¯ï¼Œè€Œä¸æ˜¯å®Œå…¨è¿æ¥çš„å±‚ã€‚è¿™å¯ä»¥ä½¿ç”¨ 3D çŸ¢é‡è€Œä¸æ˜¯ 1D çŸ¢é‡æ¥å®Œæˆã€‚åœ¨å›¾åƒçš„ä¸Šä¸‹æ–‡ä¸­ï¼Œå¯¹å›¾åƒè¿›è¡Œä¸‹é‡‡æ ·ä¼šå¼ºåˆ¶è‡ªåŠ¨ç¼–ç å™¨å­¦ä¹ å›¾åƒçš„å‹ç¼©ç‰ˆæœ¬ã€‚

<title>Coded example â€“ convolutional autoencoder</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# ç¼–ç ç¤ºä¾‹â€“å·ç§¯è‡ªåŠ¨ç¼–ç å™¨

åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ç¼–è¯‘å·ç§¯è‡ªåŠ¨ç¼–ç å™¨:

1.  å’Œå‰é¢ä¸€æ ·ï¼Œæ‚¨ä» MNIST æ•°æ®é›†è·å¾—è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†ï¼Œå¹¶å®šä¹‰æ¨¡å‹å‚æ•°:

```py
number_epochs = 10
batch_size = 128
learning_rate = 1e-4

transform_image = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

dataset = MNIST('./data', transform=transform_image)
data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
```

2.  ä»è¿™é‡Œå¼€å§‹ï¼Œåˆå§‹åŒ–å·ç§¯è‡ªåŠ¨ç¼–ç å™¨çš„æ¨¡å‹:

```py
class conv_autoencoder(nn.Module):
    def __init__(self):
        super(conv_autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 16, 3, stride=3, padding=1), 
            nn.ReLU(True),
            nn.MaxPool2d(2, stride=2), 
            nn.Conv2d(16, 8, 3, stride=2, padding=1), 
            nn.ReLU(True),
            nn.MaxPool2d(2, stride=1) 
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(8, 16, 3, stride=2), 
            nn.ReLU(True),
            nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1), 
            nn.ReLU(True),
            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1), 
            nn.Tanh()
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

model = conv_autoencoder()
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)
```

3.  æœ€åï¼Œåœ¨æ¯ä¸ªæ—¶æœŸè¿è¡Œæ¨¡å‹ï¼ŒåŒæ—¶ä¿å­˜è¾“å‡ºå›¾åƒä»¥ä¾›å‚è€ƒ:

```py
for epoch in range(number_epochs):
    for data in data_loader:
        img, i = data
        img = Variable(img)

        # Forward pass
        output = model(img)
        loss = criterion(output, img)

        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    # Print results
    print('epoch [{}/{}], loss:{:.4f}'
          .format(epoch+1, number_epochs, loss.data[0]))
    if epoch % 10 == 0:
        pic = to_image(output.cpu().data)
        save_image(pic, './dc_img/image_{}.png'.format(epoch))

torch.save(model.state_dict(), './convolutional_autoencoder.pth')
```

æˆ‘ä»¬å¯ä»¥åœ¨ä»£ç ä¸­æåˆ°çš„æ–‡ä»¶å¤¹ä¸­æŸ¥çœ‹æ¯ä¸ªçºªå…ƒåä¿å­˜çš„å›¾åƒã€‚

<title>Denoising autoencoders</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# é™å™ªè‡ªåŠ¨ç¼–ç å™¨

å»å™ªç¼–ç å™¨æ•…æ„å°†å™ªå£°æ·»åŠ åˆ°ç½‘ç»œçš„è¾“å…¥ä¸­ã€‚è¿™äº›è‡ªåŠ¨ç¼–ç å™¨å®é™…ä¸Šåˆ›å»ºäº†æ•°æ®çš„æŸåå‰¯æœ¬ã€‚è¿™æ ·åšæœ‰åŠ©äºç¼–ç å™¨å­¦ä¹ è¾“å…¥æ•°æ®ä¸­çš„æ½œåœ¨è¡¨ç¤ºï¼Œä½¿å…¶æ›´å…·æ™®éæ€§:

![](assets/7fb53730-c36b-4900-be3b-39f76e76f65e.png)

è¿™ä¸ªè¢«ç ´åçš„å›¾åƒä»¥ä¸å…¶ä»–æ ‡å‡†è‡ªåŠ¨ç¼–ç å™¨ç›¸åŒçš„æ–¹å¼è¢«é¦ˆé€åˆ°ç½‘ç»œä¸­:

![](assets/0c46e5ba-3ff4-4584-b559-6f772c705114.png)

æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼ŒåŸå§‹è¾“å…¥ä¸­æ·»åŠ äº†å™ªå£°ï¼Œç¼–ç å™¨å¯¹è¾“å…¥è¿›è¡Œç¼–ç å¹¶å°†å…¶å‘é€ç»™è§£ç å™¨ï¼Œç„¶åè§£ç å™¨å°†å™ªå£°è¾“å…¥è§£ç ä¸ºå¹²å‡€çš„è¾“å‡ºã€‚å› æ­¤ï¼Œæˆ‘ä»¬ç ”ç©¶äº†è‡ªåŠ¨ç¼–ç å™¨çš„å„ç§åº”ç”¨ã€‚æˆ‘ä»¬ç°åœ¨æ¥çœ‹ä¸€ç§ç‰¹å®šç±»å‹çš„è‡ªåŠ¨ç¼–ç å™¨ï¼Œå®ƒæ˜¯ä¸€ç§**å˜å‹è‡ªåŠ¨ç¼–ç å™¨** ( **VAE** )ã€‚

<title>Variational autoencoders</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# å¯å˜è‡ªåŠ¨ç¼–ç å™¨

VAEs ä¸åŒäºè¿„ä»Šä¸ºæ­¢æˆ‘ä»¬æ‰€è€ƒè™‘çš„æ ‡å‡†è‡ªåŠ¨ç¼–ç å™¨ï¼Œå› ä¸ºå®ƒä»¬ä»¥æ¦‚ç‡æ–¹å¼è€Œä¸æ˜¯ç¡®å®šæ€§æ–¹å¼æè¿°æ½œåœ¨ç©ºé—´ä¸­çš„è§‚å¯Ÿã€‚è¾“å‡ºæ¯ä¸ªæ½œåœ¨å±æ€§çš„æ¦‚ç‡åˆ†å¸ƒï¼Œè€Œä¸æ˜¯å•ä¸ªå€¼ã€‚

æ ‡å‡†è‡ªåŠ¨ç¼–ç å™¨åœ¨ç°å®ä¸–ç•Œä¸­çš„åº”ç”¨æœ‰äº›æœ‰é™ï¼Œå› ä¸ºå®ƒä»¬åªæœ‰åœ¨æ‚¨æƒ³è¦å¤åˆ¶å·²ç»æ”¾å…¥å…¶ä¸­çš„æ•°æ®æ—¶æ‰çœŸæ­£æœ‰ç”¨ã€‚ç”±äº vae æ˜¯åˆ›æˆå¼æ¨¡å‹ï¼Œå› æ­¤å®ƒä»¬å¯ä»¥åº”ç”¨äºä¸å¸Œæœ›è¾“å‡ºä¸è¾“å…¥ç›¸åŒçš„æ•°æ®çš„æƒ…å†µã€‚

è®©æˆ‘ä»¬åœ¨ç°å®ç¯å¢ƒä¸­è€ƒè™‘è¿™ä¸ªé—®é¢˜ã€‚å½“åœ¨äººè„¸æ•°æ®é›†ä¸Šè®­ç»ƒ autoencoder æ¨¡å‹æ—¶ï¼Œæ‚¨ä¼šå¸Œæœ›å®ƒèƒ½å¤Ÿå­¦ä¹ æ½œåœ¨çš„å±æ€§ï¼Œä¾‹å¦‚è¿™ä¸ªäººæ˜¯å¦åœ¨å¾®ç¬‘ï¼Œä»–ä»¬çš„è‚¤è‰²ï¼Œä»–ä»¬æ˜¯å¦æˆ´ç€çœ¼é•œï¼Œç­‰ç­‰:

![](assets/4cc640bb-841f-438d-a6cc-79837d7e85dd.png)

æ­£å¦‚æˆ‘ä»¬åœ¨ä¸Šå›¾ä¸­çœ‹åˆ°çš„ï¼Œæ ‡å‡†è‡ªåŠ¨ç¼–ç å™¨å°†è¿™äº›æ½œåœ¨å±æ€§è¡¨ç¤ºä¸ºç¦»æ•£å€¼ã€‚

å¦‚æœæˆ‘ä»¬å…è®¸æ¯ä¸ªç‰¹å¾åœ¨ä¸€ä¸ªå¯èƒ½å€¼çš„èŒƒå›´å†…ï¼Œè€Œä¸æ˜¯å•ä¸ªå€¼ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ VAEs ä»¥æ¦‚ç‡æœ¯è¯­æè¿°å±æ€§:

![](assets/76947b8a-b694-4db9-b32a-498f4972ba45.png)

ä¸Šå›¾æè¿°äº†æˆ‘ä»¬å¦‚ä½•ç”¨ç¦»æ•£å€¼æˆ–æ¦‚ç‡åˆ†å¸ƒæ¥è¡¨ç¤ºä¸€ä¸ªäººæ˜¯å¦åœ¨å¾®ç¬‘ã€‚

ä»å›¾åƒä¸­é‡‡æ ·æ¯ä¸ªæ½œåœ¨å±æ€§çš„åˆ†å¸ƒï¼Œä»¥ä¾¿ç”Ÿæˆç”¨ä½œè§£ç å™¨æ¨¡å‹çš„è¾“å…¥çš„å‘é‡:

![](assets/07851c42-ae8a-4888-a8d8-39704d6948da.png)

è¾“å‡ºä¸¤ä¸ªå‘é‡ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤º:

![](assets/d6e926bd-3db3-4433-969d-9237af0bf3a0.png)

ä¸€ä¸ªæè¿°å¹³å‡å€¼ï¼Œå¦ä¸€ä¸ªæè¿°åˆ†å¸ƒçš„æ–¹å·®ã€‚

<title>Training VAEs</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# åŸ¹è®­è¯¾ç¨‹

åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ç§°ä¸º**åå‘ä¼ æ’­**çš„è¿‡ç¨‹æ¥è®¡ç®—ç½‘ç»œä¸­æ¯ä¸ªå‚æ•°ç›¸å¯¹äºæ€»æŸè€—çš„å…³ç³»ã€‚

æ ‡å‡†è‡ªåŠ¨ç¼–ç å™¨ä½¿ç”¨åå‘ä¼ æ’­æ¥é‡å»ºç½‘ç»œæƒé‡çš„æŸå¤±å€¼ã€‚ç”±äº VAEs ä¸­çš„é‡‡æ ·æ“ä½œä¸å¯å¾®ï¼Œæ¢¯åº¦ä¸èƒ½ä»é‡å»ºè¯¯å·®ä¸­ä¼ æ’­ã€‚ä¸‹å›¾å¯¹æ­¤è¿›è¡Œäº†è¿›ä¸€æ­¥è§£é‡Š:

![](assets/12949e89-c9f1-491d-a822-7e82befa9fa2.png)

ä¸ºäº†å…‹æœè¿™ä¸ªé™åˆ¶ï¼Œå¯ä»¥ä½¿ç”¨é‡æ–°å‚æ•°åŒ–æŠ€å·§ã€‚é‡æ–°å‚æ•°åŒ–æŠ€å·§ä»å•ä½æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·Îµï¼Œé€šè¿‡æ½œåœ¨å±æ€§çš„å¹³å‡ğœ‡å¯¹å…¶è¿›è¡Œç§»ä½ï¼Œç„¶åé€šè¿‡æ½œåœ¨å±æ€§çš„æ–¹å·®ğœ:å¯¹å…¶è¿›è¡Œç¼©æ”¾

![](assets/6376b4ec-ebd3-4464-adcd-4c39f59e1313.png)

è¿™å°†é‡‡æ ·è¿‡ç¨‹ä»æ¢¯åº¦æµä¸­ç§»é™¤ï¼Œå› ä¸ºå®ƒç°åœ¨åœ¨ç½‘ç»œä¹‹å¤–ã€‚å› æ­¤ï¼Œé‡‡æ ·è¿‡ç¨‹ä¸ä¾èµ–äºç½‘ç»œä¸­çš„ä»»ä½•ä¸œè¥¿ã€‚æˆ‘ä»¬ç°åœ¨å¯ä»¥ä¼˜åŒ–åˆ†å¸ƒçš„å‚æ•°ï¼ŒåŒæ—¶ä¿æŒä»ä¸­éšæœºå–æ ·çš„èƒ½åŠ›:

![](assets/0727f2d1-a7f3-4436-a031-7c6a717b2192.png)

ç”±äºæ¯ä¸ªå±æ€§çš„åˆ†å¸ƒä¸ºé«˜æ–¯åˆ†å¸ƒï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å‡å€¼ã€ğœ‡å’Œåæ–¹å·®çŸ©é˜µâˆ‘è¿›è¡Œå˜æ¢ï¼Œå¦‚ä¸‹æ‰€ç¤º:

![](assets/08421e67-3535-434a-9586-d98bf7e661a4.png)

Here, Îµ ~ N(0,1).

ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å¼•å…¥é‡æ–°å‚æ•°åŒ–æŠ€å·§ï¼Œä½¿ç”¨ç®€å•çš„åå‘ä¼ æ’­æ¥è®­ç»ƒæ¨¡å‹:

![](assets/20d8edd5-d1d0-4190-942c-710c7cd089cb.png)

å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œæˆ‘ä»¬å·²ç»è®­ç»ƒäº†è‡ªåŠ¨ç¼–ç å™¨æ¥å¹³æ»‘å›¾åƒã€‚

<title>Coded example â€“ VAE</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# ç¼–ç ç¤ºä¾‹-VAE

ä¸ºäº†åœ¨ PyTorch ä¸­ç¼–å†™ä¸€ä¸ª VAEï¼Œæˆ‘ä»¬å¯ä»¥åƒå‰é¢çš„ä¾‹å­ä¸€æ ·åŠ è½½åº“å’Œæ•°æ®é›†ã€‚ä»è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰ VAE ç±»:

```py
class VariationalAutoEncoder(nn.Module):
    def __init__(self):
        super(VariationalAutoEncoder, self).__init__()

        self.fc1 = nn.Linear(784, 400)
        self.fc21 = nn.Linear(400, 20)
        self.fc22 = nn.Linear(400, 20)
        self.fc3 = nn.Linear(20, 400)
        self.fc4 = nn.Linear(400, 784)

    def encode_function(self, x):
        h1 = F.relu(self.fc1(x))
        return self.fc21(h1), self.fc22(h1)

    def reparametrize(self, mu, logvar):
        std = logvar.mul(0.5).exp_()
        if torch.cuda.is_available():
            eps = torch.cuda.FloatTensor(std.size()).normal_()
        else:
            eps = torch.FloatTensor(std.size()).normal_()
        eps = Variable(eps)
        return eps.mul(std).add_(mu)

    def decode_function(self, z):
        h3 = F.relu(self.fc3(z))
        return F.sigmoid(self.fc4(h3))

    def forward(self, x):
        mu, logvar = self.encode_function(x)
        z = self.reparametrize(mu, logvar)
        return self.decode_function(z), mu, logvar
```

ç„¶åï¼Œæˆ‘ä»¬å€ŸåŠ© KL æ•£åº¦å®šä¹‰æŸå¤±å‡½æ•°ï¼Œå¹¶å¯åŠ¨æ¨¡å‹:

```py
def loss_function(reconstruction_x, x, mu, latent_log_variance):
    """
    reconstruction_x: generating images
    x: original images
    mu: latent mean
    """
    BCE = reconstruction_function(reconstruction_x, x) 
    # KL loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)
    KLD_aspect = mu.pow(2).add_(latent_log_variance.exp()).mul_(-1).add_(1).add_(logvar)
    KLD = torch.sum(KLD_aspect).mul_(-0.5)
    # KL divergence
    return BCE + KLD

optimizer = optim.Adam(model.parameters(), lr=1e-4)
```

ä»è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æ¯ä¸ªæ—¶æœŸè¿è¡Œæ¨¡å‹å¹¶ä¿å­˜è¾“å‡º:

```py
for epoch in range(number_epochs):
    model.train()
    train_loss = 0
    for batch_idx, data in enumerate(data_loader):
        img, _ = data
        img = img.view(img.size(0), -1)
        img = Variable(img)
        if torch.cuda.is_available():
            img = img.cuda()
        optimizer.zero_grad()
        recon_batch, mu, logvar = model(img)
        loss = loss_function(recon_batch, img, mu, logvar)
        loss.backward()
        train_loss += loss.data[0]
        optimizer.step()
        if batch_idx % 100 == 0:
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch,
                batch_idx * len(img),
                len(data_loader.dataset), 100\. * batch_idx / len(data_loader),
                loss.data[0] / len(img)))

    print('Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(data_loader.dataset)))
    if epoch % 10 == 0:
        save = to_image(recon_batch.cpu().data)
        save_image(save, './vae_img/image_{}.png'.format(epoch))

torch.save(model.state_dict(), './vae.pth')
```

ç°åœ¨æˆ‘ä»¬å·²ç»çœ‹åˆ°äº†å„ç§è‡ªåŠ¨ç¼–ç å™¨ä»¥åŠå¦‚ä½•ç¼–è¯‘å®ƒä»¬ï¼Œè®©æˆ‘ä»¬å­¦ä¹ å¦‚ä½•åœ¨æ¨èç³»ç»Ÿä¸­å®ç°å®ƒä»¬ã€‚

<title>Restricted Boltzmann machines</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# å—é™ç»å°”å…¹æ›¼æœºå™¨

ä¸€ä¸ª **RBM** æ˜¯ä¸€ç§ç®—æ³•ï¼Œå·²ç»è¢«å¹¿æ³›ç”¨äºè¯¸å¦‚ååŒè¿‡æ»¤ã€ç‰¹å¾æå–ã€ä¸»é¢˜å»ºæ¨¡å’Œç»´åº¦å‡å°‘çš„ä»»åŠ¡ã€‚ä»–ä»¬å¯ä»¥åœ¨æ— äººç›‘ç£çš„æƒ…å†µä¸‹å­¦ä¹ æ•°æ®é›†ä¸­çš„æ¨¡å¼ã€‚

ä¾‹å¦‚ï¼Œå¦‚æœä½ çœ‹äº†ä¸€éƒ¨ç”µå½±ï¼Œç„¶åè¯´ä½ æ˜¯å¦å–œæ¬¢å®ƒï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ RBM æ¥å¸®åŠ©æˆ‘ä»¬ç¡®å®šä½ åšå‡ºè¿™ä¸ªå†³å®šçš„åŸå› ã€‚

RBM çš„ç›®æ ‡æ˜¯æœ€å°åŒ–ç”±ä»¥ä¸‹å…¬å¼å®šä¹‰çš„èƒ½é‡ï¼Œè¯¥å…¬å¼å–å†³äºå¯è§/è¾“å…¥çŠ¶æ€ã€éšè—çŠ¶æ€ã€æƒé‡å’Œåå·®çš„é…ç½®:

![](assets/b2d5c938-993c-4018-8312-747bdca6ea70.png)

RBM æ˜¯ä¸¤å±‚ç½‘ç»œï¼Œæ˜¯ DBN çš„åŸºæœ¬æ„é€ å—ã€‚RBM çš„ç¬¬ä¸€å±‚æ˜¯ç¥ç»å…ƒçš„å¯è§/è¾“å…¥å±‚ï¼Œç¬¬äºŒå±‚æ˜¯ç¥ç»å…ƒçš„éšè—å±‚:

![](assets/e6352c09-c581-41b7-858f-b5bf82a3f269.png)

RBM è½¬æ¢æ¥è‡ªå¯è§å±‚çš„è¾“å…¥ï¼Œå¹¶å°†å…¶è½¬æ¢æˆä¸€ç»„æ•°å­—ã€‚é€šè¿‡å‡ æ¬¡å‘å‰å’Œå‘åä¼ é€’ï¼Œç„¶åå°†æ•°å­—è½¬æ¢å›æ¥ä»¥é‡å»ºè¾“å…¥ã€‚RBM ä¸­çš„é™åˆ¶æ˜¯åŒä¸€å±‚ä¸­çš„èŠ‚ç‚¹ä¸è¿æ¥ã€‚

ä»è®­ç»ƒæ•°æ®é›†ä¸­å‘å¯è§å›¾å±‚çš„æ¯ä¸ªèŠ‚ç‚¹æä¾›ä¸€ä¸ªä½çº§è¦ç´ ã€‚åœ¨å›¾åƒåˆ†ç±»çš„æƒ…å†µä¸‹ï¼Œæ¯ä¸ªèŠ‚ç‚¹å°†æ¥æ”¶å›¾åƒä¸­æ¯ä¸ªåƒç´ çš„ä¸€ä¸ªåƒç´ å€¼:

![](assets/a3310e3c-b99d-4ff3-97bf-aa1ff08491dc.png)

é€šè¿‡ç½‘ç»œè·Ÿéšä¸€ä¸ªåƒç´ ï¼Œè¾“å…¥ *x* ä¹˜ä»¥æ¥è‡ªéšè—å±‚çš„æƒé‡ï¼Œç„¶ååŠ ä¸Šåå·®ã€‚ä»è¿™é‡Œï¼Œè¿™ç„¶åè¢«é¦ˆå…¥ä¸€ä¸ªæ¿€æ´»å‡½æ•°ï¼Œè¯¥å‡½æ•°äº§ç”Ÿè¾“å‡ºï¼Œè¯¥è¾“å‡ºå®è´¨ä¸Šæ˜¯åœ¨ç»™å®šè¾“å…¥ *x* çš„æƒ…å†µä¸‹é€šè¿‡å®ƒçš„ä¿¡å·çš„å¼ºåº¦ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤º:

![](assets/02467675-a93e-4d99-81ca-01aa85c3ac72.png)

åœ¨éšè—å±‚çš„æ¯ä¸ªèŠ‚ç‚¹ï¼Œæ¯ä¸ªåƒç´ å€¼çš„ x ä¹˜ä»¥ä¸€ä¸ªå•ç‹¬çš„æƒé‡ã€‚ç„¶åå¯¹ä¹˜ç§¯æ±‚å’Œï¼Œå¹¶åŠ ä¸Šä¸€ä¸ªåå·®ã€‚ç„¶åï¼Œå…¶è¾“å‡ºé€šè¿‡æ¿€æ´»å‡½æ•°ä¼ é€’ï¼Œåœ¨å•ä¸ªèŠ‚ç‚¹ä¸Šäº§ç”Ÿè¾“å‡º:

![](assets/00ee7d87-14b2-4e4a-8776-4c879004bb8b.png)

åœ¨æ¯ä¸€ä¸ªæ—¶é—´ç‚¹ï¼ŒRBM éƒ½å¤„äºä¸€å®šçš„çŠ¶æ€ï¼Œè¿™æ˜¯æŒ‡å¯è§ *v* å’Œéšè— *h* å±‚ä¸­ç¥ç»å…ƒçš„å€¼ã€‚è¿™ç§çŠ¶æ€çš„æ¦‚ç‡å¯ä»¥ç”±ä¸‹é¢çš„è”åˆåˆ†å¸ƒå‡½æ•°ç»™å‡º:

![](assets/125757b1-9b57-487d-9133-726cc7addde4.png)

è¿™é‡Œï¼ŒZ æ˜¯é…åˆ†å‡½æ•°ï¼Œå®ƒæ˜¯æ‰€æœ‰å¯èƒ½çš„å¯è§å’Œéšè—å‘é‡å¯¹çš„æ€»å’Œã€‚

<title>Training RBMs</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# åŸ¹è®­æˆæœç®¡ç†åˆ¶

RBM åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸»è¦æ‰§è¡Œä¸¤ä¸ªæ­¥éª¤:

1.  **å‰å¸ƒæ–¯é‡‡æ ·**:è®­ç»ƒè¿‡ç¨‹çš„ç¬¬ä¸€æ­¥ä½¿ç”¨å‰å¸ƒæ–¯é‡‡æ ·ï¼Œé‡å¤ä»¥ä¸‹è¿‡ç¨‹ *k* æ¬¡:

*   ç»™å®šè¾“å…¥å‘é‡æ—¶éšè—å‘é‡çš„æ¦‚ç‡ï¼›éšè—å€¼çš„é¢„æµ‹ã€‚
*   ç»™å®šéšè—å‘é‡æ—¶è¾“å…¥å‘é‡çš„æ¦‚ç‡ï¼›è¾“å…¥å€¼çš„é¢„æµ‹ã€‚ç”±æ­¤ï¼Œæˆ‘ä»¬è·å¾—äº†å¦ä¸€ä¸ªè¾“å…¥å‘é‡ï¼Œå®ƒæ˜¯ä»åŸå§‹è¾“å…¥å€¼é‡æ–°åˆ›å»ºçš„ã€‚

2.  **å¯¹æ¯”å·®å¼‚**:RBM é€šè¿‡å¯¹æ¯”å·®å¼‚è°ƒæ•´æƒé‡ã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œéšæœºç”Ÿæˆå¯è§èŠ‚ç‚¹çš„æƒé‡ï¼Œå¹¶ç”¨äºç”Ÿæˆéšè—èŠ‚ç‚¹ã€‚ç„¶åï¼Œéšè—èŠ‚ç‚¹ä½¿ç”¨ç›¸åŒçš„æƒé‡æ¥é‡å»ºå¯è§èŠ‚ç‚¹ã€‚ç”¨äºé‡æ„å¯è§èŠ‚ç‚¹çš„æƒé‡å§‹ç»ˆç›¸åŒã€‚ä½†æ˜¯ï¼Œç”Ÿæˆçš„èŠ‚ç‚¹å¹¶ä¸ç›¸åŒï¼Œå› ä¸ºå®ƒä»¬å½¼æ­¤å¹¶ä¸ç›¸è¿ã€‚

ä¸€æ—¦ RBM ç»è¿‡è®­ç»ƒï¼Œå®ƒåŸºæœ¬ä¸Šèƒ½å¤Ÿè¡¨è¾¾ä¸¤ä»¶äº‹:

*   è¾“å…¥æ•°æ®ç‰¹å¾ä¹‹é—´çš„ç›¸äº’å…³ç³»
*   è¯†åˆ«æ¨¡å¼æ—¶ï¼Œå“ªäº›ç‰¹å¾æ˜¯æœ€é‡è¦çš„

<title>Theoretical example â€“ RBM recommender system</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# ç†è®ºç¤ºä¾‹â€”â€”RBM æ¨èç³»ç»Ÿ

åœ¨ç”µå½±çš„èƒŒæ™¯ä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ RBM æ¥æ­ç¤ºä¸€ç³»åˆ—ä»£è¡¨å…¶ç±»å‹çš„æ½œåœ¨å› ç´ ï¼Œä»è€Œç¡®å®šä¸€ä¸ªäººå–œæ¬¢å“ªç§ç±»å‹çš„ç”µå½±ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬è¦æ±‚æŸäººå‘Šè¯‰æˆ‘ä»¬ä»–ä»¬çœ‹è¿‡å“ªäº›ç”µå½±ä»¥åŠä»–ä»¬æ˜¯å¦å–œæ¬¢è¿™äº›ç”µå½±ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥å°†ä»–ä»¬è¡¨ç¤ºä¸º RBM çš„äºŒè¿›åˆ¶è¾“å…¥(1 æˆ– 0)ã€‚å¯¹äºé‚£äº›ä»–ä»¬æ²¡æœ‰çœ‹è¿‡æˆ–æ²¡æœ‰å‘Šè¯‰æˆ‘ä»¬çš„ç”µå½±ï¼Œæˆ‘ä»¬éœ€è¦åˆ†é…ä¸€ä¸ªå€¼-1ï¼Œä»¥ä¾¿ç½‘ç»œå¯ä»¥åœ¨è®­ç»ƒæœŸé—´è¯†åˆ«è¿™äº›ç”µå½±ï¼Œå¹¶å¿½ç•¥å®ƒä»¬çš„ç›¸å…³æƒé‡ã€‚

è®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸ªä¾‹å­ï¼Œç”¨æˆ·å–œæ¬¢*çªˆçª•å¥¶çˆ¸*ã€*å®¿é†‰*å’Œ*ä¼´å¨˜*ï¼Œä¸å–œæ¬¢*å°–å«*æˆ–*ç²¾ç¥ç—…*ï¼Œå¹¶ä¸”è¿˜æ²¡æœ‰çœ‹è¿‡*éœæ¯”ç‰¹äºº*ã€‚ç»™å®šè¿™äº›è¾“å…¥ï¼ŒRBM å¯ä»¥è¯†åˆ«ä¸‰ä¸ªéšè—çš„å› ç´ :å–œå‰§ã€ææ€–å’Œå¹»æƒ³ï¼Œå®ƒä»¬å¯¹åº”äºç”µå½±çš„ç±»å‹:

![](assets/6d8e29ec-2944-4f90-a8c8-aaab69ca68c5.png)

å¯¹äºæ¯ä¸ªéšè—ç¥ç»å…ƒï¼Œåœ¨ç»™å®šè¾“å…¥ç¥ç»å…ƒçš„æƒ…å†µä¸‹ï¼ŒRBM åˆ†é…éšè—ç¥ç»å…ƒçš„æ¦‚ç‡ã€‚ç¥ç»å…ƒçš„æœ€ç»ˆäºŒè¿›åˆ¶å€¼æ˜¯é€šè¿‡ä»ä¼¯åŠªåˆ©åˆ†å¸ƒé‡‡æ ·è·å¾—çš„ã€‚

åœ¨å‰é¢çš„ä¾‹å­ä¸­ï¼Œä»£è¡¨å–œå‰§ç±»å‹çš„å”¯ä¸€éšè—ç¥ç»å…ƒå˜å¾—æ´»è·ƒã€‚è¿™æ ·ï¼Œç»™å®šè¾“å…¥åˆ° RBM ä¸­çš„ç”µå½±è¯„çº§ï¼Œå®ƒé¢„æµ‹ç”¨æˆ·æœ€å–œæ¬¢å–œå‰§ç”µå½±ã€‚

å¯¹äºè®­ç»ƒæœ‰ç´ çš„ RBM æ¥è¯´ï¼Œæ ¹æ®ä»–ä»¬çš„åå¥½ï¼Œå¯¹ç”¨æˆ·å°šæœªçœ‹è¿‡çš„ç”µå½±è¿›è¡Œé¢„æµ‹ï¼ŒRBM ä½¿ç”¨å¯è§ç¥ç»å…ƒç»™å®šéšè—ç¥ç»å…ƒçš„æ¦‚ç‡ã€‚å®ƒä»ä¼¯åŠªåˆ©åˆ†å¸ƒä¸­å–æ ·ï¼Œä»¥æ‰¾å‡ºå“ªä¸€ä¸ªå¯è§ç¥ç»å…ƒå¯ä»¥å˜å¾—æ´»è·ƒã€‚

<title>Coded example â€“ RBM recommender system</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# ç¼–ç ç¤ºä¾‹-RBM æ¨èç³»ç»Ÿ

ç»§ç»­ç”µå½±çš„ä¸Šä¸‹æ–‡ï¼Œæˆ‘ä»¬ç°åœ¨å°†ç»™å‡ºä¸€ä¸ªä¾‹å­ï¼Œè¯´æ˜å¦‚ä½•ä½¿ç”¨ PyTorch åº“æ„å»ºä¸€ä¸ª RBM æ¨èç³»ç»Ÿã€‚è¯¥ç¤ºä¾‹çš„ç›®æ ‡æ˜¯è®­ç»ƒä¸€ä¸ªæ¨¡å‹æ¥ç¡®å®šç”¨æˆ·æ˜¯å¦ä¼šå–œæ¬¢æŸéƒ¨ç”µå½±ã€‚

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† 100 ä¸‡æ”¶è§†ç‡çš„ MovieLens æ•°æ®é›†([https://grouplens.org/datasets/movielens/](https://grouplens.org/datasets/movielens/))ï¼Œå®ƒæ˜¯ç”±æ˜å°¼è‹è¾¾å¤§å­¦çš„ GroupLens ç ”ç©¶å°ç»„åˆ›å»ºçš„:

1.  é¦–å…ˆï¼Œä¸‹è½½æ•°æ®é›†ã€‚è¿™å¯ä»¥é€šè¿‡ç»ˆç«¯å‘½ä»¤å®Œæˆï¼Œå¦‚ä¸‹æ‰€ç¤º:

```py
wget -O moviedataset.zip http://files.grouplens.org/datasets/movielens/ml-1m.zip
unzip -o moviedataset.zip -d ./data
unzip -o moviedataset.zip -d ./data
```

2.  ç°åœ¨å¯¼å…¥æˆ‘ä»¬å°†ä½¿ç”¨çš„åº“:

```py
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.optim as optim
import torch.utils.data
from torch.autograd import Variable
```

3.  ç„¶åå¯¼å…¥æ•°æ®:

```py
movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')
users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')
ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')
```

ä¸‹é¢çš„å±å¹•æˆªå›¾å±•ç¤ºäº†æˆ‘ä»¬çš„æ•°æ®é›†çš„ç»“æ„:

![](assets/272925c4-059f-410c-b3f1-0833472cddf1.png)

4.  å‡†å¤‡æµ‹è¯•å’Œè®­ç»ƒæ•°æ®é›†:

```py
training_dataset = pd.read_csv('ml-100k/u1.base', delimiter = '\t')
training_dataset = np.array(training_set, dtype = 'int')
test_dataset = pd.read_csv('ml-100k/u1.test', delimiter = '\t')
test_dataset = np.array(test_dataset, dtype = 'int') 
```

5.  ç°åœ¨æˆ‘ä»¬éœ€è¦å‡†å¤‡ä¸€ä¸ªç”¨æˆ·è¯„çº§çŸ©é˜µã€‚è¯¥çŸ©é˜µå°†ç”¨æˆ·ä½œä¸ºè¡Œï¼Œç”µå½±ä½œä¸ºåˆ—ã€‚é›¶ç”¨æ¥è¡¨ç¤ºç”¨æˆ·æ²¡æœ‰ç»™æŸéƒ¨ç”µå½±è¯„åˆ†çš„æƒ…å†µã€‚æˆ‘ä»¬å®šä¹‰`no_users`å’Œ`no_movies`å˜é‡ï¼Œç„¶åè€ƒè™‘è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†ä¸­çš„`max`å€¼ï¼Œå¦‚ä¸‹æ‰€ç¤º:

```py
no_users = int(max(max(training_dataset[:,0]), max(test_dataset[:,0])))
no_movies = int(max(max(training_dataset[:,1]), max(test_dataset[:,1])))
```

6.  ç°åœ¨æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªåä¸º`convert_dataset`çš„å‡½æ•°ï¼Œå°†æ•°æ®é›†è½¬æ¢æˆä¸€ä¸ªçŸ©é˜µã€‚è¿™æ˜¯é€šè¿‡åˆ›å»ºä¸€ä¸ªå¾ªç¯æ¥å®ç°çš„ï¼Œè¯¥å¾ªç¯å°†éå†æ•°æ®é›†å¹¶è·å–ç‰¹å®šç”¨æˆ·è¯„çº§çš„æ‰€æœ‰ç”µå½±ä»¥åŠè¯¥ç”¨æˆ·çš„è¯„çº§ã€‚æˆ‘ä»¬é¦–å…ˆåˆ›å»ºä¸€ä¸ªé›¶çŸ©é˜µï¼Œå› ä¸ºå­˜åœ¨ç”¨æˆ·æ²¡æœ‰è¯„çº§çš„ç”µå½±:

```py
def convert_dataset(data):
    converted_data = []
    for id_users in range(1, no_users + 1):
        id_movies = data[:,1][data[:,0] == id_users]
        id_ratings = data[:,2][data[:,0] == id_users]
        movie_ratings = np.zeros(no_movies)
        ratings[id_movies - 1] = id_ratings
        converted_data.append(list(movie_ratings))
    return converted_data

training_dataset = convert_dataset(training_dataset)
test_dataset = convert_dataset(test_dataset)
```

7.  ç°åœ¨æˆ‘ä»¬é€šè¿‡ä½¿ç”¨`FloatTensor`å®ç”¨ç¨‹åºå°†æ•°æ®è½¬æ¢æˆ Torch å¼ é‡ã€‚è¿™å°†æŠŠæ•°æ®é›†è½¬æ¢æˆ PyTorch æ•°ç»„:

```py
training_dataset = torch.FloatTensor(training_dataset)
test_dataset = torch.FloatTensor(test_dataset)
```

8.  åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬è¦è¿›è¡ŒäºŒå…ƒåˆ†ç±»ï¼Œå³ç”¨æˆ·æ˜¯å¦ä¼šå–œæ¬¢è¿™éƒ¨ç”µå½±ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†è¯„çº§è½¬æ¢ä¸º 0 å’Œ 1ã€‚ä½†æ˜¯ï¼Œé¦–å…ˆï¼Œæˆ‘ä»¬ç”¨-1 æ›¿æ¢ç°æœ‰çš„é›¶ï¼Œä»¥è¡¨ç¤ºç”¨æˆ·ä»æœªè¯„ä»·è¿‡çš„ç”µå½±:

```py
training_dataset[training_dataset == 0] = -1
training_dataset[training_dataset == 1] = 0
training_dataset[training_dataset == 2] = 0
training_dataset[training_dataset >= 3] = 1
test_dataset[test_dataset == 0] = -1
test_dataset[test_dataset == 1] = 0
test_dataset[test_dataset == 2] = 0
test_dataset[test_dataset >= 3] = 1
```

9.  ç°åœ¨ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªç±»æ¥å®šä¹‰ RBM çš„æ¶æ„ã€‚è¯¥ç±»ä½¿ç”¨éšæœºæ­£æ€åˆ†å¸ƒåˆå§‹åŒ–æƒé‡å’Œåå·®ã€‚è¿˜å®šä¹‰äº†ä¸¤ç§ç±»å‹çš„åå·®ï¼Œå…¶ä¸­`a`æ˜¯ç»™å®šå¯è§èŠ‚ç‚¹æ—¶éšè—èŠ‚ç‚¹çš„æ¦‚ç‡ï¼Œè€Œ`b`æ˜¯ç»™å®šéšè—èŠ‚ç‚¹æ—¶å¯è§èŠ‚ç‚¹çš„æ¦‚ç‡ã€‚è¯¥ç±»åˆ›å»ºäº†ä¸€ä¸ª`sample_hidden_nodes`å‡½æ•°ï¼Œå®ƒä»¥`x`ä½œä¸ºå‚æ•°ï¼Œè¡¨ç¤ºå¯è§çš„ç¥ç»å…ƒã€‚ä»è¿™é‡Œï¼Œæˆ‘ä»¬è®¡ç®—ç»™å®š`v`çš„`h`çš„æ¦‚ç‡ï¼Œå…¶ä¸­`h`å’Œ`v`åˆ†åˆ«ä»£è¡¨éšè—å’Œå¯è§çš„èŠ‚ç‚¹ã€‚è¿™ä»£è¡¨äº†ä¹™çŠ¶ç»“è‚ æ¿€æ´»åŠŸèƒ½ã€‚å®ƒè¢«è®¡ç®—ä¸ºæƒé‡å‘é‡å’Œ`x`åŠ ä¸Šåå·®`a`çš„ä¹˜ç§¯ã€‚ç”±äºæˆ‘ä»¬æ­£åœ¨è€ƒè™‘äºŒå…ƒåˆ†ç±»æ¨¡å‹ï¼Œæˆ‘ä»¬è¿”å›éšè—ç¥ç»å…ƒçš„ä¼¯åŠªåˆ©æ ·æœ¬ã€‚ä»è¿™é‡Œï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ª`sample_visible_function`å‡½æ•°ï¼Œå®ƒå°†å¯¹å¯è§èŠ‚ç‚¹è¿›è¡Œé‡‡æ ·ã€‚æœ€åï¼Œæˆ‘ä»¬åˆ›å»ºè®­ç»ƒå‡½æ•°ã€‚å®ƒé‡‡ç”¨åŒ…å«ç”µå½±åˆ†çº§çš„è¾“å…¥å‘é‡ã€åœ¨ *k* æ¬¡é‡‡æ ·åè·å¾—çš„å¯è§èŠ‚ç‚¹ã€æ¦‚ç‡å‘é‡ä»¥åŠåœ¨ *k* æ¬¡é‡‡æ ·åéšè—èŠ‚ç‚¹çš„æ¦‚ç‡:

```py
class RBM():
    def __init__(self, num_visible_nodes, num_hidden_nodes):
        self.W = torch.randn(num_hidden_nodes, num_visible_nodes)
        self.a = torch.randn(1, num_hidden_nodes)
        self.b = torch.randn(1, num_visible_nodes)

    def sample_hidden_nodes(self, x):
        wx = torch.mm(x, self.W.t())
        activation = wx + self.a.expand_as(wx)
        p_h_given_v = torch.sigmoid(activation)
        return p_h_given_v, torch.bernoulli(p_h_given_v)

    def sample_visible_nodes(self, y):
        wy = torch.mm(y, self.W)
        activation = wy + self.b.expand_as(wy)
        p_v_given_h = torch.sigmoid(activation)
        return p_v_given_h, torch.bernoulli(p_v_given_h)

    def train(self, v0, vk, ph0, phk):
        self.W += torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)
        self.b += torch.sum((v0 - vk), 0)
        self.a += torch.sum((ph0 - phk), 0)
```

10.  ç°åœ¨æˆ‘ä»¬å®šä¹‰æˆ‘ä»¬çš„æ¨¡å‹å‚æ•°:

```py
num_visible_nodes = len(training_dataset[0])
num_hidden_nodes = 200
batch_size = 100
rbm = RBM(num_visible_nodes, num_hidden_nodes)
```

11.  ä»è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºæ¯ä¸ªæ—¶æœŸè®­ç»ƒæ¨¡å‹:

```py
nb_epoch = 10
for epoch in range(1, nb_epoch + 1):
    train_loss = 0
    s = 0.
    for id_user in range(0, nb_users - batch_size, batch_size):
        vk = training_dataset[id_user:id_user+batch_size]
        v0 = training_dataset[id_user:id_user+batch_size]
        ph0,_ = rbm.sample_hidden_nodes(v0)
        for k in range(10):
            _,hk = rbm.sample_hidden_nodes(vk)
            _,vk = rbm.sample_visible_nodes(hk)
            vk[v0<0] = v0[v0<0]
        phk,_ = rbm.sample_hidden_nodes(vk)
        rbm.train(v0, vk, ph0, phk)
        train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))
        s += 1.
    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))
```

æˆ‘ä»¬å¯ä»¥åœ¨è®­ç»ƒæœŸé—´ç»˜åˆ¶è·¨æ—¶æœŸçš„è¯¯å·®:

![](assets/c613abe5-4900-4baa-bf32-656a44fdf51a.png)

è¿™å¯ä»¥å¸®åŠ©æˆ‘ä»¬ç¡®å®šåº”è¯¥è¿è¡Œå¤šå°‘ä¸ªæ—¶æœŸçš„è®­ç»ƒã€‚å®ƒè¡¨æ˜åœ¨å…­ä¸ªæ—¶æœŸä¹‹åï¼Œæ”¹è¿›çš„æ€§èƒ½æ¯”ç‡ä¸‹é™ï¼Œå› æ­¤æˆ‘ä»¬åº”è¯¥è€ƒè™‘åœ¨è¿™ä¸ªé˜¶æ®µåœæ­¢è®­ç»ƒã€‚

æˆ‘ä»¬å·²ç»çœ‹åˆ°äº†åœ¨ RBM å®ç°æ¨èç³»ç»Ÿçš„ç¼–ç ç¤ºä¾‹ï¼Œç°åœ¨è®©æˆ‘ä»¬ç®€å•åœ°æµè§ˆä¸€ä¸‹ DBN çš„æ¶æ„ã€‚

<title>DBN architecture</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# DBN å»ºç­‘

DBN æ˜¯ä¸€ä¸ªå¤šå±‚çš„ä¿¡å¿µç½‘ç»œï¼Œå…¶ä¸­æ¯ä¸€å±‚éƒ½æ˜¯ç›¸äº’å †å çš„ RBMã€‚é™¤äº† DBN çš„ç¬¬ä¸€å±‚å’Œæœ€åä¸€å±‚ä¹‹å¤–ï¼Œæ¯ä¸€å±‚éƒ½æ—¢æ˜¯å…¶ä¹‹å‰èŠ‚ç‚¹çš„éšè—å±‚ï¼Œä¹Ÿæ˜¯å…¶ä¹‹åèŠ‚ç‚¹çš„è¾“å…¥å±‚:

![](assets/476edcd1-4181-4f6b-8111-adf963439fc9.png)

DBN ä¸­çš„ä¸¤å±‚ç”±æƒé‡çŸ©é˜µè¿æ¥ã€‚DBN çš„æœ€ä¸Šé¢ä¸¤å±‚æ˜¯æ— å‘çš„ï¼Œè¿™ä½¿å¾—å®ƒä»¬ä¹‹é—´æœ‰ä¸€ä¸ªå¯¹ç§°çš„è¿æ¥ï¼Œå½¢æˆä¸€ä¸ªè”æƒ³è®°å¿†ã€‚ä¸‹é¢çš„ä¸¤å±‚ä¸ä¸Šé¢çš„å±‚ç›´æ¥ç›¸è¿ã€‚æ–¹å‘æ„Ÿå°†è”æƒ³è®°å¿†è½¬åŒ–ä¸ºè§‚å¯Ÿå˜é‡:

![](assets/884509b6-a309-48a5-a398-c1a3f3cde68f.png)

DBNs çš„ä¸¤ä¸ªæœ€é‡è¦çš„å±æ€§å¦‚ä¸‹:

*   DBN é€šè¿‡æœ‰æ•ˆçš„é€å±‚è¿‡ç¨‹è‡ªä¸Šè€Œä¸‹åœ°å­¦ä¹ ç”Ÿæˆæƒé‡ã€‚è¿™äº›æƒé‡å†³å®šäº†ä¸€ä¸ªå±‚ä¸­çš„å˜é‡å¦‚ä½•ä¾èµ–äºä¸Šé¢çš„å±‚ã€‚
*   ä¸€æ—¦è®­ç»ƒå®Œæˆï¼Œæ¯ä¸€å±‚ä¸­çš„éšè—å˜é‡çš„å€¼å¯ä»¥é€šè¿‡å•æ¬¡è‡ªåº•å‘ä¸Šçš„ä¼ é€’æ¥æ¨æ–­ã€‚è¯¥è¿‡ç¨‹ä»è¾ƒä½å±‚ä¸­çš„å¯è§æ•°æ®å‘é‡å¼€å§‹ï¼Œå¹¶åœ¨ç›¸åæ–¹å‘ä¸Šä½¿ç”¨å…¶ç”Ÿæˆæƒé‡ã€‚

å¯è§å±‚å’Œéšè—å±‚ä¸Šçš„è”åˆé…ç½®ç½‘ç»œçš„æ¦‚ç‡å–å†³äºè”åˆé…ç½®ç½‘ç»œçš„èƒ½é‡ä¸æ‰€æœ‰å…¶ä»–è”åˆé…ç½®ç½‘ç»œçš„èƒ½é‡çš„æ¯”è¾ƒ:

![](assets/9b151fd9-0ff8-4e58-b605-3c292d38b857.png)

ä¸€æ—¦ RBM å †æ ˆå®Œæˆäº† DBN çš„é¢„è®­ç»ƒé˜¶æ®µï¼Œå‰é¦ˆç½‘ç»œå°±å¯ä»¥ç”¨äºå¾®è°ƒé˜¶æ®µï¼Œä»¥ä¾¿åˆ›å»ºåˆ†ç±»å™¨æˆ–ç®€å•åœ°å¸®åŠ©åœ¨æ— ç›‘ç£å­¦ä¹ åœºæ™¯ä¸­èšç±»æœªæ ‡è®°çš„æ•°æ®ã€‚

<title>Fine-tuning</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# å¾®è°ƒ

å¾®è°ƒæ—¨åœ¨æ‰¾åˆ°å„å±‚ä¹‹é—´æƒé‡çš„æœ€ä½³å€¼ã€‚å®ƒè°ƒæ•´äº†åŸå§‹ç‰¹å¾ï¼Œä»¥è·å¾—æ›´ç²¾ç¡®çš„ç±»è¾¹ç•Œã€‚ä¸ºäº†å¸®åŠ©æ¨¡å‹å°†æ¨¡å¼å’Œç‰¹å¾ä¸æ•°æ®é›†ç›¸å…³è”ï¼Œä½¿ç”¨äº†ä¸€ä¸ªå°çš„å¸¦æ ‡ç­¾çš„æ•°æ®é›†ã€‚

å¾®è°ƒå¯ä»¥ä½œä¸ºè‡ªä¸‹è€Œä¸Šçš„éšæœºè¿‡ç¨‹æ¥åº”ç”¨ï¼Œç„¶åç”¨äºè°ƒæ•´è‡ªä¸Šè€Œä¸‹çš„æƒé‡ã€‚ä¸€æ—¦åˆ°è¾¾é¡¶å±‚ï¼Œé€’å½’å°±è¢«åº”ç”¨åˆ°é¡¶å±‚ã€‚ä¸ºäº†è¿›ä¸€æ­¥å¾®è°ƒï¼Œæˆ‘ä»¬å¯ä»¥åšä¸€ä¸ªéšæœºçš„è‡ªä¸Šè€Œä¸‹çš„ä¼ é€’ï¼Œå¹¶è°ƒæ•´è‡ªä¸‹è€Œä¸Šçš„æƒé‡ã€‚

<title>Summary</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# æ‘˜è¦

åœ¨è¿™ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬è§£é‡Šäº†ä»€ä¹ˆæ˜¯è‡ªåŠ¨ç¼–ç å™¨ä»¥åŠå®ƒä»¬çš„ä¸åŒå˜ä½“ã€‚åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬ç»™å‡ºäº†ä¸€äº›ç¼–ç ç¤ºä¾‹ï¼Œè¯´æ˜å¦‚ä½•å°†å®ƒä»¬åº”ç”¨äº MNIST æ•°æ®é›†ã€‚æˆ‘ä»¬éšåä»‹ç»äº† RBMï¼Œå¹¶é€šè¿‡ä¸€äº›é¢å¤–çš„ä¾‹å­è§£é‡Šäº†å¦‚ä½•å°†å®ƒä»¬å¼€å‘æˆ DBNã€‚

åœ¨ä¸‹ä¸€ç« ï¼Œæˆ‘ä»¬å°†ä»‹ç»ç”Ÿæˆæ•Œå¯¹ç½‘ç»œã€‚æˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨å®ƒä»¬æ¥ç”Ÿæˆå›¾åƒå’Œæ–‡æœ¬ã€‚

<title>Further reading</title> <link rel="stylesheet" href="css/style.css" type="text/css"> 

# è¿›ä¸€æ­¥é˜…è¯»

æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒä»¥ä¸‹å†…å®¹:

*   *å˜å‹è‡ªåŠ¨ç¼–ç å™¨æ•™ç¨‹*:ã€https://arxiv.org/abs/1606.05908 
*   *cs 598 lazâ€“å˜å‹è‡ªåŠ¨ç¼–ç å™¨*:ã€http://slazebni.cs.illinois.edu/spring17/lec12_vae.pdf 
*   *è‡ªåŠ¨ç¼–ç å˜åˆ†è´å¶æ–¯*:ã€https://arxiv.org/abs/1312.6114 
*   *æ·±åº¦å­¦ä¹ ä¹¦ç±*:ã€https://www.deeplearningbook.org/contents/autoencoders.htmlã€‘T2
*   *æ·±åº¦ä¿¡å¿µç½‘çš„å¿«é€Ÿå­¦ä¹ ç®—æ³•*:ã€http://www.cs.toronto.edu/~fritz/absps/ncfast.pdfã€‘T2
*   *è®­ç»ƒå—é™ç»å°”å…¹æ›¼æœºå™¨:ä»‹ç»*:[https://www . science direct . com/science/article/ABS/pii/s 0031320313002495](https://www.sciencedirect.com/science/article/abs/pii/S0031320313002495)
*   *æ·±åº¦ç»å°”å…¹æ›¼æœºå™¨*:[http://proceedings . MLR . press/V5/salakhutdinov 09 a/salakhutdinov 09 a . pdf](http://proceedings.mlr.press/v5/salakhutdinov09a/salakhutdinov09a.pdf)
*   è®­ç»ƒå—é™ç»å°”å…¹æ›¼æœºå™¨çš„å®ç”¨æŒ‡å—:ã€https://www.cs.toronto.edu/~hinton/absps/guideTR.pdf 
*   *æ·±åº¦ä¿¡å¿µç½‘ç»œ*:[https://link . springer . com/chapter/10.1007/978-3-319-06938-8 _ 8](https://link.springer.com/chapter/10.1007/978-3-319-06938-8_8)
*   *åŠ¨æ‰‹ç¥ç»ç½‘ç»œ:*[https://www . Amazon . co . uk/Hands-Neural-Networks-Neural-network-ebook/DP/b 07 SKD SGB 6/](https://www.amazon.co.uk/Hands-Neural-Networks-neural-network-ebook/dp/B07SKDSGB6/)