

# 七、序列数据的自然语言处理

在这一章中，我们将研究对构建深度学习模型有用的文本数据的不同表示。我们将帮助你理解**循环神经网络** ( **RNNs** )。本章将涵盖 RNNs 的不同实现，如**长短期记忆** ( **LSTM** )和**门控递归单元** ( **GRU** )，它们为大多数文本和序列数据的深度学习模型提供动力。我们将研究文本数据的不同表示，以及它们如何有助于构建深度学习模型。此外，本章将讨论可用于顺序数据的一维卷积。

可以使用 RNNs 构建的一些应用如下:

*   **文档分类器**:识别推文或评论的情感，对新闻文章进行分类
*   **序列到序列学习**:用于语言翻译等任务，将英语转换成法语
*   **时间序列预测**:在给定前几天销售记录细节的情况下，预测商店的销售额

本章将涵盖以下主题:

*   使用文本数据
*   通过建立情感分类器来训练嵌入
*   使用预训练的单词嵌入
*   循环神经网络
*   利用 LSTM 解决文本分类问题
*   序列数据上的卷积网络
*   语言建模



# 使用文本数据

文本是最常用的顺序数据类型之一。文本数据可以被视为字符序列或单词序列。对于大多数问题来说，将文本视为一系列单词是很常见的。深度学习序列模型(如 RNNs 及其变体)能够从文本数据中学习重要的模式，这些模式可以解决以下领域的问题:

*   自然语言理解
*   文件分类
*   情感分类

这些顺序模型也是各种系统的重要组成部分，例如**问答** ( **QA** )系统。

尽管这些模型在构建这些应用程序时非常有用，但由于人类语言固有的复杂性，它们并不理解人类语言。这些顺序模型能够成功地找到有用的模式，然后用于执行不同的任务。将深度学习应用于文本是一个快速发展的领域，每个月都有大量新技术问世。我们将涵盖支持大多数现代深度学习应用的基本组件。

深度学习模型和其他任何机器学习模型一样，不理解文本，所以我们需要将文本转换成数字表示。将文本转换成数字表示的过程称为**矢量化**，可以用不同的方式完成，如下所示:

*   将文本转换成单词，并将每个单词表示为一个向量
*   将文本转换为字符，并将每个字符表示为一个向量
*   创建单词的 n 元语法，并将其表示为向量

文本数据可以分解成这些表示形式中的一种。每个更小的文本单元称为一个令牌，将文本分解成令牌的过程称为**令牌化**。Python 中有很多强大的库可以帮助我们进行分词。一旦我们将文本数据转换成标记，我们就需要将每个标记映射到一个向量。一键编码和单词嵌入是将标记映射到向量的两种最流行的方法。下图总结了将文本转换为矢量表示的步骤:

![](img/73e7d9d7-448e-467e-864f-20f9f0fd4e44.png)

让我们更详细地看看分词、n 元语法表示和向量化。



# 分词

给定一个句子，把它分成字符或单词称为分词。有些库，比如 spaCy，提供了复杂的令牌化解决方案。让我们使用简单的 Python 函数，如`split`和`list`，将文本转换成标记。

为了演示分词如何作用于字符和单词，让我们来看一下电影*玩具总动员*的小回顾。我们将使用以下文本:

```py
Just perfect. Script, character, animation....this manages to break free of the yoke of 'children's movie' to simply be one of the best movies of the 90's, full-stop.
```



# 将文本转换为字符

Python `list`函数获取一个字符串，并将其转换成一个单个字符的列表。这完成了将文本转换成字符的工作。下面的代码块显示了使用的代码和结果:

```py
toy_story_review = "Just perfect. Script, character, animation....this manages to break free of the yoke of 'children's movie' to simply be one of the best movies of the 90's, full-stop."

print(list(toy_story_review))
```

结果如下:

```py
['J', 'u', 's', 't', ' ', 'p', 'e', 'r', 'f', 'e', 'c', 't', '.', ' ', 'S', 'c', 'r', 'i', 'p', 't', ',', ' ', 'c', 'h', 'a', 'r', 'a', 'c', 't', 'e', 'r', ',', ' ', 'a', 'n', 'i', 'm', 'a', 't', 'i', 'o', 'n', '.', '.', '.', '.', 't', 'h', 'i', 's', ' ', 'm', 'a', 'n', 'a', 'g', 'e', 's', ' ', 't', 'o', ' ', 'b', 'r', 'e', 'a', 'k', ' ', 'f', 'r', 'e', 'e', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'y', 'o', 'k', 'e', ' ', 'o', 'f', ' ', "'", 'c', 'h', 'i', 'l', 'd', 'r', 'e', 'n', "'", 's', ' ', 'm', 'o', 'v', 'i', 'e', "'", ' ', 't', 'o', ' ', 's', 'i', 'm', 'p', 'l', 'y', ' ', 'b', 'e', ' ', 'o', 'n', 'e', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'b', 'e', 's', 't', ' ', 'm', 'o', 'v', 'i', 'e', 's', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', '9', '0', "'", 's', ',', ' ', 'f', 'u', 'l', 'l', '-', 's', 't', 'o', 'p', '.']
```

这个结果显示了我们简单的 Python 函数是如何将文本转换成标记的。



# 将文本转换为单词

我们将使用 Python string 对象中可用的`split`函数将文本分解成单词。`split`函数接受一个参数，并基于这个参数将文本分割成标记。对于我们的例子，我们将使用空格作为分隔符。下面的代码块演示了我们如何使用 Python `split`函数将文本转换成单词:

```py
print(list(toy_story_review.split()))
```

这会产生以下输出:

```py
['Just', 'perfect.', 'Script,', 'character,', 'animation....this', 'manages', 'to', 'break', 'free', 'of', 'the', 'yoke', 'of', "'children's", "movie'", 'to', 'simply', 'be', 'one', 'of', 'the', 'best', 'movies', 'of', 'the', "90's,", 'full-stop.']
```

在前面的代码中，我们没有使用任何分隔符；默认情况下，`split`函数在空格处拆分。



# n 元语法表示

我们已经看到文本是如何被表示为字符和单词的。有时候，把两个、三个或更多的单词放在一起看是很有用的。 **N-grams** 是从给定文本中提取的单词组。在 n 元语法中， *n* 代表可以一起使用的单词数。让我们看一个二元模型( *n=2* )的例子。我们使用 Python `nltk`包为`toy_story_review`生成一个二元模型。以下代码块显示了二元模型的结果以及用于生成它的代码:

```py
from nltk import ngrams 
print(list(ngrams(toy_story_review.split(),2)))
```

这会产生以下输出:

```py
[('Just', 'perfect.'), ('perfect.', 'Script,'), ('Script,', 'character,'), ('character,', 'animation....this'), ('animation....this', 'manages'), ('manages', 'to'), ('to', 'break'), ('break', 'free'), ('free', 'of'), ('of', 'the'), ('the', 'yoke'), ('yoke', 'of'), ('of', "'children's"), ("'children's", "movie'"), ("movie'", 'to'), ('to', 'simply'), ('simply', 'be'), ('be', 'one'), ('one', 'of'), ('of', 'the'), ('the', 'best'), ('best', 'movies'), ('movies', 'of'), ('of', 'the'), ('the', "90's,"), ("90's,", 'full-stop.')]
```

`ngrams`函数接受单词序列作为第一个参数，接受要分组的单词数作为第二个参数。下面的代码块显示了三元模型的外观，以及用于它的代码:

```py
print(list(ngrams(toy_story_review.split(),3)))
```

这会产生以下输出:

```py
[('Just', 'perfect.', 'Script,'), ('perfect.', 'Script,', 'character,'), ('Script,', 'character,', 'animation....this'), ('character,', 'animation....this', 'manages'), ('animation....this', 'manages', 'to'), ('manages', 'to', 'break'), ('to', 'break', 'free'), ('break', 'free', 'of'), ('free', 'of', 'the'), ('of', 'the', 'yoke'), ('the', 'yoke', 'of'), ('yoke', 'of', "'children's"), ('of', "'children's", "movie'"), ("'children's", "movie'", 'to'), ("movie'", 'to', 'simply'), ('to', 'simply', 'be'), ('simply', 'be', 'one'), ('be', 'one', 'of'), ('one', 'of', 'the'), ('of', 'the', 'best'), ('the', 'best', 'movies'), ('best', 'movies', 'of'), ('movies', 'of', 'the'), ('of', 'the', "90's,"), ('the', "90's,", 'full-stop.')]
```

前面代码中唯一改变的是函数的第二个参数 *n* 值。

许多有监督的机器学习模型，例如朴素贝叶斯，使用 n-grams 来改善它们的特征空间。n-gram 也用于拼写纠正和文本摘要任务。

n-gram 表示的一个挑战是它失去了文本的顺序性。它通常用于浅层机器学习模型。这种技术很少用于深度学习，因为 RNN 和 Conv1D 等架构会自动学习这些表示。



# …向量化…

将生成的标记映射到数字向量有两种流行的方法，称为一键编码和单词嵌入。让我们通过编写一个简单的 Python 程序来理解如何将令牌转换成这些向量表示。我们还将讨论每种方法的各种利弊。



# 一键编码

在独热编码中，每个令牌由长度为 *N* 的向量表示，其中 *N* 是词汇表的大小。词汇表是文档中唯一单词的总数。让我们用一个简单的句子来观察每个记号是如何被表示为一个热编码向量的。下面是句子及其相关的标记表示:

医生说，一天一个苹果，医生远离我。

前面句子的独热编码可以用如下表格格式表示:

| 一；一个 | One hundred million |
| 苹果 | Ten million |
| a | One million |
| 天 | One hundred thousand |
| 保持 | ten thousand |
| 医生 | One thousand |
| 离开 | One hundred |
| 说 | Ten |
| 这 | one |

下表描述了令牌及其独热编码表示。向量长度是 9，因为句子中有 9 个唯一的单词。许多机器学习库简化了创建一次性编码变量的过程。为了更容易理解，我们将编写自己的实现，并且我们可以使用相同的实现来构建后面的示例所需的其他特性。下面的代码包含一个`Dictionary`类，该类包含创建唯一单词字典的功能，以及返回特定单词的一键编码向量的功能。让我们看一下代码，然后浏览一下每个功能:

```py
class Dictionary(object): 
    def init (self):
        self.word2index = {} 
        self.index2word = [] 
        self.length = 0

    def add_word(self,word):
        if word not in self.index2word: 
            self.indexword.append(word) 
            self.word2index[word] = self.length + 1 
            self.length += 1
        return self.word2index[word] 

    def len (self):
        return len(self.index2word) 

    def onehot_encoded(self,word):
        vec = np.zeros(self.length)
        vec[self.word2index[word]] = 1 
        return vec
```

前面的代码提供了三个重要的功能:

*   初始化函数`init`创建了一个`word2index`字典，它将存储所有唯一的单词和索引。`index2word`列表存储所有唯一的单词，而`length`变量包含文档中唯一单词的总数。
*   `add_word`函数获取一个单词并将其添加到`word2index`和`index2word`中，并增加词汇表的长度，前提是该单词是唯一的。
*   `onehot_encoded`函数获取一个单词，并返回一个长度为 *N* 的向量，除了单词的索引处，其他地方都是零。如果传递的字的索引是 2，那么索引 2 处的向量的值将是 1，所有剩余的值将是 0。

因为我们已经定义了我们的`Dictionary`类，所以让我们在我们的`toy_story_review`数据上使用它。下面的代码演示了如何构建`word2index`字典，以及如何调用我们的`onehot_encoded`函数:

```py
dic = Dictionary()

for tok in toy_story_review.split(): dic.add_word(tok)
print(dic.word2index)
```

一键表示的挑战之一是数据过于稀疏，并且随着词汇表中唯一单词数量的增加，向量的大小会快速增长。另一个限制是，one-hot 没有表示单词之间的内部关系。由于这些原因，one-hot 很少与深度学习一起使用。



# 单词嵌入

在深度学习算法解决的问题中，单词嵌入是一种非常流行的表示文本数据的方式。单词嵌入提供了用浮点数填充的单词的密集表示。向量的维数根据词汇量的大小而变化。通常使用尺寸大小为 50、100、256、300 以及有时 1000 的字嵌入。维度大小是一个超参数，我们需要在训练阶段使用它。

如果我们试图用一键表示法来表示 20，000 个词汇，那么我们将得到 20，000 x 20，000 个数字，其中大部分为零。相同的词汇表可以在单词嵌入中表示为 20，000×维度大小，其中维度大小可以是 10、50、300 等等。

创建单词嵌入的一种方式是从包含随机数的每个标记的密集向量开始，然后训练用于情感分类的模型，例如文档分类器。表示标记的浮点数将以这样的方式进行调整，即语义上更接近的单词将具有相似的表示。为了理解它，让我们看下图，其中我们在五部电影的二维图上绘制了单词嵌入向量:

![](img/cd68a722-b8a3-4dfb-bd5e-d753a5d2c3e4.png)

上图显示了如何调整密集向量，以使语义相似的单词具有较小的距离。由于电影名称如*海底总动员*、*玩具总动员*和*超人特攻队*都是带有卡通的虚构电影，因此这些词的嵌入更为紧密。另一方面，电影*泰坦尼克号*的嵌入远离漫画，更接近电影名称*笔记本*，因为它们是浪漫电影。

当数据太少时，学习单词嵌入可能不可行，在这些情况下，我们可以使用由其他机器学习算法训练的单词嵌入。从另一个任务生成的嵌入称为预训练单词嵌入。我们将学习如何构建我们自己的单词嵌入和使用预训练的单词嵌入。



# 通过建立情感分类器训练单词嵌入

在上一节中，我们简要地了解了没有实现的单词嵌入。在本节中，我们将下载一个名为 IMDb 的数据集，其中包含评论，并构建一个情感分类器来计算评论的情感是积极、消极还是未知。在构建过程中，我们还将为 IMDb 数据集中的单词训练单词嵌入。

我们将使用一个名为`torchtext`的库，它使下载、文本矢量化和批处理等许多过程变得更加容易。训练情感分类器将包括以下步骤:

1.  下载 IMDb 数据并执行文本分词
2.  积累词汇
3.  生成成批的矢量
4.  创建具有嵌入的网络模型
5.  训练模型

我们将在接下来的章节中更详细地了解这些步骤。



# 下载 IMDb 数据并执行文本分词

对于与计算机视觉相关的应用，我们使用了`torchvision`库，它为我们提供了很多实用函数，有助于构建计算机视觉应用。同样，有一个名为`torchtext`的库，它是为 PyTorch 而构建的，通过为文本提供不同的数据加载器和抽象，简化了许多与**自然语言处理** ( **NLP** )相关的活动。在撰写本文时，`torchtext`没有附带标准 PyTorch 安装，需要单独安装。您可以在机器的命令行中运行以下代码来安装`torchtext`:

```py
pip install torchtext
```

一旦安装完毕，我们就可以使用它了。`torchtext`下载提供了两个重要的模块，分别叫做`torchtext.data`和`torchtext.datasets`。

我们可以从以下链接下载 IMDb 电影数据集:
[【https://grouplens.org/datasets/movielens/】](https://grouplens.org/datasets/movielens/)。



# 使用 torchtext.data 进行标记

`torchtext.data`实例定义了一个`Field`类，它帮助我们定义如何读取和标记数据。让我们看看下面的例子，我们将使用它来准备我们的 IMDb 数据集:

```py
from torchtext import data
text = data.Field(lower=True, batch_first=True,fix_length=20) 
label = data.Field(sequential=False)
```

在前面的代码中，我们定义了两个`Field`对象，一个用于实际文本，另一个用于标签数据。对于实际的文本，我们期望`torchtext`将所有文本小写，标记文本，并将其修剪到最大长度 20。如果我们为生产环境构建一个应用程序，我们可以将长度固定为一个更大的数字。然而，对于玩具示例，这种方式效果很好。`Field`构造函数还接受另一个名为`tokenize`的参数，该参数默认使用`str.split`函数。我们还可以指定`spaCy`作为参数，或者任何其他标记符。对于我们的例子，我们将坚持使用`str.split`。



# 使用 torchtext.datasets 进行分词

`torchtext.datasets`实例提供了使用不同数据集的包装器，比如 IMDb、TREC(问题分类)、语言建模(WikiText-2)和其他一些数据集。我们将使用`torch.datasets`下载 IMDb 数据集，并将其分成训练和测试数据集。以下代码执行此操作，首次运行时，它可能需要几分钟时间(取决于您的宽带连接)才能从互联网下载 IMDb 数据集:

```py
train, test = datasets.IMDB.splits(text, label)
```

前面的 dataset 的`IMDB`类抽象出了下载、标记和将数据库分成训练和测试数据集所涉及的所有复杂性。`train.fields`下载包含一个字典，其中`TEXT`是键，`LABEL`是值。让我们看看`train.fields`和`train`的每一个元素包含了什么:

```py
print('train.fields', train.fields)
```

这会产生以下输出:

```py
#Results
train.fields {'text': <torchtext.data.field.Field object at 0x1129db160>, 'label': <torchtext.data.field.Field object at 0x1129db1d0>}
```

类似地，训练数据集的方差如下:

```py
print(vars(train[0]))
```

这会产生以下输出:

```py
#Results
vars(train[0]) {'text': ['for', 'a', 'movie', 'that', 'gets', 'no', 'respect', 'there', 'sure', 'are', 'a', 'lot', 'of', 'memorable', 'quotes', 'listed', 'for', 'this', 'gem.', 'imagine', 'a', 'movie', 'where', 'joe', 'piscopo', 'is', 'actually', 'funny!', 'maureen', 'stapleton', 'is', 'a', 'scene', 'stealer.', 'the', 'moroni', 'character', 'is', 'an', 'absolute', 'scream.', 'watch', 'for', 'alan', '"the', 'skipper"', 'hale', 'jr.', 'as', 'a', 'police', 'sgt.'], 'label': 'pos'}
```

从这些结果中我们可以看到，单个元素包含一个字段和文本，以及表示文本的所有标记，还有一个包含文本标签的`label`字段。现在，我们已经为批处理准备好了 IMDb 数据集。



# 构建词汇

当我们为`toy_story_review`创建一次性编码时，我们创建了一个`word2index`字典，它被称为词汇表，因为它包含了文档中唯一单词的所有细节。`torchtext`的例子让我们更容易做到这一点。一旦加载了数据，我们就可以调用`build_vocab`并传递必要的参数来为数据构建词汇表。以下代码显示了词汇表是如何构建的:

```py
text.build_vocab(train, vectors=GloVe(name='6B', dim=300),max_size=10000,min_freq=10)
label.build_vocab(train)
```

在前面的代码中，我们传入了需要在其上构建词汇表的`train`对象，我们还要求它使用预训练的维度嵌入`300`来初始化向量。`build_vocab`对象只是下载并创建维度，稍后当我们使用预先训练的权重训练情感分类器时将会用到这个维度。`max_size`实例限制词汇表中的单词数量，`min_freq`删除任何没有出现超过 10 次的单词，其中`10`是可配置的。

一旦构建了词汇表，我们就可以获得不同的值，比如频率、单词索引和每个单词的向量表示。下面的代码演示了如何访问这些值:

```py
print(text.vocab.freqs)
```

这会产生以下输出:

```py
# A sample result 
Counter({"i'm": 4174,
         'not': 28597,
         'tired': 328,
         'to': 133967,
         'say': 4392,
         'this': 69714,
         'is': 104171,
         'one': 22480,
         'of': 144462,
         'the': 322198,
```

以下代码演示了如何访问结果:

```py
print(text.vocab.vectors)
```

这会产生以下输出:

```py
#Results displaying the 300 dimension vector for each word.
0.0000 0.0000 0.0000 ... 0.0000 0.0000 0.0000
0.0000 0.0000 0.0000 ... 0.0000 0.0000 0.0000
0.0466 0.2132 -0.0074 ... 0.0091 -0.2099 0.0539
 ... ... ... 
0.0000 0.0000 0.0000 ... 0.0000 0.0000 0.0000
0.7724 -0.1800 0.2072 ... 0.6736 0.2263 -0.2919
0.0000 0.0000 0.0000 ... 0.0000 0.0000 0.0000
[torch.FloatTensor of size 10002x300]
```

类似地，我们将打印包含单词及其索引的字典的值，如下所示:

```py
print(TEXT.vocab.stoi)
```

这会产生以下输出:

```py
# Sample results
defaultdict(<function torchtext.vocab._default_unk_index>,
 {'<unk>': 0,
 '<pad>': 1,
 'the': 2,
 'a': 3,
 'and': 4,
 'of': 5,
 'to': 6,
 'is': 7,
 'in': 8,
 'i': 9,
 'this': 10,
 'that': 11,
 'it': 12,
```

`stoi`值提供了对包含单词及其索引的字典的访问。



# 生成成批的矢量

`torchtext`下载提供了`BucketIterator`，它有助于对所有文本进行批处理，并用单词的索引号替换单词。`BucketIterator`实例带有很多有用的参数，比如`batch_size`、`device` (GPU 或 CPU)和`shuffle`(数据是否需要被打乱)。下面的代码演示如何创建迭代器，这些迭代器为定型数据集和测试数据集生成批处理:

```py
train_iter, test_iter = data.BucketIterator.splits((train, test), batch_size=128, device=-1,shuffle=True)
#device = -1 represents cpu , if you want gpu leave it to None.
```

前面的代码为训练和测试数据集提供了一个`BucketIterator`对象。以下代码显示了如何创建批处理并显示批处理的结果:

```py
batch = next(iter(train_iter)) batch.text
```

这会产生以下输出:

```py
#Results
Variable containing:
 5128 427 19 ... 1688 0 542
 58 2 0 ... 2 0 1352
 0 9 14 ... 2676 96 9
 ... ... ... 
 129 1181 648 ... 45 0 2
 6484 0 627 ... 381 5 2
 748 0 5052 ... 18 6660 9827
[torch.LongTensor of size 128x20]
```

我们将按如下方式打印标签:

```py
batch.label
```

这会产生以下输出:

```py
#Results
Variable containing:
 2
 1
 2
 1
 2
 1
 1
 1
[torch.LongTensor of size 128]
```

从前面代码块的结果中，我们可以看到文本数据是如何转换成大小为`(batch_size` * `fix_len`)的矩阵的，即(128 x 20)。



# 使用嵌入创建网络模型

我们之前简要讨论了单词嵌入。在本节中，我们创建单词嵌入作为我们网络架构的一部分，并训练整个模型来预测每个评论的情感。在训练结束时，我们将有一个情感分类器模型，以及 IMDB 数据集的单词嵌入。下面的代码演示了如何创建一个网络架构来使用单词嵌入来预测情感:

```py
class EmbeddingNetwork(nn.Module):
    def init(self,emb_size,hidden_size1,hidden_size2=400): 
        super().  init ()
        self.embedding = nn.Embedding(emb_size,hidden_size1) 
        self.fc = nn.Linear(hidden_size2,3)
    def forward(self,x):
        embeds = self.embedding(x).view(x.size(0),-1) 
        out = self.fc(embeds)
        return F.log_softmax(out,dim=-1)
```

在前面的代码中，`EmbeddingNetwork`创建了用于情感分类的模型。在`_init_`函数中，我们初始化了一个`nn.Embedding`类的对象，它有两个参数，即词汇表的大小和我们希望为每个单词创建的维度。因为我们已经限制了唯一单词的数量，所以词汇大小将是 10，000，并且我们可以从 10 的小嵌入大小开始。为了快速运行程序，较小的嵌入大小是有用的，但是当您试图为生产系统构建应用程序时，请使用较大的嵌入大小。我们还有一个线性层，将单词嵌入映射到类别(正面、负面或未知)。

forward 函数确定如何处理输入数据。对于 32 个批量和最大长度为 20 个单词的句子，我们将输入 32 x 20 的形状。第一个嵌入层充当查找表，用相应的嵌入向量替换每个单词。对于 10 的嵌入维数，当每个单词被其对应的嵌入替换时，输出变成 32 x 20 x 10。`view()`函数将展平来自嵌入层的结果。传递给视图的第一个参数将保持该维度不变。

在我们的例子中，我们不想合并来自不同批次的数据，所以我们保留第一维，并展平张量中的其余值。应用`view()`功能后，张量形状变为 32 x 200。密集层将扁平化嵌入映射到类别的数量。一旦定义了网络，我们就可以像往常一样训练网络。

请记住，在这个网络中，我们失去了文本的连续性，我们只是把文本当作一个单词包。



# 训练模型

训练模型与我们看到的构建图像分类器非常相似，因此我们将使用相同的函数。我们通过模型传递批量数据，计算输出和损失，然后优化模型权重，包括嵌入权重。下面的代码可以做到这一点:

```py
def fit(epoch,model,data_loader,phase='training',volatile=False): 
    if phase == 'training':
        model.train()
    if phase == 'validation': 
        model.evaluation() 
volatile=True
running_loss = 0.0
running_correct = 0
```

现在我们迭代数据集:

```py
for batch_idx , batch in enumerate(data_loader):
    text, target = batch.text , batch.label 
    if is_cuda:
        text,target = text.cuda(),target.cuda() 
    if phase == 'training':
        optimizer.zero_grad() 
        output = model(text)
    loss = F.nll_loss(output,target) 
    running_loss += F.nll_loss(output,target,size_average=False).data[0] 
    predictions = output.data.max(dim=1,keepdim=True)[1]
    running_correct += predictions.eq(target.data.view_as(predictions)).cpu().sum() 
    if phase == 'training':
        loss.backward() 
        optimizer.step()
        loss = running_loss/len(data_loader.dataset)
        accuracy = 100\. * running_correct/len(data_loader.dataset) 
        print(f'{phase} loss is {loss:{5}.{2}} and {phase} accuracy is {running_correct}/{len(data_loader.dataset)}{accuracy:{10}.{4}}').format(loss,accuracy)
```

从这里，我们可以在每个时期训练模型:

```py
train_losses , train_accuracy = [],[] 
validation_losses , validation_accuracy = [],[]

train_iter.repeat = False
test_iter.repeat = False
for epoch in range(1,10): 
    epoch_loss, epoch_accuracy = fit(epoch,model,train_iter,phase='training')
    validation_epoch_loss, validation_epoch_accuracy = fit(epoch,model,test_iter,phase='validation')
    train_losses.append(epoch_loss) 
    train_accuracy.append(epoch_accuracy) 
    validation_losses.append(validation_epoch_loss) 
    validation_accuracy.append(validation_epoch_accuracy)
```

在前面的代码中，我们通过传递为批处理数据而创建的`BucketIterator`对象来调用`fit`方法。默认情况下，迭代器不会停止生成批处理，所以我们必须将`BucketIterator`对象的重复变量设置为`False`。如果我们不将重复变量设置为`False`，那么`fit`功能将无限期运行。训练该模型大约 10 个时期给出了大约 70%的验证准确度。既然您已经学习了如何通过构建情感分类器来训练单词嵌入，那么让我们在下一节学习如何使用预训练的单词嵌入。



# 使用预训练的单词嵌入

当我们在特定领域工作时，预训练的单词嵌入是有用的，例如在医学和制造业中，我们有大量的数据来训练嵌入。当我们只有很少的数据，并且我们不能有意义地训练嵌入时，我们可以使用在不同的数据语料库上训练的嵌入，例如维基百科、谷歌新闻和 Twitter tweets。许多团队使用不同的方法训练开源单词嵌入。在这一节中，我们将探索`torchtext`如何使使用不同的单词嵌入变得更容易，以及如何在我们的 PyTorch 模型中使用它们。它类似于我们在计算机视觉应用中使用的迁移学习。通常，使用预训练嵌入会涉及以下步骤:

1.  下载嵌入
2.  在模型中加载嵌入
3.  冻结嵌入层权重

让我们详细探讨一下每一步是如何实现的。



# 下载嵌入

`torchtext`库抽象出了下载嵌入并将它们映射到正确单词的大量复杂性。`torchtext`库在`vocab`模块中提供了三个类，即 GloVe、FastText、CharNGram，这简化了下载嵌入并将它们映射到我们的词汇表的过程。这些类中的每一个都提供了在不同数据集上训练的不同嵌入，并使用不同的技术。让我们看看提供的一些不同的嵌入:

*   `charngram.100d`
*   `fasttext.en.300d`
*   `fasttext.simple.300d`
*   `glove.42B.300d`
*   `glove.840B.300d`
*   `glove.twitter.27B.25d`
*   `glove.twitter.27B.50d`
*   `glove.twitter.27B.100d`
*   ``glove.twitter.27B.200d``
*   `glove.6B.50d`

*   `glove.6B.100d`
*   `glove.6B.200d`
*   `glove.6B.300d`

`Field`对象的`build_vocab`方法接受嵌入的一个参数。下面的代码解释了我们如何下载嵌入:

```py
from torchtext.vocab import GloVe 
TEXT.build_vocab(train, vectors=GloVe(name='6B', dim=300),max_size=10000,min_freq=10) 
LABEL.build_vocab(train,)
```

参数向量的值表示要使用什么嵌入类。`name`和`dim`参数决定了可以使用哪些嵌入。我们可以很容易地从`vocab`对象中访问嵌入。下面的代码演示了它，并展示了结果的外观:

```py
TEXT.vocab.vectors
```

这会产生以下输出:

```py
#Output
0.0000 0.0000 0.0000 ... 0.0000 0.0000 0.0000
0.0000 0.0000 0.0000 ... 0.0000 0.0000 0.0000
0.0466 0.2132 -0.0074 ... 0.0091 -0.2099 0.0539
... ...  ...

[torch.FloatTensor of size 10002x300]
```

现在我们已经下载并映射了嵌入到我们的词汇表中。让我们了解如何在 PyTorch 模型中使用它们。



# 在模型中加载嵌入

`vectors`变量返回形状为`vocab_size` x `dimensions`的 torch 张量，包含预训练的嵌入。我们必须存储嵌入到我们的嵌入层的权重中。我们可以通过访问嵌入层的权重来分配嵌入的权重，如以下代码所示:

```py
model.embedding.weight.data = TEXT.vocab.vectors
```

`model`下载代表我们网络的对象，`embedding`代表嵌入层。当我们使用新维度的嵌入层时，嵌入层之后的线性层的输入会有一个小的变化。下面的代码采用了新的架构，它类似于之前我们用来训练嵌入的架构:

```py
class EmbeddingNetwork(nn.Module):
def   init (self,embedding_size,hidden_size1,hidden_size2=400): super().  init ()
self.embedding = nn.Embedding(embedding_size,hidden_size1) self.fc1 = nn.Linear(hidden_size2,3)

def forward(self,x):
embeds = self.embedding(x).view(x.size(0),-1) out = self.fc1(embeddings)
return F.log_softmax(out,dim=-1)

model = EmbeddingNetwork(len(TEXT.vocab.stoi),300,12000)
```

一旦嵌入被加载，我们必须确保，在训练期间，我们不改变嵌入权重。让我们讨论如何实现这一点。



# 冻结嵌入层权重

告诉 PyTorch 不要更改嵌入层的权重是一个两步过程:

1.  将`requires_grad`属性设置为`False`，这指示 PyTorch 对于这些权重不需要渐变。
2.  删除向优化器传递嵌入层参数。如果没有完成这一步，那么优化器将抛出一个错误，因为它期望所有的参数都有梯度。

以下代码演示了冻结嵌入层权重并指示优化器不要使用这些参数是多么容易:

```py
model.embedding.weight.requires_grad = False
optimizer = optim.SGD([ param for param in model.parameters() if param.requires_grad == True],lr=0.001)
```

我们通常将所有的模型参数传递给优化器，但是在前面的代码中，我们传递了将`requires_grad`作为`True`的参数。

我们可以使用这种精确的代码来训练模型，并且应该达到类似的精度。所有这些模型架构都未能利用文本的顺序性质。在下一节中，我们将探讨两种流行的技术，即 RNN 和 Conv1D，它们利用了数据的顺序性。



# 循环神经网络

rnn 是最强大的模型之一，它使我们能够进行分类、标记序列数据、生成文本序列(如使用 SwiftKey 键盘应用程序，它可以预测下一个单词)，以及将一个序列转换为另一个序列，如翻译语言时(例如，从法语到英语)。大多数模型结构，如前馈神经网络，没有利用数据的顺序性质。例如，我们需要数据来表示向量中每个示例的特征，比如表示一个句子、段落或文档的所有标记。前馈网络被设计成只查看所有特征一次，并将它们映射到输出。让我们来看一个文本示例，它展示了为什么文本的顺序或序列性质是重要的。我清洗了我的车和*我清洗了我的车*是两个相同词组的英语句子，但是当我们考虑单词的顺序时，它们的意思是不同的。

在大多数现代语言中，人类通过从左到右阅读单词来理解文本数据，并建立一个强大的模型，该模型可以理解文本中所说的所有不同内容。RNN 的工作方式与此类似，一次只看文本中的一个单词。RNN 也是一个神经网络，其中有一个特殊的层，它循环数据，而不是一次处理所有数据。由于 rnn 可以按顺序处理数据，我们可以使用不同长度的向量，并生成不同长度的输出。下图提供了一些不同的表示法:

![](img/b5536b92-c0fc-446f-bdbc-b1e77ee93f23.jpeg)

前面的图表来自 rnn 上的一个著名博客([http://kar pathy . github . io/2015/05/21/rnn-effectiveness](http://karpathy.github.io/2015/05/21/rnn-effectiveness))，作者 Andrej Karpathy 在其中写了如何使用 Python 从头构建一个 RNN，并将其用作序列生成器。



# 用一个例子理解 RNN 是如何工作的

让我们从假设我们已经建立了一个 RNN 模型开始，让我们试着理解它提供了什么功能。一旦我们理解了 RNN 的功能，接下来让我们探索一下 RNN 内部发生了什么。

让我们把《玩具总动员》的评论看作是 RNN 模型的输入。我们正在看的例子文本是*刚刚好。剧本、角色、动画....它设法挣脱了....*。我们首先将第一个字*传递给我们的模型，模型生成两个不同的东西:一个**状态向量**和一个**输出**向量。当模型处理评论中的下一个单词时，**状态向量**被传递给模型，并且生成新的**状态向量**。我们只考虑在最后一个序列中生成的模型的**输出**。下图对此进行了总结:*

![](img/7f19b5d5-4e41-410e-bf89-0d4057d2b74c.png)

上图演示了以下内容:

*   RNN 是如何展开文本输入和图像的
*   状态如何递归地传递给同一个模型

到现在为止，你应该知道 RNN 是做什么的，但不知道它是如何工作的。在我们深入了解它的工作原理之前，让我们先来看一个代码片段，它更详细地展示了我们所学到的东西。我们仍将把 RNN 视为一个黑盒子:

```py
rnn = RNN(input_size, hidden_size,output_size) 
for i in range(len(toy_story_review):
        output, hidden = rnn(toy_story_review[i], hidden)
```

在前面的代码中，`hidden`变量代表状态向量，有时称为**隐藏状态**。到目前为止，我们应该对如何使用 RNN 有所了解。现在，让我们看看实现 RNN 的代码，了解 RNN 内部发生了什么。下面的代码包含了`RNN`类:

```py
import torch.nn as nn
from torch.autograd import Variable

class RNN(nn.Module):
    def   init (self, input_size, hidden_size, output_size): 
        super(RNN, self). init ()
        self.hidden_size = hidden_size
        self.i2h = nn.Linear(input_size + hidden_size, hidden_size) 
        self.i2o = nn.Linear(input_size + hidden_size, output_size) 
        self.softmax = nn.LogSoftmax(dim=1)

    def forward(self, input, hidden):
        combined = torch.cat((input, hidden), 1) 
        hidden = self.i2h(combined)
        output = self.i2o(combined)
        output = self.softmax(output) 
        return output, hidden

    def initHidden(self):
        return Variable(torch.zeros(1, self.hidden_size))
```

除了前面代码中的单词 RNN，其他的听起来都和我们在前面章节中使用的非常相似，因为 PyTorch 隐藏了大量复杂的反向传播。让我们通过`__init__`函数和`forward`函数来理解发生了什么。

`__init__`函数初始化两个线性层，一个用于计算输出，另一个用于计算状态或隐藏向量。

`forward`函数将输入向量和隐藏向量结合起来，通过两个线性层，生成一个输出向量和一个隐藏状态。对于输出层，我们应用了一个`log_softmax`函数。

`initHidden`函数帮助创建隐藏向量，没有第一次调用 RNN 的状态。让我们在下图中直观地看一下 RNN 类的作用:

![](img/488bd1e1-0128-4c9d-8375-0ca89bb15457.png)

上图显示了 RNN 的工作原理。

当你第一次遇到 RNN 的概念时，有时很难理解，所以我强烈推荐以下链接中提供的一些令人惊叹的博客:[http://karpathy.github.io/2015/05/21/rnn-effectiveness/](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)和[http://colah.github.io/posts/2015-08-Understanding-LSTMs/.](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)

在下一节中，我们将学习如何使用一个叫做 LSTM 的 RNN 的变体在 IMDB 数据集上构建一个情感分类器。



# 利用 LSTM 解决文本分类问题

rnn 在构建真实世界的应用程序中非常流行，例如语言翻译、文本分类和许多其他的顺序问题。然而，在现实中，我们很少使用 RNN 的普通版本，就像我们在上一节看到的那样。香草版本的 RNN 有问题，如消失梯度和梯度爆炸时，处理大序列。在大多数现实世界的问题中，使用 RNN 的变体，如 LSTM 或 GRU，它们解决了普通 RNN 的局限性，并且还具有更好地处理序列数据的能力。我们将试图了解在 LSTM 发生的事情，并建立一个基于 LSTM 的网络来解决 IMDB 数据集上的文本分类问题。



# 长期依赖

理论上，rnn 应该从历史数据中学习所有需要的相关性，以构建接下来发生的事情的上下文。比方说，我们正试图预测句子*中的最后一个单词:云在天上*。RNN 将能够预测它，因为信息(云)就在后面几个字。让我们来看另一个长段落，其中的依赖关系不需要那么紧密，我们希望预测其中的最后一个单词。句子是:*我出生在金奈，泰米尔纳德邦的一个城市。我和印度不同邦的学校教育...实际上，香草版的《RNN》很难记住发生在故事前几部分的背景。LSTMs 和 RNN 的其他不同变体通过在 LSTM 内部添加不同的神经网络来解决这个问题，这些神经网络后来决定可以记住多少或哪些数据。*



# LSTM 网络公司

LSTMs 是一种特殊的 RNN，能够学习长期依赖性。它们于 1997 年推出，并在最近几年随着可用数据和硬件的进步而流行起来。它们在各种各样的问题上表现得非常好，并且被广泛使用。

LSTMs 的设计是为了避免长期的依赖性问题，因为 LSTMs 的设计可以自然地长时间记忆信息。在 RNNs 中，我们看到它们如何在序列的每个元素上重复自己。在标准 RNNs 中，重复模块将具有像单个线性层一样的简单结构。

下图显示了一个简单的 RNN 是如何自我重复的:

![](img/c492b55a-f731-4b2e-a0a0-015848b3a8cb.png)

在 LSTM 内部，我们没有使用简单的线性层，而是在 LSTM 内部使用更小的网络，它们独立工作。下图展示了 LSTM 内部的情况:

![](img/5122dbe6-0dd9-4680-91a4-6d898baa8669.png)

图片来源:[http://colah.github.io/posts/2015-08-Understanding-LSTMs/](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)

上图第二个方框中的每个小矩形(黄色)方框表示 PyTorch 图层，圆圈表示元素矩阵或矢量加法，合并线表示两个矢量正在连接。好的一面是，我们不需要手动实现所有这些。大多数现代深度学习框架提供了一种抽象，可以处理 LSTM 内部发生的事情。PyTorch 提供了对`nn.LSTM`层中所有功能的抽象，我们可以像使用其他层一样使用它。

LSTM 中最重要的事情是通过所有迭代的单元状态，在上图中由穿过单元的水平线表示。LSTM 内部的多个网络控制着细胞状态间的信息传递。LSTM(一个由符号σ表示的小网络)的第一步是决定什么信息将从细胞状态中被丢弃。这个网络被称为**遗忘门**，并且具有作为激活函数的 sigmoid，其为单元状态中的每个元素输出 0 和 1 之间的值。网络(PyTorch 层)使用以下公式表示:

![](img/39818084-8346-4d7a-8d4a-0eb898c16dd5.png)

来自网络的值决定哪些值将被保存在单元状态中，哪些值将被丢弃。下一步是决定我们将向单元状态添加什么信息。这有两个部分:一个称为输入门的 sigmoid 层，它决定要更新什么值，还有一个 *tanh* 层，它创建要添加到单元状态的新值。数学表示看起来像这样:

![](img/70fea098-0372-4393-a059-4c4b8a510564.png)

下一步，我们合并输入门和 *tanh* 产生的两个值。现在，我们可以通过在遗忘门和它与 *Ct* 的乘积之和之间进行逐元素乘法来更新单元状态，如下式所示:

![](img/8e447e5e-118b-4001-9a99-d5140f016bdb.png)

最后，我们需要决定输出，这将是单元状态的过滤版本。有不同版本的 LSTM 可用，其中大多数工作原理相似。作为开发人员或数据科学家，我们很少需要担心 LSTM 内部发生的事情。

如果你想了解更多，可以浏览下面的博客链接，它们以非常直观的方式涵盖了很多理论。

看看克里斯多佛·奥拉关于 LSTM 的令人惊叹的博客([http://colah.github.io/posts/2015- 08-理解-LSTMs](http://colah.github.io/posts/2015-08-Understanding-LSTMs) )，以及布兰登·罗尔([https://brohrer.github.io/how_rnns_lstm_work.html](https://brohrer.github.io/how_rnns_lstm_work.html))的另一个博客，在那里他用一段很棒的视频解释了 LSTM。

既然我们了解了 LSTM，让我们实现一个 PyTorch 网络，我们可以用它来建立一个情感分类器。像往常一样，我们将遵循以下步骤来创建分类器:

1.  准备数据
2.  创建批处理
3.  创建网络
4.  训练模型

我们将在下一节中详细了解这些步骤。



# 准备数据

我们使用相同的`torchtext`库来下载、标记和构建 IMDB 数据集的词汇表。当创建`Field`对象时，我们将`batch_first`参数留在`False`。rnn 期望数据采用`sequence_length`、`batch_size`和`features.`的形式。以下用于准备数据集:

```py
TEXT = data.Field(lower=True,fix_length=200,batch_first=False) 
LABEL = data.Field(sequential=False,)
train, test = IMDB.splits(TEXT, LABEL) 
TEXT.build_vocab(train, vectors=GloVe(name='6B', dim=300),max_size=10000,min_freq=10) 
LABEL.build_vocab(train,)
```



# 创建批次

我们使用`torchtext BucketIterator`函数来创建批次，批次的大小将是序列长度和批次。对于我们的例子，大小将是[200，32]，其中 200 是序列长度，32 是批量大小。

以下是用于批处理的代码:

```py
train_iter, test_iter = data.BucketIterator.splits((train, test), batch_size=32, device=-1) 
train_iter.repeat = False 
test_iter.repeat = False
```



# 创建网络

让我们先看看代码，然后再浏览一遍。您可能会惊讶于这些代码看起来是如此的熟悉:

```py
class IMDBRnn(nn.Module):

    def   init (self,vocab,hidden_size,n_cat,bs=1,nl=2): 
        super().  init ()
        self.hidden_size = hidden_size 
        self.bs = bs
        self.nl = nl
        self.e = nn.Embedding(n_vocab,hidden_size) 
        self.rnn = nn.LSTM(hidden_size,hidden_size,nl) 
       self.fc2 = nn.Linear(hidden_size,n_cat) 
        self.softmax = nn.LogSoftmax(dim=-1)

    def forward(self,inp): 
        bs = inp.size()[1] 
        if bs != self.bs:
            self.bs = bs 
        e_out = self.e(inp) 
        h0 = c0 = Variable(e_out.data.new(*(self.nl,self.bs,self.hidden_size)).zero_()) 
        rnn_o,_ = self.rnn(e_out,(h0,c0))
        rnn_o = rnn_o[-1]
        fc = F.dropout(self.fc2(rnn_o),p=0.8) 
        return self.softmax(fc)
```

`init`方法创建一个词汇表和`hidden_size`大小的嵌入层。它还创建了一个 LSTM 和一个线性层。最后一层是`LogSoftmax`层，用于将线性层的结果转换成概率。

在`forward`函数中，我们传递大小为[200，32]的输入数据，该数据通过嵌入层传递，批中的每个标记都被嵌入替换，大小变为[200，32，100]，其中 100 是嵌入维数。LSTM 层采用嵌入层的输出以及两个隐藏变量。隐藏变量应该与嵌入输出的类型相同，并且它们的大小应该为[ `num_layers`、`batch_size`、`hidden_size` ]。LSTM 按顺序处理数据，并生成形状[ `Sequence_length`、`batch_size`、`hidden_size` ]的输出，其中每个序列索引代表该序列的输出。在这种情况下，我们只需获取最后一个序列的输出，其形状为[ `batch_size`，`hidden_dim` ]，并将其传递到一个线性层，以将其映射到输出类别。由于模型往往过拟合，添加一个辍学层。你可以玩辍学概率。



# 训练模型

一旦创建了网络，我们就可以使用与前面示例中相同的代码来训练模型。下面是为模型定型的代码:

```py
model = IMDBRnn(n_vocab,n_hidden,3,bs=32) 
model = model.cuda()

optimizer = optim.Adam(model.parameters(),lr=1e-3)

def fit(epoch,model,data_loader,phase='training',volatile=False): 
    if phase == 'training':
        model.train()
    if phase == 'validation': 
        model.eval() 
        volatile=True
    running_loss = 0.0
    running_correct = 0
    for batch_idx , batch in enumerate(data_loader): 
        text , target = batch.text , batch.label
        if is_cuda:
            text,target = text.cuda(),target.cuda() 

        if phase == 'training':
            optimizer.zero_grad() 
        output = model(text)
        loss = F.nll_loss(output,target) 

        running_loss += F.nll_loss(output,target,size_average=False).data[0] 
        preds = output.data.max(dim=1,keepdim=True)[1]
        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum() 
        if phase == 'training':
            loss.backward() 
            optimizer.step()

    loss = running_loss/len(data_loader.dataset)
    accuracy = 100\. * running_correct/len(data_loader.dataset) 

    print(f'{phase} loss is {loss:{5}.{2}} and {phase} accuracy is {running_correct}/{len(data_loader.dataset)}{accuracy:{10}.{4}}')         return loss,accuracy

train_losses , train_accuracy = [],[]
validation_losses , validation_accuracy = [],[]

for epoch in range(1,5): 

    epoch_loss, epoch_accuracy =
fit(epoch,model,train_iter,phase='training')
    validation_epoch_loss , validation_epoch_accuracy =
fit(epoch,model,test_iter,phase='validation')
    train_losses.append(epoch_loss)
    train_accuracy.append(epoch_accuracy)
    validation_losses.append(validation_epoch_loss)
    validation_accuracy.append(validation_epoch_accuracy)
```

以下是培训模型的结果:

```py
training loss is 0.7 and training accuracy is 12564/25000 50.26
validation loss is 0.7 and validation accuracy is 12500/25000 50.0
training loss is 0.66 and training accuracy is 14931/25000 59.72
validation loss is 0.57 and validation accuracy is 17766/25000 71.06
training loss is 0.43 and training accuracy is 20229/25000 80.92
validation loss is 0.4 and validation accuracy is 20446/25000 81.78
training loss is 0.3 and training accuracy is 22026/25000 88.1
validation loss is 0.37 and validation accuracy is 21009/25000 84.04
```

训练四个时期的模型给出了 84%的准确度。随着损失开始增加，更多时期的训练导致模型过度拟合。我们可以尝试一些我们尝试过的技术，例如减少隐藏维度，增加序列长度，以及用较小的学习率进行训练，以进一步提高准确性。

我们还将探索如何使用一维卷积对序列数据进行训练。



# 序列数据上的卷积网络

我们在[第四章](bfebc11a-90af-4c67-ab9a-3118061abaf3.xhtml)、*计算机视觉深度学习*中学习了 CNN 如何通过从图像中学习特征来解决计算机视觉中的问题。在图像中，CNN 通过在高度和宽度上卷积来工作。同样，时间可以被视为卷积特征。一维卷积有时比 RNNs 性能更好，并且计算成本更低。在过去的几年里，像脸书这样的公司已经在音频生成和机器翻译方面取得了成功。在本节中，我们将学习如何使用 CNN 来构建文本分类解决方案。



# 理解序列数据的一维卷积

在[第四章](bfebc11a-90af-4c67-ab9a-3118061abaf3.xhtml)、*计算机视觉深度学习*中，我们已经看到了如何从训练数据中学习二维权重。这些权重在图像上移动以产生不同的激活。同样，在我们的文本分类器的训练期间学习一维卷积激活，其中这些权重通过在数据中移动来学习模式。下图解释了一维卷积的工作原理:

![](img/712620f7-e5b3-4826-b33e-8fce255942d6.png)

为了在 IMDB 数据集上训练文本分类器，我们将遵循与使用 LSTMs 构建分类器相同的步骤。唯一改变的是我们使用`batch_first =` `True`，不像我们的 LSTM 网络。所以，让我们看看网络，训练代码，和它的结果。



# 创建网络

让我们看看网络架构，然后浏览代码:

```py
class IMDBCnn(nn.Module): 

    def
__init__(self,vocab,hidden_size,n_cat,bs=1,kernel_size=3,max_len=200):         super().__init__()
        self.hidden_size = hidden_size 
        self.bs = bs
    self.e = nn.Embedding(n_vocab,hidden_size)
    self.cnn = nn.Conv1d(max_len,hidden_size,kernel_size) 
    self.avg = nn.AdaptiveAvgPool1d(10)
        self.fc = nn.Linear(1000,n_cat)
        self.softmax = nn.LogSoftmax(dim=-1) 

    def forward(self,inp):
        bs = inp.size()[0] 
        if bs != self.bs:
            self.bs = bs 
        e_out = self.e(inp)
        cnn_o = self.cnn(e_out) 
        cnn_avg = self.avg(cnn_o)
        cnn_avg = cnn_avg.view(self.bs,-1)
        fc = F.dropout(self.fc(cnn_avg),p=0.5) 
        return self.softmax(fc)
```

在前面的代码中，我们有一个`Conv1d`层和一个`AdaptiveAvgPool1d`层，而不是 LSTM 层。卷积层接受序列长度作为其输入大小，输出大小作为隐藏大小，内核大小作为 3。由于我们必须改变线性层的尺寸，每次我们试图用不同的长度运行它时，我们使用一个`AdaptiveAvgpool1d`层，它接受任意大小的输入并生成给定大小的输出。因此，我们可以使用一个大小固定的线性层。其余的代码与我们在大多数网络架构中看到的类似。



# 训练模型

该模型的训练步骤与前面的示例相同。让我们来看看调用`fit`方法的代码和它生成的结果:

```py
train_losses , train_accuracy = [],[] 
validation_losses , validation_accuracy = [],[]

for epoch in range(1,5): 

    epoch_loss, epoch_accuracy =
fit(epoch,model,train_iter,phase='training')
    validation_epoch_loss , validation_epoch_accuracy = fit(epoch,model,test_iter,phase='validation')
    train_losses.append(epoch_loss)
    train_accuracy.append(epoch_accuracy)
    validation_losses.append(validation_epoch_loss)
    validation_accuracy.append(validation_epoch_accuracy)
```

我们运行了四个时期的模型，给出了大约 83%的准确率。以下是运行模型的结果:

```py
training loss is 0.59 and training accuracy is 16724/25000 66.9
validation loss is 0.45 and validation accuracy is 19687/25000 78.75
training loss is 0.38 and training accuracy is 20876/25000 83.5
validation loss is 0.4 and validation accuracy is 20618/25000 82.47
training loss is 0.28 and training accuracy is 22109/25000 88.44
validation loss is 0.41 and validation accuracy is 20713/25000 82.85
training loss is 0.22 and training accuracy is 22820/25000 91.28
validation loss is 0.44 and validation accuracy is 20641/25000 82.56
```

由于验证损失在三个时期后开始增加，我停止运行模型。我们可以尝试改善结果的一些事情是使用预训练的权重，添加另一个卷积层，并尝试在卷积之间添加一个`MaxPool1d`层。我让您尝试一下，看看是否有助于提高精确度。现在，我们已经了解了处理序列数据的各种神经网络，让我们在下一节看看语言建模。



# 语言建模

语言建模的任务是根据前面的单词预测一段文本中的下一个单词。生成这种顺序数据的能力在许多不同的领域都有应用，例如:

*   图像字幕
*   语音识别
*   语言翻译
*   自动回复电子邮件
*   写故事、新闻文章、诗歌等等

这一领域的重点最初是由注册护士，特别是 LSTMs 掌握的。然而，在 2017 年引入 Transformer 架构([https://arxiv.org/pdf/1706.03762.pdf](https://arxiv.org/pdf/1706.03762.pdf))后，它在 NLP 任务中变得流行起来。自那以后，转换器出现了许多修改，其中一些我们将在本章中介绍。



# 预训练模型

最近，人们对使用预训练模型完成 NLP 任务产生了浓厚的兴趣。使用预训练语言模型的一个关键好处是，它们能够用少得多的数据进行学习。这些模型对于标记数据稀缺的语言特别有用，因为它们只需要标记数据。

序列学习的预训练模型最初是由戴(A. M. Dai)和乐(Q. V. Le)在 2015 年发表的一篇名为*半监督序列学习*(【http://arxiv.org/abs/1511.01432】)的论文中提出的。然而，直到最近，它们才被证明在广泛的任务中是有益的。我们现在将考虑近来该领域中一些最值得注意的进展，包括但绝不限于以下方面:

*   **来自语言模型的嵌入** ( **埃尔莫**)
*   **来自转换器** ( **伯特**)的双向编码器表示
*   **生成式预调理转换器 2** ( **GPT** - **2** )



# 来自语言模型的嵌入

2018 年 2 月，M. Peters 等人(【https://arxiv.org/abs/1802.05365】)的*深度语境化的文字表述*论文介绍了 ELMo。它基本上演示了语言模型嵌入可以用作目标模型中的功能，如下图所示:

![](img/03d95256-f743-459d-8efb-63b6e8df13b5.png)

ELMo 使用双向语言模型来学习单词和上下文。前向和后向传递的内部状态在每个字处被连接，以产生中间向量。正是这种模型的双向性质为它提供了关于句子中的下一个单词和它前面的单词的信息。



# 来自转换器的双向编码器表示

在谷歌 2018 年 11 月发表的一篇后来的论文([https://arxiv.org/pdf/1810.04805.pdf](https://arxiv.org/pdf/1810.04805.pdf))中，提出了来自转换器 ( **伯特**)的**双向编码器表示，其中包含了一种学习单词和文本之间上下文关系的注意机制:**

![](img/f0368534-50c8-4c93-b718-3080f02282c6.png)

ELMo 是按顺序(从左到右或从右到左)读取文本输入的，而 BERT 是一次读取整个单词序列。本质上，BERT 是一个经过训练的 transformer 编码器堆栈。



# 生成式预训练转换器 2

在撰写本文时，OpenAI 的 GTP-2 是最先进的语言模型之一，旨在提高生成文本的真实性和连贯性。在 2019 年 2 月的论文*中介绍了语言模型是无监督的多任务学习者*([https://d4mucfpksywv . cloudfront . net/better-Language-Models/Language _ Models _ are _ Unsupervised _ multask _ Learners . pdf](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf))。它被训练成用 15 亿个参数预测 800 万个网页(总共 40 GB 的文本)上的下一个单词，这是 BERT 的四倍。以下是 OpenAI 对 GPT 2 号的评价:

*GPT-2 g**enerates coherent paragraphs of text, achieves state-of-the-art* *performance on many language modeling benchmarks,* *and performs rudimentary reading comprehension, machine translation,* *question answering, and summarization—all without task-specific training.*

起初，OpenAI 表示他们不会发布数据集、代码或完整的 GPT-2 模型权重。这样做的原因是由于担心它们被用来大规模产生欺骗性的、有偏见的或侮辱性的语言。恶意应用这些模型的一些示例如下:

*   逼真的假新闻文章
*   逼真地在网上模仿他人
*   可能发布在社交媒体上的辱骂或伪造内容
*   自动化垃圾邮件或网络钓鱼内容的制作

然后，该团队决定分阶段发布该模型，以便给人们时间来评估社会影响，并评估每个阶段后发布的影响。



# PyTorch 实现

在 PyTorch 中实现了 BERT 和 GPT-2 的开发者拥抱脸有一个流行的 GitHub 库。可以在以下网址找到:[https://github.com/huggingface/pytorch-pretrained-BERT](https://github.com/huggingface/pytorch-pretrained-BERT)。该知识库于 2018 年 11 月首次推出，允许用户根据自己的数据生成句子。它还包括各种类，当应用于不同的任务时，可以用来测试不同的模型，如问题回答、标记分类和序列分类。

以下代码片段演示了如何使用 GitHub 资源库中的代码从 GPT-2 模型中生成文本。首先，我们导入相关的库并初始化预训练的信息，如下所示:

```py
import torch
from torch.nn import functional as F
from pytorch_pretrained_bert import GPT2Tokenizer, GPT2LMHeadModel

tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
gtp2model = GPT2LMHeadModel.from_pretrained('gpt2')
```

在这个例子中，我们给模型输入`'We like unicorns because they'`句子，它就这样生成单词:

```py
input_text = tokenizer.encode('We like unicorns because they')
input, past = torch.tensor([input_text]), None
for _ in range(25):
    logits, past = gtp2model(input, past=past)
    input = torch.multinomial(F.softmax(logits[:, -1]), 1)
    input_text.append(input.item())
```

以下是输出:

![](img/287e51be-3416-478c-91a1-83ef17291737.png)



# GPT 2 号游乐场

开发者 ilopezfr 还有一个有用的 GitHub 资源库，可以在下面的链接找到:[https://github.com/ilopezfr/gpt-2](https://github.com/ilopezfr/gpt-2)。它还在 Google Colab 中提供了一个笔记本，允许用户玩和实验 OpenAI GPT-2 模型([https://Colab . research . Google . com/github/ilopezfr/GPT-2/blob/master/GPT-2-playground _)。ipynb](https://colab.research.google.com/github/ilopezfr/gpt-2/blob/master/gpt-2-playground_.ipynb) )。

以下是操场不同区域的一些例子:

*   **正文完成**部分:

![](img/13cc1515-9720-464e-8a64-a3ad0d5a4a74.png)

*   **问答**部分:

![](img/b0350b09-fe81-4365-9650-abe2f0181f09.png)

*   **翻译**章节:

![](img/49c7641e-839d-4f53-8aef-8af2f70b7107.png)



# 摘要

在本章中，我们学习了在深度学习中表示文本数据的不同技术。我们学习了在不同领域工作时如何使用预训练的单词嵌入和我们自己训练的嵌入。我们使用 LSTMs 和一维卷积构建了一个文本分类器。我们还学习了如何使用最先进的语言建模架构生成文本。

在下一章中，我们将学习如何训练深度学习算法来生成时尚的图像和新图像，以及生成文本。